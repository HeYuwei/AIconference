{"0": {"title": "finding task-relevant features for few-shot learning by category traversal", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Finding_Task-Relevant_Features_for_Few-Shot_Learning_by_Category_Traversal_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1": {"title": "edge-labeling graph neural network for few-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Edge-Labeling_Graph_Neural_Network_for_Few-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "2": {"title": "generating classification weights with gnn denoising autoencoders for few-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gidaris_Generating_Classification_Weights_With_GNN_Denoising_Autoencoders_for_Few-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "3": {"title": "kervolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Kervolutional_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "4": {"title": "why relu networks yield high-confidence predictions far away from the training data and how to mitigate the problem", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hein_Why_ReLU_Networks_Yield_High-Confidence_Predictions_Far_Away_From_the_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "5": {"title": "on the structural sensitivity of deep convolutional networks to the directions of fourier basis functions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tsuzuku_On_the_Structural_Sensitivity_of_Deep_Convolutional_Networks_to_the_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "6": {"title": "neural rejuvenation: improving deep network training by enhancing computational resource utilization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qiao_Neural_Rejuvenation_Improving_Deep_Network_Training_by_Enhancing_Computational_Resource_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "7": {"title": "hardness-aware deep metric learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Hardness-Aware_Deep_Metric_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "8": {"title": "auto-deeplab: hierarchical neural architecture search for semantic image segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Auto-DeepLab_Hierarchical_Neural_Architecture_Search_for_Semantic_Image_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "9": {"title": "learning loss for active learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yoo_Learning_Loss_for_Active_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "10": {"title": "striking the right balance with uncertainty", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Khan_Striking_the_Right_Balance_With_Uncertainty_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "11": {"title": "autoaugment: learning augmentation strategies from data", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cubuk_AutoAugment_Learning_Augmentation_Strategies_From_Data_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "12": {"title": "sdrsac: semidefinite-based randomized approach for robust point cloud registration without correspondences", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Le_SDRSAC_Semidefinite-Based_Randomized_Approach_for_Robust_Point_Cloud_Registration_Without_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "13": {"title": "bad slam: bundle adjusted direct rgb-d slam", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Schops_BAD_SLAM_Bundle_Adjusted_Direct_RGB-D_SLAM_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "14": {"title": "revealing scenes by inverting structure from motion reconstructions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pittaluga_Revealing_Scenes_by_Inverting_Structure_From_Motion_Reconstructions_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "15": {"title": "strand-accurate multi-view hair capture", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Nam_Strand-Accurate_Multi-View_Hair_Capture_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "16": {"title": "deepsdf: learning continuous signed distance functions for shape representation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "17": {"title": "pushing the boundaries of view extrapolation with multiplane images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Srinivasan_Pushing_the_Boundaries_of_View_Extrapolation_With_Multiplane_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "18": {"title": "ga-net: guided aggregation net for end-to-end stereo matching", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_GA-Net_Guided_Aggregation_Net_for_End-To-End_Stereo_Matching_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "19": {"title": "real-time self-adaptive deep stereo", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tonioni_Real-Time_Self-Adaptive_Deep_Stereo_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "20": {"title": "laf-net: locally adaptive fusion networks for stereo confidence estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_LAF-Net_Locally_Adaptive_Fusion_Networks_for_Stereo_Confidence_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "21": {"title": "nm-net: mining reliable neighbors for robust feature correspondences", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_NM-Net_Mining_Reliable_Neighbors_for_Robust_Feature_Correspondences_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "22": {"title": "coordinate-free carlsson-weinshall duality and relative multi-view geometry", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Trager_Coordinate-Free_Carlsson-Weinshall_Duality_and_Relative_Multi-View_Geometry_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "23": {"title": "deep reinforcement learning of volume-guided progressive view inpainting for 3d point scene completion from a single depth image", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Han_Deep_Reinforcement_Learning_of_Volume-Guided_Progressive_View_Inpainting_for_3D_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "24": {"title": "video action transformer network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Girdhar_Video_Action_Transformer_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "25": {"title": "timeception for complex action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hussein_Timeception_for_Complex_Action_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "26": {"title": "step: spatio-temporal progressive learning for video action detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_STEP_Spatio-Temporal_Progressive_Learning_for_Video_Action_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "27": {"title": "relational action forecasting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Relational_Action_Forecasting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "28": {"title": "long-term feature banks for detailed video understanding", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Long-Term_Feature_Banks_for_Detailed_Video_Understanding_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "29": {"title": "which way are you going? imitative decision learning for path forecasting in dynamic scenes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Which_Way_Are_You_Going_Imitative_Decision_Learning_for_Path_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "30": {"title": "what and how well you performed? a multitask learning approach to action quality assessment", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Parmar_What_and_How_Well_You_Performed_A_Multitask_Learning_Approach_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "31": {"title": "mhp-vos: multiple hypotheses propagation for video object segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_MHP-VOS_Multiple_Hypotheses_Propagation_for_Video_Object_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "32": {"title": "2.5d visual sound", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gao_2.5D_Visual_Sound_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "33": {"title": "language-driven temporal activity localization: a semantic matching reinforcement learning model", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Language-Driven_Temporal_Activity_Localization_A_Semantic_Matching_Reinforcement_Learning_Model_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "34": {"title": "gaussian temporal awareness networks for action localization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Long_Gaussian_Temporal_Awareness_Networks_for_Action_Localization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "35": {"title": "efficient video classification using fewer frames", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Bhardwaj_Efficient_Video_Classification_Using_Fewer_Frames_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "36": {"title": "parsing r-cnn for instance-level human analysis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Parsing_R-CNN_for_Instance-Level_Human_Analysis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "37": {"title": "large scale incremental learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Large_Scale_Incremental_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "38": {"title": "topnet: structural point cloud decoder", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tchapmi_TopNet_Structural_Point_Cloud_Decoder_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "39": {"title": "perceive where to focus: learning visibility-aware part-level features for partial person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Perceive_Where_to_Focus_Learning_Visibility-Aware_Part-Level_Features_for_Partial_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "40": {"title": "meta-transfer learning for few-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Meta-Transfer_Learning_for_Few-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "41": {"title": "structured binary neural networks for accurate image classification and semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhuang_Structured_Binary_Neural_Networks_for_Accurate_Image_Classification_and_Semantic_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "42": {"title": "deep rnn framework for visual sequential applications", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pang_Deep_RNN_Framework_for_Visual_Sequential_Applications_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "43": {"title": "graph-based global reasoning networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Graph-Based_Global_Reasoning_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "44": {"title": "ssn: learning sparse switchable normalization via sparsestmax", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shao_SSN_Learning_Sparse_Switchable_Normalization_via_SparsestMax_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "45": {"title": "spherical fractal convolutional neural networks for point cloud recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Rao_Spherical_Fractal_Convolutional_Neural_Networks_for_Point_Cloud_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "46": {"title": "learning to generate synthetic data via compositing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tripathi_Learning_to_Generate_Synthetic_Data_via_Compositing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "47": {"title": "divide and conquer the embedding space for metric learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sanakoyeu_Divide_and_Conquer_the_Embedding_Space_for_Metric_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "48": {"title": "latent space autoregression for novelty detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Abati_Latent_Space_Autoregression_for_Novelty_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "49": {"title": "attending to discriminative certainty for domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kurmi_Attending_to_Discriminative_Certainty_for_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "50": {"title": "feature denoising for improving adversarial robustness", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Feature_Denoising_for_Improving_Adversarial_Robustness_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "51": {"title": "selective kernel networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Selective_Kernel_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "52": {"title": "on implicit filter level sparsity in convolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mehta_On_Implicit_Filter_Level_Sparsity_in_Convolutional_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "53": {"title": "flownet3d: learning scene flow in 3d point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_FlowNet3D_Learning_Scene_Flow_in_3D_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "54": {"title": "scene memory transformer for embodied agents in long-horizon tasks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fang_Scene_Memory_Transformer_for_Embodied_Agents_in_Long-Horizon_Tasks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "55": {"title": "co-occurrent features in semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Co-Occurrent_Features_in_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "56": {"title": "bag of tricks for image classification with convolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "57": {"title": "learning channel-wise interactions for binary convolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_Channel-Wise_Interactions_for_Binary_Convolutional_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "58": {"title": "knowledge adaptation for efficient semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Knowledge_Adaptation_for_Efficient_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "59": {"title": "parametric noise injection: trainable randomness to improve deep neural network robustness against adversarial attack", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Parametric_Noise_Injection_Trainable_Randomness_to_Improve_Deep_Neural_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "60": {"title": "invariance matters: exemplar memory for domain adaptive person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Invariance_Matters_Exemplar_Memory_for_Domain_Adaptive_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "61": {"title": "dissecting person re-identification from the viewpoint of viewpoint", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Dissecting_Person_Re-Identification_From_the_Viewpoint_of_Viewpoint_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "62": {"title": "learning to reduce dual-level discrepancy for infrared-visible person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_to_Reduce_Dual-Level_Discrepancy_for_Infrared-Visible_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "63": {"title": "progressive feature alignment for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Progressive_Feature_Alignment_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "64": {"title": "feature-level frankenstein: eliminating variations for discriminative recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Feature-Level_Frankenstein_Eliminating_Variations_for_Discriminative_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "65": {"title": "learning a deep convnet for multi-label classification with partial labels", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Durand_Learning_a_Deep_ConvNet_for_Multi-Label_Classification_With_Partial_Labels_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "66": {"title": "generalized intersection over union: a metric and a loss for bounding box regression", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Rezatofighi_Generalized_Intersection_Over_Union_A_Metric_and_a_Loss_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "67": {"title": "densely semantically aligned person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Densely_Semantically_Aligned_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "68": {"title": "generalising fine-grained sketch-based image retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pang_Generalising_Fine-Grained_Sketch-Based_Image_Retrieval_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "69": {"title": "adapting object detectors via selective cross-domain alignment", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Adapting_Object_Detectors_via_Selective_Cross-Domain_Alignment_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "70": {"title": "cyclic guidance for weakly supervised joint detection and segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shen_Cyclic_Guidance_for_Weakly_Supervised_Joint_Detection_and_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "71": {"title": "thinking outside the pool: active training image creation for relative attributes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Thinking_Outside_the_Pool_Active_Training_Image_Creation_for_Relative_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "72": {"title": "generalizable person re-identification by domain-invariant mapping network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Song_Generalizable_Person_Re-Identification_by_Domain-Invariant_Mapping_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "73": {"title": "visual attention consistency under image transforms for multi-label image classification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Visual_Attention_Consistency_Under_Image_Transforms_for_Multi-Label_Image_Classification_CVPR_2019_paper.html", "abstract": "Human visual perception shows good consistency for many multi-label image classification tasks under\n certain spatial transforms, such as scaling, rotation, flipping and translation. This has motivated\n the data augmentation strategy widely used in CNN classifier training -- transformed images are inc\nluded for training by assuming the same class labels as their original images. In this paper, we fur\nther propose the assumption of perceptual consistency of visual attention regions for classification\n under such transforms, i.e., the attention region for a classification follows the same transform i\nf the input image is spatially transformed. While the attention regions of CNN classifiers can be de\nrived as an attention heatmap in middle layers of the network, we find that their consistency under \nmany transforms are not preserved.  To address this problem, we propose a two-branch network with an\n original image and its transformed image as inputs and introduce a new attention consistency loss t\nhat measures the attention heatmap consistency between two branches. This new loss is then combined \nwith multi-label image classification loss for network training. Experiments on three datasets verif\ny the superiority of the proposed network by achieving new state-of-the-art classification performan\nce.\r", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "74": {"title": "re-ranking via metric fusion for object retrieval and person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Bai_Re-Ranking_via_Metric_Fusion_for_Object_Retrieval_and_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "75": {"title": "unsupervised open domain recognition by semantic discrepancy minimization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhuo_Unsupervised_Open_Domain_Recognition_by_Semantic_Discrepancy_Minimization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "76": {"title": "weakly supervised person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Meng_Weakly_Supervised_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "77": {"title": "pointrcnn: 3d object proposal generation and detection from point cloud", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_PointRCNN_3D_Object_Proposal_Generation_and_Detection_From_Point_Cloud_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "78": {"title": "automatic adaptation of object detectors to new domains using self-training", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/RoyChowdhury_Automatic_Adaptation_of_Object_Detectors_to_New_Domains_Using_Self-Training_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "79": {"title": "deep sketch-shape hashing with segmented 3d stochastic viewing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Deep_Sketch-Shape_Hashing_With_Segmented_3D_Stochastic_Viewing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "80": {"title": "generative dual adversarial network for generalized zero-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Generative_Dual_Adversarial_Network_for_Generalized_Zero-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "81": {"title": "query-guided end-to-end person search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Munjal_Query-Guided_End-To-End_Person_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "82": {"title": "libra r-cnn: towards balanced learning for object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pang_Libra_R-CNN_Towards_Balanced_Learning_for_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "83": {"title": "learning a unified classifier incrementally via rebalancing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hou_Learning_a_Unified_Classifier_Incrementally_via_Rebalancing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "84": {"title": "feature selective anchor-free module for single-shot object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Feature_Selective_Anchor-Free_Module_for_Single-Shot_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "85": {"title": "bottom-up object detection by grouping extreme and center points", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Bottom-Up_Object_Detection_by_Grouping_Extreme_and_Center_Points_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "86": {"title": "feature distillation: dnn-oriented jpeg compression against adversarial examples", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Feature_Distillation_DNN-Oriented_JPEG_Compression_Against_Adversarial_Examples_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "87": {"title": "scops: self-supervised co-part segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hung_SCOPS_Self-Supervised_Co-Part_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "88": {"title": "unsupervised moving object detection via contextual information separation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Unsupervised_Moving_Object_Detection_via_Contextual_Information_Separation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "89": {"title": "pose2seg: detection free human instance segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Pose2Seg_Detection_Free_Human_Instance_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "90": {"title": "drivingstereo: a large-scale dataset for stereo matching in autonomous driving scenarios", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_DrivingStereo_A_Large-Scale_Dataset_for_Stereo_Matching_in_Autonomous_Driving_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "91": {"title": "partnet: a large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mo_PartNet_A_Large-Scale_Benchmark_for_Fine-Grained_and_Hierarchical_Part-Level_3D_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "92": {"title": "a dataset and benchmark for large-scale multi-modal face anti-spoofing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_A_Dataset_and_Benchmark_for_Large-Scale_Multi-Modal_Face_Anti-Spoofing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "93": {"title": "unsupervised learning of consensus maximization for 3d vision problems", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Probst_Unsupervised_Learning_of_Consensus_Maximization_for_3D_Vision_Problems_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "94": {"title": "vizwiz-priv: a dataset for recognizing the presence and purpose of private visual information in images taken by blind people", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gurari_VizWiz-Priv_A_Dataset_for_Recognizing_the_Presence_and_Purpose_of_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "95": {"title": "structural relational reasoning of point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Duan_Structural_Relational_Reasoning_of_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "96": {"title": "mvf-net: multi-view 3d face morphable model regression", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_MVF-Net_Multi-View_3D_Face_Morphable_Model_Regression_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "97": {"title": "photometric mesh optimization for video-aligned 3d object reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lin_Photometric_Mesh_Optimization_for_Video-Aligned_3D_Object_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "98": {"title": "guided stereo matching", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Poggi_Guided_Stereo_Matching_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "99": {"title": "unsupervised event-based learning of optical flow, depth, and egomotion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Unsupervised_Event-Based_Learning_of_Optical_Flow_Depth_and_Egomotion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "100": {"title": "modeling local geometric structure of 3d point clouds using geo-cnn", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lan_Modeling_Local_Geometric_Structure_of_3D_Point_Clouds_Using_Geo-CNN_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "101": {"title": "3d point capsule networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_3D_Point_Capsule_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "102": {"title": "gs3d: an efficient 3d object detection framework for autonomous driving", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_GS3D_An_Efficient_3D_Object_Detection_Framework_for_Autonomous_Driving_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "103": {"title": "single-image piece-wise planar 3d reconstruction via associative embedding", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Single-Image_Piece-Wise_Planar_3D_Reconstruction_via_Associative_Embedding_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "104": {"title": "3dn: 3d deformation network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_3DN_3D_Deformation_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "105": {"title": "horizonnet: learning room layout with 1d representation and pano stretch data augmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_HorizonNet_Learning_Room_Layout_With_1D_Representation_and_Pano_Stretch_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "106": {"title": "deep fitting degree scoring network for monocular 3d object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Deep_Fitting_Degree_Scoring_Network_for_Monocular_3D_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "107": {"title": "pushing the envelope for rgb-based dense 3d hand pose estimation via neural rendering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Baek_Pushing_the_Envelope_for_RGB-Based_Dense_3D_Hand_Pose_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "108": {"title": "self-supervised learning of 3d human pose using multi-view geometry", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kocabas_Self-Supervised_Learning_of_3D_Human_Pose_Using_Multi-View_Geometry_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "109": {"title": "fsa-net: learning fine-grained structure aggregation for head pose estimation from a single image", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_FSA-Net_Learning_Fine-Grained_Structure_Aggregation_for_Head_Pose_Estimation_From_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "110": {"title": "dense 3d face decoding over 2500fps: joint texture & shape convolutional mesh decoders", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Dense_3D_Face_Decoding_Over_2500FPS_Joint_Texture__Shape_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "111": {"title": "does learning specific features for related parts help human pose estimation?", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tang_Does_Learning_Specific_Features_for_Related_Parts_Help_Human_Pose_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "112": {"title": "linkage based face clustering via graph convolution network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Linkage_Based_Face_Clustering_via_Graph_Convolution_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "113": {"title": "towards high-fidelity nonlinear 3d face morphable model", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tran_Towards_High-Fidelity_Nonlinear_3D_Face_Morphable_Model_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "114": {"title": "regularface: deep face recognition via exclusive regularization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_RegularFace_Deep_Face_Recognition_via_Exclusive_Regularization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "115": {"title": "bridgenet: a continuity-aware probabilistic network for age estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_BridgeNet_A_Continuity-Aware_Probabilistic_Network_for_Age_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "116": {"title": "ganfit: generative adversarial network fitting for high fidelity 3d face reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gecer_GANFIT_Generative_Adversarial_Network_Fitting_for_High_Fidelity_3D_Face_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "117": {"title": "improving the performance of unimodal dynamic hand-gesture recognition with multimodal training", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Abavisani_Improving_the_Performance_of_Unimodal_Dynamic_Hand-Gesture_Recognition_With_Multimodal_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "118": {"title": "learning to reconstruct people in clothing from a single rgb camera", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Alldieck_Learning_to_Reconstruct_People_in_Clothing_From_a_Single_RGB_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "119": {"title": "distilled person re-identification: towards a more scalable system", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Distilled_Person_Re-Identification_Towards_a_More_Scalable_System_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "120": {"title": "a perceptual prediction framework for self supervised event segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Aakur_A_Perceptual_Prediction_Framework_for_Self_Supervised_Event_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "121": {"title": "coin: a large-scale dataset for comprehensive instructional video analysis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tang_COIN_A_Large-Scale_Dataset_for_Comprehensive_Instructional_Video_Analysis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "122": {"title": "recurrent attentive zooming for joint crowd counting and precise localization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Recurrent_Attentive_Zooming_for_Joint_Crowd_Counting_and_Precise_Localization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "123": {"title": "an attention enhanced graph convolutional lstm network for skeleton-based action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Si_An_Attention_Enhanced_Graph_Convolutional_LSTM_Network_for_Skeleton-Based_Action_CVPR_2019_paper.html", "abstract": "Skeleton-based action recognition is an important task that requires the adequate understanding of m\novement characteristics of a human action from the given skeleton sequence. Recent studies have show\nn that exploring spatial and temporal features of the skeleton sequence is vital for this task. Neve\nrtheless, how to effectively extract discriminative spatial and temporal features is still a challen\nging problem. In this paper, we propose a novel Attention Enhanced Graph Convolutional LSTM Network \n(AGC-LSTM) for human action recognition from skeleton data. The proposed AGC-LSTM can not only captu\nre discriminative features in spatial configuration and temporal dynamics but also explore the co-oc\ncurrence relationship between spatial and temporal domains. We also present a temporal hierarchical \narchitecture to increase temporal receptive fields of the top AGC-LSTM layer, which boosts the abili\nty to learn the high-level semantic representation and significantly reduces the computation cost. F\nurthermore, to select discriminative spatial information, the attention mechanism is employed to enh\nance information of key joints in each AGC-LSTM layer. Experimental results on two datasets are prov\nided: NTU RGB+D dataset and Northwestern-UCLA dataset. The comparison results demonstrate the effect\niveness of our approach and show that our approach outperforms the state-of-the-art methods on both \ndatasets.\r", "cite_num": 2, "conf": "cvpr", "time": "2019"}, "124": {"title": "graph convolutional label noise cleaner: train a plug-and-play action classifier for anomaly detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Graph_Convolutional_Label_Noise_Cleaner_Train_a_Plug-And-Play_Action_Classifier_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "125": {"title": "man: moment alignment network for natural language moment retrieval via iterative graph adjustment", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_MAN_Moment_Alignment_Network_for_Natural_Language_Moment_Retrieval_via_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "126": {"title": "less is more: learning highlight detection from video duration", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_Less_Is_More_Learning_Highlight_Detection_From_Video_Duration_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "127": {"title": "dmc-net: generating discriminative motion cues for fast compressed video action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shou_DMC-Net_Generating_Discriminative_Motion_Cues_for_Fast_Compressed_Video_Action_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "128": {"title": "adaframe: adaptive frame selection for fast video recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_AdaFrame_Adaptive_Frame_Selection_for_Fast_Video_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "129": {"title": "spatio-temporal video re-localization by warp lstm", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Feng_Spatio-Temporal_Video_Re-Localization_by_Warp_LSTM_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "130": {"title": "completeness modeling and context separation for weakly supervised temporal action localization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Completeness_Modeling_and_Context_Separation_for_Weakly_Supervised_Temporal_Action_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "131": {"title": "unsupervised deep tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Unsupervised_Deep_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "132": {"title": "tracking by animation: unsupervised learning of multi-object attentive trackers", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Tracking_by_Animation_Unsupervised_Learning_of_Multi-Object_Attentive_Trackers_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "133": {"title": "fast online object tracking and segmentation: a unifying approach", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Fast_Online_Object_Tracking_and_Segmentation_A_Unifying_Approach_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "134": {"title": "object tracking by reconstruction with view-specific discriminative correlation filters", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kart_Object_Tracking_by_Reconstruction_With_View-Specific_Discriminative_Correlation_Filters_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "135": {"title": "sophie: an attentive gan for predicting paths compliant to social and physical constraints", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sadeghian_SoPhie_An_Attentive_GAN_for_Predicting_Paths_Compliant_to_Social_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "136": {"title": "leveraging shape completion for 3d siamese tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Giancola_Leveraging_Shape_Completion_for_3D_Siamese_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "137": {"title": "target-aware deep tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Target-Aware_Deep_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "138": {"title": "spatiotemporal cnn for video object segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Spatiotemporal_CNN_for_Video_Object_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "139": {"title": "towards rich feature discovery with class activation maps augmentation for person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Towards_Rich_Feature_Discovery_With_Class_Activation_Maps_Augmentation_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "140": {"title": "wide-context semantic image extrapolation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Wide-Context_Semantic_Image_Extrapolation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "141": {"title": "end-to-end time-lapse video synthesis from a single outdoor image", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Nam_End-To-End_Time-Lapse_Video_Synthesis_From_a_Single_Outdoor_Image_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "142": {"title": "gif2video: color dequantization and temporal interpolation of gif images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_GIF2Video_Color_Dequantization_and_Temporal_Interpolation_of_GIF_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "143": {"title": "mode seeking generative adversarial networks for diverse image synthesis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mao_Mode_Seeking_Generative_Adversarial_Networks_for_Diverse_Image_Synthesis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "144": {"title": "pluralistic image completion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Pluralistic_Image_Completion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "145": {"title": "salient object detection with pyramid attention and salient edges", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Salient_Object_Detection_With_Pyramid_Attention_and_Salient_Edges_CVPR_2019_paper.html", "abstract": "This paper presents a new method for detecting salient objects in images using convolutional neural \nnetworks (CNNs). The proposed network, named PAGE-Net, offers two key contributions. The first is th\ne exploitation of an essential pyramid attention structure for salient object detection. This enable\ns the network to concentrate more on salient regions while considering multi-scale saliency informat\nion. Such a stacked attention design provides a powerful tool to efficiently improve the representat\nion ability of the corresponding network layer with an enlarged receptive field. The second contribu\ntion lies in the emphasis on the importance of salient edges. Salient edge information offers a stro\nng cue to better segment salient objects and refine object boundaries. To this end, our model is equ\nipped with a salient edge detection module, which is learned for precise salient boundary estimation\n. This encourages better edge-preserving salient object segmentation. Exhaustive experiments confirm\n that the proposed pyramid attention and salient edges are effective for salient object detection. W\ne show that our deep saliency model outperforms state-of-the-art approaches for several benchmarks w\nith a fast processing speed (25fps on one GPU).\r", "cite_num": 2, "conf": "cvpr", "time": "2019"}, "146": {"title": "latent filter scaling for multimodal unsupervised image-to-image translation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Alharbi_Latent_Filter_Scaling_for_Multimodal_Unsupervised_Image-To-Image_Translation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "147": {"title": "attention-aware multi-stroke style transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yao_Attention-Aware_Multi-Stroke_Style_Transfer_CVPR_2019_paper.html", "abstract": "Neural style transfer has drawn considerable attention from both academic and industrial field. Alth\nough visual effect and efficiency have been significantly improved, existing methods are unable to c\noordinate spatial distribution of visual attention between the content image and stylized image, or \nrender diverse level of detail via different brush strokes. In this paper, we tackle these limitatio\nns by developing an attention-aware multi-stroke style transfer model. We first propose to assemble \nself-attention mechanism into a style-agnostic reconstruction autoencoder framework, from which the \nattention map of a content image can be derived. By performing multi-scale style swap on content fea\ntures and style features, we produce multiple feature maps reflecting different stroke patterns. A f\nlexible fusion strategy is further presented to incorporate the salient characteristics from the att\nention map, which allows integrating multiple stroke patterns into different spatial regions of the \noutput image harmoniously. We demonstrate the effectiveness of our method, as well as generate compa\nrable stylized images with multiple stroke patterns against the state-of-the-art methods.", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "148": {"title": "feedback adversarial learning: spatial feedback for improving generative adversarial networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Huh_Feedback_Adversarial_Learning_Spatial_Feedback_for_Improving_Generative_Adversarial_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "149": {"title": "learning pyramid-context encoder network for high-quality image inpainting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Learning_Pyramid-Context_Encoder_Network_for_High-Quality_Image_Inpainting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "150": {"title": "example-guided style-consistent image synthesis from semantic labeling", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Example-Guided_Style-Consistent_Image_Synthesis_From_Semantic_Labeling_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "151": {"title": "mirrorgan: learning text-to-image generation by redescription", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qiao_MirrorGAN_Learning_Text-To-Image_Generation_by_Redescription_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "152": {"title": "light field messaging with deep photographic steganography", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wengrowski_Light_Field_Messaging_With_Deep_Photographic_Steganography_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "153": {"title": "im2pencil: controllable pencil illustration from photographs", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Im2Pencil_Controllable_Pencil_Illustration_From_Photographs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "154": {"title": "when color constancy goes wrong: correcting improperly white-balanced images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Afifi_When_Color_Constancy_Goes_Wrong_Correcting_Improperly_White-Balanced_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "155": {"title": "beyond volumetric albedo -- a surface optimization framework for non-line-of-sight imaging", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tsai_Beyond_Volumetric_Albedo_--_A_Surface_Optimization_Framework_for_Non-Line-Of-Sight_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "156": {"title": "reflection removal using a dual-pixel sensor", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Punnappurath_Reflection_Removal_Using_a_Dual-Pixel_Sensor_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "157": {"title": "practical coding function design for time-of-flight imaging", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gutierrez-Barragan_Practical_Coding_Function_Design_for_Time-Of-Flight_Imaging_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "158": {"title": "meta-sr: a magnification-arbitrary network for super-resolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Meta-SR_A_Magnification-Arbitrary_Network_for_Super-Resolution_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "159": {"title": "multispectral and hyperspectral image fusion by ms/hs fusion net", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Multispectral_and_Hyperspectral_Image_Fusion_by_MSHS_Fusion_Net_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "160": {"title": "learning attraction field representation for robust line segment detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xue_Learning_Attraction_Field_Representation_for_Robust_Line_Segment_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "161": {"title": "blind super-resolution with iterative kernel correction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gu_Blind_Super-Resolution_With_Iterative_Kernel_Correction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "162": {"title": "video magnification in the wild using fractional anisotropy in temporal distribution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Takeda_Video_Magnification_in_the_Wild_Using_Fractional_Anisotropy_in_Temporal_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "163": {"title": "attentive feedback network for boundary-aware salient object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Feng_Attentive_Feedback_Network_for_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "164": {"title": "heavy rain image restoration: integrating physics model and conditional adversarial learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Heavy_Rain_Image_Restoration_Integrating_Physics_Model_and_Conditional_Adversarial_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "165": {"title": "learning to calibrate straight lines for fisheye image rectification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xue_Learning_to_Calibrate_Straight_Lines_for_Fisheye_Image_Rectification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "166": {"title": "camera lens super-resolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Camera_Lens_Super-Resolution_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "167": {"title": "frame-consistent recurrent video deraining with dual-level flow", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Frame-Consistent_Recurrent_Video_Deraining_With_Dual-Level_Flow_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "168": {"title": "deep plug-and-play super-resolution for arbitrary blur kernels", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deep_Plug-And-Play_Super-Resolution_for_Arbitrary_Blur_Kernels_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "169": {"title": "sea-thru: a method for removing water from underwater images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Akkaynak_Sea-Thru_A_Method_for_Removing_Water_From_Underwater_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "170": {"title": "deep network interpolation for continuous imagery effect transition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Deep_Network_Interpolation_for_Continuous_Imagery_Effect_Transition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "171": {"title": "spatially variant linear representation models for joint filtering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Spatially_Variant_Linear_Representation_Models_for_Joint_Filtering_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "172": {"title": "toward convolutional blind denoising of real photographs", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Toward_Convolutional_Blind_Denoising_of_Real_Photographs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "173": {"title": "towards real scene super-resolution with raw images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Towards_Real_Scene_Super-Resolution_With_Raw_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "174": {"title": "ode-inspired network design for single image super-resolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_ODE-Inspired_Network_Design_for_Single_Image_Super-Resolution_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "175": {"title": "blind image deblurring with local maximum gradient prior", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Blind_Image_Deblurring_With_Local_Maximum_Gradient_Prior_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "176": {"title": "attention-guided network for ghost-free high dynamic range imaging", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yan_Attention-Guided_Network_for_Ghost-Free_High_Dynamic_Range_Imaging_CVPR_2019_paper.html", "abstract": "Ghosting artifacts caused by moving objects or misalignments is a key challenge in high dynamic rang\ne (HDR) imaging for dynamic scenes. Previous methods first register the input low dynamic range (LDR\n) images using optical flow before merging them, which are error-prone and cause ghosts in results. \nA very recent work tries to bypass optical flows via a deep network with skip-connections, however, \nwhich still suffers from ghosting artifacts for severe movement. To avoid the ghosting from the sour\nce, we propose a novel attention-guided end-to-end deep neural network (AHDRNet) to produce high-qua\nlity ghost-free HDR images. Unlike previous methods directly stacking the LDR images or features for\n merging, we use attention modules to guide the merging according to the reference image. The attent\nion modules automatically suppress undesired components caused by misalignments and saturation and e\nnhance desirable fine details in the non-reference images. In addition to the attention model, we us\ne dilated residual dense block (DRDB) to make full use of the hierarchical features and increase the\n receptive field for hallucinating the missing details. The proposed AHDRNet is a non-flow-based met\nhod, which can also avoid the artifacts generated by optical-flow estimation error. Experiments on d\nifferent datasets show that the proposed AHDRNet can achieve state-of-the-art quantitative and quali\ntative results.", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "177": {"title": "searching for a robust neural architecture in four gpu hours", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Searching_for_a_Robust_Neural_Architecture_in_Four_GPU_Hours_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "178": {"title": "hierarchy denoising recursive autoencoders for 3d scene layout prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Hierarchy_Denoising_Recursive_Autoencoders_for_3D_Scene_Layout_Prediction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "179": {"title": "adaptively connected neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Adaptively_Connected_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "180": {"title": "crdoco: pixel-level domain transfer with cross-domain consistency", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_CrDoCo_Pixel-Level_Domain_Transfer_With_Cross-Domain_Consistency_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "181": {"title": "temporal cycle-consistency learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dwibedi_Temporal_Cycle-Consistency_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "182": {"title": "predicting future frames using retrospective cycle gan", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kwon_Predicting_Future_Frames_Using_Retrospective_Cycle_GAN_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "183": {"title": "density map regression guided detection network for rgb-d crowd counting and localization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lian_Density_Map_Regression_Guided_Detection_Network_for_RGB-D_Crowd_Counting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "184": {"title": "tafe-net: task-aware feature embeddings for low shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_TAFE-Net_Task-Aware_Feature_Embeddings_for_Low_Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "185": {"title": "learning semantic segmentation from synthetic data: a geometrically guided input-output adaptation approach", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Semantic_Segmentation_From_Synthetic_Data_A_Geometrically_Guided_Input-Output_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "186": {"title": "attentive single-tasking of multiple tasks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Maninis_Attentive_Single-Tasking_of_Multiple_Tasks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "187": {"title": "deep metric learning to rank", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cakir_Deep_Metric_Learning_to_Rank_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "188": {"title": "end-to-end multi-task learning with attention", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_End-To-End_Multi-Task_Learning_With_Attention_CVPR_2019_paper.html", "abstract": "In this paper, we propose a novel multi-task learning architecture, which incorporates recent advanc\nes in attention mechanisms. Our approach, the Multi-Task Attention Network (MTAN), consists of a sin\ngle shared network containing a global feature pool, together with task-specific soft-attention modu\nles, which are trainable in an end-to-end manner. These attention modules allow for learning of task\n-specific features from the global pool, whilst simultaneously allowing for features to be shared ac\nross different tasks. The architecture can be built upon any feed-forward neural network, is simple \nto implement, and is parameter efficient. Experiments on the CityScapes dataset show that our method\n outperforms several baselines in both single-task and multi-task learning, and is also more robust \nto the various weighting schemes in the multi-task loss function. We further explore the effectivene\nss of our method through experiments over a range of task complexities, and show how our method scal\nes well with task complexity compared to baselines.", "cite_num": 7, "conf": "cvpr", "time": "2019"}, "189": {"title": "self-supervised learning via conditional motion propagation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhan_Self-Supervised_Learning_via_Conditional_Motion_Propagation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "190": {"title": "bridging stereo matching and optical flow via spatiotemporal correspondence", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lai_Bridging_Stereo_Matching_and_Optical_Flow_via_Spatiotemporal_Correspondence_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "191": {"title": "all about structure: adapting structural information across domains for boosting semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chang_All_About_Structure_Adapting_Structural_Information_Across_Domains_for_Boosting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "192": {"title": "iterative reorganization with weak spatial constraints: solving arbitrary jigsaw puzzles for unsupervised representation learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Iterative_Reorganization_With_Weak_Spatial_Constraints_Solving_Arbitrary_Jigsaw_Puzzles_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "193": {"title": "revisiting self-supervised visual representation learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kolesnikov_Revisiting_Self-Supervised_Visual_Representation_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "194": {"title": "it's not about the journey; it's about the destination: following soft paths under question-guidance for visual reasoning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Haurilet_Its_Not_About_the_Journey_Its_About_the_Destination_Following_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "195": {"title": "actively seeking and learning from live data", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Teney_Actively_Seeking_and_Learning_From_Live_Data_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "196": {"title": "improving referring expression grounding with cross-modal attention-guided erasing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Improving_Referring_Expression_Grounding_With_Cross-Modal_Attention-Guided_Erasing_CVPR_2019_paper.html", "abstract": "Referring expression grounding aims at locating certain objects or persons in an image with a referr\ning expression, where the key challenge is to comprehend and align various types of information from\n visual and textual domain, such as visual attributes, location and interactions with surrounding re\ngions. Although the attention mechanism has been successfully applied for cross-modal alignments, pr\nevious attention models focus on only the most dominant features of both modalities, and neglect the\n fact that there could be multiple comprehensive textual-visual correspondences between images and r\neferring expressions. To tackle this issue, we design a novel cross-modal attention-guided erasing a\npproach, where we discard the most dominant information from either textual or visual domains to gen\nerate difficult training samples online, and to drive the model to discover complementary textual-vi\nsual correspondences. Extensive experiments demonstrate the effectiveness of our proposed method, wh\nich achieves state-of-the-art performance on three referring expression grounding datasets.", "cite_num": 2, "conf": "cvpr", "time": "2019"}, "197": {"title": "neighbourhood watch: referring expression comprehension via language-guided graph attention networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Neighbourhood_Watch_Referring_Expression_Comprehension_via_Language-Guided_Graph_Attention_Networks_CVPR_2019_paper.html", "abstract": "The task in referring expression comprehension is to localise the object instance in an image descri\nbed by a referring expression phrased in natural language. As a language-to-vision matching task, th\ne key to this problem is to learn a discriminative object feature that can adapt to the expression u\nsed. To avoid ambiguity, the expression normally tends to describe not only the properties of the re\nferent itself, but also its relationships to its neighbourhood. To capture and exploit this importan\nt information we propose a graph-based, language-guided attention mechanism. Being composed of node \nattention component and edge attention component, the proposed graph attention mechanism explicitly \nrepresents inter-object relationships, and properties with a flexibility and power impossible with c\nompeting approaches. Furthermore, the proposed graph attention mechanism enables the comprehension d\necision to be visualisable and explainable. Experiments on three referring expression comprehension \ndatasets show the advantage of the proposed approach.", "cite_num": 2, "conf": "cvpr", "time": "2019"}, "198": {"title": "scene graph generation with external knowledge and image reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gu_Scene_Graph_Generation_With_External_Knowledge_and_Image_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "199": {"title": "polysemous visual-semantic embedding for cross-modal retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Song_Polysemous_Visual-Semantic_Embedding_for_Cross-Modal_Retrieval_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "200": {"title": "murel: multimodal relational reasoning for visual question answering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cadene_MUREL_Multimodal_Relational_Reasoning_for_Visual_Question_Answering_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "201": {"title": "heterogeneous memory enhanced multimodal attention model for video question answering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Heterogeneous_Memory_Enhanced_Multimodal_Attention_Model_for_Video_Question_Answering_CVPR_2019_paper.html", "abstract": "In this paper, we propose a novel end-to-end trainable Video Question Answering (VideoQA) framework \nwith three major components: 1) a new heterogeneous memory which can effectively learn global contex\nt information from appearance and motion features; 2) a redesigned question memory which helps under\nstand the complex semantics of question and highlights queried subjects; and 3) a new multimodal fus\nion layer which performs multi-step reasoning by attending to relevant visual and textual hints with\n self-updated attention. Our VideoQA model firstly generates the global context-aware visual and tex\ntual features respectively by interacting current inputs with memory contents. After that, it makes \nthe attentional fusion of the multimodal visual and textual representations to infer the correct ans\nwer. Multiple cycles of reasoning can be made to iteratively refine attention weights of the multimo\ndal data and improve the final representation of the QA pair. Experimental results demonstrate our a\npproach achieves state-of-the-art performance on four VideoQA benchmark datasets.\r", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "202": {"title": "information maximizing visual question generation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Krishna_Information_Maximizing_Visual_Question_Generation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "203": {"title": "learning to detect human-object interactions with knowledge", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Learning_to_Detect_Human-Object_Interactions_With_Knowledge_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "204": {"title": "learning words by drawing images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Suris_Learning_Words_by_Drawing_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "205": {"title": "factor graph attention", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Schwartz_Factor_Graph_Attention_CVPR_2019_paper.html", "abstract": "Dialog is an effective way to exchange information, but subtle details and nuances are extremely imp\nortant. While significant progress has paved a path   to address visual dialog with algorithms,  det\nails and nuances remain a challenge. Attention mechanisms have demonstrated compelling results to ex\ntract details in visual question answering and also provide a convincing framework for visual dialog\n due to their interpretability and effectiveness. However, the many data utilities that accompany vi\nsual dialog challenge  existing attention techniques. We address this issue and develop a general at\ntention mechanism for visual dialog which operates on any number of data utilities. To this end, we \ndesign a factor graph based attention mechanism which combines any number of utility representations\n. We illustrate the applicability of the proposed approach on the challenging and recently introduce\nd VisDial datasets, outperforming recent state-of-the-art methods by 1.1% for VisDial0.9 and by 2% f\nor VisDial1.0 on MRR. Our ensemble model improved the MRR score on VisDial1.0 by more than 6%. \r", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "206": {"title": "reducing uncertainty in undersampled mri reconstruction with active acquisition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Reducing_Uncertainty_in_Undersampled_MRI_Reconstruction_With_Active_Acquisition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "207": {"title": "esir: end-to-end scene text recognition via iterative image rectification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhan_ESIR_End-To-End_Scene_Text_Recognition_via_Iterative_Image_Rectification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "208": {"title": "roi-10d: monocular lifting of 2d detection to 6d pose and metric shape", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Manhardt_ROI-10D_Monocular_Lifting_of_2D_Detection_to_6D_Pose_and_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "209": {"title": "collaborative learning of semi-supervised segmentation and classification for medical images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Collaborative_Learning_of_Semi-Supervised_Segmentation_and_Classification_for_Medical_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "210": {"title": "biologically-constrained graphs for global connectomics reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Matejek_Biologically-Constrained_Graphs_for_Global_Connectomics_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "211": {"title": "p3sgd: patient privacy preserving sgd for regularizing deep cnns in pathological image classification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_P3SGD_Patient_Privacy_Preserving_SGD_for_Regularizing_Deep_CNNs_in_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "212": {"title": "elastic boundary projection for 3d medical image segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ni_Elastic_Boundary_Projection_for_3D_Medical_Image_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "213": {"title": "sixray: a large-scale security inspection x-ray benchmark for prohibited item discovery in overlapping images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Miao_SIXray_A_Large-Scale_Security_Inspection_X-Ray_Benchmark_for_Prohibited_Item_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "214": {"title": "noise2void - learning denoising from single noisy images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Krull_Noise2Void_-_Learning_Denoising_From_Single_Noisy_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "215": {"title": "joint discriminative and generative learning for person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Joint_Discriminative_and_Generative_Learning_for_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "216": {"title": "unsupervised person re-identification by soft multilabel learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Unsupervised_Person_Re-Identification_by_Soft_Multilabel_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "217": {"title": "learning context graph for person search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yan_Learning_Context_Graph_for_Person_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "218": {"title": "gradient matching generative networks for zero-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sariyildiz_Gradient_Matching_Generative_Networks_for_Zero-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "219": {"title": "doodle to search: practical zero-shot sketch-based image retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dey_Doodle_to_Search_Practical_Zero-Shot_Sketch-Based_Image_Retrieval_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "220": {"title": "zero-shot task transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pal_Zero-Shot_Task_Transfer_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "221": {"title": "c-mil: continuation multiple instance learning for weakly supervised object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wan_C-MIL_Continuation_Multiple_Instance_Learning_for_Weakly_Supervised_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "222": {"title": "weakly supervised learning of instance segmentation with inter-pixel relations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ahn_Weakly_Supervised_Learning_of_Instance_Segmentation_With_Inter-Pixel_Relations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "223": {"title": "attention-based dropout layer for weakly supervised object localization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Choe_Attention-Based_Dropout_Layer_for_Weakly_Supervised_Object_Localization_CVPR_2019_paper.html", "abstract": "Weakly Supervised Object Localization (WSOL) techniques learn the object location only using image-l\nevel labels, without location annotations. A common limitation for these techniques is that they cov\ner only the most discriminative part of the object, not the entire object. To address this problem, \nwe propose an Attention-based Dropout Layer (ADL), which utilizes the self-attention mechanism to pr\nocess the feature maps of the model. The proposed method is composed of two key components: 1) hidin\ng the most discriminative part from the model for capturing the integral extent of object, and 2) hi\nghlighting the informative region for improving the recognition power of the model. Based on extensi\nve experiments, we demonstrate that the proposed method is effective to improve the accuracy of WSOL\n, achieving a new state-of-the-art localization accuracy in CUB-200-2011 dataset. We also show that \nthe proposed method is much more efficient in terms of both parameter and computation overheads than\n existing techniques.\r", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "224": {"title": "domain generalization by solving jigsaw puzzles", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Carlucci_Domain_Generalization_by_Solving_Jigsaw_Puzzles_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "225": {"title": "transferrable prototypical networks for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Transferrable_Prototypical_Networks_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "226": {"title": "blending-target domain adaptation by adversarial meta-adaptation networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Blending-Target_Domain_Adaptation_by_Adversarial_Meta-Adaptation_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "227": {"title": "elastic: improving cnns with dynamic scaling policies", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_ELASTIC_Improving_CNNs_With_Dynamic_Scaling_Policies_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "228": {"title": "scratchdet: training single-shot object detectors from scratch", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_ScratchDet_Training_Single-Shot_Object_Detectors_From_Scratch_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "229": {"title": "sfnet: learning object-aware semantic correspondence", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_SFNet_Learning_Object-Aware_Semantic_Correspondence_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "230": {"title": "deep metric learning beyond binary supervision", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Deep_Metric_Learning_Beyond_Binary_Supervision_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "231": {"title": "learning to cluster faces on an affinity graph", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Learning_to_Cluster_Faces_on_an_Affinity_Graph_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "232": {"title": "c2ae: class conditioned auto-encoder for open-set recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Oza_C2AE_Class_Conditioned_Auto-Encoder_for_Open-Set_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "233": {"title": "shapes and context: in-the-wild image synthesis & manipulation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Bansal_Shapes_and_Context_In-The-Wild_Image_Synthesis__Manipulation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "234": {"title": "semantics disentangling for text-to-image generation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yin_Semantics_Disentangling_for_Text-To-Image_Generation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "235": {"title": "semantic image synthesis with spatially-adaptive normalization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Park_Semantic_Image_Synthesis_With_Spatially-Adaptive_Normalization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "236": {"title": "progressive pose attention transfer for person image generation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Progressive_Pose_Attention_Transfer_for_Person_Image_Generation_CVPR_2019_paper.html", "abstract": "This paper proposes a new generative adversarial network for pose transfer, i.e., transferring the p\nose of a given person to a target pose. The generator of the network comprises a sequence of Pose-At\ntentional Transfer Blocks that each transfers certain regions it attends to, generating the person i\nmage progressively. Compared with those in previous works, our generated person images possess bette\nr appearance consistency and shape consistency with the input images, thus significantly more realis\ntic-looking. The efficacy and efficiency of the proposed network are validated both qualitatively an\nd quantitatively on Market-1501 and DeepFashion. Furthermore, the proposed architecture can generate\n training images for person re-identification, alleviating data insufficiency. Codes and models are \navailable at: this https URL.", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "237": {"title": "unsupervised person image generation with semantic parsing transformation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Song_Unsupervised_Person_Image_Generation_With_Semantic_Parsing_Transformation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "238": {"title": "deepview: view synthesis with learned gradient descent", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Flynn_DeepView_View_Synthesis_With_Learned_Gradient_Descent_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "239": {"title": "animating arbitrary objects via deep motion transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Siarohin_Animating_Arbitrary_Objects_via_Deep_Motion_Transfer_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "240": {"title": "textured neural avatars", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shysheya_Textured_Neural_Avatars_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "241": {"title": "im-net for high resolution video frame interpolation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Peleg_IM-Net_for_High_Resolution_Video_Frame_Interpolation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "242": {"title": "homomorphic latent space interpolation for unpaired image-to-image translation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Homomorphic_Latent_Space_Interpolation_for_Unpaired_Image-To-Image_Translation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "243": {"title": "multi-channel attention selection gan with cascaded semantic guidance for cross-view image translation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tang_Multi-Channel_Attention_Selection_GAN_With_Cascaded_Semantic_Guidance_for_Cross-View_CVPR_2019_paper.html", "abstract": "Cross-view image translation is challenging because it involves images with drastically different vi\news and severe deformation. In this paper, we propose a novel approach named Multi-Channel Attention\n SelectionGAN (SelectionGAN) that makes it possible to generate images of natural scenes in arbitrar\ny viewpoints, based on an image of the scene and a novel semantic map. The proposed SelectionGAN exp\nlicitly utilizes the semantic information and consists of two stages. In the first stage, the condit\nion image and the target semantic map are fed into a cycled semantic-guided generation network to pr\noduce initial coarse results. In the second stage, we refine the initial results by using a multi-ch\nannel attention selection mechanism. Moreover, uncertainty maps automatically learned from attention\ns are used to guide the pixel loss for better network optimization. Extensive experiments on Dayton,\n CVUSA and Ego2Top datasets show that our model is able to generate significantly better results tha\nn the state-of-the-art methods. The source code, data and trained models are available at https://gi\nthub.com/Ha0Tang/SelectionGAN.\r", "cite_num": 3, "conf": "cvpr", "time": "2019"}, "244": {"title": "geometry-consistent generative adversarial networks for one-sided unsupervised domain mapping", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fu_Geometry-Consistent_Generative_Adversarial_Networks_for_One-Sided_Unsupervised_Domain_Mapping_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "245": {"title": "deepvoxels: learning persistent 3d feature embeddings", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sitzmann_DeepVoxels_Learning_Persistent_3D_Feature_Embeddings_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "246": {"title": "inverse path tracing for joint material and lighting estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Azinovic_Inverse_Path_Tracing_for_Joint_Material_and_Lighting_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "247": {"title": "the visual centrifuge: model-free layered video representations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Alayrac_The_Visual_Centrifuge_Model-Free_Layered_Video_Representations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "248": {"title": "label-noise robust generative adversarial networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kaneko_Label-Noise_Robust_Generative_Adversarial_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "249": {"title": "dlow: domain flow for adaptation and generalization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gong_DLOW_Domain_Flow_for_Adaptation_and_Generalization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "250": {"title": "collagan: collaborative gan for missing image data imputation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_CollaGAN_Collaborative_GAN_for_Missing_Image_Data_Imputation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "251": {"title": "d-sne: domain adaptation using stochastic neighborhood embedding", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_d-SNE_Domain_Adaptation_Using_Stochastic_Neighborhood_Embedding_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "252": {"title": "taking a closer look at domain shift: category-level adversaries for semantics consistent domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Luo_Taking_a_Closer_Look_at_Domain_Shift_Category-Level_Adversaries_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "253": {"title": "advent: adversarial entropy minimization for domain adaptation in semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Vu_ADVENT_Adversarial_Entropy_Minimization_for_Domain_Adaptation_in_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "254": {"title": "contextdesc: local descriptor augmentation with cross-modality context", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Luo_ContextDesc_Local_Descriptor_Augmentation_With_Cross-Modality_Context_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "255": {"title": "large-scale long-tailed recognition in an open world", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Large-Scale_Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "256": {"title": "aet vs. aed: unsupervised representation learning by auto-encoding transformations rather than data", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_AET_vs._AED_Unsupervised_Representation_Learning_by_Auto-Encoding_Transformations_Rather_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "257": {"title": "sdc - stacked dilated convolution: a unified descriptor network for dense matching tasks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Schuster_SDC_-_Stacked_Dilated_Convolution_A_Unified_Descriptor_Network_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "258": {"title": "learning correspondence from the cycle-consistency of time", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_Correspondence_From_the_Cycle-Consistency_of_Time_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "259": {"title": "ae2-nets: autoencoder in autoencoder networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_AE2-Nets_Autoencoder_in_Autoencoder_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "260": {"title": "mitigating information leakage in image representations: a maximum entropy approach", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Roy_Mitigating_Information_Leakage_in_Image_Representations_A_Maximum_Entropy_Approach_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "261": {"title": "learning spatial common sense with geometry-aware recurrent networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tung_Learning_Spatial_Common_Sense_With_Geometry-Aware_Recurrent_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "262": {"title": "structured knowledge distillation for semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Structured_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "263": {"title": "scan2cad: learning cad model alignment in rgb-d scans", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Avetisyan_Scan2CAD_Learning_CAD_Model_Alignment_in_RGB-D_Scans_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "264": {"title": "towards scene understanding: unsupervised monocular depth estimation with semantic-aware representation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Towards_Scene_Understanding_Unsupervised_Monocular_Depth_Estimation_With_Semantic-Aware_Representation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "265": {"title": "tell me where i am: object-level scene context prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qiao_Tell_Me_Where_I_Am_Object-Level_Scene_Context_Prediction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "266": {"title": "normalized object coordinate space for category-level 6d object pose and size estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Normalized_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_and_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "267": {"title": "supervised fitting of geometric primitives to 3d point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Supervised_Fitting_of_Geometric_Primitives_to_3D_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "268": {"title": "do better imagenet models transfer better?", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kornblith_Do_Better_ImageNet_Models_Transfer_Better_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "269": {"title": "gotta adapt 'em all: joint pixel and feature-level domain adaptation for recognition in the wild", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tran_Gotta_Adapt_Em_All_Joint_Pixel_and_Feature-Level_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "270": {"title": "understanding the disharmony between dropout and batch normalization by variance shift", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Understanding_the_Disharmony_Between_Dropout_and_Batch_Normalization_by_Variance_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "271": {"title": "circulant binary convolutional networks: enhancing the performance of 1-bit dcnns with circulant back propagation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Circulant_Binary_Convolutional_Networks_Enhancing_the_Performance_of_1-Bit_DCNNs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "272": {"title": "defusionnet: defocus blur detection via recurrently fusing and refining multi-scale deep features", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tang_DeFusionNET_Defocus_Blur_Detection_via_Recurrently_Fusing_and_Refining_Multi-Scale_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "273": {"title": "deep virtual networks for memory efficient inference of multiple tasks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Deep_Virtual_Networks_for_Memory_Efficient_Inference_of_Multiple_Tasks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "274": {"title": "universal domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/You_Universal_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "275": {"title": "improving transferability of adversarial examples with input diversity", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Improving_Transferability_of_Adversarial_Examples_With_Input_Diversity_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "276": {"title": "sequence-to-sequence domain adaptation network for robust text image recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Sequence-To-Sequence_Domain_Adaptation_Network_for_Robust_Text_Image_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "277": {"title": "hybrid-attention based decoupled metric learning for zero-shot image retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Hybrid-Attention_Based_Decoupled_Metric_Learning_for_Zero-Shot_Image_Retrieval_CVPR_2019_paper.html", "abstract": "In zero-shot image retrieval (ZSIR) task, embedding learning becomes more attractive, however, many \nmethods follow the traditional metric learning idea and omit the problems behind zero-shot settings.\n In this paper, we first emphasize the importance of learning visual discriminative metric and preve\nnting the partial/selective learning behavior of learner in ZSIR, and then propose the Decoupled Met\nric Learning (DeML) framework to achieve these individually. Instead of coarsely optimizing an unifi\ned metric, we decouple it into multiple attention-specific parts so as to recurrently induce the dis\ncrimination and explicitly enhance the generalization. And they are mainly achieved by our object-at\ntention module based on random walk graph propagation and the channel-attention module based on the \nadversary constraint, respectively. We demonstrate the necessity of addressing the vital problems in\n ZSIR on the popular benchmarks, outperforming the state-of-the-art methods by a significant margin.\n Code is available at http://www.bhchen.cn\r", "cite_num": 2, "conf": "cvpr", "time": "2019"}, "278": {"title": "learning to sample", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dovrat_Learning_to_Sample_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "279": {"title": "few-shot learning via saliency-guided hallucination of samples", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Few-Shot_Learning_via_Saliency-Guided_Hallucination_of_Samples_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "280": {"title": "variational convolutional neural network pruning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Variational_Convolutional_Neural_Network_Pruning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "281": {"title": "towards optimal structured cnn pruning via generative adversarial learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lin_Towards_Optimal_Structured_CNN_Pruning_via_Generative_Adversarial_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "282": {"title": "exploiting kernel sparsity and entropy for interpretable cnn compression", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Exploiting_Kernel_Sparsity_and_Entropy_for_Interpretable_CNN_Compression_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "283": {"title": "fully quantized network for object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Fully_Quantized_Network_for_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "284": {"title": "mnasnet: platform-aware neural architecture search for mobile", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tan_MnasNet_Platform-Aware_Neural_Architecture_Search_for_Mobile_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "285": {"title": "student becoming the master: knowledge amalgamation for joint scene parsing, depth estimation, and more", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Student_Becoming_the_Master_Knowledge_Amalgamation_for_Joint_Scene_Parsing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "286": {"title": "k-nearest neighbors hashing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_K-Nearest_Neighbors_Hashing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "287": {"title": "learning roi transformer for oriented object detection in aerial images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Learning_RoI_Transformer_for_Oriented_Object_Detection_in_Aerial_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "288": {"title": "snapshot distillation: teacher-student optimization in one generation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Snapshot_Distillation_Teacher-Student_Optimization_in_One_Generation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "289": {"title": "geometry-aware distillation for indoor semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jiao_Geometry-Aware_Distillation_for_Indoor_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "290": {"title": "livesketch: query perturbations for guided sketch-based visual search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Collomosse_LiveSketch_Query_Perturbations_for_Guided_Sketch-Based_Visual_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "291": {"title": "bounding box regression with uncertainty for accurate object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Bounding_Box_Regression_With_Uncertainty_for_Accurate_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "292": {"title": "ocgan: one-class novelty detection using gans with constrained latent representations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Perera_OCGAN_One-Class_Novelty_Detection_Using_GANs_With_Constrained_Latent_Representations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "293": {"title": "learning metrics from teachers: compact networks for image embedding", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Learning_Metrics_From_Teachers_Compact_Networks_for_Image_Embedding_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "294": {"title": "activity driven weakly supervised object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Activity_Driven_Weakly_Supervised_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "295": {"title": "separate to adapt: open set domain adaptation via progressive separation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Separate_to_Adapt_Open_Set_Domain_Adaptation_via_Progressive_Separation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "296": {"title": "layout-graph reasoning for fashion landmark detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Layout-Graph_Reasoning_for_Fashion_Landmark_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "297": {"title": "distillhash: unsupervised deep hashing by distilling data pairs", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_DistillHash_Unsupervised_Deep_Hashing_by_Distilling_Data_Pairs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "298": {"title": "mind your neighbours: image annotation with metadata neighbourhood graph co-attention networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Mind_Your_Neighbours_Image_Annotation_With_Metadata_Neighbourhood_Graph_Co-Attention_CVPR_2019_paper.html", "abstract": "As the visual reflections of our daily lives, images are frequently shared on the social network, wh\nich generates the abundant 'metadata' that records user interactions with images. Due to the diverse\n contents and complex styles, some images can be challenging to recognise when neglecting the contex\nt. Images with the similar metadata, such as 'relevant topics and textual descriptions', 'common fri\nends of users' and 'nearby locations', form a neighbourhood for each image, which can be used to ass\nist the annotation. In this paper, we propose a Metadata Neighbourhood Graph Co-Attention Network (M\nangoNet) to model the correlations between each target image and its neighbours. To accurately captu\nre the visual clues from the neighbourhood, a co-attention mechanism is introduced to embed the targ\net image and its neighbours as graph nodes, while the graph edges capture the node pair correlations\n. By reasoning on the neighbourhood graph, we obtain the graph representation to help annotate the t\narget image. Experimental results on three benchmark datasets indicate that our proposed model achie\nves the best performance compared to the state-of-the-art methods.\r", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "299": {"title": "region proposal by guided anchoring", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Region_Proposal_by_Guided_Anchoring_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "300": {"title": "distant supervised centroid shift: a simple and efficient approach to visual domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Distant_Supervised_Centroid_Shift_A_Simple_and_Efficient_Approach_to_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "301": {"title": "learning to transfer examples for partial domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cao_Learning_to_Transfer_Examples_for_Partial_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "302": {"title": "generalized zero-shot recognition based on visually semantic embedding", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Generalized_Zero-Shot_Recognition_Based_on_Visually_Semantic_Embedding_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "303": {"title": "towards visual feature translation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Towards_Visual_Feature_Translation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "304": {"title": "amodal instance segmentation with kins dataset", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qi_Amodal_Instance_Segmentation_With_KINS_Dataset_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "305": {"title": "global second-order pooling convolutional networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Global_Second-Order_Pooling_Convolutional_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "306": {"title": "weakly supervised complementary parts models for fine-grained image classification from the bottom up", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ge_Weakly_Supervised_Complementary_Parts_Models_for_Fine-Grained_Image_Classification_From_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "307": {"title": "nettailor: tuning the architecture, not just the weights", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Morgado_NetTailor_Tuning_the_Architecture_Not_Just_the_Weights_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "308": {"title": "learning-based sampling for natural image matting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tang_Learning-Based_Sampling_for_Natural_Image_Matting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "309": {"title": "learning unsupervised video object segmentation through visual attention", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_Unsupervised_Video_Object_Segmentation_Through_Visual_Attention_CVPR_2019_paper.html", "abstract": "This paper conducts a systematic study on the role of visual attention in Unsupervised Video Object \nSegmentation (UVOS) tasks. By elaborately annotating three popular video segmentation datasets (DAVI\nS, Youtube-Objects and SegTrack V2) with dynamic eye-tracking data in the UVOS setting, for the firs\nt time, we quantitatively verified the high consistency of visual attention behavior among human obs\nervers, and found strong correlation between human attention and explicit primary object judgements \nduring dynamic, task-driven viewing. Such novel observations provide an in-depth insight into the un\nderlying rationale behind UVOS. Inspired by these findings, we decouple UVOS into two sub-tasks: UVO\nS-driven Dynamic Visual Attention Prediction (DVAP) in spatiotemporal domain, and Attention-Guided O\nbject Segmentation (AGOS) in spatial domain. Our UVOS solution enjoys three major merits: 1) modular\n training without using expensive video segmentation annotations, instead, using more affordable dyn\namic fixation data to train the initial video attention module and using existing fixation-segmentat\nion paired static/image data to train the subsequent segmentation module; 2) comprehensive foregroun\nd understanding through multi-source learning; and 3) additional interpretability from the biologica\nlly-inspired and assessable attention. Experiments on popular benchmarks show that, even without usi\nng expensive video object mask annotations, our model achieves compelling performance in comparison \nwith state-of-the-arts. \r", "cite_num": 2, "conf": "cvpr", "time": "2019"}, "310": {"title": "4d spatio-temporal convnets: minkowski convolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Choy_4D_Spatio-Temporal_ConvNets_Minkowski_Convolutional_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "311": {"title": "pyramid feature attention network for saliency detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Pyramid_Feature_Attention_Network_for_Saliency_Detection_CVPR_2019_paper.html", "abstract": "Saliency detection is one of the basic challenges in computer vision. How to extract effective featu\nres is a critical point for saliency detection. Recent methods mainly adopt integrating multi-scale \nconvolutional features indiscriminately. However, not all features are useful for saliency detection\n and some even cause interferences. To solve this problem, we propose Pyramid Feature Attention netw\nork to focus on effective high-level context features and low-level spatial structural features. Fir\nst, we design Context-aware Pyramid Feature Extraction (CPFE) module for multi-scale high-level feat\nure maps to capture rich context features. Second, we adopt channel-wise attention (CA) after CPFE f\neature maps and spatial attention (SA) after low-level feature maps, then fuse outputs of CA & SA to\ngether. Finally, we propose an edge preservation loss to guide network to learn more detailed inform\nation in boundary localization. Extensive evaluations on five benchmark datasets demonstrate that th\ne proposed method outperforms the state-of-the-art approaches under different evaluation metrics.", "cite_num": 2, "conf": "cvpr", "time": "2019"}, "312": {"title": "co-saliency detection via mask-guided fully convolutional networks with multi-scale label smoothing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Co-Saliency_Detection_via_Mask-Guided_Fully_Convolutional_Networks_With_Multi-Scale_Label_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "313": {"title": "sail-vos: semantic amodal instance level video object segmentation - a synthetic dataset and baselines", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_SAIL-VOS_Semantic_Amodal_Instance_Level_Video_Object_Segmentation_-_A_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "314": {"title": "learning instance activation maps for weakly supervised instance segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Learning_Instance_Activation_Maps_for_Weakly_Supervised_Instance_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "315": {"title": "decoders matter for semantic segmentation: data-dependent decoding enables flexible feature aggregation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tian_Decoders_Matter_for_Semantic_Segmentation_Data-Dependent_Decoding_Enables_Flexible_Feature_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "316": {"title": "box-driven class-wise region masking and filling rate guided loss for weakly supervised semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Song_Box-Driven_Class-Wise_Region_Masking_and_Filling_Rate_Guided_Loss_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "317": {"title": "dual attention network for scene segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fu_Dual_Attention_Network_for_Scene_Segmentation_CVPR_2019_paper.html", "abstract": "In this paper, we address the scene segmentation task by capturing rich contextual dependencies base\nd on the selfattention mechanism. Unlike previous works that capture contexts by multi-scale feature\ns fusion, we propose a Dual Attention Networks (DANet) to adaptively integrate local features with t\nheir global dependencies. Specifically, we append two types of attention modules on top of tradition\nal dilated FCN, which model the semantic interdependencies in spatial and channel dimensions respect\nively. The position attention module selectively aggregates the features at each position by a weigh\nted sum of the features at all positions. Similar features would be related to each other regardless\n of their distances. Meanwhile, the channel attention module selectively emphasizes interdependent c\nhannel maps by integrating associated features among all channel maps. We sum the outputs of the two\n attention modules to further improve feature representation which contributes to more precise segme\nntation results. We achieve new state-of-the-art segmentation performance on three challenging scene\n segmentation datasets, i.e., Cityscapes, PASCAL Context and COCO Stuff dataset. In particular, a Me\nan IoU score of 81.5% on Cityscapes test set is achieved without using coarse data. We make the code\n and trained model publicly available at this https URL", "cite_num": 27, "conf": "cvpr", "time": "2019"}, "318": {"title": "inverserendernet: learning single image inverse rendering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_InverseRenderNet_Learning_Single_Image_Inverse_Rendering_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "319": {"title": "a variational auto-encoder model for stochastic point processes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mehrasa_A_Variational_Auto-Encoder_Model_for_Stochastic_Point_Processes_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "320": {"title": "unifying heterogeneous classifiers with distillation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Vongkulbhisal_Unifying_Heterogeneous_Classifiers_With_Distillation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "321": {"title": "assessment of faster r-cnn in man-machine collaborative search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Deza_Assessment_of_Faster_R-CNN_in_Man-Machine_Collaborative_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "322": {"title": "ok-vqa: a visual question answering benchmark requiring external knowledge", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Marino_OK-VQA_A_Visual_Question_Answering_Benchmark_Requiring_External_Knowledge_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "323": {"title": "nddr-cnn: layerwise feature fusing in multi-task cnns by neural discriminative dimensionality reduction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gao_NDDR-CNN_Layerwise_Feature_Fusing_in_Multi-Task_CNNs_by_Neural_Discriminative_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "324": {"title": "spectral metric for dataset complexity assessment", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Branchaud-Charron_Spectral_Metric_for_Dataset_Complexity_Assessment_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "325": {"title": "adcrowdnet: an attention-injective deformable convolutional network for crowd understanding", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_ADCrowdNet_An_Attention-Injective_Deformable_Convolutional_Network_for_Crowd_Understanding_CVPR_2019_paper.html", "abstract": "We propose an attention-injective deformable convolutional network called ADCrowdNet for crowd under\nstanding that can address the accuracy degradation problem of highly congested noisy scenes. ADCrowd\nNet contains two concatenated networks. An attention-aware network called Attention Map Generator (A\nMG) first detects crowd regions in images and computes the congestion degree of these regions. Based\n on detected crowd regions and congestion priors, a multi-scale deformable network called Density Ma\np Estimator (DME) then generates high-quality density maps. With the attention-aware training scheme\n and multi-scale deformable convolutional scheme, the proposed ADCrowdNet achieves the capability of\n being more effective to capture the crowd features and more resistant to various noises. We have ev\naluated our method on four popular crowd counting datasets (ShanghaiTech, UCF_CC_50, WorldEXPO'10, a\nnd UCSD) and an extra vehicle counting dataset TRANCOS, and our approach beats existing state-of-the\n-art approaches on all of these datasets.", "cite_num": 3, "conf": "cvpr", "time": "2019"}, "326": {"title": "veri-wild: a large dataset and a new method for vehicle re-identification in the wild", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lou_VERI-Wild_A_Large_Dataset_and_a_New_Method_for_Vehicle_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "327": {"title": "3d local features for direct pairwise registration", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Deng_3D_Local_Features_for_Direct_Pairwise_Registration_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "328": {"title": "hplflownet: hierarchical permutohedral lattice flownet for scene flow estimation on large-scale point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gu_HPLFlowNet_Hierarchical_Permutohedral_Lattice_FlowNet_for_Scene_Flow_Estimation_on_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "329": {"title": "gpsfm: global projective sfm using algebraic constraints on multi-view fundamental matrices", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kasten_GPSfM_Global_Projective_SFM_Using_Algebraic_Constraints_on_Multi-View_Fundamental_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "330": {"title": "group-wise correlation stereo network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Group-Wise_Correlation_Stereo_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "331": {"title": "multi-level context ultra-aggregation for stereo matching", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Nie_Multi-Level_Context_Ultra-Aggregation_for_Stereo_Matching_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "332": {"title": "large-scale, metric structure from motion for unordered light fields", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Nousias_Large-Scale_Metric_Structure_From_Motion_for_Unordered_Light_Fields_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "333": {"title": "understanding the limitations of cnn-based absolute camera pose regression", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sattler_Understanding_the_Limitations_of_CNN-Based_Absolute_Camera_Pose_Regression_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "334": {"title": "deeplidar: deep surface normal guided depth prediction for outdoor scene from sparse lidar data and single color image", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qiu_DeepLiDAR_Deep_Surface_Normal_Guided_Depth_Prediction_for_Outdoor_Scene_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "335": {"title": "modeling point clouds with self-attention and gumbel subset sampling", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Modeling_Point_Clouds_With_Self-Attention_and_Gumbel_Subset_Sampling_CVPR_2019_paper.html", "abstract": "Geometric deep learning is increasingly important thanks to the popularity of 3D sensors. Inspired b\ny the recent advances in NLP domain, the self-attention transformer is introduced to consume the poi\nnt clouds. We develop Point Attention Transformers (PATs), using a parameter-efficient Group Shuffle\n Attention (GSA) to replace the costly Multi-Head Attention. We demonstrate its ability to process s\nize-varying inputs, and prove its permutation equivariance. Besides, prior work uses heuristics depe\nndence on the input data (e.g., Furthest Point Sampling) to hierarchically select subsets of input p\noints. Thereby, we for the first time propose an end-to-end learnable and task-agnostic sampling ope\nration, named Gumbel Subset Sampling (GSS), to select a representative subset of input points. Equip\nped with Gumbel-Softmax, it produces a \"soft\" continuous subset in training phase, and a \"hard\" disc\nrete subset in test phase. By selecting representative subsets in a hierarchical fashion, the networ\nks learn a stronger representation of the input sets with lower computation cost. Experiments on cla\nssification and segmentation benchmarks show the effectiveness and efficiency of our methods. Furthe\nrmore, we propose a novel application, to process event camera stream as point clouds, and achieve a\n state-of-the-art performance on DVS128 Gesture Dataset.", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "336": {"title": "learning with batch-wise optimal transport loss for 3d shape recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Learning_With_Batch-Wise_Optimal_Transport_Loss_for_3D_Shape_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "337": {"title": "densefusion: 6d object pose estimation by iterative dense fusion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_DenseFusion_6D_Object_Pose_Estimation_by_Iterative_Dense_Fusion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "338": {"title": "dense depth posterior (ddp) from single image and sparse range", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Dense_Depth_Posterior_DDP_From_Single_Image_and_Sparse_Range_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "339": {"title": "dula-net: a dual-projection network for estimating room layouts from a single rgb panorama", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_DuLa-Net_A_Dual-Projection_Network_for_Estimating_Room_Layouts_From_a_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "340": {"title": "veritatem dies aperit - temporally consistent depth prediction enabled by a multi-task geometric and semantic scene understanding approach", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Atapour-Abarghouei_Veritatem_Dies_Aperit_-_Temporally_Consistent_Depth_Prediction_Enabled_by_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "341": {"title": "segmentation-driven 6d object pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Segmentation-Driven_6D_Object_Pose_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "342": {"title": "exploiting temporal context for 3d human pose estimation in the wild", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Arnab_Exploiting_Temporal_Context_for_3D_Human_Pose_Estimation_in_the_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "343": {"title": "what do single-view 3d reconstruction networks learn?", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tatarchenko_What_Do_Single-View_3D_Reconstruction_Networks_Learn_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "344": {"title": "uniformface: learning deep equidistributed representation for face recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Duan_UniformFace_Learning_Deep_Equidistributed_Representation_for_Face_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "345": {"title": "semantic graph convolutional networks for 3d human pose regression", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Semantic_Graph_Convolutional_Networks_for_3D_Human_Pose_Regression_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "346": {"title": "mask-guided portrait editing with conditional gans", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gu_Mask-Guided_Portrait_Editing_With_Conditional_GANs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "347": {"title": "group sampling for scale invariant face detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ming_Group_Sampling_for_Scale_Invariant_Face_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "348": {"title": "joint representation and estimator learning for facial action unit intensity estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Joint_Representation_and_Estimator_Learning_for_Facial_Action_Unit_Intensity_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "349": {"title": "semantic alignment: finding semantically consistent ground-truth for facial landmark detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Semantic_Alignment_Finding_Semantically_Consistent_Ground-Truth_for_Facial_Landmark_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "350": {"title": "laeo-net: revisiting people looking at each other in videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Marin-Jimenez_LAEO-Net_Revisiting_People_Looking_at_Each_Other_in_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "351": {"title": "robust facial landmark detection via occlusion-adaptive deep networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Robust_Facial_Landmark_Detection_via_Occlusion-Adaptive_Deep_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "352": {"title": "learning individual styles of conversational gesture", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ginosar_Learning_Individual_Styles_of_Conversational_Gesture_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "353": {"title": "face anti-spoofing: model matters, so does data", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Face_Anti-Spoofing_Model_Matters_so_Does_Data_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "354": {"title": "fast human pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Fast_Human_Pose_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "355": {"title": "decorrelated adversarial learning for age-invariant face recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Decorrelated_Adversarial_Learning_for_Age-Invariant_Face_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "356": {"title": "cross-task weakly supervised learning from instructional videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhukov_Cross-Task_Weakly_Supervised_Learning_From_Instructional_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "357": {"title": "d3tw: discriminative differentiable dynamic time warping for weakly supervised action alignment and segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chang_D3TW_Discriminative_Differentiable_Dynamic_Time_Warping_for_Weakly_Supervised_Action_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "358": {"title": "progressive teacher-student learning for early action prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Progressive_Teacher-Student_Learning_for_Early_Action_Prediction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "359": {"title": "social relation recognition from videos via multi-scale spatial-temporal reasoning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Social_Relation_Recognition_From_Videos_via_Multi-Scale_Spatial-Temporal_Reasoning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "360": {"title": "ms-tcn: multi-stage temporal convolutional network for action segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Abu_Farha_MS-TCN_Multi-Stage_Temporal_Convolutional_Network_for_Action_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "361": {"title": "transferable interactiveness knowledge for human-object interaction detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Transferable_Interactiveness_Knowledge_for_Human-Object_Interaction_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "362": {"title": "actional-structural graph convolutional networks for skeleton-based action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Actional-Structural_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "363": {"title": "multi-granularity generator for temporal action proposal", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Multi-Granularity_Generator_for_Temporal_Action_Proposal_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "364": {"title": "deep rigid instance scene flow", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ma_Deep_Rigid_Instance_Scene_Flow_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "365": {"title": "see more, know more: unsupervised video object segmentation with co-attention siamese networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lu_See_More_Know_More_Unsupervised_Video_Object_Segmentation_With_Co-Attention_CVPR_2019_paper.html", "abstract": "We introduce a novel network, called as CO-attention Siamese Network (COSNet), to address the unsupe\nrvised video object segmentation task from a holistic view. We emphasize the importance of inherent \ncorrelation among video frames and incorporate a global co-attention mechanism to improve further th\ne state-of-the-art deep learning based solutions that primarily focus on learning discriminative for\neground representations over appearance and motion in short-term temporal segments. The co-attention\n layers in our network provide efficient and competent stages for capturing global correlations and \nscene context by jointly computing and appending co-attention responses into a joint feature space. \nWe train COSNet with pairs of video frames, which naturally augments training data and allows increa\nsed learning capacity. During the segmentation stage, the co-attention model encodes useful informat\nion by processing multiple reference frames together, which is leveraged to infer the frequently rea\nppearing and salient foreground objects better. We propose a unified and end-to-end trainable framew\nork where different co-attention variants can be derived for mining the rich context within videos. \nOur extensive experiments over three large benchmarks manifest that COSNet outperforms the current a\nlternatives by a large margin. We will publicly release our implementation and models.\r", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "366": {"title": "patch-based discriminative feature learning for unsupervised person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Patch-Based_Discriminative_Feature_Learning_for_Unsupervised_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "367": {"title": "spm-tracker: series-parallel matching for real-time visual object tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_SPM-Tracker_Series-Parallel_Matching_for_Real-Time_Visual_Object_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "368": {"title": "spatial fusion gan for image synthesis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhan_Spatial_Fusion_GAN_for_Image_Synthesis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "369": {"title": "text guided person image synthesis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Text_Guided_Person_Image_Synthesis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "370": {"title": "stgan: a unified selective transfer network for arbitrary image attribute editing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_STGAN_A_Unified_Selective_Transfer_Network_for_Arbitrary_Image_Attribute_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "371": {"title": "towards instance-level image-to-image translation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shen_Towards_Instance-Level_Image-To-Image_Translation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "372": {"title": "dense intrinsic appearance flow for human pose transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Dense_Intrinsic_Appearance_Flow_for_Human_Pose_Transfer_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "373": {"title": "depth-aware video frame interpolation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Bao_Depth-Aware_Video_Frame_Interpolation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "374": {"title": "sliced wasserstein generative models", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Sliced_Wasserstein_Generative_Models_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "375": {"title": "deep flow-guided video inpainting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Deep_Flow-Guided_Video_Inpainting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "376": {"title": "video generation from single semantic label map", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Video_Generation_From_Single_Semantic_Label_Map_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "377": {"title": "polarimetric camera calibration using an lcd monitor", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Polarimetric_Camera_Calibration_Using_an_LCD_Monitor_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "378": {"title": "fully automatic video colorization with self-regularization and diversity", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lei_Fully_Automatic_Video_Colorization_With_Self-Regularization_and_Diversity_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "379": {"title": "zoom to learn, learn to zoom", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Zoom_to_Learn_Learn_to_Zoom_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "380": {"title": "single image reflection removal beyond linearity", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wen_Single_Image_Reflection_Removal_Beyond_Linearity_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "381": {"title": "learning to separate multiple illuminants in a single image", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hui_Learning_to_Separate_Multiple_Illuminants_in_a_Single_Image_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "382": {"title": "shape unicode: a unified shape representation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Muralikrishnan_Shape_Unicode_A_Unified_Shape_Representation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "383": {"title": "robust video stabilization by optimization in cnn weight space", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Robust_Video_Stabilization_by_Optimization_in_CNN_Weight_Space_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "384": {"title": "learning linear transformations for fast image and video style transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_Linear_Transformations_for_Fast_Image_and_Video_Style_Transfer_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "385": {"title": "local detection of stereo occlusion boundaries", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Local_Detection_of_Stereo_Occlusion_Boundaries_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "386": {"title": "bi-directional cascade network for perceptual edge detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Bi-Directional_Cascade_Network_for_Perceptual_Edge_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "387": {"title": "single image deraining: a comprehensive benchmark analysis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Single_Image_Deraining_A_Comprehensive_Benchmark_Analysis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "388": {"title": "dynamic scene deblurring with parameter selective sharing and nested skip connections", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Dynamic_Scene_Deblurring_With_Parameter_Selective_Sharing_and_Nested_Skip_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "389": {"title": "events-to-video: bringing modern computer vision to event cameras", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Rebecq_Events-To-Video_Bringing_Modern_Computer_Vision_to_Event_Cameras_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "390": {"title": "feedback network for image super-resolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Feedback_Network_for_Image_Super-Resolution_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "391": {"title": "semi-supervised transfer learning for image rain removal", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Semi-Supervised_Transfer_Learning_for_Image_Rain_Removal_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "392": {"title": "eventnet: asynchronous recursive event processing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sekikawa_EventNet_Asynchronous_Recursive_Event_Processing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "393": {"title": "recurrent back-projection network for video super-resolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Haris_Recurrent_Back-Projection_Network_for_Video_Super-Resolution_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "394": {"title": "cascaded partial decoder for fast and accurate salient object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Cascaded_Partial_Decoder_for_Fast_and_Accurate_Salient_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "395": {"title": "a simple pooling-based design for real-time salient object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_A_Simple_Pooling-Based_Design_for_Real-Time_Salient_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "396": {"title": "contrast prior and fluid pyramid integration for rgbd salient object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Contrast_Prior_and_Fluid_Pyramid_Integration_for_RGBD_Salient_Object_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "397": {"title": "progressive image deraining networks: a better and simpler baseline", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ren_Progressive_Image_Deraining_Networks_A_Better_and_Simpler_Baseline_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "398": {"title": "gspn: generative shape proposal network for 3d instance segmentation in point cloud", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yi_GSPN_Generative_Shape_Proposal_Network_for_3D_Instance_Segmentation_in_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "399": {"title": "attentive relational networks for mapping images to scene graphs", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qi_Attentive_Relational_Networks_for_Mapping_Images_to_Scene_Graphs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "400": {"title": "relational knowledge distillation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Park_Relational_Knowledge_Distillation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "401": {"title": "compressing convolutional neural networks via factorized convolutional filters", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Compressing_Convolutional_Neural_Networks_via_Factorized_Convolutional_Filters_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "402": {"title": "on the intrinsic dimensionality of image representations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gong_On_the_Intrinsic_Dimensionality_of_Image_Representations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "403": {"title": "part-regularized near-duplicate vehicle re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Part-Regularized_Near-Duplicate_Vehicle_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "404": {"title": "self-supervised spatio-temporal representation learning for videos by predicting motion and appearance statistics", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Self-Supervised_Spatio-Temporal_Representation_Learning_for_Videos_by_Predicting_Motion_and_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "405": {"title": "classification-reconstruction learning for open-set recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yoshihashi_Classification-Reconstruction_Learning_for_Open-Set_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "406": {"title": "emotion-aware human attention prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cordel_Emotion-Aware_Human_Attention_Prediction_CVPR_2019_paper.html", "abstract": "Despite the recent success in face recognition and object classification, in the field of human gaze\n prediction, computer models are still struggling to accurately mimic human attention. One main reas\non is that visual attention is a complex human behavior influenced by multiple factors, ranging from\n low-level features (e.g., color, contrast) to high-level human perception (e.g., objects interactio\nns, object sentiment), making it difficult to model computationally. In this work, we investigate th\ne relation between object sentiment and human attention. We first introduce a new evaluation metric \n(AttI) for measuring human attention that focuses on human fixation consensus. A series of empirical\n data analyses with AttI indicate that emotion-evoking objects receive attention favor, especially w\nhen they co-occur with emotionally-neutral objects, and this favor varies with different image compl\nexity. Based on the empirical analyses, we design a deep neural network for human attention predicti\non which allows the attention bias on emotion-evoking objects to be encoded in its feature space. Ex\nperiments on two benchmark datasets demonstrate its superior performance, especially on metrics that\n evaluate relative importance of salient regions. This research provides the clearest picture to dat\ne on how object sentiments influence human attention, and it makes one of the first attempts to mode\nl this phenomenon computationally.\r", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "407": {"title": "residual regression with semantic prior for crowd counting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wan_Residual_Regression_With_Semantic_Prior_for_Crowd_Counting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "408": {"title": "context-reinforced semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Context-Reinforced_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "409": {"title": "adversarial structure matching for structured prediction tasks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hwang_Adversarial_Structure_Matching_for_Structured_Prediction_Tasks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "410": {"title": "deep spectral clustering using dual autoencoder network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Deep_Spectral_Clustering_Using_Dual_Autoencoder_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "411": {"title": "deep asymmetric metric learning via rich relationship mining", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Deep_Asymmetric_Metric_Learning_via_Rich_Relationship_Mining_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "412": {"title": "did it change? learning to detect point-of-interest changes for proactive map updates", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Revaud_Did_It_Change_Learning_to_Detect_Point-Of-Interest_Changes_for_Proactive_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "413": {"title": "associatively segmenting instances and semantics in point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Associatively_Segmenting_Instances_and_Semantics_in_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "414": {"title": "pattern-affinitive propagation across depth, surface normal and semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Pattern-Affinitive_Propagation_Across_Depth_Surface_Normal_and_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "415": {"title": "scene categorization from contours: medial axis based salience measures", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Rezanejad_Scene_Categorization_From_Contours_Medial_Axis_Based_Salience_Measures_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "416": {"title": "unsupervised image captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Feng_Unsupervised_Image_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "417": {"title": "exact adversarial attack to image captioning via structured output learning with latent variables", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Exact_Adversarial_Attack_to_Image_Captioning_via_Structured_Output_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "418": {"title": "cross-modal relationship inference for grounding referring expressions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Cross-Modal_Relationship_Inference_for_Grounding_Referring_Expressions_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "419": {"title": "what's to know? uncertainty as a guide to asking goal-oriented questions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Abbasnejad_Whats_to_Know_Uncertainty_as_a_Guide_to_Asking_Goal-Oriented_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "420": {"title": "iterative alignment network for continuous sign language recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pu_Iterative_Alignment_Network_for_Continuous_Sign_Language_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "421": {"title": "neural sequential phrase grounding (seqground)", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dogan_Neural_Sequential_Phrase_Grounding_SeqGROUND_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "422": {"title": "clevr-ref+: diagnosing visual reasoning with referring expressions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_CLEVR-Ref_Diagnosing_Visual_Reasoning_With_Referring_Expressions_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "423": {"title": "describing like humans: on diversity in image captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Describing_Like_Humans_On_Diversity_in_Image_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "424": {"title": "mscap: multi-style image captioning with unpaired stylized text", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Guo_MSCap_Multi-Style_Image_Captioning_With_Unpaired_Stylized_Text_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "425": {"title": "craves: controlling robotic arm with a vision-based economic system", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zuo_CRAVES_Controlling_Robotic_Arm_With_a_Vision-Based_Economic_System_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "426": {"title": "networks for joint affine and non-parametric image registration", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shen_Networks_for_Joint_Affine_and_Non-Parametric_Image_Registration_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "427": {"title": "learning shape-aware embedding for scene text detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tian_Learning_Shape-Aware_Embedding_for_Scene_Text_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "428": {"title": "learning to film from professional human motion videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Learning_to_Film_From_Professional_Human_Motion_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "429": {"title": "pay attention! - robustifying a deep visuomotor policy through task-focused visual attention", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Abolghasemi_Pay_Attention_-_Robustifying_a_Deep_Visuomotor_Policy_Through_Task-Focused_CVPR_2019_paper.html", "abstract": "Several recent studies have demonstrated the promise of deep visuomotor policies for robot manipulat\nor control. Despite impressive progress, these systems are known to be vulnerable to physical distur\nbances, such as accidental or adversarial bumps that make them drop the manipulated object. They als\no tend to be distracted by visual disturbances such as objects moving in the robot's field of view, \neven if the disturbance does not physically prevent the execution of the task. In this paper, we pro\npose an approach for augmenting a deep visuomotor policy trained through demonstrations with Task Fo\ncused visual Attention (TFA). The manipulation task is specified with a natural language text such a\ns \"move the red bowl to the left\". This allows the visual attention component to concentrate on the \ncurrent object that the robot needs to manipulate. We show that even in benign environments, the TFA\n allows the policy to consistently outperform a variant with no attention mechanism. More importantl\ny, the new policy is significantly more robust: it regularly recovers from severe physical disturban\nces (such as bumps causing it to drop the object) from which the baseline policy, i.e. with no visua\nl attention, almost never recovers. In addition, we show that the proposed policy performs correctly\n in the presence of a wide class of visual disturbances, exhibiting a behavior reminiscent of human \nselective visual attention experiments. \r", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "430": {"title": "deep blind video decaptioning by temporal aggregation and recurrence", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Deep_Blind_Video_Decaptioning_by_Temporal_Aggregation_and_Recurrence_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "431": {"title": "learning video representations from correspondence proposals", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Learning_Video_Representations_From_Correspondence_Proposals_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "432": {"title": "siamrpn++: evolution of siamese visual tracking with very deep networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_SiamRPN_Evolution_of_Siamese_Visual_Tracking_With_Very_Deep_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "433": {"title": "sphere generative adversarial network based on geometric moment matching", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Park_Sphere_Generative_Adversarial_Network_Based_on_Geometric_Moment_Matching_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "434": {"title": "adversarial attacks beyond the image space", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Adversarial_Attacks_Beyond_the_Image_Space_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "435": {"title": "evading defenses to transferable adversarial examples by translation-invariant attacks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Evading_Defenses_to_Transferable_Adversarial_Examples_by_Translation-Invariant_Attacks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "436": {"title": "decoupling direction and norm for efficient gradient-based l2 adversarial attacks and defenses", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Rony_Decoupling_Direction_and_Norm_for_Efficient_Gradient-Based_L2_Adversarial_Attacks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "437": {"title": "a general and adaptive robust loss function", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Barron_A_General_and_Adaptive_Robust_Loss_Function_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "438": {"title": "filter pruning via geometric median for deep convolutional neural networks acceleration", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Filter_Pruning_via_Geometric_Median_for_Deep_Convolutional_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "439": {"title": "learning to quantize deep networks by optimizing quantization intervals with task loss", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jung_Learning_to_Quantize_Deep_Networks_by_Optimizing_Quantization_Intervals_With_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "440": {"title": "not all areas are equal: transfer learning for semantic segmentation via hierarchical region selection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Not_All_Areas_Are_Equal_Transfer_Learning_for_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "441": {"title": "unsupervised learning of dense shape correspondence", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Halimi_Unsupervised_Learning_of_Dense_Shape_Correspondence_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "442": {"title": "unsupervised visual domain adaptation: a deep max-margin gaussian process approach", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Unsupervised_Visual_Domain_Adaptation_A_Deep_Max-Margin_Gaussian_Process_Approach_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "443": {"title": "balanced self-paced learning for generative adversarial clustering network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ghasedi_Balanced_Self-Paced_Learning_for_Generative_Adversarial_Clustering_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "444": {"title": "a style-based generator architecture for generative adversarial networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "445": {"title": "parallel optimal transport gan", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Avraham_Parallel_Optimal_Transport_GAN_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "446": {"title": "3d-sis: 3d semantic instance segmentation of rgb-d scans", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hou_3D-SIS_3D_Semantic_Instance_Segmentation_of_RGB-D_Scans_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "447": {"title": "causes and corrections for bimodal multi-path scanning with structured light", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Causes_and_Corrections_for_Bimodal_Multi-Path_Scanning_With_Structured_Light_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "448": {"title": "texturenet: consistent local parametrizations for learning from high-resolution signals on meshes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Huang_TextureNet_Consistent_Local_Parametrizations_for_Learning_From_High-Resolution_Signals_on_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "449": {"title": "planercnn: 3d plane detection and reconstruction from a single image", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_PlaneRCNN_3D_Plane_Detection_and_Reconstruction_From_a_Single_Image_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "450": {"title": "occupancy networks: learning 3d reconstruction in function space", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mescheder_Occupancy_Networks_Learning_3D_Reconstruction_in_Function_Space_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "451": {"title": "3d shape reconstruction from images in the frequency domain", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shen_3D_Shape_Reconstruction_From_Images_in_the_Frequency_Domain_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "452": {"title": "siclope: silhouette-based clothed people", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Natsume_SiCloPe_Silhouette-Based_Clothed_People_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "453": {"title": "detailed human shape estimation from a single image by hierarchical mesh deformation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Detailed_Human_Shape_Estimation_From_a_Single_Image_by_Hierarchical_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "454": {"title": "convolutional mesh regression for single-image human shape reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kolotouros_Convolutional_Mesh_Regression_for_Single-Image_Human_Shape_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "455": {"title": "h+o: unified egocentric recognition of 3d hand-object poses and interactions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tekin_HO_Unified_Egocentric_Recognition_of_3D_Hand-Object_Poses_and_Interactions_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "456": {"title": "learning the depths of moving people by watching frozen people", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_the_Depths_of_Moving_People_by_Watching_Frozen_People_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "457": {"title": "extreme relative pose estimation for rgb-d scans via scene completion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Extreme_Relative_Pose_Estimation_for_RGB-D_Scans_via_Scene_Completion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "458": {"title": "a skeleton-bridged deep learning approach for generating meshes of complex topologies from single rgb images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tang_A_Skeleton-Bridged_Deep_Learning_Approach_for_Generating_Meshes_of_Complex_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "459": {"title": "learning structure-and-motion-aware rolling shutter correction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhuang_Learning_Structure-And-Motion-Aware_Rolling_Shutter_Correction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "460": {"title": "pvnet: pixel-wise voting network for 6dof pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Peng_PVNet_Pixel-Wise_Voting_Network_for_6DoF_Pose_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "461": {"title": "selflow: self-supervised learning of optical flow", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_SelFlow_Self-Supervised_Learning_of_Optical_Flow_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "462": {"title": "taking a deeper look at the inverse compositional algorithm", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lv_Taking_a_Deeper_Look_at_the_Inverse_Compositional_Algorithm_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "463": {"title": "deeper and wider siamese networks for real-time visual tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deeper_and_Wider_Siamese_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "464": {"title": "self-supervised adaptation of high-fidelity face models for monocular performance tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yoon_Self-Supervised_Adaptation_of_High-Fidelity_Face_Models_for_Monocular_Performance_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "465": {"title": "diverse generation for multi-agent sports games", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yeh_Diverse_Generation_for_Multi-Agent_Sports_Games_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "466": {"title": "efficient online multi-person 2d pose tracking with recurrent spatio-temporal affinity fields", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Raaj_Efficient_Online_Multi-Person_2D_Pose_Tracking_With_Recurrent_Spatio-Temporal_Affinity_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "467": {"title": "gframes: gradient-based local reference frame for 3d shape matching", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Melzi_GFrames_Gradient-Based_Local_Reference_Frame_for_3D_Shape_Matching_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "468": {"title": "eliminating exposure bias and metric mismatch in multiple object tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Maksai_Eliminating_Exposure_Bias_and_Metric_Mismatch_in_Multiple_Object_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "469": {"title": "graph convolutional tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Graph_Convolutional_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "470": {"title": "atom: accurate tracking by overlap maximization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Danelljan_ATOM_Accurate_Tracking_by_Overlap_Maximization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "471": {"title": "visual tracking via adaptive spatially-regularized correlation filters", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dai_Visual_Tracking_via_Adaptive_Spatially-Regularized_Correlation_Filters_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "472": {"title": "deep tree learning for zero-shot face anti-spoofing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Deep_Tree_Learning_for_Zero-Shot_Face_Anti-Spoofing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "473": {"title": "arcface: additive angular margin loss for deep face recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Deng_ArcFace_Additive_Angular_Margin_Loss_for_Deep_Face_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "474": {"title": "learning joint gait representation via quintuplet loss minimization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Learning_Joint_Gait_Representation_via_Quintuplet_Loss_Minimization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "475": {"title": "gait recognition via disentangled representation learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Gait_Recognition_via_Disentangled_Representation_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "476": {"title": "reversible gans for memory-efficient image-to-image translation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/van_der_Ouderaa_Reversible_GANs_for_Memory-Efficient_Image-To-Image_Translation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "477": {"title": "sensitive-sample fingerprinting of deep neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Sensitive-Sample_Fingerprinting_of_Deep_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "478": {"title": "soft labels for ordinal regression", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Diaz_Soft_Labels_for_Ordinal_Regression_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "479": {"title": "local to global learning: gradually adding classes for training deep neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_Local_to_Global_Learning_Gradually_Adding_Classes_for_Training_Deep_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "480": {"title": "what does it mean to learn in deep networks? and, how does one detect adversarial attacks?", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Corneanu_What_Does_It_Mean_to_Learn_in_Deep_Networks_And_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "481": {"title": "handwriting recognition in low-resource scripts using adversarial learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Bhunia_Handwriting_Recognition_in_Low-Resource_Scripts_Using_Adversarial_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "482": {"title": "adversarial defense through network profiling based path extraction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qiu_Adversarial_Defense_Through_Network_Profiling_Based_Path_Extraction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "483": {"title": "renas: reinforced evolutionary neural architecture search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_RENAS_Reinforced_Evolutionary_Neural_Architecture_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "484": {"title": "co-occurrence neural network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shevlev_Co-Occurrence_Neural_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "485": {"title": "spottune: transfer learning through adaptive fine-tuning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Guo_SpotTune_Transfer_Learning_Through_Adaptive_Fine-Tuning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "486": {"title": "signal-to-noise ratio: a robust distance metric for deep metric learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yuan_Signal-To-Noise_Ratio_A_Robust_Distance_Metric_for_Deep_Metric_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "487": {"title": "detection based defense against adversarial examples from the steganalysis point of view", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Detection_Based_Defense_Against_Adversarial_Examples_From_the_Steganalysis_Point_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "488": {"title": "hetconv: heterogeneous kernel-based convolutions for deep cnns", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Singh_HetConv_Heterogeneous_Kernel-Based_Convolutions_for_Deep_CNNs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "489": {"title": "strike (with) a pose: neural networks are easily fooled by strange poses of familiar objects", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Alcorn_Strike_With_a_Pose_Neural_Networks_Are_Easily_Fooled_by_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "490": {"title": "blind geometric distortion correction on images through deep learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Blind_Geometric_Distortion_Correction_on_Images_Through_Deep_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "491": {"title": "instance-level meta normalization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jia_Instance-Level_Meta_Normalization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "492": {"title": "iterative normalization: beyond standardization towards efficient whitening", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Iterative_Normalization_Beyond_Standardization_Towards_Efficient_Whitening_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "493": {"title": "on learning density aware embeddings", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ghosh_On_Learning_Density_Aware_Embeddings_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "494": {"title": "contrastive adaptation network for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kang_Contrastive_Adaptation_Network_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "495": {"title": "lp-3dcnn: unveiling local phase in 3d convolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kumawat_LP-3DCNN_Unveiling_Local_Phase_in_3D_Convolutional_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "496": {"title": "attribute-driven feature disentangling and temporal aggregation for video person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Attribute-Driven_Feature_Disentangling_and_Temporal_Aggregation_for_Video_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "497": {"title": "binary ensemble neural network: more bits per network or more networks per bit?", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Binary_Ensemble_Neural_Network_More_Bits_per_Network_or_More_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "498": {"title": "distilling object detectors with fine-grained feature imitation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Distilling_Object_Detectors_With_Fine-Grained_Feature_Imitation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "499": {"title": "centripetal sgd for pruning very deep convolutional networks with complicated structure", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Centripetal_SGD_for_Pruning_Very_Deep_Convolutional_Networks_With_Complicated_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "500": {"title": "knockoff nets: stealing functionality of black-box models", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Orekondy_Knockoff_Nets_Stealing_Functionality_of_Black-Box_Models_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "501": {"title": "deep embedding learning with discriminative sampling policy", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Duan_Deep_Embedding_Learning_With_Discriminative_Sampling_Policy_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "502": {"title": "hybrid task cascade for instance segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Hybrid_Task_Cascade_for_Instance_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "503": {"title": "multi-task self-supervised object detection via recycling of bounding box annotations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Multi-Task_Self-Supervised_Object_Detection_via_Recycling_of_Bounding_Box_Annotations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "504": {"title": "clusternet: deep hierarchical cluster network with rigorously rotation-invariant representation for point cloud analysis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_ClusterNet_Deep_Hierarchical_Cluster_Network_With_Rigorously_Rotation-Invariant_Representation_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "505": {"title": "learning to learn relation for important people detection in still images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_to_Learn_Relation_for_Important_People_Detection_in_Still_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "506": {"title": "looking for the devil in the details: learning trilinear attention sampling network for fine-grained image recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Looking_for_the_Devil_in_the_Details_Learning_Trilinear_Attention_CVPR_2019_paper.html", "abstract": "Learning subtle yet discriminative features (e.g., beak and eyes for a bird) plays a significant rol\ne in fine-grained image recognition. Existing attention-based approaches localize and amplify signif\nicant parts to learn fine-grained details, which often suffer from a limited number of parts and hea\nvy computational cost. In this paper, we propose to learn such fine-grained features from hundreds o\nf part proposals by Trilinear Attention Sampling Network (TASN) in an efficient teacher-student mann\ner. Specifically, TASN consists of 1) a trilinear attention module, which generates attention maps b\ny modeling the inter-channel relationships, 2) an attention-based sampler which highlights attended \nparts with high resolution, and 3) a feature distiller, which distills part features into an object-\nlevel feature by weight sharing and feature preserving strategies. Extensive experiments verify that\n TASN yields the best performance under the same settings with the most competitive approaches, in i\nNaturalist-2017, CUB-Bird, and Stanford-Cars datasets.\r", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "507": {"title": "multi-similarity loss with general pair weighting for deep metric learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "508": {"title": "domain-symmetric networks for adversarial domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Domain-Symmetric_Networks_for_Adversarial_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "509": {"title": "end-to-end supervised product quantization for image search and retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Klein_End-To-End_Supervised_Product_Quantization_for_Image_Search_and_Retrieval_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "510": {"title": "learning to learn from noisy labeled data", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_to_Learn_From_Noisy_Labeled_Data_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "511": {"title": "dsfd: dual shot face detector", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_DSFD_Dual_Shot_Face_Detector_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "512": {"title": "label propagation for deep semi-supervised learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Iscen_Label_Propagation_for_Deep_Semi-Supervised_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "513": {"title": "deep global generalized gaussian networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Deep_Global_Generalized_Gaussian_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "514": {"title": "semantically tied paired cycle consistency for zero-shot sketch-based image retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dutta_Semantically_Tied_Paired_Cycle_Consistency_for_Zero-Shot_Sketch-Based_Image_Retrieval_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "515": {"title": "context-aware crowd counting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Context-Aware_Crowd_Counting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "516": {"title": "detect-to-retrieve: efficient regional aggregation for image search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Teichmann_Detect-To-Retrieve_Efficient_Regional_Aggregation_for_Image_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "517": {"title": "towards accurate one-stage object detection with ap-loss", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Towards_Accurate_One-Stage_Object_Detection_With_AP-Loss_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "518": {"title": "on exploring undetermined relationships for visual relationship detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhan_On_Exploring_Undetermined_Relationships_for_Visual_Relationship_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "519": {"title": "learning without memorizing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dhar_Learning_Without_Memorizing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "520": {"title": "dynamic recursive neural network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Dynamic_Recursive_Neural_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "521": {"title": "destruction and construction learning for fine-grained image recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Destruction_and_Construction_Learning_for_Fine-Grained_Image_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "522": {"title": "distraction-aware shadow detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Distraction-Aware_Shadow_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "523": {"title": "multi-label image recognition with graph convolutional networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Multi-Label_Image_Recognition_With_Graph_Convolutional_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "524": {"title": "high-level semantic feature detection: a new perspective for pedestrian detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_High-Level_Semantic_Feature_Detection_A_New_Perspective_for_Pedestrian_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "525": {"title": "repmet: representative-based metric learning for classification and few-shot object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Karlinsky_RepMet_Representative-Based_Metric_Learning_for_Classification_and_Few-Shot_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "526": {"title": "ranked list loss for deep metric learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Ranked_List_Loss_for_Deep_Metric_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "527": {"title": "canet: class-agnostic segmentation networks with iterative refinement and attentive few-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_CANet_Class-Agnostic_Segmentation_Networks_With_Iterative_Refinement_and_Attentive_Few-Shot_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "528": {"title": "precise detection in densely packed scenes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Goldman_Precise_Detection_in_Densely_Packed_Scenes_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "529": {"title": "ke-gan: knowledge embedded generative adversarial networks for semi-supervised scene parsing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qi_KE-GAN_Knowledge_Embedded_Generative_Adversarial_Networks_for_Semi-Supervised_Scene_Parsing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "530": {"title": "fast user-guided video object segmentation by interaction-and-propagation networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Oh_Fast_User-Guided_Video_Object_Segmentation_by_Interaction-And-Propagation_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "531": {"title": "fast interactive object annotation with curve-gcn", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ling_Fast_Interactive_Object_Annotation_With_Curve-GCN_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "532": {"title": "ficklenet: weakly and semi-supervised semantic image segmentation using stochastic inference", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_FickleNet_Weakly_and_Semi-Supervised_Semantic_Image_Segmentation_Using_Stochastic_Inference_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "533": {"title": "rvos: end-to-end recurrent network for video object segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ventura_RVOS_End-To-End_Recurrent_Network_for_Video_Object_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "534": {"title": "deepflux for skeletons in the wild", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_DeepFlux_for_Skeletons_in_the_Wild_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "535": {"title": "interactive image segmentation via backpropagating refinement scheme", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jang_Interactive_Image_Segmentation_via_Backpropagating_Refinement_Scheme_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "536": {"title": "scene parsing via integrated classification model and variance-based regularization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Scene_Parsing_via_Integrated_Classification_Model_and_Variance-Based_Regularization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "537": {"title": "raven: a dataset for relational and analogical visual reasoning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_RAVEN_A_Dataset_for_Relational_and_Analogical_Visual_REasoNing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "538": {"title": "surface reconstruction from normals: a robust dgp-based discontinuity preservation approach", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Surface_Reconstruction_From_Normals_A_Robust_DGP-Based_Discontinuity_Preservation_Approach_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "539": {"title": "deepfashion2: a versatile benchmark for detection, pose estimation, segmentation and re-identification of clothing images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ge_DeepFashion2_A_Versatile_Benchmark_for_Detection_Pose_Estimation_Segmentation_and_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "540": {"title": "jumping manifolds: geometry aware dense non-rigid structure from motion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kumar_Jumping_Manifolds_Geometry_Aware_Dense_Non-Rigid_Structure_From_Motion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "541": {"title": "lvis: a dataset for large vocabulary instance segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gupta_LVIS_A_Dataset_for_Large_Vocabulary_Instance_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "542": {"title": "fast object class labelling via speech", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gygli_Fast_Object_Class_Labelling_via_Speech_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "543": {"title": "lasot: a high-quality benchmark for large-scale single object tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fan_LaSOT_A_High-Quality_Benchmark_for_Large-Scale_Single_Object_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "544": {"title": "creative flow+ dataset", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shugrina_Creative_Flow_Dataset_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "545": {"title": "weakly supervised open-set domain adaptation by dual-domain collaboration", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tan_Weakly_Supervised_Open-Set_Domain_Adaptation_by_Dual-Domain_Collaboration_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "546": {"title": "a neurobiological evaluation metric for neural network model search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Blanchard_A_Neurobiological_Evaluation_Metric_for_Neural_Network_Model_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "547": {"title": "iterative projection and matching: finding structure-preserving representatives and its application to computer vision", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zaeemzadeh_Iterative_Projection_and_Matching_Finding_Structure-Preserving_Representatives_and_Its_Application_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "548": {"title": "efficient multi-domain learning by covariance normalization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Efficient_Multi-Domain_Learning_by_Covariance_Normalization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "549": {"title": "predicting visible image differences under varying display brightness and viewing distance", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Predicting_Visible_Image_Differences_Under_Varying_Display_Brightness_and_Viewing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "550": {"title": "a bayesian perspective on the deep image prior", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_A_Bayesian_Perspective_on_the_Deep_Image_Prior_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "551": {"title": "apollocar3d: a large 3d car instance understanding benchmark for autonomous driving", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Song_ApolloCar3D_A_Large_3D_Car_Instance_Understanding_Benchmark_for_Autonomous_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "552": {"title": "compressing unknown images with product quantizer for efficient zero-shot classification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Compressing_Unknown_Images_With_Product_Quantizer_for_Efficient_Zero-Shot_Classification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "553": {"title": "self-supervised convolutional subspace clustering network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Self-Supervised_Convolutional_Subspace_Clustering_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "554": {"title": "multi-scale geometric consistency guided multi-view stereo", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Multi-Scale_Geometric_Consistency_Guided_Multi-View_Stereo_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "555": {"title": "privacy preserving image-based localization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Speciale_Privacy_Preserving_Image-Based_Localization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "556": {"title": "simulcap : single-view human performance capture with cloth simulation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_SimulCap__Single-View_Human_Performance_Capture_With_Cloth_Simulation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "557": {"title": "hierarchical deep stereo matching on high-resolution images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Hierarchical_Deep_Stereo_Matching_on_High-Resolution_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "558": {"title": "recurrent mvsnet for high-resolution multi-view stereo depth inference", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yao_Recurrent_MVSNet_for_High-Resolution_Multi-View_Stereo_Depth_Inference_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "559": {"title": "synthesizing 3d shapes from silhouette image collections using multi-projection generative adversarial networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Synthesizing_3D_Shapes_From_Silhouette_Image_Collections_Using_Multi-Projection_Generative_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "560": {"title": "the perfect match: 3d point cloud matching with smoothed densities", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gojcic_The_Perfect_Match_3D_Point_Cloud_Matching_With_Smoothed_Densities_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "561": {"title": "recurrent neural network for (un-)supervised learning of monocular video visual odometry and depth", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Recurrent_Neural_Network_for_Un-Supervised_Learning_of_Monocular_Video_Visual_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "562": {"title": "pointweb: enhancing local neighborhood features for point cloud processing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_PointWeb_Enhancing_Local_Neighborhood_Features_for_Point_Cloud_Processing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "563": {"title": "scan2mesh: from unstructured range scans to 3d meshes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dai_Scan2Mesh_From_Unstructured_Range_Scans_to_3D_Meshes_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "564": {"title": "unsupervised domain adaptation for tof data denoising with adversarial learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Agresti_Unsupervised_Domain_Adaptation_for_ToF_Data_Denoising_With_Adversarial_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "565": {"title": "learning independent object motion from unlabelled stereoscopic videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cao_Learning_Independent_Object_Motion_From_Unlabelled_Stereoscopic_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "566": {"title": "learning single-image depth from videos using quality assessment networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Single-Image_Depth_From_Videos_Using_Quality_Assessment_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "567": {"title": "learning 3d human dynamics from video", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kanazawa_Learning_3D_Human_Dynamics_From_Video_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "568": {"title": "lending orientation to neural networks for cross-view geo-localization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Lending_Orientation_to_Neural_Networks_for_Cross-View_Geo-Localization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "569": {"title": "visual localization by learning objects-of-interest dense match regression", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Weinzaepfel_Visual_Localization_by_Learning_Objects-Of-Interest_Dense_Match_Regression_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "570": {"title": "bilateral cyclic constraint and adaptive regularization for unsupervised monocular depth prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wong_Bilateral_Cyclic_Constraint_and_Adaptive_Regularization_for_Unsupervised_Monocular_Depth_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "571": {"title": "face parsing with roi tanh-warping", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lin_Face_Parsing_With_RoI_Tanh-Warping_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "572": {"title": "multi-person articulated tracking with spatial and temporal embeddings", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jin_Multi-Person_Articulated_Tracking_With_Spatial_and_Temporal_Embeddings_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "573": {"title": "multi-person pose estimation with enhanced channel-wise and spatial information", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Su_Multi-Person_Pose_Estimation_With_Enhanced_Channel-Wise_and_Spatial_Information_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "574": {"title": "a compact embedding for facial expression similarity", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Vemulapalli_A_Compact_Embedding_for_Facial_Expression_Similarity_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "575": {"title": "deep high-resolution representation learning for human pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Deep_High-Resolution_Representation_Learning_for_Human_Pose_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "576": {"title": "feature transfer learning for face recognition with under-represented data", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yin_Feature_Transfer_Learning_for_Face_Recognition_With_Under-Represented_Data_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "577": {"title": "unsupervised 3d pose estimation with geometric self-supervision", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Unsupervised_3D_Pose_Estimation_With_Geometric_Self-Supervision_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "578": {"title": "peeking into the future: predicting future person activities and locations in videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Peeking_Into_the_Future_Predicting_Future_Person_Activities_and_Locations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "579": {"title": "re-identification with consistent attentive siamese networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Re-Identification_With_Consistent_Attentive_Siamese_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "580": {"title": "on the continuity of rotation representations in neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_On_the_Continuity_of_Rotation_Representations_in_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "581": {"title": "iterative residual refinement for joint optical flow and occlusion estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hur_Iterative_Residual_Refinement_for_Joint_Optical_Flow_and_Occlusion_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "582": {"title": "inverse discriminative networks for handwritten signature verification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Inverse_Discriminative_Networks_for_Handwritten_Signature_Verification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "583": {"title": "led3d: a lightweight and efficient deep approach to recognizing low-quality 3d faces", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mu_Led3D_A_Lightweight_and_Efficient_Deep_Approach_to_Recognizing_Low-Quality_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "584": {"title": "roi pooled correlation filters for visual tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_ROI_Pooled_Correlation_Filters_for_Visual_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "585": {"title": "deep video inpainting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Deep_Video_Inpainting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "586": {"title": "dm-gan: dynamic memory generative adversarial networks for text-to-image synthesis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_DM-GAN_Dynamic_Memory_Generative_Adversarial_Networks_for_Text-To-Image_Synthesis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "587": {"title": "non-adversarial image synthesis with generative latent nearest neighbors", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hoshen_Non-Adversarial_Image_Synthesis_With_Generative_Latent_Nearest_Neighbors_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "588": {"title": "mixture density generative adversarial networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Eghbal-zadeh_Mixture_Density_Generative_Adversarial_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "589": {"title": "sketchgan: joint sketch completion and recognition with generative adversarial network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_SketchGAN_Joint_Sketch_Completion_and_Recognition_With_Generative_Adversarial_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "590": {"title": "foreground-aware image inpainting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_Foreground-Aware_Image_Inpainting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "591": {"title": "art2real: unfolding the reality of artworks via semantically-aware image-to-image translation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tomei_Art2Real_Unfolding_the_Reality_of_Artworks_via_Semantically-Aware_Image-To-Image_Translation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "592": {"title": "structure-preserving stereoscopic view synthesis with multi-scale adversarial correlation matching", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Structure-Preserving_Stereoscopic_View_Synthesis_With_Multi-Scale_Adversarial_Correlation_Matching_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "593": {"title": "dyntypo: example-based dynamic text effects transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Men_DynTypo_Example-Based_Dynamic_Text_Effects_Transfer_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "594": {"title": "arbitrary style transfer with style-attentional networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Park_Arbitrary_Style_Transfer_With_Style-Attentional_Networks_CVPR_2019_paper.html", "abstract": "Arbitrary style transfer aims to synthesize a content image with the style of an image to create a t\nhird image that has never been seen before. Recent arbitrary style transfer algorithms find it chall\nenging to balance the content structure and the style patterns. Moreover, simultaneously maintaining\n the global and local style patterns is difficult due to the patch-based mechanism. In this paper, w\ne introduce a novel style-attentional network (SANet) that efficiently and flexibly integrates the l\nocal style patterns according to the semantic spatial distribution of the content image. A new ident\nity loss function and multi-level feature embeddings enable our SANet and decoder to preserve the co\nntent structure as much as possible while enriching the style patterns. Experimental results demonst\nrate that our algorithm synthesizes stylized images in real-time that are higher in quality than tho\nse produced by the state-of-the-art algorithms.", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "595": {"title": "typography with decor: intelligent text style transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Typography_With_Decor_Intelligent_Text_Style_Transfer_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "596": {"title": "rl-gan-net: a reinforcement learning agent controlled gan network for real-time point cloud shape completion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sarmad_RL-GAN-Net_A_Reinforcement_Learning_Agent_Controlled_GAN_Network_for_Real-Time_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "597": {"title": "photo wake-up: 3d character animation from a single photo", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Weng_Photo_Wake-Up_3D_Character_Animation_From_a_Single_Photo_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "598": {"title": "deeplight: learning illumination for unconstrained mobile mixed reality", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/LeGendre_DeepLight_Learning_Illumination_for_Unconstrained_Mobile_Mixed_Reality_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "599": {"title": "iterative residual cnns for burst photography applications", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kokkinos_Iterative_Residual_CNNs_for_Burst_Photography_Applications_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "600": {"title": "learning implicit fields for generative shape modeling", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Implicit_Fields_for_Generative_Shape_Modeling_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "601": {"title": "reliable and efficient image cropping: a grid anchor based approach", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Reliable_and_Efficient_Image_Cropping_A_Grid_Anchor_Based_Approach_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "602": {"title": "patch-based progressive 3d point set upsampling", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yifan_Patch-Based_Progressive_3D_Point_Set_Upsampling_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "603": {"title": "an iterative and cooperative top-down and bottom-up inference network for salient object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_An_Iterative_and_Cooperative_Top-Down_and_Bottom-Up_Inference_Network_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "604": {"title": "deep stacked hierarchical multi-patch network for image deblurring", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deep_Stacked_Hierarchical_Multi-Patch_Network_for_Image_Deblurring_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "605": {"title": "turn a silicon camera into an ingaas camera", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lv_Turn_a_Silicon_Camera_Into_an_InGaAs_Camera_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "606": {"title": "low-rank tensor completion with a new tensor nuclear norm induced by invertible linear transforms", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lu_Low-Rank_Tensor_Completion_With_a_New_Tensor_Nuclear_Norm_Induced_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "607": {"title": "joint representative selection and feature learning: a semi-supervised approach", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Joint_Representative_Selection_and_Feature_Learning_A_Semi-Supervised_Approach_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "608": {"title": "the domain transform solver", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Bapat_The_Domain_Transform_Solver_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "609": {"title": "capsal: leveraging captioning to boost semantics for salient object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_CapSal_Leveraging_Captioning_to_Boost_Semantics_for_Salient_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "610": {"title": "phase-only image based kernel estimation for single image blind deblurring", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Phase-Only_Image_Based_Kernel_Estimation_for_Single_Image_Blind_Deblurring_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "611": {"title": "hierarchical discrete distribution decomposition for match density estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yin_Hierarchical_Discrete_Distribution_Decomposition_for_Match_Density_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "612": {"title": "focnet: a fractional optimal control network for image denoising", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jia_FOCNet_A_Fractional_Optimal_Control_Network_for_Image_Denoising_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "613": {"title": "orthogonal decomposition network for pixel-wise binary classification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Orthogonal_Decomposition_Network_for_Pixel-Wise_Binary_Classification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "614": {"title": "multi-source weak supervision for saliency detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Multi-Source_Weak_Supervision_for_Saliency_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "615": {"title": "comdefend: an efficient image compression model to defend adversarial examples", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jia_ComDefend_An_Efficient_Image_Compression_Model_to_Defend_Adversarial_Examples_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "616": {"title": "combinatorial persistency criteria for multicut and max-cut", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lange_Combinatorial_Persistency_Criteria_for_Multicut_and_Max-Cut_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "617": {"title": "s4net: single stage salient-instance segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fan_S4Net_Single_Stage_Salient-Instance_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "618": {"title": "a decomposition algorithm for the sparse generalized eigenvalue problem", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yuan_A_Decomposition_Algorithm_for_the_Sparse_Generalized_Eigenvalue_Problem_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "619": {"title": "polynomial representation for persistence diagram", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Polynomial_Representation_for_Persistence_Diagram_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "620": {"title": "crowd counting and density estimation by trellis encoder-decoder networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jiang_Crowd_Counting_and_Density_Estimation_by_Trellis_Encoder-Decoder_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "621": {"title": "cross-atlas convolution for parameterization invariant learning on textured mesh surface", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Cross-Atlas_Convolution_for_Parameterization_Invariant_Learning_on_Textured_Mesh_Surface_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "622": {"title": "deep surface normal estimation with hierarchical rgb-d fusion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Deep_Surface_Normal_Estimation_With_Hierarchical_RGB-D_Fusion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "623": {"title": "knowledge-embedded routing network for scene graph generation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Knowledge-Embedded_Routing_Network_for_Scene_Graph_Generation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "624": {"title": "an end-to-end network for panoptic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_An_End-To-End_Network_for_Panoptic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "625": {"title": "fast and flexible indoor scene synthesis via deep convolutional generative models", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ritchie_Fast_and_Flexible_Indoor_Scene_Synthesis_via_Deep_Convolutional_Generative_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "626": {"title": "marginalized latent semantic encoder for zero-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Marginalized_Latent_Semantic_Encoder_for_Zero-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "627": {"title": "scale-adaptive neural dense features: learning via hierarchical context aggregation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Spencer_Scale-Adaptive_Neural_Dense_Features_Learning_via_Hierarchical_Context_Aggregation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "628": {"title": "unsupervised embedding learning via invariant and spreading instance feature", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Unsupervised_Embedding_Learning_via_Invariant_and_Spreading_Instance_Feature_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "629": {"title": "aognets: compositional grammatical architectures for deep learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_AOGNets_Compositional_Grammatical_Architectures_for_Deep_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "630": {"title": "a robust local spectral descriptor for matching non-rigid shapes with incompatible shape structures", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_A_Robust_Local_Spectral_Descriptor_for_Matching_Non-Rigid_Shapes_With_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "631": {"title": "context and attribute grounded dense captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yin_Context_and_Attribute_Grounded_Dense_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "632": {"title": "spot and learn: a maximum-entropy patch sampler for few-shot image classification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chu_Spot_and_Learn_A_Maximum-Entropy_Patch_Sampler_for_Few-Shot_Image_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "633": {"title": "interpreting cnns via decision trees", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Interpreting_CNNs_via_Decision_Trees_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "634": {"title": "dense relational captioning: triple-stream networks for relationship-based captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Dense_Relational_Captioning_Triple-Stream_Networks_for_Relationship-Based_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "635": {"title": "deep modular co-attention networks for visual question answering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Deep_Modular_Co-Attention_Networks_for_Visual_Question_Answering_CVPR_2019_paper.html", "abstract": "Visual Question Answering (VQA) requires a fine-grained and simultaneous understanding of both the v\nisual content of images and the textual content of questions. Therefore, designing an effective `co-\nattention' model to associate key words in questions with key objects in images is central to VQA pe\nrformance. So far, most successful attempts at co-attention learning have been achieved by using sha\nllow models, and deep co-attention models show little improvement over their shallow counterparts. I\nn this paper, we propose a deep Modular Co-Attention Network (MCAN) that consists of Modular Co-Atte\nntion (MCA) layers cascaded in depth. Each MCA layer models the self-attention of questions and imag\nes, as well as the question-guided-attention of images jointly using a modular composition of two ba\nsic attention units. We quantitatively and qualitatively evaluate MCAN on the benchmark VQA-v2 datas\net and conduct extensive ablation studies to explore the reasons behind MCAN's effectiveness. Experi\nmental results demonstrate that MCAN significantly outperforms the previous state-of-the-art. Our be\nst single model delivers 70.63% overall accuracy on the test-dev set.\r", "cite_num": 2, "conf": "cvpr", "time": "2019"}, "636": {"title": "synthesizing environment-aware activities via activity sketches", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liao_Synthesizing_Environment-Aware_Activities_via_Activity_Sketches_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "637": {"title": "self-critical n-step training for image captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Self-Critical_N-Step_Training_for_Image_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "638": {"title": "multi-target embodied question answering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Multi-Target_Embodied_Question_Answering_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "639": {"title": "visual question answering as reading comprehension", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Visual_Question_Answering_as_Reading_Comprehension_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "640": {"title": "storygan: a sequential conditional gan for story visualization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_StoryGAN_A_Sequential_Conditional_GAN_for_Story_Visualization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "641": {"title": "noise-aware unsupervised deep lidar-stereo fusion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_Noise-Aware_Unsupervised_Deep_Lidar-Stereo_Fusion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "642": {"title": "versatile multiple choice learning and its application to vision computing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tian_Versatile_Multiple_Choice_Learning_and_Its_Application_to_Vision_Computing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "643": {"title": "ev-gait: event-based robust gait recognition using dynamic vision sensors", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_EV-Gait_Event-Based_Robust_Gait_Recognition_Using_Dynamic_Vision_Sensors_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "644": {"title": "toothnet: automatic tooth instance segmentation and identification from cone beam ct images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cui_ToothNet_Automatic_Tooth_Instance_Segmentation_and_Identification_From_Cone_Beam_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "645": {"title": "modularized textual grounding for counterfactual resilience", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fang_Modularized_Textual_Grounding_for_Counterfactual_Resilience_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "646": {"title": "l3-net: towards learning based lidar localization for autonomous driving", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lu_L3-Net_Towards_Learning_Based_LiDAR_Localization_for_Autonomous_Driving_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "647": {"title": "panoptic feature pyramid networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kirillov_Panoptic_Feature_Pyramid_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "648": {"title": "mask scoring r-cnn", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Mask_Scoring_R-CNN_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "649": {"title": "reasoning-rcnn: unifying adaptive global reasoning into large-scale object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Reasoning-RCNN_Unifying_Adaptive_Global_Reasoning_Into_Large-Scale_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "650": {"title": "cross-modality personalization for retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Murrugarra-Llerena_Cross-Modality_Personalization_for_Retrieval_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "651": {"title": "composing text and image for image retrieval - an empirical odyssey", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Vo_Composing_Text_and_Image_for_Image_Retrieval_-_an_Empirical_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "652": {"title": "arbitrary shape scene text detection with adaptive text region representation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Arbitrary_Shape_Scene_Text_Detection_With_Adaptive_Text_Region_Representation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "653": {"title": "adaptive nms: refining pedestrian detection in a crowd", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Adaptive_NMS_Refining_Pedestrian_Detection_in_a_Crowd_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "654": {"title": "point in, box out: beyond counting persons in crowds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Point_in_Box_Out_Beyond_Counting_Persons_in_Crowds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "655": {"title": "locating objects without bounding boxes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ribera_Locating_Objects_Without_Bounding_Boxes_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "656": {"title": "finegan: unsupervised hierarchical disentanglement for fine-grained object generation and discovery", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Singh_FineGAN_Unsupervised_Hierarchical_Disentanglement_for_Fine-Grained_Object_Generation_and_Discovery_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "657": {"title": "mutual learning of complementary networks via residual correction for improving semi-supervised classification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Mutual_Learning_of_Complementary_Networks_via_Residual_Correction_for_Improving_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "658": {"title": "sampling techniques for large-scale object detection from sparsely annotated objects", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Niitani_Sampling_Techniques_for_Large-Scale_Object_Detection_From_Sparsely_Annotated_Objects_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "659": {"title": "curls & whey: boosting black-box adversarial attacks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Curls__Whey_Boosting_Black-Box_Adversarial_Attacks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "660": {"title": "barrage of random transforms for adversarially robust defense", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Raff_Barrage_of_Random_Transforms_for_Adversarially_Robust_Defense_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "661": {"title": "aggregation cross-entropy for sequence recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Aggregation_Cross-Entropy_for_Sequence_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "662": {"title": "laso: label-set operations networks for multi-label few-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Alfassy_LaSO_Label-Set_Operations_Networks_for_Multi-Label_Few-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "663": {"title": "few-shot learning with localization in realistic settings", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wertheimer_Few-Shot_Learning_With_Localization_in_Realistic_Settings_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "664": {"title": "adagraph: unifying predictive and continuous domain adaptation through graphs", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mancini_AdaGraph_Unifying_Predictive_and_Continuous_Domain_Adaptation_Through_Graphs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "665": {"title": "grounded video description", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Grounded_Video_Description_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "666": {"title": "streamlined dense video captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mun_Streamlined_Dense_Video_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "667": {"title": "adversarial inference for multi-sentence video description", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Park_Adversarial_Inference_for_Multi-Sentence_Video_Description_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "668": {"title": "unified visual-semantic embeddings: bridging vision and language with structured meaning representations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Unified_Visual-Semantic_Embeddings_Bridging_Vision_and_Language_With_Structured_Meaning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "669": {"title": "learning to compose dynamic tree structures for visual contexts", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tang_Learning_to_Compose_Dynamic_Tree_Structures_for_Visual_Contexts_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "670": {"title": "reinforced cross-modal matching and self-supervised imitation learning for vision-language navigation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Reinforced_Cross-Modal_Matching_and_Self-Supervised_Imitation_Learning_for_Vision-Language_Navigation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "671": {"title": "dynamic fusion with intra- and inter-modality attention flow for visual question answering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Dynamic_Fusion_With_Intra-_and_Inter-Modality_Attention_Flow_for_Visual_CVPR_2019_paper.html", "abstract": "Learning effective fusion of multi-modality features is at the heart of visual question answering. W\ne propose a novel method of dynamically fusing multi-modal features with intra- and inter-modality i\nnformation flow, which alternatively pass dynamic information between and across the visual and lang\nuage modalities. It can robustly capture the high-level interactions between language and vision dom\nains, thus significantly improves the performance of visual question answering. We also show that th\ne proposed dynamic intra-modality attention flow conditioned on the other modality can dynamically m\nodulate the intra-modality attention of the target modality, which is vital for multimodality featur\ne fusion. Experimental evaluations on the VQA 2.0 dataset show that the proposed method achieves sta\nte-of-the-art VQA performance. Extensive ablation studies are carried out for the comprehensive anal\nysis of the proposed method.", "cite_num": 3, "conf": "cvpr", "time": "2019"}, "672": {"title": "cycle-consistency for robust visual question answering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shah_Cycle-Consistency_for_Robust_Visual_Question_Answering_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "673": {"title": "embodied question answering in photorealistic environments with point cloud perception", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wijmans_Embodied_Question_Answering_in_Photorealistic_Environments_With_Point_Cloud_Perception_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "674": {"title": "reasoning visual dialogs with structural and partial observations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Reasoning_Visual_Dialogs_With_Structural_and_Partial_Observations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "675": {"title": "recursive visual attention in visual dialog", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Niu_Recursive_Visual_Attention_in_Visual_Dialog_CVPR_2019_paper.html", "abstract": "Visual dialog is a challenging vision-language task, which requires the agent to answer multi-round \nquestions about an image. It typically needs to address two major problems: (1) How to answer visual\nly-grounded questions, which is the core challenge in visual question answering (VQA); (2) How to in\nfer the co-reference between questions and the dialog history. An example of visual co-reference is:\n pronouns (e.g., `they') in the question (e.g., `Are they on or off?') are linked with nouns (e.g., \n`lamps') appearing in the dialog history (e.g., `How many lamps are there?') and the object grounded\n in the image. In this work, to resolve the visual co-reference for visual dialog, we propose a nove\nl attention mechanism called Recursive Visual Attention (RvA). Specifically, our dialog agent browse\ns the dialog history until the agent has sufficient confidence in the visual co-reference resolution\n, and refines the visual attention recursively. The quantitative and qualitative experimental result\ns on the large-scale VisDial v0.9 and v1.0 datasets demonstrate that the proposed RvA not only outpe\nrforms the state-of-the-art methods, but also achieves reasonable recursion and interpretable attent\nion maps without additional annotations.", "cite_num": 4, "conf": "cvpr", "time": "2019"}, "676": {"title": "two body problem: collaborative visual task completion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jain_Two_Body_Problem_Collaborative_Visual_Task_Completion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "677": {"title": "gqa: a new dataset for real-world visual reasoning and compositional question answering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hudson_GQA_A_New_Dataset_for_Real-World_Visual_Reasoning_and_Compositional_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "678": {"title": "text2scene: generating compositional scenes from textual descriptions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tan_Text2Scene_Generating_Compositional_Scenes_From_Textual_Descriptions_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "679": {"title": "from recognition to cognition: visual commonsense reasoning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zellers_From_Recognition_to_Cognition_Visual_Commonsense_Reasoning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "680": {"title": "the regretful agent: heuristic-aided navigation through progress estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ma_The_Regretful_Agent_Heuristic-Aided_Navigation_Through_Progress_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "681": {"title": "tactical rewind: self-correction via backtracking in vision-and-language navigation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ke_Tactical_Rewind_Self-Correction_via_Backtracking_in_Vision-And-Language_Navigation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "682": {"title": "learning to learn how to learn: self-adaptive visual navigation using meta-learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wortsman_Learning_to_Learn_How_to_Learn_Self-Adaptive_Visual_Navigation_Using_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "683": {"title": "high flux passive imaging with single-photon sensors", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ingle_High_Flux_Passive_Imaging_With_Single-Photon_Sensors_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "684": {"title": "photon-flooded single-photon 3d cameras", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gupta_Photon-Flooded_Single-Photon_3D_Cameras_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "685": {"title": "acoustic non-line-of-sight imaging", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lindell_Acoustic_Non-Line-Of-Sight_Imaging_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "686": {"title": "steady-state non-line-of-sight imaging", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Steady-State_Non-Line-Of-Sight_Imaging_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "687": {"title": "a theory of fermat paths for non-line-of-sight shape reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xin_A_Theory_of_Fermat_Paths_for_Non-Line-Of-Sight_Shape_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "688": {"title": "end-to-end projector photometric compensation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Huang_End-To-End_Projector_Photometric_Compensation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "689": {"title": "bringing a blurry frame alive at high frame-rate with an event camera", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Bringing_a_Blurry_Frame_Alive_at_High_Frame-Rate_With_an_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "690": {"title": "bringing alive blurred moments", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Purohit_Bringing_Alive_Blurred_Moments_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "691": {"title": "learning to synthesize motion blur", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Brooks_Learning_to_Synthesize_Motion_Blur_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "692": {"title": "underexposed photo enhancement using deep illumination estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Underexposed_Photo_Enhancement_Using_Deep_Illumination_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "693": {"title": "blind visual motif removal from a single image", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hertz_Blind_Visual_Motif_Removal_From_a_Single_Image_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "694": {"title": "non-local meets global: an integrated paradigm for hyperspectral denoising", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Non-Local_Meets_Global_An_Integrated_Paradigm_for_Hyperspectral_Denoising_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "695": {"title": "neural rerendering in the wild", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Meshry_Neural_Rerendering_in_the_Wild_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "696": {"title": "geonet: deep geodesic networks for point cloud analysis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_GeoNet_Deep_Geodesic_Networks_for_Point_Cloud_Analysis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "697": {"title": "meshadv: adversarial meshes for visual recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xiao_MeshAdv_Adversarial_Meshes_for_Visual_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "698": {"title": "fast spatially-varying indoor lighting estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Garon_Fast_Spatially-Varying_Indoor_Lighting_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "699": {"title": "neural illumination: lighting prediction for indoor environments", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Song_Neural_Illumination_Lighting_Prediction_for_Indoor_Environments_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "700": {"title": "deep sky modeling for single image outdoor lighting estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hold-Geoffroy_Deep_Sky_Modeling_for_Single_Image_Outdoor_Lighting_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "701": {"title": "bidirectional learning for domain adaptation of semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Bidirectional_Learning_for_Domain_Adaptation_of_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "702": {"title": "enhanced bayesian compression via deep reinforcement learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yuan_Enhanced_Bayesian_Compression_via_Deep_Reinforcement_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "703": {"title": "strong-weak distribution alignment for adaptive object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Saito_Strong-Weak_Distribution_Alignment_for_Adaptive_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "704": {"title": "mfas: multimodal fusion architecture search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Perez-Rua_MFAS_Multimodal_Fusion_Architecture_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "705": {"title": "disentangling adversarial robustness and generalization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Stutz_Disentangling_Adversarial_Robustness_and_Generalization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "706": {"title": "shieldnets: defending against adversarial attacks using probabilistic adversarial robustness", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Theagarajan_ShieldNets_Defending_Against_Adversarial_Attacks_Using_Probabilistic_Adversarial_Robustness_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "707": {"title": "deeply-supervised knowledge synergy", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Deeply-Supervised_Knowledge_Synergy_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "708": {"title": "dual residual networks leveraging the potential of paired operations for image restoration", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Dual_Residual_Networks_Leveraging_the_Potential_of_Paired_Operations_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "709": {"title": "probabilistic end-to-end noise correction for learning with noisy labels", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yi_Probabilistic_End-To-End_Noise_Correction_for_Learning_With_Noisy_Labels_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "710": {"title": "attention-guided unified network for panoptic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Attention-Guided_Unified_Network_for_Panoptic_Segmentation_CVPR_2019_paper.html", "abstract": "This paper studies panoptic segmentation, a recently proposed task which segments foreground (FG) ob\njects at the instance level as well as background (BG) contents at the semantic level. Existing meth\nods mostly dealt with these two problems separately, but in this paper, we reveal the underlying rel\nationship between them, in particular, FG objects provide complementary cues to assist BG understand\ning. Our approach, named the Attention-guided Unified Network (AUNet), is a unified framework with t\nwo branches for FG and BG segmentation simultaneously. Two sources of attentions are added to the BG\n branch, namely, RPN and FG segmentation mask to provide object-level and pixel-level attentions, re\nspectively. Our approach is generalized to different backbones with consistent accuracy gain in both\n FG and BG segmentation, and also sets new state-of-the-arts both in the MS-COCO (46.5% PQ) and City\nscapes (59.0% PQ) benchmarks.", "cite_num": 7, "conf": "cvpr", "time": "2019"}, "711": {"title": "nas-fpn: learning scalable feature pyramid architecture for object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ghiasi_NAS-FPN_Learning_Scalable_Feature_Pyramid_Architecture_for_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "712": {"title": "oicsr: out-in-channel sparsity regularization for compact deep neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_OICSR_Out-In-Channel_Sparsity_Regularization_for_Compact_Deep_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "713": {"title": "semantically aligned bias reducing zero shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Paul_Semantically_Aligned_Bias_Reducing_Zero_Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "714": {"title": "feature space perturbations yield more transferable adversarial examples", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Inkawhich_Feature_Space_Perturbations_Yield_More_Transferable_Adversarial_Examples_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "715": {"title": "ige-net: inverse graphics energy networks for human pose estimation and single-view reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jack_IGE-Net_Inverse_Graphics_Energy_Networks_for_Human_Pose_Estimation_and_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "716": {"title": "accelerating convolutional neural networks via activation map compression", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Georgiadis_Accelerating_Convolutional_Neural_Networks_via_Activation_Map_Compression_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "717": {"title": "knowledge distillation via instance relationship graph", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Knowledge_Distillation_via_Instance_Relationship_Graph_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "718": {"title": "ppgnet: learning point-pair graph for line segment detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_PPGNet_Learning_Point-Pair_Graph_for_Line_Segment_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "719": {"title": "building detail-sensitive semantic segmentation networks with polynomial pooling", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Building_Detail-Sensitive_Semantic_Segmentation_Networks_With_Polynomial_Pooling_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "720": {"title": "variational bayesian dropout with a hierarchical prior", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Variational_Bayesian_Dropout_With_a_Hierarchical_Prior_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "721": {"title": "aanet: attribute attention network for person re-identifications", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tay_AANet_Attribute_Attention_Network_for_Person_Re-Identifications_CVPR_2019_paper.html", "abstract": "This paper proposes Attribute Attention Network (AANet), a new architecture that integrates person a\nttributes and attribute attention maps into a classification framework to solve the person re-identi\nfication (re-ID) problem. Many person re-ID models typically employ semantic cues such as body parts\n or human pose to improve the re-ID performance. Attribute information, however, is often not utiliz\ned. The proposed AANet leverages on a baseline model that uses body parts and integrates the key att\nribute information in an unified learning framework. The AANet consists of a global person ID task, \na part detection task and a crucial attribute detection task. By estimating the class responses of i\nndividual attributes and combining them to form the attribute attention map (AAM), a very strong dis\ncriminatory representation is constructed. The proposed AANet outperforms the best state-of-the-art \nmethod [??] using ResNet-50 by 3.36% in mAP and 3.12% in Rank-1 accuracy on DukeMTMC-reID dataset. O\nn Market1501 dataset, AANet achieves 92.38% mAP and 95.10% Rank-1 accuracy with re-ranking,  outperf\norming [??], another state of the art method using ResNet-152, by 1.42% in mAP and 0.47% in Rank-1 a\nccuracy. In addition, AANet can perform person attribute prediction (e.g., gender, hair length, clot\nhing length etc.), and localize the attributes in the query image.\r", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "722": {"title": "overcoming limitations of mixture density networks: a sampling and fitting framework for multimodal future prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Makansi_Overcoming_Limitations_of_Mixture_Density_Networks_A_Sampling_and_Fitting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "723": {"title": "a main/subsidiary network framework for simplifying binary neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_A_MainSubsidiary_Network_Framework_for_Simplifying_Binary_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "724": {"title": "pointnetlk: robust & efficient point cloud registration using pointnet", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Aoki_PointNetLK_Robust__Efficient_Point_Cloud_Registration_Using_PointNet_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "725": {"title": "few-shot adaptive faster r-cnn", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Few-Shot_Adaptive_Faster_R-CNN_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "726": {"title": "vrstc: occlusion-free video person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hou_VRSTC_Occlusion-Free_Video_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "727": {"title": "compact feature learning for multi-domain image classification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Compact_Feature_Learning_for_Multi-Domain_Image_Classification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "728": {"title": "adaptive transfer network for cross-domain person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Adaptive_Transfer_Network_for_Cross-Domain_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "729": {"title": "large-scale few-shot learning: knowledge transfer with class hierarchy", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Large-Scale_Few-Shot_Learning_Knowledge_Transfer_With_Class_Hierarchy_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "730": {"title": "moving object detection under discontinuous change in illumination using tensor low-rank and invariant sparse decomposition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shakeri_Moving_Object_Detection_Under_Discontinuous_Change_in_Illumination_Using_Tensor_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "731": {"title": "pedestrian detection with autoregressive network phases", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Brazil_Pedestrian_Detection_With_Autoregressive_Network_Phases_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "732": {"title": "all you need is a few shifts: designing efficient convolutional neural networks for image classification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_All_You_Need_Is_a_Few_Shifts_Designing_Efficient_Convolutional_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "733": {"title": "stochastic class-based hard example mining for deep metric learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Suh_Stochastic_Class-Based_Hard_Example_Mining_for_Deep_Metric_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "734": {"title": "revisiting local descriptor based image-to-class measure for few-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Revisiting_Local_Descriptor_Based_Image-To-Class_Measure_for_Few-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "735": {"title": "towards robust curve text detection with conditional spatial expansion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Towards_Robust_Curve_Text_Detection_With_Conditional_Spatial_Expansion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "736": {"title": "revisiting perspective information for efficient crowd counting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Revisiting_Perspective_Information_for_Efficient_Crowd_Counting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "737": {"title": "towards universal object detection by domain attention", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Towards_Universal_Object_Detection_by_Domain_Attention_CVPR_2019_paper.html", "abstract": "Despite increasing efforts on universal representations for visual recognition, few have addressed o\nbject detection. In this paper, we develop an effective and efficient universal object detection sys\ntem that is capable of working on various image domains, from human faces and traffic signs to medic\nal CT images. Unlike multi-domain models, this universal model does not require prior knowledge of t\nhe domain of interest. This is achieved by the introduction of a new family of adaptation layers, ba\nsed on the principles of squeeze and excitation, and a new domain-attention mechanism. In the propos\ned universal detector, all parameters and computations are shared across domains, and a single netwo\nrk processes all domains all the time. Experiments, on a newly established universal object detectio\nn benchmark of 11 diverse datasets, show that the proposed detector outperforms a bank of individual\n detectors, a multi-domain detector, and a baseline universal detector, with a 1.3x parameter increa\nse over a single-domain baseline detector. The code and benchmark will be released at this http URL.\n", "cite_num": 3, "conf": "cvpr", "time": "2019"}, "738": {"title": "ensemble deep manifold similarity learning using hard proxies", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Aziere_Ensemble_Deep_Manifold_Similarity_Learning_Using_Hard_Proxies_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "739": {"title": "quantization networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Quantization_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "740": {"title": "res-pca: a scalable approach to recovering low-rank matrices", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Peng_RES-PCA_A_Scalable_Approach_to_Recovering_Low-Rank_Matrices_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "741": {"title": "occlusion-net: 2d/3d occluded keypoint localization using graph networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Reddy_Occlusion-Net_2D3D_Occluded_Keypoint_Localization_Using_Graph_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "742": {"title": "efficient featurized image pyramid network for single shot detector", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pang_Efficient_Featurized_Image_Pyramid_Network_for_Single_Shot_Detector_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "743": {"title": "multi-task multi-sensor fusion for 3d object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Multi-Task_Multi-Sensor_Fusion_for_3D_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "744": {"title": "domain-specific batch normalization for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chang_Domain-Specific_Batch_Normalization_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "745": {"title": "grid r-cnn", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lu_Grid_R-CNN_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "746": {"title": "metacleaner: learning to hallucinate clean representations for noisy-labeled visual recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_MetaCleaner_Learning_to_Hallucinate_Clean_Representations_for_Noisy-Labeled_Visual_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "747": {"title": "mapping, localization and path planning for image-based navigation using visual features and map", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Thoma_Mapping_Localization_and_Path_Planning_for_Image-Based_Navigation_Using_Visual_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "748": {"title": "triply supervised decoder networks for joint detection and segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cao_Triply_Supervised_Decoder_Networks_for_Joint_Detection_and_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "749": {"title": "leveraging the invariant side of generative zero-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Leveraging_the_Invariant_Side_of_Generative_Zero-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "750": {"title": "exploring the bounds of the utility of context for object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Barnea_Exploring_the_Bounds_of_the_Utility_of_Context_for_Object_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "751": {"title": "a-cnn: annularly convolutional neural networks on point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Komarichev_A-CNN_Annularly_Convolutional_Neural_Networks_on_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "752": {"title": "darnet: deep active ray network for building segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_DARNet_Deep_Active_Ray_Network_for_Building_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "753": {"title": "point cloud oversegmentation with graph-structured deep metric learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Landrieu_Point_Cloud_Oversegmentation_With_Graph-Structured_Deep_Metric_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "754": {"title": "graphonomy: universal human parsing via graph transfer learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gong_Graphonomy_Universal_Human_Parsing_via_Graph_Transfer_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "755": {"title": "fitting multiple heterogeneous models by multi-class cascaded t-linkage", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Magri_Fitting_Multiple_Heterogeneous_Models_by_Multi-Class_Cascaded_T-Linkage_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "756": {"title": "a late fusion cnn for digital matting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_A_Late_Fusion_CNN_for_Digital_Matting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "757": {"title": "basnet: boundary-aware salient object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qin_BASNet_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "758": {"title": "zigzagnet: fusing top-down and bottom-up context for object segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lin_ZigZagNet_Fusing_Top-Down_and_Bottom-Up_Context_for_Object_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "759": {"title": "object instance annotation with deep extreme level set evolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Object_Instance_Annotation_With_Deep_Extreme_Level_Set_Evolution_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "760": {"title": "leveraging crowdsourced gps data for road extraction from aerial imagery", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Leveraging_Crowdsourced_GPS_Data_for_Road_Extraction_From_Aerial_Imagery_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "761": {"title": "adaptive pyramid context network for semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Adaptive_Pyramid_Context_Network_for_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "762": {"title": "isospectralization, or how to hear shape, style, and correspondence", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cosmo_Isospectralization_or_How_to_Hear_Shape_Style_and_Correspondence_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "763": {"title": "speech2face: learning the face behind a voice", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Oh_Speech2Face_Learning_the_Face_Behind_a_Voice_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "764": {"title": "joint manifold diffusion for combining predictions on decoupled observations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Joint_Manifold_Diffusion_for_Combining_Predictions_on_Decoupled_Observations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "765": {"title": "audio visual scene-aware dialog", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Alamri_Audio_Visual_Scene-Aware_Dialog_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "766": {"title": "learning to minify photometric stereo", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_to_Minify_Photometric_Stereo_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "767": {"title": "reflective and fluorescent separation under narrow-band illumination", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Koyamatsu_Reflective_and_Fluorescent_Separation_Under_Narrow-Band_Illumination_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "768": {"title": "depth from a polarisation + rgb stereo pair", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Depth_From_a_Polarisation__RGB_Stereo_Pair_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "769": {"title": "rethinking the evaluation of video summaries", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Otani_Rethinking_the_Evaluation_of_Video_Summaries_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "770": {"title": "what object should i use? - task driven object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sawatzky_What_Object_Should_I_Use_-_Task_Driven_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "771": {"title": "triangulation learning network: from monocular to stereo 3d object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qin_Triangulation_Learning_Network_From_Monocular_to_Stereo_3D_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "772": {"title": "connecting the dots: learning representations for active monocular depth estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Riegler_Connecting_the_Dots_Learning_Representations_for_Active_Monocular_Depth_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "773": {"title": "learning non-volumetric depth fusion using successive reprojections", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Donne_Learning_Non-Volumetric_Depth_Fusion_Using_Successive_Reprojections_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "774": {"title": "stereo r-cnn based 3d object detection for autonomous driving", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Stereo_R-CNN_Based_3D_Object_Detection_for_Autonomous_Driving_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "775": {"title": "hybrid scene compression for visual localization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Camposeco_Hybrid_Scene_Compression_for_Visual_Localization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "776": {"title": "mmface: a multi-metric regression network for unconstrained face reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yi_MMFace_A_Multi-Metric_Regression_Network_for_Unconstrained_Face_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "777": {"title": "3d motion decomposition for rgbd future dynamic scene synthesis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qi_3D_Motion_Decomposition_for_RGBD_Future_Dynamic_Scene_Synthesis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "778": {"title": "single image depth estimation trained via depth from defocus cues", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gur_Single_Image_Depth_Estimation_Trained_via_Depth_From_Defocus_Cues_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "779": {"title": "rgbd based dimensional decomposition residual network for 3d semantic scene completion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_RGBD_Based_Dimensional_Decomposition_Residual_Network_for_3D_Semantic_Scene_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "780": {"title": "neural scene decomposition for multi-person motion capture", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Rhodin_Neural_Scene_Decomposition_for_Multi-Person_Motion_Capture_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "781": {"title": "efficient decision-based black-box adversarial attacks on face recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Efficient_Decision-Based_Black-Box_Adversarial_Attacks_on_Face_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "782": {"title": "fa-rpn: floating region proposals for face detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Najibi_FA-RPN_Floating_Region_Proposals_for_Face_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "783": {"title": "bayesian hierarchical dynamic model for human action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Bayesian_Hierarchical_Dynamic_Model_for_Human_Action_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "784": {"title": "mixed effects neural networks (menets) with applications to gaze estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_Mixed_Effects_Neural_Networks_MeNets_With_Applications_to_Gaze_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "785": {"title": "3d human pose estimation in video with temporal convolutions and semi-supervised training", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pavllo_3D_Human_Pose_Estimation_in_Video_With_Temporal_Convolutions_and_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "786": {"title": "learning to regress 3d face shape and expression from an image without 3d supervision", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sanyal_Learning_to_Regress_3D_Face_Shape_and_Expression_From_an_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "787": {"title": "posefix: model-agnostic general human pose refinement network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Moon_PoseFix_Model-Agnostic_General_Human_Pose_Refinement_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "788": {"title": "repnet: weakly supervised training of an adversarial reprojection network for 3d human pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wandt_RepNet_Weakly_Supervised_Training_of_an_Adversarial_Reprojection_Network_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "789": {"title": "fast and robust multi-person 3d pose estimation from multiple views", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Fast_and_Robust_Multi-Person_3D_Pose_Estimation_From_Multiple_Views_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "790": {"title": "face-focused cross-stream network for deception detection in videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Face-Focused_Cross-Stream_Network_for_Deception_Detection_in_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "791": {"title": "unequal-training for deep face recognition with long-tailed noisy data", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Unequal-Training_for_Deep_Face_Recognition_With_Long-Tailed_Noisy_Data_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "792": {"title": "t-net: parametrizing fully convolutional nets with a single high-order tensor", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kossaifi_T-Net_Parametrizing_Fully_Convolutional_Nets_With_a_Single_High-Order_Tensor_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "793": {"title": "hierarchical cross-modal talking face generation with dynamic pixel-wise loss", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Hierarchical_Cross-Modal_Talking_Face_Generation_With_Dynamic_Pixel-Wise_Loss_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "794": {"title": "object-centric auto-encoders and dummy anomalies for abnormal event detection in video", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ionescu_Object-Centric_Auto-Encoders_and_Dummy_Anomalies_for_Abnormal_Event_Detection_in_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "795": {"title": "ddlstm: dual-domain lstm for cross-dataset action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Perrett_DDLSTM_Dual-Domain_LSTM_for_Cross-Dataset_Action_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "796": {"title": "the pros and cons: rank-aware temporal attention for skill determination in long videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Doughty_The_Pros_and_Cons_Rank-Aware_Temporal_Attention_for_Skill_Determination_CVPR_2019_paper.html", "abstract": "We present a new model to determine relative skill from long videos, through learnable temporal atte\nntion modules. Skill determination is formulated as a ranking problem, making it suitable for common\n and generic tasks. However, for long videos, parts of the video are irrelevant for assessing skill,\n and there may be variability in the skill exhibited throughout a video. We therefore propose a meth\nod which assesses the relative overall level of skill in a long video by attending to its skill-rele\nvant parts. Our approach trains temporal attention modules, learned with only video-level supervisio\nn, using a novel rank-aware loss function. In addition to attending to task relevant video parts, ou\nr proposed loss jointly trains two attention modules to separately attend to video parts which are i\nndicative of higher (pros) and lower (cons) skill. We evaluate our approach on the EPIC-Skills datas\net and additionally annotate a larger dataset from YouTube videos for skill determination with five \npreviously unexplored tasks. Our method outperforms previous approaches and classic softmax attentio\nn on both datasets by over 4% pairwise accuracy, and as much as 12% on individual tasks. We also dem\nonstrate our model's ability to attend to rank-aware parts of the video.", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "797": {"title": "collaborative spatiotemporal feature learning for video action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Collaborative_Spatiotemporal_Feature_Learning_for_Video_Action_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "798": {"title": "mars: motion-augmented rgb stream for action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Crasto_MARS_Motion-Augmented_RGB_Stream_for_Action_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "799": {"title": "convolutional relational machine for group activity recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Azar_Convolutional_Relational_Machine_for_Group_Activity_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "800": {"title": "video summarization by learning from unpaired data", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Rochan_Video_Summarization_by_Learning_From_Unpaired_Data_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "801": {"title": "skeleton-based action recognition with directed graph neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Skeleton-Based_Action_Recognition_With_Directed_Graph_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "802": {"title": "pa3d: pose-action 3d machine for video recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yan_PA3D_Pose-Action_3D_Machine_for_Video_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "803": {"title": "deep dual relation modeling for egocentric interaction recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Deep_Dual_Relation_Modeling_for_Egocentric_Interaction_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "804": {"title": "mots: multi-object tracking and segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Voigtlaender_MOTS_Multi-Object_Tracking_and_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "805": {"title": "siamese cascaded region proposal networks for real-time visual tracking", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Siamese_Cascaded_Region_Proposal_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "806": {"title": "pointflownet: learning representations for rigid motion estimation from point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Behl_PointFlowNet_Learning_Representations_for_Rigid_Motion_Estimation_From_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "807": {"title": "listen to the image", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Listen_to_the_Image_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "808": {"title": "image super-resolution by neural texture transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Image_Super-Resolution_by_Neural_Texture_Transfer_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "809": {"title": "conditional adversarial generative flow for controllable image synthesis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Conditional_Adversarial_Generative_Flow_for_Controllable_Image_Synthesis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "810": {"title": "how to make a pizza: learning a compositional layer-based gan model", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Papadopoulos_How_to_Make_a_Pizza_Learning_a_Compositional_Layer-Based_GAN_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "811": {"title": "transgaga: geometry-aware unsupervised image-to-image translation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_TransGaGa_Geometry-Aware_Unsupervised_Image-To-Image_Translation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "812": {"title": "depth-attentional features for single-image rain removal", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Depth-Attentional_Features_for_Single-Image_Rain_Removal_CVPR_2019_paper.html", "abstract": "Rain is a common weather phenomenon, where object visibility varies with depth from the camera and o\nbjects faraway are visually blocked more by fog than by rain streaks. Existing methods and datasets \nfor rain removal, however, ignore these physical properties, thereby limiting the rain removal effic\niency on real photos. In this work, we first analyze the visual effects of rain subject to scene dep\nth and formulate a rain imaging model collectively with rain streaks and fog; by then, we prepare a \nnew dataset called RainCityscapes with rain streaks and fog on real outdoor photos. Furthermore, we \ndesign an end-to-end deep neural network, where we train it to learn depth-attentional features via \na depth-guided attention mechanism, and regress a residual map to produce the rain-free image output\n. We performed various experiments to visually and quantitatively compare our method with several st\nate-of-the-art methods to demonstrate its superiority over the others.\r", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "813": {"title": "hyperspectral image reconstruction using a deep spatial-spectral prior", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Hyperspectral_Image_Reconstruction_Using_a_Deep_Spatial-Spectral_Prior_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "814": {"title": "liff: light field features in scale and depth", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dansereau_LiFF_Light_Field_Features_in_Scale_and_Depth_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "815": {"title": "deep exemplar-based video colorization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deep_Exemplar-Based_Video_Colorization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "816": {"title": "on finding gray pixels", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qian_On_Finding_Gray_Pixels_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "817": {"title": "unos: unified unsupervised optical-flow and stereo-depth estimation by watching videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_UnOS_Unified_Unsupervised_Optical-Flow_and_Stereo-Depth_Estimation_by_Watching_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "818": {"title": "learning transformation synchronization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Learning_Transformation_Synchronization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "819": {"title": "d2-net: a trainable cnn for joint description and detection of local features", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dusmanu_D2-Net_A_Trainable_CNN_for_Joint_Description_and_Detection_of_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "820": {"title": "recurrent neural networks with intra-frame iterations for video deblurring", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Nah_Recurrent_Neural_Networks_With_Intra-Frame_Iterations_for_Video_Deblurring_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "821": {"title": "learning to extract flawless slow motion from blurry videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jin_Learning_to_Extract_Flawless_Slow_Motion_From_Blurry_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "822": {"title": "natural and realistic single image super-resolution with explicit natural manifold discrimination", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Soh_Natural_and_Realistic_Single_Image_Super-Resolution_With_Explicit_Natural_Manifold_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "823": {"title": "rf-net: an end-to-end image matching network based on receptive field", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shen_RF-Net_An_End-To-End_Image_Matching_Network_Based_on_Receptive_Field_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "824": {"title": "fast single image reflection suppression via convex optimization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Fast_Single_Image_Reflection_Suppression_via_Convex_Optimization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "825": {"title": "a mutual learning method for salient object detection with intertwined multi-supervision", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_A_Mutual_Learning_Method_for_Salient_Object_Detection_With_Intertwined_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "826": {"title": "enhanced pix2pix dehazing network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qu_Enhanced_Pix2pix_Dehazing_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "827": {"title": "assessing personally perceived image quality via image features and collaborative filtering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Korhonen_Assessing_Personally_Perceived_Image_Quality_via_Image_Features_and_Collaborative_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "828": {"title": "single image reflection removal exploiting misaligned training data and network enhancements", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Single_Image_Reflection_Removal_Exploiting_Misaligned_Training_Data_and_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "829": {"title": "exploring context and visual pattern of relationship for scene graph generation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Exploring_Context_and_Visual_Pattern_of_Relationship_for_Scene_Graph_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "830": {"title": "learning from synthetic data for crowd counting in the wild", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_From_Synthetic_Data_for_Crowd_Counting_in_the_Wild_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "831": {"title": "a local block coordinate descent algorithm for the csc model", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zisselman_A_Local_Block_Coordinate_Descent_Algorithm_for_the_CSC_Model_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "832": {"title": "not using the car to see the sidewalk -- quantifying and controlling the effects of context in classification and segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shetty_Not_Using_the_Car_to_See_the_Sidewalk_--_Quantifying_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "833": {"title": "discovering fair representations in the data domain", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Quadrianto_Discovering_Fair_Representations_in_the_Data_Domain_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "834": {"title": "actor-critic instance segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Araslanov_Actor-Critic_Instance_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "835": {"title": "generalized zero- and few-shot learning via aligned variational autoencoders", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Schonfeld_Generalized_Zero-_and_Few-Shot_Learning_via_Aligned_Variational_Autoencoders_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "836": {"title": "semantic projection network for zero- and few-label semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xian_Semantic_Projection_Network_for_Zero-_and_Few-Label_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "837": {"title": "gcan: graph convolutional adversarial network for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ma_GCAN_Graph_Convolutional_Adversarial_Network_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "838": {"title": "seamless scene segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Porzi_Seamless_Scene_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "839": {"title": "unsupervised image matching and object discovery as optimization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Vo_Unsupervised_Image_Matching_and_Object_Discovery_as_Optimization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "840": {"title": "wide-area crowd counting via ground-plane density maps and multi-view fusion cnns", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Wide-Area_Crowd_Counting_via_Ground-Plane_Density_Maps_and_Multi-View_Fusion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "841": {"title": "show, control and tell: a framework for generating controllable and grounded captions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cornia_Show_Control_and_Tell_A_Framework_for_Generating_Controllable_and_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "842": {"title": "towards vqa models that can read", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Singh_Towards_VQA_Models_That_Can_Read_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "843": {"title": "object-aware aggregation with bidirectional temporal graph for video captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Object-Aware_Aggregation_With_Bidirectional_Temporal_Graph_for_Video_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "844": {"title": "progressive attention memory network for movie story question answering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Progressive_Attention_Memory_Network_for_Movie_Story_Question_Answering_CVPR_2019_paper.html", "abstract": "This paper proposes the progressive attention memory network (PAMN) for movie story question answeri\nng (QA). Movie story QA is challenging compared to VQA in two aspects: (1) pinpointing the temporal \nparts relevant to answer the question is difficult as the movies are typically longer than an hour, \n(2) it has both video and subtitle where different questions require different modality to infer the\n answer. To overcome these challenges, PAMN involves three main features: (1) progressive attention \nmechanism that utilizes cues from both question and answer to progressively prune out irrelevant tem\nporal parts in memory, (2) dynamic modality fusion that adaptively determines the contribution of ea\nch modality for answering the current question, and (3) belief correction answering scheme that succ\nessively corrects the prediction score on each candidate answer. Experiments on publicly available b\nenchmark datasets, MovieQA and TVQA, demonstrate that each feature contributes to our movie story QA\n architecture, PAMN, and improves performance to achieve the state-of-the-art result. Qualitative an\nalysis by visualizing the inference mechanism of PAMN is also provided.", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "845": {"title": "memory-attended recurrent network for video captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pei_Memory-Attended_Recurrent_Network_for_Video_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "846": {"title": "visual query answering by entity-attribute graph matching and reasoning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_Visual_Query_Answering_by_Entity-Attribute_Graph_Matching_and_Reasoning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "847": {"title": "look back and predict forward in image captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qin_Look_Back_and_Predict_Forward_in_Image_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "848": {"title": "explainable and explicit visual reasoning over scene graphs", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Explainable_and_Explicit_Visual_Reasoning_Over_Scene_Graphs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "849": {"title": "transfer learning via unsupervised task discovery for visual question answering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Noh_Transfer_Learning_via_Unsupervised_Task_Discovery_for_Visual_Question_Answering_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "850": {"title": "intention oriented image captions with guiding objects", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Intention_Oriented_Image_Captions_With_Guiding_Objects_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "851": {"title": "uncertainty guided multi-scale residual learning-using a cycle spinning cnn for single image de-raining", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yasarla_Uncertainty_Guided_Multi-Scale_Residual_Learning-Using_a_Cycle_Spinning_CNN_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "852": {"title": "toward realistic image compositing with adversarial learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Toward_Realistic_Image_Compositing_With_Adversarial_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "853": {"title": "cross-classification clustering: an efficient multi-object tracking technique for 3-d instance segmentation in connectomics", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Meirovitch_Cross-Classification_Clustering_An_Efficient_Multi-Object_Tracking_Technique_for_3-D_Instance_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "854": {"title": "deep charuco: dark charuco marker pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Deep_ChArUco_Dark_ChArUco_Marker_Pose_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "855": {"title": "pseudo-lidar from visual depth estimation: bridging the gap in 3d object detection for autonomous driving", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Pseudo-LiDAR_From_Visual_Depth_Estimation_Bridging_the_Gap_in_3D_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "856": {"title": "rules of the road: predicting driving behavior with a convolutional model of semantic interactions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hong_Rules_of_the_Road_Predicting_Driving_Behavior_With_a_Convolutional_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "857": {"title": "metric learning for image registration", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Niethammer_Metric_Learning_for_Image_Registration_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "858": {"title": "lo-net: deep real-time lidar odometry", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_LO-Net_Deep_Real-Time_Lidar_Odometry_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "859": {"title": "traphic: trajectory prediction in dense and heterogeneous traffic using weighted interactions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chandra_TraPHic_Trajectory_Prediction_in_Dense_and_Heterogeneous_Traffic_Using_Weighted_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "860": {"title": "world from blur", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qiu_World_From_Blur_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "861": {"title": "topology reconstruction of tree-like structure in images via structural similarity measure and dominant set clustering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Topology_Reconstruction_of_Tree-Like_Structure_in_Images_via_Structural_Similarity_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "862": {"title": "pyramidal person re-identification via multi-loss dynamic training", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Pyramidal_Person_Re-IDentification_via_Multi-Loss_Dynamic_Training_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "863": {"title": "holistic and comprehensive annotation of clinically significant findings on diverse ct images: learning from radiology reports and label ontology", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yan_Holistic_and_Comprehensive_Annotation_of_Clinically_Significant_Findings_on_Diverse_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "864": {"title": "robust histopathology image analysis: to label or to synthesize?", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hou_Robust_Histopathology_Image_Analysis_To_Label_or_to_Synthesize_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "865": {"title": "data augmentation using learned transformations for one-shot medical image segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Data_Augmentation_Using_Learned_Transformations_for_One-Shot_Medical_Image_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "866": {"title": "shifting more attention to video salient object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Shifting_More_Attention_to_Video_Salient_Object_Detection_CVPR_2019_paper.html", "abstract": "The last decade has witnessed a growing interest in video salient object detection (VSOD). However, \nthe research community long-term lacked a well-established VSOD dataset representative of real dynam\nic scenes with high-quality annotations. To address this issue, we elaborately collected a visual-at\ntention-consistent Densely Annotated VSOD (DAVSOD) dataset, which contains 226 videos with 23,938 fr\names that cover diverse realistic-scenes, objects, instances and motions. With corresponding real hu\nman eye-fixation data, we obtain precise ground-truths. This is the first work that explicitly empha\nsizes the challenge of saliency shift, i.e., the video salient object(s) may dynamically change. To \nfurther contribute the community a complete benchmark, we systematically assess 17 representative VS\nOD algorithms over seven existing VSOD datasets and our DAVSOD with totally  84K frames (largest-sca\nle). Utilizing three famous metrics, we then present a comprehensive and insightful performance anal\nysis. Furthermore, we propose a baseline model. It is equipped with a saliency shift- aware convLSTM\n, which can efficiently capture video saliency dynamics through learning human attention-shift behav\nior. Extensive experiments open up promising future directions for model development and comparison.\n\r", "cite_num": 7, "conf": "cvpr", "time": "2019"}, "867": {"title": "neural task graphs: generalizing to unseen tasks from a single video demonstration", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Neural_Task_Graphs_Generalizing_to_Unseen_Tasks_From_a_Single_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "868": {"title": "beyond tracking: selecting memory and refining poses for deep visual odometry", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xue_Beyond_Tracking_Selecting_Memory_and_Refining_Poses_for_Deep_Visual_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "869": {"title": "image generation from layout", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Image_Generation_From_Layout_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "870": {"title": "multimodal explanations by predicting counterfactuality in videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kanehira_Multimodal_Explanations_by_Predicting_Counterfactuality_in_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "871": {"title": "learning to explain with complemental examples", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kanehira_Learning_to_Explain_With_Complemental_Examples_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "872": {"title": "haq: hardware-aware automated quantization with mixed precision", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_HAQ_Hardware-Aware_Automated_Quantization_With_Mixed_Precision_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "873": {"title": "content authentication for neural imaging pipelines: end-to-end optimization of photo provenance in complex distribution channels", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Korus_Content_Authentication_for_Neural_Imaging_Pipelines_End-To-End_Optimization_of_Photo_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "874": {"title": "inverse procedural modeling of knitwear", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Trunz_Inverse_Procedural_Modeling_of_Knitwear_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "875": {"title": "estimating 3d motion and forces of person-object interactions from monocular video", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Estimating_3D_Motion_and_Forces_of_Person-Object_Interactions_From_Monocular_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "876": {"title": "deepmapping: unsupervised map estimation from multiple point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ding_DeepMapping_Unsupervised_Map_Estimation_From_Multiple_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "877": {"title": "end-to-end interpretable neural motion planner", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_End-To-End_Interpretable_Neural_Motion_Planner_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "878": {"title": "divergence triangle for joint training of generator model, energy-based model, and inferential model", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Han_Divergence_Triangle_for_Joint_Training_of_Generator_Model_Energy-Based_Model_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "879": {"title": "image deformation meta-networks for one-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Image_Deformation_Meta-Networks_for_One-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "880": {"title": "online high rank matrix completion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Online_High_Rank_Matrix_Completion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "881": {"title": "multispectral imaging for fine-grained recognition of powders on complex backgrounds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhi_Multispectral_Imaging_for_Fine-Grained_Recognition_of_Powders_on_Complex_Backgrounds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "882": {"title": "contactdb: analyzing and predicting grasp contact via thermal imaging", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Brahmbhatt_ContactDB_Analyzing_and_Predicting_Grasp_Contact_via_Thermal_Imaging_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "883": {"title": "robust subspace clustering with independent and piecewise identically distributed noise modeling", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Robust_Subspace_Clustering_With_Independent_and_Piecewise_Identically_Distributed_Noise_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "884": {"title": "what correspondences reveal about unknown camera and motion models?", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Probst_What_Correspondences_Reveal_About_Unknown_Camera_and_Motion_Models_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "885": {"title": "self-calibrating deep photometric stereo networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Self-Calibrating_Deep_Photometric_Stereo_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "886": {"title": "argoverse: 3d tracking and forecasting with rich maps", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chang_Argoverse_3D_Tracking_and_Forecasting_With_Rich_Maps_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "887": {"title": "side window filtering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yin_Side_Window_Filtering_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "888": {"title": "defense against adversarial images using web-scale nearest-neighbor search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dubey_Defense_Against_Adversarial_Images_Using_Web-Scale_Nearest-Neighbor_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "889": {"title": "incremental object learning from contiguous views", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Stojanov_Incremental_Object_Learning_From_Contiguous_Views_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "890": {"title": "ip102: a large-scale benchmark dataset for insect pest recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_IP102_A_Large-Scale_Benchmark_Dataset_for_Insect_Pest_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "891": {"title": "cityflow: a city-scale benchmark for multi-target multi-camera vehicle tracking and re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tang_CityFlow_A_City-Scale_Benchmark_for_Multi-Target_Multi-Camera_Vehicle_Tracking_and_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "892": {"title": "social-iq: a question answering benchmark for artificial social intelligence", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "893": {"title": "upsnet: a unified panoptic segmentation network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_UPSNet_A_Unified_Panoptic_Segmentation_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "894": {"title": "jsis3d: joint semantic-instance segmentation of 3d point clouds with multi-task pointwise networks and multi-value conditional random fields", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pham_JSIS3D_Joint_Semantic-Instance_Segmentation_of_3D_Point_Clouds_With_Multi-Task_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "895": {"title": "instance segmentation by jointly optimizing spatial embeddings and clustering bandwidth", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Neven_Instance_Segmentation_by_Jointly_Optimizing_Spatial_Embeddings_and_Clustering_Bandwidth_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "896": {"title": "deepco3: deep instance co-segmentation by co-peak search and co-saliency detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hsu_DeepCO3_Deep_Instance_Co-Segmentation_by_Co-Peak_Search_and_Co-Saliency_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "897": {"title": "improving semantic segmentation via video propagation and label relaxation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Improving_Semantic_Segmentation_via_Video_Propagation_and_Label_Relaxation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "898": {"title": "accel: a corrective fusion network for efficient semantic segmentation on video", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jain_Accel_A_Corrective_Fusion_Network_for_Efficient_Semantic_Segmentation_on_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "899": {"title": "shape2motion: joint analysis of motion parts and attributes from 3d shapes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Shape2Motion_Joint_Analysis_of_Motion_Parts_and_Attributes_From_3D_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "900": {"title": "semantic correlation promoted shape-variant context for segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "901": {"title": "relation-shape convolutional neural network for point cloud analysis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Relation-Shape_Convolutional_Neural_Network_for_Point_Cloud_Analysis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "902": {"title": "enhancing diversity of defocus blur detectors via cross-ensemble network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Enhancing_Diversity_of_Defocus_Blur_Detectors_via_Cross-Ensemble_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "903": {"title": "bubblenets: learning to select the guidance frame in video object segmentation by deep sorting frames", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Griffin_BubbleNets_Learning_to_Select_the_Guidance_Frame_in_Video_Object_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "904": {"title": "collaborative global-local networks for memory-efficient segmentation of ultra-high resolution images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Collaborative_Global-Local_Networks_for_Memory-Efficient_Segmentation_of_Ultra-High_Resolution_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "905": {"title": "efficient parameter-free clustering using first neighbor relations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sarfraz_Efficient_Parameter-Free_Clustering_Using_First_Neighbor_Relations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "906": {"title": "learning personalized modular network guided by structured knowledge", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Learning_Personalized_Modular_Network_Guided_by_Structured_Knowledge_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "907": {"title": "a generative appearance model for end-to-end video object segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Johnander_A_Generative_Appearance_Model_for_End-To-End_Video_Object_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "908": {"title": "a flexible convolutional solver for fast style transfers", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Puy_A_Flexible_Convolutional_Solver_for_Fast_Style_Transfers_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "909": {"title": "cross domain model compression by structurally weight sharing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Cross_Domain_Model_Compression_by_Structurally_Weight_Sharing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "910": {"title": "travelgan: image-to-image translation by transformation vector learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Amodio_TraVeLGAN_Image-To-Image_Translation_by_Transformation_Vector_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "911": {"title": "deep robust subjective visual property prediction in crowdsourcing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Deep_Robust_Subjective_Visual_Property_Prediction_in_Crowdsourcing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "912": {"title": "transferable automl by model sharing over grouped datasets", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xue_Transferable_AutoML_by_Model_Sharing_Over_Grouped_Datasets_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "913": {"title": "learning not to learn: training deep neural networks with biased data", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Learning_Not_to_Learn_Training_Deep_Neural_Networks_With_Biased_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "914": {"title": "irlas: inverse reinforcement learning for architecture search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Guo_IRLAS_Inverse_Reinforcement_Learning_for_Architecture_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "915": {"title": "learning for single-shot confidence calibration in deep neural networks through stochastic inferences", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Seo_Learning_for_Single-Shot_Confidence_Calibration_in_Deep_Neural_Networks_Through_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "916": {"title": "attention-based adaptive selection of operations for image restoration in the presence of unknown combined distortions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Suganuma_Attention-Based_Adaptive_Selection_of_Operations_for_Image_Restoration_in_the_CVPR_2019_paper.html", "abstract": "Many studies have been conducted so far on image restoration, the problem of restoring a clean image\n from its distorted version. There are many different types of distortion affecting image quality. P\nrevious studies have focused on single types of distortion, proposing methods for removing them. How\never, image quality degrades due to multiple factors in the real world. Thus, depending on applicati\nons, e.g., vision for autonomous cars or surveillance cameras, we need to be able to deal with multi\nple combined distortions with unknown mixture ratios. For this purpose, we propose a simple yet effe\nctive layer architecture of neural networks. It performs multiple operations in parallel, which are \nweighted by an attention mechanism to enable selection of proper operations depending on the input. \nThe layer can be stacked to form a deep network, which is differentiable and thus can be trained in \nan end-to-end fashion by gradient descent. The experimental results show that the proposed method wo\nrks better than previous methods by a good margin on tasks of restoring images with multiple combine\nd distortions.\r", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "917": {"title": "fully learnable group convolution for acceleration of deep neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Fully_Learnable_Group_Convolution_for_Acceleration_of_Deep_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "918": {"title": "eigen: ecologically-inspired genetic approach for neural network structure searching from scratch", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ren_EIGEN_Ecologically-Inspired_GENetic_Approach_for_Neural_Network_Structure_Searching_From_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "919": {"title": "deep incremental hashing network for efficient image retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Deep_Incremental_Hashing_Network_for_Efficient_Image_Retrieval_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "920": {"title": "robustness via curvature regularization, and vice versa", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Moosavi-Dezfooli_Robustness_via_Curvature_Regularization_and_Vice_Versa_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "921": {"title": "sparsefool: a few pixels make a big difference", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Modas_SparseFool_A_Few_Pixels_Make_a_Big_Difference_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "922": {"title": "interpretable and fine-grained visual explanations for convolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wagner_Interpretable_and_Fine-Grained_Visual_Explanations_for_Convolutional_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "923": {"title": "structured pruning of neural networks with budget-aware regularization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lemaire_Structured_Pruning_of_Neural_Networks_With_Budget-Aware_Regularization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "924": {"title": "mbs: macroblock scaling for cnn model reduction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lin_MBS_Macroblock_Scaling_for_CNN_Model_Reduction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "925": {"title": "fast neural architecture search of compact semantic segmentation models via auxiliary cells", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Nekrasov_Fast_Neural_Architecture_Search_of_Compact_Semantic_Segmentation_Models_via_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "926": {"title": "generating 3d adversarial point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xiang_Generating_3D_Adversarial_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "927": {"title": "partial order pruning: for best speed/accuracy trade-off in neural architecture search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Partial_Order_Pruning_For_Best_SpeedAccuracy_Trade-Off_in_Neural_Architecture_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "928": {"title": "memory in memory: a predictive neural network for learning higher-order non-stationarity from spatiotemporal dynamics", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Memory_in_Memory_A_Predictive_Neural_Network_for_Learning_Higher-Order_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "929": {"title": "variational information distillation for knowledge transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ahn_Variational_Information_Distillation_for_Knowledge_Transfer_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "930": {"title": "you look twice: gaternet for dynamic filter selection in cnns", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_You_Look_Twice_GaterNet_for_Dynamic_Filter_Selection_in_CNNs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "931": {"title": "spherephd: applying cnns on a spherical polyhedron representation of 360deg images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_SpherePHD_Applying_CNNs_on_a_Spherical_PolyHeDron_Representation_of_360deg_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "932": {"title": "espnetv2: a light-weight, power efficient, and general purpose convolutional neural network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mehta_ESPNetv2_A_Light-Weight_Power_Efficient_and_General_Purpose_Convolutional_Neural_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "933": {"title": "assisted excitation of activations: a learning technique to improve object detectors", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Derakhshani_Assisted_Excitation_of_Activations_A_Learning_Technique_to_Improve_Object_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "934": {"title": "exploiting edge features for graph neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gong_Exploiting_Edge_Features_for_Graph_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "935": {"title": "propagation mechanism for deep and wide neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Propagation_Mechanism_for_Deep_and_Wide_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "936": {"title": "catastrophic child's play: easy to perform, hard to defend adversarial attacks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ho_Catastrophic_Childs_Play_Easy_to_Perform_Hard_to_Defend_Adversarial_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "937": {"title": "embedding complementary deep networks for image classification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Embedding_Complementary_Deep_Networks_for_Image_Classification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "938": {"title": "deep multimodal clustering for unsupervised audiovisual learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Deep_Multimodal_Clustering_for_Unsupervised_Audiovisual_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "939": {"title": "dense classification and implanting for few-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lifchitz_Dense_Classification_and_Implanting_for_Few-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "940": {"title": "class-balanced loss based on effective number of samples", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cui_Class-Balanced_Loss_Based_on_Effective_Number_of_Samples_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "941": {"title": "discovering visual patterns in art collections with spatially-consistent feature learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shen_Discovering_Visual_Patterns_in_Art_Collections_With_Spatially-Consistent_Feature_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "942": {"title": "min-max statistical alignment for transfer learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Herath_Min-Max_Statistical_Alignment_for_Transfer_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "943": {"title": "spatial-aware graph relation network for large-scale object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Spatial-Aware_Graph_Relation_Network_for_Large-Scale_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "944": {"title": "deformable convnets v2: more deformable, better results", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Deformable_ConvNets_V2_More_Deformable_Better_Results_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "945": {"title": "interaction-and-aggregation network for person re-identification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hou_Interaction-And-Aggregation_Network_for_Person_Re-Identification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "946": {"title": "rare event detection using disentangled representation learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hamaguchi_Rare_Event_Detection_Using_Disentangled_Representation_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "947": {"title": "shape robust text detection with progressive scale expansion network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Shape_Robust_Text_Detection_With_Progressive_Scale_Expansion_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "948": {"title": "dual encoding for zero-example video retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Dual_Encoding_for_Zero-Example_Video_Retrieval_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "949": {"title": "maxpoolnms: getting rid of nms bottlenecks in two-stage object detectors", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cai_MaxpoolNMS_Getting_Rid_of_NMS_Bottlenecks_in_Two-Stage_Object_Detectors_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "950": {"title": "character region awareness for text detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Baek_Character_Region_Awareness_for_Text_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "951": {"title": "effective aesthetics prediction with multi-level spatially pooled features", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hosu_Effective_Aesthetics_Prediction_With_Multi-Level_Spatially_Pooled_Features_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "952": {"title": "attentive region embedding network for zero-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Attentive_Region_Embedding_Network_for_Zero-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "953": {"title": "explicit spatial encoding for deep local descriptors", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mukundan_Explicit_Spatial_Encoding_for_Deep_Local_Descriptors_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "954": {"title": "panoptic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kirillov_Panoptic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "955": {"title": "you reap what you sow: using videos to generate high precision object proposals for weakly-supervised object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Singh_You_Reap_What_You_Sow_Using_Videos_to_Generate_High_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "956": {"title": "explore-exploit graph traversal for image retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chang_Explore-Exploit_Graph_Traversal_for_Image_Retrieval_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "957": {"title": "dissimilarity coefficient based weakly supervised object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Arun_Dissimilarity_Coefficient_Based_Weakly_Supervised_Object_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "958": {"title": "kernel transformer networks for compact spherical convolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Su_Kernel_Transformer_Networks_for_Compact_Spherical_Convolution_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "959": {"title": "object detection with location-aware deformable convolution and backward attention filtering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Object_Detection_With_Location-Aware_Deformable_Convolution_and_Backward_Attention_Filtering_CVPR_2019_paper.html", "abstract": "Multi-class and multi-scale object detection for autonomous driving is challenging because of the hi\ngh variation in object scales and the cluttered background in complex street scenes. Context informa\ntion and high-resolution features are the keys to achieve a good performance in multi-scale object d\netection. However, context information is typically unevenly distributed, and the high-resolution fe\nature map also contains distractive low-level features. In this paper, we propose a location-aware d\neformable convolution and a backward attention filtering to improve the detection performance. The l\nocation-aware deformable convolution extracts the unevenly distributed context features by sampling \nthe input from where informative context exists. Different from the original deformable convolution,\n the proposed method applies an individual convolutional layer on each input sampling grid location \nto obtain a wide and unique receptive field for a better offset estimation. Meanwhile, the backward \nattention filtering module filters the high-resolution feature map by highlighting the informative f\neatures and suppressing the distractive features using the semantic features from the deep layers. E\nxtensive experiments are conducted on the KITTI object detection and PASCAL VOC 2007 datasets. The p\nroposed method shows an average 6% performance improvement over the Faster R-CNN baseline, and it ha\ns the top-3 performance on the KITTI leaderboard with the fastest processing speed.\r", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "960": {"title": "variational prototyping-encoder: one-shot learning with prototypical images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Variational_Prototyping-Encoder_One-Shot_Learning_With_Prototypical_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "961": {"title": "unsupervised domain adaptation using feature-whitening and consensus loss", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Roy_Unsupervised_Domain_Adaptation_Using_Feature-Whitening_and_Consensus_Loss_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "962": {"title": "feelvos: fast end-to-end embedding learning for video object segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Voigtlaender_FEELVOS_Fast_End-To-End_Embedding_Learning_for_Video_Object_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "963": {"title": "partnet: a recursive part decomposition network for fine-grained and hierarchical shape segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_PartNet_A_Recursive_Part_Decomposition_Network_for_Fine-Grained_and_Hierarchical_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "964": {"title": "learning multi-class segmentations from single-class datasets", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dmitriev_Learning_Multi-Class_Segmentations_From_Single-Class_Datasets_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "965": {"title": "convolutional recurrent network for road boundary extraction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Convolutional_Recurrent_Network_for_Road_Boundary_Extraction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "966": {"title": "dfanet: deep feature aggregation for real-time semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_DFANet_Deep_Feature_Aggregation_for_Real-Time_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "967": {"title": "a cross-season correspondence dataset for robust semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Larsson_A_Cross-Season_Correspondence_Dataset_for_Robust_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "968": {"title": "mantra-net: manipulation tracing network for detection and localization of image forgeries with anomalous features", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_ManTra-Net_Manipulation_Tracing_Network_for_Detection_and_Localization_of_Image_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "969": {"title": "on zero-shot recognition of generic objects", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hascoet_On_Zero-Shot_Recognition_of_Generic_Objects_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "970": {"title": "explicit bias discovery in visual question answering models", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Manjunatha_Explicit_Bias_Discovery_in_Visual_Question_Answering_Models_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "971": {"title": "repair: removing representation bias by dataset resampling", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_REPAIR_Removing_Representation_Bias_by_Dataset_Resampling_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "972": {"title": "label efficient semi-supervised learning via graph filtering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Label_Efficient_Semi-Supervised_Learning_via_Graph_Filtering_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "973": {"title": "mvtec ad -- a comprehensive real-world dataset for unsupervised anomaly detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Bergmann_MVTec_AD_--_A_Comprehensive_Real-World_Dataset_for_Unsupervised_Anomaly_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "974": {"title": "abc: a big cad model dataset for geometric deep learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Koch_ABC_A_Big_CAD_Model_Dataset_for_Geometric_Deep_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "975": {"title": "tightness-aware evaluation protocol for scene text detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Tightness-Aware_Evaluation_Protocol_for_Scene_Text_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "976": {"title": "pointconv: deep convolutional networks on 3d point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_PointConv_Deep_Convolutional_Networks_on_3D_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "977": {"title": "octree guided cnn with spherical kernels for 3d point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lei_Octree_Guided_CNN_With_Spherical_Kernels_for_3D_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "978": {"title": "vitamin-e: visual tracking and mapping with extremely dense feature points", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yokozuka_VITAMIN-E_VIsual_Tracking_and_MappINg_With_Extremely_Dense_Feature_Points_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "979": {"title": "conditional single-view shape generation for multi-view stereo reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Conditional_Single-View_Shape_Generation_for_Multi-View_Stereo_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "980": {"title": "learning to adapt for stereo", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tonioni_Learning_to_Adapt_for_Stereo_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "981": {"title": "3d appearance super-resolution with deep learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_3D_Appearance_Super-Resolution_With_Deep_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "982": {"title": "radial distortion triangulation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kukelova_Radial_Distortion_Triangulation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "983": {"title": "robust point cloud based reconstruction of large-scale outdoor scenes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lan_Robust_Point_Cloud_Based_Reconstruction_of_Large-Scale_Outdoor_Scenes_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "984": {"title": "minimal solvers for mini-loop closures in 3d multi-scan alignment", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Miraldo_Minimal_Solvers_for_Mini-Loop_Closures_in_3D_Multi-Scan_Alignment_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "985": {"title": "volumetric capture of humans with a single rgbd camera via semi-parametric learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pandey_Volumetric_Capture_of_Humans_With_a_Single_RGBD_Camera_via_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "986": {"title": "joint face detection and facial motion retargeting for multiple faces", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chaudhuri_Joint_Face_Detection_and_Facial_Motion_Retargeting_for_Multiple_Faces_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "987": {"title": "monocular depth estimation using relative depth maps", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Monocular_Depth_Estimation_Using_Relative_Depth_Maps_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "988": {"title": "unsupervised primitive discovery for improved 3d generative modeling", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Khan_Unsupervised_Primitive_Discovery_for_Improved_3D_Generative_Modeling_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "989": {"title": "learning to explore intrinsic saliency for stereoscopic video", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Learning_to_Explore_Intrinsic_Saliency_for_Stereoscopic_Video_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "990": {"title": "spherical regression: learning viewpoints, surface normals and 3d rotations on n-spheres", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liao_Spherical_Regression_Learning_Viewpoints_Surface_Normals_and_3D_Rotations_on_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "991": {"title": "refine and distill: exploiting cycle-inconsistency and knowledge distillation for unsupervised monocular depth estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pilzer_Refine_and_Distill_Exploiting_Cycle-Inconsistency_and_Knowledge_Distillation_for_Unsupervised_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "992": {"title": "learning view priors for single-view 3d reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kato_Learning_View_Priors_for_Single-View_3D_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "993": {"title": "geometry-aware symmetric domain adaptation for monocular depth estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Geometry-Aware_Symmetric_Domain_Adaptation_for_Monocular_Depth_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "994": {"title": "learning monocular depth estimation infusing traditional stereo knowledge", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tosi_Learning_Monocular_Depth_Estimation_Infusing_Traditional_Stereo_Knowledge_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "995": {"title": "signet: semantic instance aided unsupervised 3d geometry perception", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Meng_SIGNet_Semantic_Instance_Aided_Unsupervised_3D_Geometry_Perception_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "996": {"title": "3d guided fine-grained face manipulation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Geng_3D_Guided_Fine-Grained_Face_Manipulation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "997": {"title": "neuro-inspired eye tracking with eye movement dynamics", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Neuro-Inspired_Eye_Tracking_With_Eye_Movement_Dynamics_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "998": {"title": "facial emotion distribution learning by exploiting low-rank label correlations locally", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jia_Facial_Emotion_Distribution_Learning_by_Exploiting_Low-Rank_Label_Correlations_Locally_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "999": {"title": "unsupervised face normalization with extreme pose and expression in the wild", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qian_Unsupervised_Face_Normalization_With_Extreme_Pose_and_Expression_in_the_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1000": {"title": "semantic component decomposition for face attribute manipulation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Semantic_Component_Decomposition_for_Face_Attribute_Manipulation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1001": {"title": "r3 adversarial network for cross model face recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_R3_Adversarial_Network_for_Cross_Model_Face_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1002": {"title": "disentangling latent hands for image synthesis and pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Disentangling_Latent_Hands_for_Image_Synthesis_and_Pose_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1003": {"title": "generating multiple hypotheses for 3d human pose estimation with mixture density network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Generating_Multiple_Hypotheses_for_3D_Human_Pose_Estimation_With_Mixture_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1004": {"title": "crossinfonet: multi-task information sharing based hand pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Du_CrossInfoNet_Multi-Task_Information_Sharing_Based_Hand_Pose_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1005": {"title": "p2sgrad: refined gradients for optimizing deep face models", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_P2SGrad_Refined_Gradients_for_Optimizing_Deep_Face_Models_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1006": {"title": "action recognition from single timestamp supervision in untrimmed videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Moltisanti_Action_Recognition_From_Single_Timestamp_Supervision_in_Untrimmed_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1007": {"title": "time-conditioned action anticipation in one shot", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ke_Time-Conditioned_Action_Anticipation_in_One_Shot_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1008": {"title": "dance with flow: two-in-one stream action detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Dance_With_Flow_Two-In-One_Stream_Action_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1009": {"title": "representation flow for action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Piergiovanni_Representation_Flow_for_Action_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1010": {"title": "lsta: long short-term attention for egocentric action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sudhakaran_LSTA_Long_Short-Term_Attention_for_Egocentric_Action_Recognition_CVPR_2019_paper.html", "abstract": "Egocentric activity recognition is one of the most challenging tasks in video analysis. It requires \na fine-grained discrimination of small objects and their manipulation. While some methods base on st\nrong supervision and attention mechanisms, they are either annotation consuming or do not take spati\no-temporal patterns into account. In this paper we propose LSTA as a mechanism to focus on features \nfrom spatial relevant parts while attention is being tracked smoothly across the video sequence. We \ndemonstrate the effectiveness of LSTA on egocentric activity recognition with an end-to-end trainabl\ne two-stream architecture, achieving state-of-the-art performance on four standard benchmarks.\r", "cite_num": 3, "conf": "cvpr", "time": "2019"}, "1011": {"title": "learning actor relation graphs for group activity recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Learning_Actor_Relation_Graphs_for_Group_Activity_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1012": {"title": "a structured model for action detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_A_Structured_Model_for_Action_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1013": {"title": "out-of-distribution detection for generalized zero-shot action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mandal_Out-Of-Distribution_Detection_for_Generalized_Zero-Shot_Action_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1014": {"title": "object discovery in videos as foreground motion clustering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Object_Discovery_in_Videos_as_Foreground_Motion_Clustering_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1015": {"title": "towards natural and accurate future motion prediction of humans and animals", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Towards_Natural_and_Accurate_Future_Motion_Prediction_of_Humans_and_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1016": {"title": "automatic face aging in videos via deep reinforcement learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Duong_Automatic_Face_Aging_in_Videos_via_Deep_Reinforcement_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1017": {"title": "multi-adversarial discriminative deep domain generalization for face presentation attack detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shao_Multi-Adversarial_Discriminative_Deep_Domain_Generalization_for_Face_Presentation_Attack_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1018": {"title": "a content transformation block for image style transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kotovenko_A_Content_Transformation_Block_for_Image_Style_Transfer_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1019": {"title": "beautyglow: on-demand makeup transfer framework with reversible generative network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_BeautyGlow_On-Demand_Makeup_Transfer_Framework_With_Reversible_Generative_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1020": {"title": "style transfer by relaxed optimal transport and self-similarity", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kolkin_Style_Transfer_by_Relaxed_Optimal_Transport_and_Self-Similarity_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1021": {"title": "inserting videos into videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Inserting_Videos_Into_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1022": {"title": "learning image and video compression through spatial-temporal energy compaction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_Learning_Image_and_Video_Compression_Through_Spatial-Temporal_Energy_Compaction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1023": {"title": "event-based high dynamic range image and very high frame rate video generation using conditional generative adversarial networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Event-Based_High_Dynamic_Range_Image_and_Very_High_Frame_Rate_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1024": {"title": "enhancing triplegan for semi-supervised conditional instance synthesis and classification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Enhancing_TripleGAN_for_Semi-Supervised_Conditional_Instance_Synthesis_and_Classification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1025": {"title": "capture, learning, and synthesis of 3d speaking styles", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cudeiro_Capture_Learning_and_Synthesis_of_3D_Speaking_Styles_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1026": {"title": "nesti-net: normal estimation for unstructured 3d point clouds using convolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ben-Shabat_Nesti-Net_Normal_Estimation_for_Unstructured_3D_Point_Clouds_Using_Convolutional_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1027": {"title": "ray-space projection model for light field camera", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Ray-Space_Projection_Model_for_Light_Field_Camera_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1028": {"title": "deep geometric prior for surface reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Williams_Deep_Geometric_Prior_for_Surface_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1029": {"title": "analysis of feature visibility in non-line-of-sight measurements", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Analysis_of_Feature_Visibility_in_Non-Line-Of-Sight_Measurements_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1030": {"title": "hyperspectral imaging with random printed mask", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Hyperspectral_Imaging_With_Random_Printed_Mask_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1031": {"title": "all-weather deep outdoor lighting estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_All-Weather_Deep_Outdoor_Lighting_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1032": {"title": "a variational em framework with adaptive edge selection for blind motion deblurring", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_A_Variational_EM_Framework_With_Adaptive_Edge_Selection_for_Blind_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1033": {"title": "viewport proposal cnn for 360deg video quality assessment", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Viewport_Proposal_CNN_for_360deg_Video_Quality_Assessment_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1034": {"title": "beyond gradient descent for regularized segmentation losses", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Marin_Beyond_Gradient_Descent_for_Regularized_Segmentation_Losses_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1035": {"title": "magsac: marginalizing sample consensus", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Barath_MAGSAC_Marginalizing_Sample_Consensus_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1036": {"title": "understanding and visualizing deep visual saliency models", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Understanding_and_Visualizing_Deep_Visual_Saliency_Models_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1037": {"title": "divergence prior and vessel-tree reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Divergence_Prior_and_Vessel-Tree_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1038": {"title": "unsupervised domain-specific deblurring via disentangled representations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lu_Unsupervised_Domain-Specific_Deblurring_via_Disentangled_Representations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1039": {"title": "douglas-rachford networks: learning both the image prior and data fidelity terms for blind image deconvolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Aljadaany_Douglas-Rachford_Networks_Learning_Both_the_Image_Prior_and_Data_Fidelity_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1040": {"title": "speed invariant time surface for learning to detect corner points with event-based cameras", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Manderscheid_Speed_Invariant_Time_Surface_for_Learning_to_Detect_Corner_Points_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1041": {"title": "training deep learning based image denoisers from undersampled measurements without ground truth and without image prior", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhussip_Training_Deep_Learning_Based_Image_Denoisers_From_Undersampled_Measurements_Without_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1042": {"title": "a variational pan-sharpening with local gradient constraints", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fu_A_Variational_Pan-Sharpening_With_Local_Gradient_Constraints_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1043": {"title": "f-vaegan-d2: a feature generating framework for any-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xian_F-VAEGAN-D2_A_Feature_Generating_Framework_for_Any-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1044": {"title": "sliced wasserstein discrepancy for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Sliced_Wasserstein_Discrepancy_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1045": {"title": "graph attention convolution for point cloud semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Graph_Attention_Convolution_for_Point_Cloud_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "Standard convolution is inherently limited for semantic segmentation of point cloud due to its isotr\nopy about features. It neglects the structure of an object, results in poor object delineation and s\nmall spurious regions in the segmentation result. This paper proposes a novel graph attention convol\nution (GAC), whose kernels can be dynamically carved into specific shapes to adapt to the structure \nof an object. Specifically, by assigning proper attentional weights to different neighboring points,\n GAC is designed to selectively focus on the most relevant part of them according to their dynamical\nly learned features. The shape of the convolution kernel is then determined by the learned distribut\nion of the attentional weights. Though simple, GAC can capture the structured features of point clou\nds for fine-grained segmentation and avoid feature contamination between objects. Theoretically, we \nprovided a thorough analysis on the expressive capabilities of GAC to show how it can learn about th\ne features of point clouds. Empirically, we evaluated the proposed GAC on challenging indoor and out\ndoor datasets and achieved the state-of-the-art results in both scenarios.\r", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "1046": {"title": "normalized diversification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Normalized_Diversification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1047": {"title": "learning to localize through compressed binary maps", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Learning_to_Localize_Through_Compressed_Binary_Maps_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1048": {"title": "a parametric top-view representation of complex road scenes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_A_Parametric_Top-View_Representation_of_Complex_Road_Scenes_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1049": {"title": "self-supervised spatiotemporal learning via video clip order prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Self-Supervised_Spatiotemporal_Learning_via_Video_Clip_Order_Prediction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1050": {"title": "superquadrics revisited: learning 3d shape parsing beyond cuboids", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Paschalidou_Superquadrics_Revisited_Learning_3D_Shape_Parsing_Beyond_Cuboids_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1051": {"title": "unsupervised disentangling of appearance and geometry by deformable generator network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xing_Unsupervised_Disentangling_of_Appearance_and_Geometry_by_Deformable_Generator_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1052": {"title": "self-supervised representation learning by rotation feature decoupling", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Feng_Self-Supervised_Representation_Learning_by_Rotation_Feature_Decoupling_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1053": {"title": "weakly supervised deep image hashing through tag embeddings", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gattupalli_Weakly_Supervised_Deep_Image_Hashing_Through_Tag_Embeddings_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1054": {"title": "improved road connectivity by joint learning of orientation and segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Batra_Improved_Road_Connectivity_by_Joint_Learning_of_Orientation_and_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1055": {"title": "deep supervised cross-modal retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhen_Deep_Supervised_Cross-Modal_Retrieval_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1056": {"title": "a theoretically sound upper bound on the triplet loss for improving the efficiency of deep distance metric learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Do_A_Theoretically_Sound_Upper_Bound_on_the_Triplet_Loss_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1057": {"title": "data representation and learning with graph diffusion-embedding networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jiang_Data_Representation_and_Learning_With_Graph_Diffusion-Embedding_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1058": {"title": "video relationship reasoning using gated spatio-temporal energy graph", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tsai_Video_Relationship_Reasoning_Using_Gated_Spatio-Temporal_Energy_Graph_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1059": {"title": "image-question-answer synergistic network for visual dialog", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Image-Question-Answer_Synergistic_Network_for_Visual_Dialog_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1060": {"title": "not all frames are equal: weakly-supervised video grounding with contextual similarity and visual clustering losses", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Not_All_Frames_Are_Equal_Weakly-Supervised_Video_Grounding_With_Contextual_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1061": {"title": "inverse cooking: recipe generation from food images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Salvador_Inverse_Cooking_Recipe_Generation_From_Food_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1062": {"title": "adversarial semantic alignment for improved image captions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dognin_Adversarial_Semantic_Alignment_for_Improved_Image_Captions_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1063": {"title": "answer them all! toward universal visual question answering models", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shrestha_Answer_Them_All_Toward_Universal_Visual_Question_Answering_Models_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1064": {"title": "unsupervised multi-modal neural machine translation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Su_Unsupervised_Multi-Modal_Neural_Machine_Translation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1065": {"title": "multi-task learning of hierarchical vision-language representation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Nguyen_Multi-Task_Learning_of_Hierarchical_Vision-Language_Representation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1066": {"title": "cross-modal self-attention network for referring image segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Cross-Modal_Self-Attention_Network_for_Referring_Image_Segmentation_CVPR_2019_paper.html", "abstract": "We consider the problem of referring image segmentation. Given an input image and a natural language\n expression, the goal is to segment the object referred by the language expression in the image. Exi\nsting works in this area treat the language expression and the input image separately in their repre\nsentations. They do not sufficiently capture long-range correlations between these two modalities. I\nn this paper, we propose a cross-modal self-attention (CMSA) module that effectively captures the lo\nng-range dependencies between linguistic and visual features. Our model can adaptively focus on info\nrmative words in the referring expression and important regions in the input image. In addition, we \npropose a gated multi-level fusion module to selectively integrate self-attentive cross-modal featur\nes corresponding to different levels in the image. This module controls the information flow of feat\nures at different levels. We validate the proposed approach on four evaluation datasets. Our propose\nd approach consistently outperforms existing state-of-the-art methods.", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "1067": {"title": "dudonet: dual domain network for ct metal artifact reduction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lin_DuDoNet_Dual_Domain_Network_for_CT_Metal_Artifact_Reduction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1068": {"title": "fast spatio-temporal residual network for video super-resolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Fast_Spatio-Temporal_Residual_Network_for_Video_Super-Resolution_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1069": {"title": "complete the look: scene-based complementary product recommendation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kang_Complete_the_Look_Scene-Based_Complementary_Product_Recommendation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1070": {"title": "selective sensor fusion for neural visual-inertial odometry", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Selective_Sensor_Fusion_for_Neural_Visual-Inertial_Odometry_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1071": {"title": "look more than once: an accurate detector for text of arbitrary shapes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Look_More_Than_Once_An_Accurate_Detector_for_Text_of_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1072": {"title": "learning binary code for personalized fashion recommendation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lu_Learning_Binary_Code_for_Personalized_Fashion_Recommendation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1073": {"title": "attention based glaucoma detection: a large-scale database and cnn model", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Attention_Based_Glaucoma_Detection_A_Large-Scale_Database_and_CNN_Model_CVPR_2019_paper.html", "abstract": "Recently, the attention mechanism has been successfully applied in convolutional neural networks (CN\nNs), significantly boosting the performance of many computer vision tasks. Unfortunately, few medica\nl image recognition approaches incorporate the attention mechanism in the CNNs. In particular, there\n exists high redundancy in fundus images for glaucoma detection, such that the attention mechanism h\nas potential in improving the performance of CNN-based glaucoma detection. This paper proposes an at\ntention-based CNN for glaucoma detection (AG-CNN). Specifically, we first establish a large-scale at\ntention based glaucoma (LAG) database, which includes 5,824 fundus images labeled with either positi\nve glaucoma (2,392) or negative glaucoma (3,432). The attention maps of the ophthalmologists are als\no collected in LAG database through a simulated eye-tracking experiment. Then, a new structure of AG\n-CNN is designed, including an attention prediction subnet, a pathological area localization subnet \nand a glaucoma classification subnet. Different from other attention-based CNN methods, the features\n are also visualized as the localized pathological area, which can advance the performance of glauco\nma detection. Finally, the experiment results show that the proposed AG-CNN approach significantly a\ndvances state-of-the-art glaucoma detection.", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "1074": {"title": "privacy protection in street-view panoramas using depth and multi-view imagery", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Uittenbogaard_Privacy_Protection_in_Street-View_Panoramas_Using_Depth_and_Multi-View_Imagery_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1075": {"title": "grounding human-to-vehicle advice for self-driving vehicles", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Grounding_Human-To-Vehicle_Advice_for_Self-Driving_Vehicles_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1076": {"title": "multi-step prediction of occupancy grid maps with recurrent neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mohajerin_Multi-Step_Prediction_of_Occupancy_Grid_Maps_With_Recurrent_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1077": {"title": "connecting touch and vision via cross-modal prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Connecting_Touch_and_Vision_via_Cross-Modal_Prediction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1078": {"title": "x2ct-gan: reconstructing ct from biplanar x-rays with generative adversarial networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ying_X2CT-GAN_Reconstructing_CT_From_Biplanar_X-Rays_With_Generative_Adversarial_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1079": {"title": "practical full resolution learned lossless image compression", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mentzer_Practical_Full_Resolution_Learned_Lossless_Image_Compression_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1080": {"title": "image-to-image translation via group-wise deep whitening-and-coloring transformation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cho_Image-To-Image_Translation_via_Group-Wise_Deep_Whitening-And-Coloring_Transformation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1081": {"title": "max-sliced wasserstein distance and its use for gans", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Deshpande_Max-Sliced_Wasserstein_Distance_and_Its_Use_for_GANs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1082": {"title": "meta-learning with differentiable convex optimization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Meta-Learning_With_Differentiable_Convex_Optimization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1083": {"title": "repr: improved training of convolutional filters", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Prakash_RePr_Improved_Training_of_Convolutional_Filters_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1084": {"title": "tangent-normal adversarial regularization for semi-supervised learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Tangent-Normal_Adversarial_Regularization_for_Semi-Supervised_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1085": {"title": "auto-encoding scene graphs for image captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Auto-Encoding_Scene_Graphs_for_Image_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1086": {"title": "fast, diverse and accurate image captioning guided by part-of-speech", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Deshpande_Fast_Diverse_and_Accurate_Image_Captioning_Guided_by_Part-Of-Speech_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1087": {"title": "attention branch network: learning of attention mechanism for visual explanation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fukui_Attention_Branch_Network_Learning_of_Attention_Mechanism_for_Visual_Explanation_CVPR_2019_paper.html", "abstract": "Visual explanation enables human to understand the decision making of Deep Convolutional Neural Netw\nork (CNN), but it is insufficient to contribute the performance improvement. In this paper, we focus\n on the attention map for visual explanation, which represents high response value as the important \nregion in image recognition. This region significantly improves the performance of CNN by introducin\ng an attention mechanism that focuses on a specific region in an image. In this work, we propose Att\nention Branch Network (ABN), which extends the top-down visual explanation model by introducing a br\nanch structure with an attention mechanism. ABN can be applicable to several image recognition tasks\n by introducing a branch for attention mechanism and is trainable for the visual explanation and ima\nge recognition in end-to-end manner. We evaluate ABN on several image recognition tasks such as imag\ne classification, fine-grained recognition, and multiple facial attributes recognition. Experimental\n results show that ABN can outperform the accuracy of baseline models on these image recognition tas\nks while generating an attention map for visual explanation. Our code is available at this https URL\n.", "cite_num": 3, "conf": "cvpr", "time": "2019"}, "1088": {"title": "cascaded projection: end-to-end network compression and acceleration", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Minnehan_Cascaded_Projection_End-To-End_Network_Compression_and_Acceleration_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1089": {"title": "deepcaps: going deeper with capsule networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Rajasegaran_DeepCaps_Going_Deeper_With_Capsule_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1090": {"title": "fbnet: hardware-aware efficient convnet design via differentiable neural architecture search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_FBNet_Hardware-Aware_Efficient_ConvNet_Design_via_Differentiable_Neural_Architecture_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1091": {"title": "apdrawinggan: generating artistic portrait drawings from face photos with hierarchical gans", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yi_APDrawingGAN_Generating_Artistic_Portrait_Drawings_From_Face_Photos_With_Hierarchical_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1092": {"title": "constrained generative adversarial networks for interactive image generation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Heim_Constrained_Generative_Adversarial_Networks_for_Interactive_Image_Generation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1093": {"title": "warpgan: automatic caricature generation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_WarpGAN_Automatic_Caricature_Generation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1094": {"title": "explainability methods for graph convolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pope_Explainability_Methods_for_Graph_Convolutional_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1095": {"title": "a generative adversarial density estimator", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Abbasnejad_A_Generative_Adversarial_Density_Estimator_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1096": {"title": "sodeep: a sorting deep net to learn ranking loss surrogates", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Engilberge_SoDeep_A_Sorting_Deep_Net_to_Learn_Ranking_Loss_Surrogates_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1097": {"title": "high-quality face capture using anatomical muscles", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Bao_High-Quality_Face_Capture_Using_Anatomical_Muscles_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1098": {"title": "fml: face model learning from videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tewari_FML_Face_Model_Learning_From_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1099": {"title": "adacos: adaptively scaling cosine logits for effectively learning deep face representations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_AdaCos_Adaptively_Scaling_Cosine_Logits_for_Effectively_Learning_Deep_Face_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1100": {"title": "3d hand shape and pose estimation from a single rgb image", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ge_3D_Hand_Shape_and_Pose_Estimation_From_a_Single_RGB_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1101": {"title": "3d hand shape and pose from images in the wild", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Boukhayma_3D_Hand_Shape_and_Pose_From_Images_in_the_Wild_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1102": {"title": "self-supervised 3d hand pose estimation through training by fitting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wan_Self-Supervised_3D_Hand_Pose_Estimation_Through_Training_by_Fitting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1103": {"title": "crowdpose: efficient crowded scenes pose estimation and a new benchmark", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_CrowdPose_Efficient_Crowded_Scenes_Pose_Estimation_and_a_New_Benchmark_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1104": {"title": "towards social artificial intelligence: nonverbal social signal prediction in a triadic interaction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Joo_Towards_Social_Artificial_Intelligence_Nonverbal_Social_Signal_Prediction_in_a_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1105": {"title": "holopose: holistic 3d human reconstruction in-the-wild", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Guler_HoloPose_Holistic_3D_Human_Reconstruction_In-The-Wild_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1106": {"title": "weakly-supervised discovery of geometry-aware representation for 3d human pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Weakly-Supervised_Discovery_of_Geometry-Aware_Representation_for_3D_Human_Pose_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1107": {"title": "in the wild human pose estimation using explicit 2d features and intermediate 3d representations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Habibie_In_the_Wild_Human_Pose_Estimation_Using_Explicit_2D_Features_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1108": {"title": "slim densepose: thrifty learning from sparse annotations and motion cues", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Neverova_Slim_DensePose_Thrifty_Learning_From_Sparse_Annotations_and_Motion_Cues_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1109": {"title": "self-supervised representation learning from videos for facial action unit detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Self-Supervised_Representation_Learning_From_Videos_for_Facial_Action_Unit_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1110": {"title": "combining 3d morphable models: a large scale face-and-head model", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ploumpis_Combining_3D_Morphable_Models_A_Large_Scale_Face-And-Head_Model_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1111": {"title": "boosting local shape matching for dense 3d face correspondence", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Boosting_Local_Shape_Matching_for_Dense_3D_Face_Correspondence_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1112": {"title": "unsupervised part-based disentangling of object shape and appearance", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lorenz_Unsupervised_Part-Based_Disentangling_of_Object_Shape_and_Appearance_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1113": {"title": "monocular total capture: posing face, body, and hands in the wild", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Xiang_Monocular_Total_Capture_Posing_Face_Body_and_Hands_in_the_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1114": {"title": "expressive body capture: 3d hands, face, and body from a single image", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pavlakos_Expressive_Body_Capture_3D_Hands_Face_and_Body_From_a_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1115": {"title": "neural rgb(r)d sensing: depth and uncertainty from a video camera", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Neural_RGBrD_Sensing_Depth_and_Uncertainty_From_a_Video_Camera_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1116": {"title": "davanet: stereo deblurring with view aggregation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_DAVANet_Stereo_Deblurring_With_View_Aggregation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1117": {"title": "dvc: an end-to-end deep video compression framework", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lu_DVC_An_End-To-End_Deep_Video_Compression_Framework_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1118": {"title": "sosnet: second order similarity regularization for local descriptor learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tian_SOSNet_Second_Order_Similarity_Regularization_for_Local_Descriptor_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1119": {"title": "\"double-dip\": unsupervised image decomposition via coupled deep-image-priors", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gandelsman_Double-DIP_Unsupervised_Image_Decomposition_via_Coupled_Deep-Image-Priors_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1120": {"title": "unprocessing images for learned raw denoising", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Brooks_Unprocessing_Images_for_Learned_Raw_Denoising_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1121": {"title": "residual networks for light field image super-resolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Residual_Networks_for_Light_Field_Image_Super-Resolution_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1122": {"title": "modulating image restoration with continual levels via adaptive feature modification layers", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Modulating_Image_Restoration_With_Continual_Levels_via_Adaptive_Feature_Modification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1123": {"title": "second-order attention network for single image super-resolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dai_Second-Order_Attention_Network_for_Single_Image_Super-Resolution_CVPR_2019_paper.html", "abstract": "Recently, deep convolutional neural networks (CNNs) have been widely explored in single image super-\nresolution (SISR) and obtained remarkable performance. However, most of the existing CNN-based SISR \nmethods mainly focus on wider or deeper architecture design, neglecting to explore the feature corre\nlations of intermediate layers, hence hindering the representational power of CNNs. To address this \nissue, in this paper, we propose a second-order attention network (SAN) for more powerful feature ex\npression and feature correlation learning. Specifically, a novel train- able second-order channel at\ntention (SOCA) module is developed to adaptively rescale the channel-wise features by using second-o\nrder feature statistics for more discriminative representations. Furthermore, we present a non-local\nly enhanced residual group (NLRG) structure, which not only incorporates non-local operations to cap\nture long-distance spatial contextual information, but also contains repeated local-source residual \nattention groups (LSRAG) to learn increasingly abstract feature representations. Experimental result\ns demonstrate the superiority of our SAN network over state-of-the-art SISR methods in terms of both\n quantitative metrics and visual quality.\r", "cite_num": 2, "conf": "cvpr", "time": "2019"}, "1124": {"title": "devil is in the edges: learning semantic boundaries from noisy annotations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Acuna_Devil_Is_in_the_Edges_Learning_Semantic_Boundaries_From_Noisy_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1125": {"title": "path-invariant map networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Path-Invariant_Map_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1126": {"title": "filterreg: robust and efficient probabilistic point-set registration using gaussian filter and twist parameterization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gao_FilterReg_Robust_and_Efficient_Probabilistic_Point-Set_Registration_Using_Gaussian_Filter_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1127": {"title": "probabilistic permutation synchronization using the riemannian structure of the birkhoff polytope", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Birdal_Probabilistic_Permutation_Synchronization_Using_the_Riemannian_Structure_of_the_Birkhoff_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1128": {"title": "lifting vectorial variational problems: a natural formulation based on geometric measure theory and discrete exterior calculus", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mollenhoff_Lifting_Vectorial_Variational_Problems_A_Natural_Formulation_Based_on_Geometric_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1129": {"title": "a sufficient condition for convergences of adam and rmsprop", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zou_A_Sufficient_Condition_for_Convergences_of_Adam_and_RMSProp_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1130": {"title": "guaranteed matrix completion under multiple linear transformations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Guaranteed_Matrix_Completion_Under_Multiple_Linear_Transformations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1131": {"title": "map inference via block-coordinate frank-wolfe algorithm", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Swoboda_MAP_Inference_via_Block-Coordinate_Frank-Wolfe_Algorithm_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1132": {"title": "a convex relaxation for multi-graph matching", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Swoboda_A_Convex_Relaxation_for_Multi-Graph_Matching_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1133": {"title": "pixel-adaptive convolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Su_Pixel-Adaptive_Convolutional_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1134": {"title": "single-frame regularization for temporally stable cnns", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Eilertsen_Single-Frame_Regularization_for_Temporally_Stable_CNNs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1135": {"title": "an end-to-end network for generating social relationship graphs", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Goel_An_End-To-End_Network_for_Generating_Social_Relationship_Graphs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1136": {"title": "meta-learning convolutional neural architectures for multi-target concrete defect classification with the concrete defect bridge image dataset", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mundt_Meta-Learning_Convolutional_Neural_Architectures_for_Multi-Target_Concrete_Defect_Classification_With_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1137": {"title": "ecc: platform-independent energy-constrained deep neural network compression via a bilinear regression model", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yang_ECC_Platform-Independent_Energy-Constrained_Deep_Neural_Network_Compression_via_a_Bilinear_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1138": {"title": "seernet: predicting convolutional neural network feature-map sparsity through low-bit quantization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cao_SeerNet_Predicting_Convolutional_Neural_Network_Feature-Map_Sparsity_Through_Low-Bit_Quantization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1139": {"title": "defending against adversarial attacks by randomized diversification", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Taran_Defending_Against_Adversarial_Attacks_by_Randomized_Diversification_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1140": {"title": "rob-gan: generator, discriminator, and adversarial attacker", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Rob-GAN_Generator_Discriminator_and_Adversarial_Attacker_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1141": {"title": "learning from noisy labels by regularized estimation of annotator confusion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tanno_Learning_From_Noisy_Labels_by_Regularized_Estimation_of_Annotator_Confusion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1142": {"title": "task-free continual learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Aljundi_Task-Free_Continual_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1143": {"title": "importance estimation for neural network pruning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Molchanov_Importance_Estimation_for_Neural_Network_Pruning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1144": {"title": "detecting overfitting of deep generative networks via latent recovery", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Webster_Detecting_Overfitting_of_Deep_Generative_Networks_via_Latent_Recovery_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1145": {"title": "coloring with limited data: few-shot colorization via memory augmented networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yoo_Coloring_With_Limited_Data_Few-Shot_Colorization_via_Memory_Augmented_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1146": {"title": "characterizing and avoiding negative transfer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Characterizing_and_Avoiding_Negative_Transfer_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1147": {"title": "building efficient deep neural networks with unitary group convolutions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Building_Efficient_Deep_Neural_Networks_With_Unitary_Group_Convolutions_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1148": {"title": "semi-supervised learning with graph learning-convolutional networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jiang_Semi-Supervised_Learning_With_Graph_Learning-Convolutional_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1149": {"title": "learning to remember: a synaptic plasticity driven framework for continual learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ostapenko_Learning_to_Remember_A_Synaptic_Plasticity_Driven_Framework_for_Continual_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1150": {"title": "aird: adversarial learning framework for image repurposing detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jaiswal_AIRD_Adversarial_Learning_Framework_for_Image_Repurposing_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1151": {"title": "a kernelized manifold mapping to diminish the effect of adversarial perturbations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Taghanaki_A_Kernelized_Manifold_Mapping_to_Diminish_the_Effect_of_Adversarial_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1152": {"title": "trust region based adversarial attack on neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yao_Trust_Region_Based_Adversarial_Attack_on_Neural_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1153": {"title": "pepsi : fast image inpainting with parallel decoding network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sagong_PEPSI__Fast_Image_Inpainting_With_Parallel_Decoding_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1154": {"title": "model-blind video denoising via frame-to-frame training", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ehret_Model-Blind_Video_Denoising_via_Frame-To-Frame_Training_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1155": {"title": "end-to-end efficient representation learning via cascading combinatorial optimization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jeong_End-To-End_Efficient_Representation_Learning_via_Cascading_Combinatorial_Optimization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1156": {"title": "sim-real joint reinforcement transfer for 3d indoor navigation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Sim-Real_Joint_Reinforcement_Transfer_for_3D_Indoor_Navigation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1157": {"title": "chamnet: towards efficient network design through platform-aware model adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dai_ChamNet_Towards_Efficient_Network_Design_Through_Platform-Aware_Model_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1158": {"title": "regularizing activation distribution for training binarized deep networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Regularizing_Activation_Distribution_for_Training_Binarized_Deep_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1159": {"title": "robustness verification of classification deep neural networks via linear programming", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lin_Robustness_Verification_of_Classification_Deep_Neural_Networks_via_Linear_Programming_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1160": {"title": "additive adversarial learning for unbiased authentication", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Additive_Adversarial_Learning_for_Unbiased_Authentication_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1161": {"title": "simultaneously optimizing weight and quantizer of ternary neural network using truncated gaussian approximation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/He_Simultaneously_Optimizing_Weight_and_Quantizer_of_Ternary_Neural_Network_Using_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1162": {"title": "adversarial defense by stratified convolutional sparse coding", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Adversarial_Defense_by_Stratified_Convolutional_Sparse_Coding_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1163": {"title": "exploring object relation in mean teacher for cross-domain detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cai_Exploring_Object_Relation_in_Mean_Teacher_for_Cross-Domain_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1164": {"title": "hierarchical disentanglement of discriminative latent features for zero-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tong_Hierarchical_Disentanglement_of_Discriminative_Latent_Features_for_Zero-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1165": {"title": "r2gan: cross-modal recipe retrieval with generative adversarial network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_R2GAN_Cross-Modal_Recipe_Retrieval_With_Generative_Adversarial_Network_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1166": {"title": "rethinking knowledge graph propagation for zero-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kampffmeyer_Rethinking_Knowledge_Graph_Propagation_for_Zero-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1167": {"title": "learning to learn image classifiers with visual analogy", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Learning_to_Learn_Image_Classifiers_With_Visual_Analogy_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1168": {"title": "where's wally now? deep generative and discriminative embeddings for novelty detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Burlina_Wheres_Wally_Now_Deep_Generative_and_Discriminative_Embeddings_for_Novelty_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1169": {"title": "weakly supervised image classification through noise regularization", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Weakly_Supervised_Image_Classification_Through_Noise_Regularization_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1170": {"title": "data-driven neuron allocation for scale aggregation networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Data-Driven_Neuron_Allocation_for_Scale_Aggregation_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1171": {"title": "graphical contrastive losses for scene graph parsing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Graphical_Contrastive_Losses_for_Scene_Graph_Parsing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1172": {"title": "deep transfer learning for multiple class novelty detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Perera_Deep_Transfer_Learning_for_Multiple_Class_Novelty_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1173": {"title": "qatm: quality-aware template matching for deep learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_QATM_Quality-Aware_Template_Matching_for_Deep_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1174": {"title": "retrieval-augmented convolutional neural networks against adversarial examples", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Retrieval-Augmented_Convolutional_Neural_Networks_Against_Adversarial_Examples_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1175": {"title": "learning cross-modal embeddings with adversarial networks for cooking recipes and food images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_Cross-Modal_Embeddings_With_Adversarial_Networks_for_Cooking_Recipes_and_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1176": {"title": "fastdraw: addressing the long tail of lane detection by adapting a sequential prediction network", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Philion_FastDraw_Addressing_the_Long_Tail_of_Lane_Detection_by_Adapting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1177": {"title": "weakly supervised video moment retrieval from text queries", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mithun_Weakly_Supervised_Video_Moment_Retrieval_From_Text_Queries_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1178": {"title": "content-aware multi-level guidance for interactive instance segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Majumder_Content-Aware_Multi-Level_Guidance_for_Interactive_Instance_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1179": {"title": "greedy structure learning of hierarchical compositional models", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kortylewski_Greedy_Structure_Learning_of_Hierarchical_Compositional_Models_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1180": {"title": "interactive full image segmentation by considering all regions jointly", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Agustsson_Interactive_Full_Image_Segmentation_by_Considering_All_Regions_Jointly_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1181": {"title": "learning active contour models for medical image segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Active_Contour_Models_for_Medical_Image_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1182": {"title": "customizable architecture search for semantic segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Customizable_Architecture_Search_for_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1183": {"title": "local features and visual words emerge in activations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Simeoni_Local_Features_and_Visual_Words_Emerge_in_Activations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1184": {"title": "hyperspectral image super-resolution with optimized rgb guidance", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Fu_Hyperspectral_Image_Super-Resolution_With_Optimized_RGB_Guidance_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1185": {"title": "adaptive confidence smoothing for generalized zero-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Atzmon_Adaptive_Confidence_Smoothing_for_Generalized_Zero-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1186": {"title": "pms-net: robust haze removal based on patch map for single images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_PMS-Net_Robust_Haze_Removal_Based_on_Patch_Map_for_Single_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1187": {"title": "deep spherical quantization for image search", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Eghbali_Deep_Spherical_Quantization_for_Image_Search_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1188": {"title": "large-scale interactive object segmentation with human annotators", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Benenson_Large-Scale_Interactive_Object_Segmentation_With_Human_Annotators_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1189": {"title": "a poisson-gaussian denoising dataset with real fluorescence microscopy images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_A_Poisson-Gaussian_Denoising_Dataset_With_Real_Fluorescence_Microscopy_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1190": {"title": "task agnostic meta-learning for few-shot learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jamal_Task_Agnostic_Meta-Learning_for_Few-Shot_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1191": {"title": "progressive ensemble networks for zero-shot recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Progressive_Ensemble_Networks_for_Zero-Shot_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1192": {"title": "direct object recognition without line-of-sight using optical coherence", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lei_Direct_Object_Recognition_Without_Line-Of-Sight_Using_Optical_Coherence_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1193": {"title": "atlas of digital pathology: a generalized hierarchical histological tissue type-annotated database for deep learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hosseini_Atlas_of_Digital_Pathology_A_Generalized_Hierarchical_Histological_Tissue_Type-Annotated_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1194": {"title": "perturbation analysis of the 8-point algorithm: a case study for wide fov cameras", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/da_Silveira_Perturbation_Analysis_of_the_8-Point_Algorithm_A_Case_Study_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1195": {"title": "robustness of 3d deep learning in an adversarial setting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wicker_Robustness_of_3D_Deep_Learning_in_an_Adversarial_Setting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1196": {"title": "scenecode: monocular dense semantic reconstruction using learned encoded scene representations", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhi_SceneCode_Monocular_Dense_Semantic_Reconstruction_Using_Learned_Encoded_Scene_Representations_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1197": {"title": "stereodrnet: dilated residual stereonet", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chabra_StereoDRNet_Dilated_Residual_StereoNet_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1198": {"title": "the alignment of the spheres: globally-optimal spherical mixture alignment for camera pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Campbell_The_Alignment_of_the_Spheres_Globally-Optimal_Spherical_Mixture_Alignment_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1199": {"title": "learning joint reconstruction of hands and manipulated objects", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hasson_Learning_Joint_Reconstruction_of_Hands_and_Manipulated_Objects_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1200": {"title": "deep single image camera calibration with radial distortion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lopez_Deep_Single_Image_Camera_Calibration_With_Radial_Distortion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1201": {"title": "cam-convs: camera-aware multi-scale convolutions for single-view depth", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Facil_CAM-Convs_Camera-Aware_Multi-Scale_Convolutions_for_Single-View_Depth_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1202": {"title": "translate-to-recognize networks for rgb-d scene recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Du_Translate-to-Recognize_Networks_for_RGB-D_Scene_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1203": {"title": "re-identification supervised texture generation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Re-Identification_Supervised_Texture_Generation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1204": {"title": "action4d: online action recognition in the crowd and clutter", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/You_Action4D_Online_Action_Recognition_in_the_Crowd_and_Clutter_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1205": {"title": "monocular 3d object detection leveraging accurate proposals and shape reconstruction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ku_Monocular_3D_Object_Detection_Leveraging_Accurate_Proposals_and_Shape_Reconstruction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1206": {"title": "attribute-aware face aging with wavelet-based generative adversarial networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Attribute-Aware_Face_Aging_With_Wavelet-Based_Generative_Adversarial_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1207": {"title": "noise-tolerant paradigm for training face recognition cnns", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Noise-Tolerant_Paradigm_for_Training_Face_Recognition_CNNs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1208": {"title": "low-rank laplacian-uniform mixed model for robust face recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Low-Rank_Laplacian-Uniform_Mixed_Model_for_Robust_Face_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1209": {"title": "generalizing eye tracking with bayesian adversarial learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Generalizing_Eye_Tracking_With_Bayesian_Adversarial_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1210": {"title": "local relationship learning with person-specific shape regularization for facial action unit detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Niu_Local_Relationship_Learning_With_Person-Specific_Shape_Regularization_for_Facial_Action_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1211": {"title": "point-to-pose voting based hand pose estimation using residual permutation equivariant layer", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Point-To-Pose_Voting_Based_Hand_Pose_Estimation_Using_Residual_Permutation_Equivariant_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1212": {"title": "improving few-shot user-specific gaze adaptation via gaze redirection synthesis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Improving_Few-Shot_User-Specific_Gaze_Adaptation_via_Gaze_Redirection_Synthesis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1213": {"title": "adaptiveface: adaptive margin and sampling for face recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_AdaptiveFace_Adaptive_Margin_and_Sampling_for_Face_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1214": {"title": "disentangled representation learning for 3d face shape", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jiang_Disentangled_Representation_Learning_for_3D_Face_Shape_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1215": {"title": "lbs autoencoder: self-supervised fitting of articulated meshes to point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_LBS_Autoencoder_Self-Supervised_Fitting_of_Articulated_Meshes_to_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1216": {"title": "pifpaf: composite fields for human pose estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kreiss_PifPaf_Composite_Fields_for_Human_Pose_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1217": {"title": "tacnet: transition-aware context network for spatio-temporal action detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Song_TACNet_Transition-Aware_Context_Network_for_Spatio-Temporal_Action_Detection_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1218": {"title": "learning regularity in skeleton trajectories for anomaly detection in videos", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Morais_Learning_Regularity_in_Skeleton_Trajectories_for_Anomaly_Detection_in_Videos_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1219": {"title": "local temporal bilinear pooling for fine-grained action parsing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Local_Temporal_Bilinear_Pooling_for_Fine-Grained_Action_Parsing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1220": {"title": "improving action localization by progressive cross-stream cooperation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Su_Improving_Action_Localization_by_Progressive_Cross-Stream_Cooperation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1221": {"title": "two-stream adaptive graph convolutional networks for skeleton-based action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Two-Stream_Adaptive_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1222": {"title": "a neural network based on spd manifold learning for skeleton-based hand gesture recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Nguyen_A_Neural_Network_Based_on_SPD_Manifold_Learning_for_Skeleton-Based_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1223": {"title": "large-scale weakly-supervised pre-training for video action recognition", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ghadiyaram_Large-Scale_Weakly-Supervised_Pre-Training_for_Video_Action_Recognition_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1224": {"title": "learning spatio-temporal representation with local and global diffusion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Qiu_Learning_Spatio-Temporal_Representation_With_Local_and_Global_Diffusion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1225": {"title": "unsupervised learning of action classes with continuous temporal embedding", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kukleva_Unsupervised_Learning_of_Action_Classes_With_Continuous_Temporal_Embedding_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1226": {"title": "double nuclear norm based low rank representation on grassmann manifolds for clustering", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Piao_Double_Nuclear_Norm_Based_Low_Rank_Representation_on_Grassmann_Manifolds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1227": {"title": "sr-lstm: state refinement for lstm towards pedestrian trajectory prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_SR-LSTM_State_Refinement_for_LSTM_Towards_Pedestrian_Trajectory_Prediction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1228": {"title": "unsupervised deep epipolar flow for stationary or dynamic scenes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Unsupervised_Deep_Epipolar_Flow_for_Stationary_or_Dynamic_Scenes_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1229": {"title": "an efficient schmidt-ekf for 3d visual-inertial slam", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Geneva_An_Efficient_Schmidt-EKF_for_3D_Visual-Inertial_SLAM_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1230": {"title": "a neural temporal model for human motion prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gopalakrishnan_A_Neural_Temporal_Model_for_Human_Motion_Prediction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1231": {"title": "multi-agent tensor fusion for contextual trajectory prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Multi-Agent_Tensor_Fusion_for_Contextual_Trajectory_Prediction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1232": {"title": "coordinate-based texture inpainting for pose-guided human image generation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Grigorev_Coordinate-Based_Texture_Inpainting_for_Pose-Guided_Human_Image_Generation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1233": {"title": "on stabilizing generative adversarial training with noise", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Jenni_On_Stabilizing_Generative_Adversarial_Training_With_Noise_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1234": {"title": "self-supervised gans via auxiliary rotation loss", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Self-Supervised_GANs_via_Auxiliary_Rotation_Loss_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1235": {"title": "texture mixer: a network for controllable synthesis and interpolation of texture", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Texture_Mixer_A_Network_for_Controllable_Synthesis_and_Interpolation_of_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1236": {"title": "object-driven text-to-image synthesis via adversarial training", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Object-Driven_Text-To-Image_Synthesis_via_Adversarial_Training_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1237": {"title": "zoom-in-to-check: boosting video interpolation via instance-level discrimination", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yuan_Zoom-In-To-Check_Boosting_Video_Interpolation_via_Instance-Level_Discrimination_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1238": {"title": "disentangling latent space for vae by label relevant/irrelevant dimensions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Disentangling_Latent_Space_for_VAE_by_Label_RelevantIrrelevant_Dimensions_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1239": {"title": "spectral reconstruction from dispersive blur: a novel light efficient spectral imager", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Spectral_Reconstruction_From_Dispersive_Blur_A_Novel_Light_Efficient_Spectral_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1240": {"title": "quasi-unsupervised color constancy", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Bianco_Quasi-Unsupervised_Color_Constancy_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1241": {"title": "deep defocus map estimation using domain adaptation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Deep_Defocus_Map_Estimation_Using_Domain_Adaptation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1242": {"title": "using unknown occluders to recover hidden scenes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yedidia_Using_Unknown_Occluders_to_Recover_Hidden_Scenes_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1243": {"title": "competitive collaboration: joint unsupervised learning of depth, camera motion, optical flow and motion segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ranjan_Competitive_Collaboration_Joint_Unsupervised_Learning_of_Depth_Camera_Motion_Optical_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1244": {"title": "learning parallax attention for stereo image super-resolution", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_Parallax_Attention_for_Stereo_Image_Super-Resolution_CVPR_2019_paper.html", "abstract": "Stereo image pairs can be used to improve the performance of super-resolution (SR) since additional \ninformation is provided from a second viewpoint. However, it is challenging to incorporate this info\nrmation for SR since disparities between stereo images vary significantly. In this paper, we propose\n a parallax-attention stereo superresolution network (PASSRnet) to integrate the information from a \nstereo image pair for SR. Specifically, we introduce a parallax-attention mechanism with a global re\nceptive field along the epipolar line to handle different stereo images with large disparity variati\nons. We also propose a new and the largest dataset for stereo image SR (namely, Flickr1024). Extensi\nve experiments demonstrate that the parallax-attention mechanism can capture correspondence between \nstereo images to improve SR performance with a small computational and memory cost. Comparative resu\nlts show that our PASSRnet achieves the state-of-the-art performance on the Middlebury, KITTI 2012 a\nnd KITTI 2015 datasets.", "cite_num": 1, "conf": "cvpr", "time": "2019"}, "1245": {"title": "knowing when to stop: evaluation and verification of conformity to output-size specifications", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Knowing_When_to_Stop_Evaluation_and_Verification_of_Conformity_to_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1246": {"title": "spatial attentive single-image deraining with a high quality real rain dataset", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Spatial_Attentive_Single-Image_Deraining_With_a_High_Quality_Real_Rain_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1247": {"title": "focus is all you need: loss functions for event-based vision", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gallego_Focus_Is_All_You_Need_Loss_Functions_for_Event-Based_Vision_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1248": {"title": "scalable convolutional neural network for image compressed sensing", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Scalable_Convolutional_Neural_Network_for_Image_Compressed_Sensing_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1249": {"title": "event cameras, contrast maximization and reward functions: an analysis", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Stoffregen_Event_Cameras_Contrast_Maximization_and_Reward_Functions_An_Analysis_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1250": {"title": "convolutional neural networks can be deceived by visual illusions", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Gomez-Villa_Convolutional_Neural_Networks_Can_Be_Deceived_by_Visual_Illusions_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1251": {"title": "pde acceleration for active contours", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yezzi_PDE_Acceleration_for_Active_Contours_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1252": {"title": "dichromatic model based temporal color constancy for ac light sources", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Yoo_Dichromatic_Model_Based_Temporal_Color_Constancy_for_AC_Light_Sources_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1253": {"title": "semantic attribute matching networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Semantic_Attribute_Matching_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1254": {"title": "skin-based identification from multispectral image data using cnns", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Uemori_Skin-Based_Identification_From_Multispectral_Image_Data_Using_CNNs_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1255": {"title": "large-scale distributed second-order optimization using kronecker-factored approximate curvature for deep convolutional neural networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Osawa_Large-Scale_Distributed_Second-Order_Optimization_Using_Kronecker-Factored_Approximate_Curvature_for_Deep_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1256": {"title": "putting humans in a scene: learning affordance in 3d indoor environments", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Putting_Humans_in_a_Scene_Learning_Affordance_in_3D_Indoor_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1257": {"title": "pies: pose invariant embeddings", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ho_PIEs_Pose_Invariant_Embeddings_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1258": {"title": "representation similarity analysis for efficient task taxonomy & transfer learning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Dwivedi_Representation_Similarity_Analysis_for_Efficient_Task_Taxonomy__Transfer_Learning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1259": {"title": "object counting and instance segmentation with image-level supervision", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cholakkal_Object_Counting_and_Instance_Segmentation_With_Image-Level_Supervision_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1260": {"title": "variational autoencoders pursue pca directions (by accident)", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Rolinek_Variational_Autoencoders_Pursue_PCA_Directions_by_Accident_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1261": {"title": "a relation-augmented fully convolutional network for semantic segmentation in aerial scenes", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Mou_A_Relation-Augmented_Fully_Convolutional_Network_for_Semantic_Segmentation_in_Aerial_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1262": {"title": "temporal transformer networks: joint learning of invariant and discriminative time warping", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lohit_Temporal_Transformer_Networks_Joint_Learning_of_Invariant_and_Discriminative_Time_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1263": {"title": "pcan: 3d attention map learning using contextual information for point cloud based retrieval", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_PCAN_3D_Attention_Map_Learning_Using_Contextual_Information_for_Point_CVPR_2019_paper.html", "abstract": "Point cloud based retrieval for place recognition is an emerging problem in vision field. The main c\nhallenge is how to find an efficient way to encode the local features into a discriminative global d\nescriptor. In this paper, we propose a Point Contextual Attention Network (PCAN), which can predict \nthe significance of each local point feature based on point context. Our network makes it possible t\no pay more attention to the task-relevent features when aggregating local features. Experiments on v\narious benchmark datasets show that the proposed network can provide outperformance than current sta\nte-of-the-art approaches.", "cite_num": 0, "conf": "cvpr", "time": "2019"}, "1264": {"title": "depth coefficients for depth completion", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Imran_Depth_Coefficients_for_Depth_Completion_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1265": {"title": "diversify and match: a domain adaptive representation learning paradigm for object detection", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Diversify_and_Match_A_Domain_Adaptive_Representation_Learning_Paradigm_for_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1266": {"title": "good news, everyone! context driven entity-aware captioning for news images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Biten_Good_News_Everyone_Context_Driven_Entity-Aware_Captioning_for_News_Images_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1267": {"title": "multi-level multimodal common semantic space for image-phrase grounding", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Akbari_Multi-Level_Multimodal_Common_Semantic_Space_for_Image-Phrase_Grounding_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1268": {"title": "spatio-temporal dynamics and semantic attribute enriched visual encoding for video captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Aafaq_Spatio-Temporal_Dynamics_and_Semantic_Attribute_Enriched_Visual_Encoding_for_Video_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1269": {"title": "pointing novel objects in image captioning", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Pointing_Novel_Objects_in_Image_Captioning_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1270": {"title": "informative object annotations: tell me something i don't know", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Bracha_Informative_Object_Annotations_Tell_Me_Something_I_Dont_Know_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1271": {"title": "engaging image captioning via personality", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Shuster_Engaging_Image_Captioning_via_Personality_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1272": {"title": "vision-based navigation with language-based assistance via imitation learning with indirect intervention", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Nguyen_Vision-Based_Navigation_With_Language-Based_Assistance_via_Imitation_Learning_With_Indirect_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1273": {"title": "touchdown: natural language navigation and spatial reasoning in visual street environments", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_TOUCHDOWN_Natural_Language_Navigation_and_Spatial_Reasoning_in_Visual_Street_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1274": {"title": "a simple baseline for audio-visual scene-aware dialog", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Schwartz_A_Simple_Baseline_for_Audio-Visual_Scene-Aware_Dialog_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1275": {"title": "end-to-end learned random walker for seeded image segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cerrone_End-To-End_Learned_Random_Walker_for_Seeded_Image_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1276": {"title": "efficient neural network compression", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Efficient_Neural_Network_Compression_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1277": {"title": "cascaded generative and discriminative learning for microcalcification detection in breast mammograms", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Cascaded_Generative_and_Discriminative_Learning_for_Microcalcification_Detection_in_Breast_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1278": {"title": "c3ae: exploring the limits of compact model for age estimation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_C3AE_Exploring_the_Limits_of_Compact_Model_for_Age_Estimation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1279": {"title": "adaptive weighting multi-field-of-view cnn for semantic segmentation in pathology", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Tokunaga_Adaptive_Weighting_Multi-Field-Of-View_CNN_for_Semantic_Segmentation_in_Pathology_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1280": {"title": "in defense of pre-trained imagenet architectures for real-time semantic segmentation of road-driving images", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Orsic_In_Defense_of_Pre-Trained_ImageNet_Architectures_for_Real-Time_Semantic_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1281": {"title": "context-aware visual compatibility prediction", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Cucurull_Context-Aware_Visual_Compatibility_Prediction_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1282": {"title": "sim-to-real via sim-to-sim: data-efficient robotic grasping via randomized-to-canonical adaptation networks", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/James_Sim-To-Real_via_Sim-To-Sim_Data-Efficient_Robotic_Grasping_via_Randomized-To-Canonical_Adaptation_Networks_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1283": {"title": "multiview 2d/3d rigid registration via a point-of-interest network for tracking and triangulation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liao_Multiview_2D3D_Rigid_Registration_via_a_Point-Of-Interest_Network_for_Tracking_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1284": {"title": "context-aware spatio-recurrent curvilinear structure segmentation", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Context-Aware_Spatio-Recurrent_Curvilinear_Structure_Segmentation_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1285": {"title": "an alternative deep feature approach to line level keyword spotting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Retsinas_An_Alternative_Deep_Feature_Approach_to_Line_Level_Keyword_Spotting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1286": {"title": "dynamics are important for the recognition of equine pain in video", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Broome_Dynamics_Are_Important_for_the_Recognition_of_Equine_Pain_in_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1287": {"title": "lasernet: an efficient probabilistic 3d object detector for autonomous driving", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Meyer_LaserNet_An_Efficient_Probabilistic_3D_Object_Detector_for_Autonomous_Driving_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1288": {"title": "machine vision guided 3d medical image compression for efficient transmission and accurate segmentation in the clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Machine_Vision_Guided_3D_Medical_Image_Compression_for_Efficient_Transmission_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1289": {"title": "pointpillars: fast encoders for object detection from point clouds", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Lang_PointPillars_Fast_Encoders_for_Object_Detection_From_Point_Clouds_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1290": {"title": "motion estimation of non-holonomic ground vehicles from a single feature correspondence measured over n views", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Motion_Estimation_of_Non-Holonomic_Ground_Vehicles_From_a_Single_Feature_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1291": {"title": "from coarse to fine: robust hierarchical localization at large scale", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Sarlin_From_Coarse_to_Fine_Robust_Hierarchical_Localization_at_Large_Scale_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1292": {"title": "large scale high-resolution land cover mapping with multi-resolution data", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Robinson_Large_Scale_High-Resolution_Land_Cover_Mapping_With_Multi-Resolution_Data_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}, "1293": {"title": "leveraging heterogeneous auxiliary tasks to assist crowd counting", "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Leveraging_Heterogeneous_Auxiliary_Tasks_to_Assist_Crowd_Counting_CVPR_2019_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2019"}}