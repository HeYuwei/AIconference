{"191": {"title": "joint cuts and matching of partitions in one graph", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Joint_Cuts_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "235": {"title": "transparency by design: closing the gap between performance and interpretability in visual reasoning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mascharka_Transparency_by_Design_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "475": {"title": "detect-and-track: efficient pose estimation in videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Girdhar_Detect-and-Track_Efficient_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "778": {"title": "sgan: an alternative training of generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chavdarova_SGAN_An_Alternative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "616": {"title": "learning a complete image indexing pipeline", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jain_Learning_a_Complete_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "889": {"title": "focal visual-text attention for visual question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liang_Focal_Visual-Text_Attention_CVPR_2018_paper.html", "abstract": "Recent insights on language and vision with neural networks have been successfully applied to simple\n single-image visual question answering. However, to tackle real-life question answering problems on\n multimedia collections such as personal photos, we have to look at whole collections with sequences\n of photos or videos. When answering questions from a large collection, a natural problem is to iden\ntify snippets to support the answer. In this paper, we describe a novel neural network called Focal \nVisual-Text Attention network (FVTA) for collective reasoning in visual question answering, where bo\nth visual and text sequence information such as images and text metadata are presented. FVTA introdu\nces an end-to-end approach that makes use of a hierarchical process to dynamically determine what me\ndia and what time to focus on in the sequential data to answer the question. FVTA can not only answe\nr the questions well but also provides the justifications which the system results are based upon to\n get the answers. FVTA achieves state-of-the-art performance on the MemexQA dataset and competitive \nresults on the MovieQA dataset.", "cite_num": 10}, "284": {"title": "sfsnet: learning shape, reflectance and illuminance of faces `in the wild'", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sengupta_SfSNet_Learning_Shape_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "8": {"title": "end-to-end weakly-supervised semantic alignment", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rocco_End-to-End_Weakly-Supervised_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "18": {"title": "finding \"it\": weakly-supervised reference-aware visual grounding in instructional videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Finding_It_Weakly-Supervised_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "816": {"title": "free supervision from video games", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Krahenbuhl_Free_Supervision_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "393": {"title": "revisiting oxford and paris: large-scale image retrieval benchmarking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Radenovic_Revisiting_Oxford_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "419": {"title": "lamv: learning to align and match videos with kernelized temporal layers", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baraldi_LAMV_Learning_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "110": {"title": "show me a story: towards coherent neural story illustration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ravi_Show_Me_a_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "35": {"title": "improved fusion of visual and language representations by dense symmetric co-attention for visual question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nguyen_Improved_Fusion_of_CVPR_2018_paper.html", "abstract": "A key solution to visual question answering (VQA) exists in how to fuse visual and language features\n extracted from an input image and question. We show that an attention mechanism that enables dense,\n bi-directional interactions between the two modalities contributes to boost accuracy of prediction \nof answers. Specifically, we present a simple architecture that is fully symmetric between visual an\nd language representations, in which each question word attends on image regions and each image regi\non attends on question words. It can be stacked to form a hierarchy for multi-step interactions betw\neen an image-question pair. We show through experiments that the proposed architecture achieves a ne\nw state-of-the-art on VQA and VQA 2.0 despite its small size. We also present qualitative evaluation\n, demonstrating how the proposed attention mechanism can generate reasonable attention maps on image\ns and questions, which leads to the correct answer prediction.", "cite_num": -1}, "450": {"title": "fots: fast oriented text spotting with a unified network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_FOTS_Fast_Oriented_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "241": {"title": "deep progressive reinforcement learning for skeleton-based action recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tang_Deep_Progressive_Reinforcement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "668": {"title": "defense against adversarial attacks using high-level representation guided denoiser", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liao_Defense_Against_Adversarial_CVPR_2018_paper.html", "abstract": "Neural networks are vulnerable to adversarial examples, which poses a threat to their application in\n security sensitive systems. We propose high-level representation guided denoiser (HGD) as a defense\n for image classification. Standard denoiser suffers from the error amplification effect, in which s\nmall residual adversarial noise is progressively amplified and leads to wrong classifications. HGD o\nvercomes this problem by using a loss function defined as the difference between the target model's \noutputs activated by the clean image and denoised image. Compared with ensemble adversarial training\n which is the state-of-the-art defending method on large images, HGD has three advantages. First, wi\nth HGD as a defense, the target model is more robust to either white-box or black-box adversarial at\ntacks. Second, HGD can be trained on a small subset of the images and generalizes well to other imag\nes and unseen classes. Third, HGD can be transferred to defend models other than the one guiding it.\n In NIPS competition on defense against adversarial attacks, our HGD solution won the first place an\nd outperformed other models by a large margin.1", "cite_num": 27}, "441": {"title": "geonet: geometric neural network for joint depth and surface normal estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_GeoNet_Geometric_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "945": {"title": "ice-ba: incremental, consistent and efficient bundle adjustment for visual-inertial slam", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_ICE-BA_Incremental_Consistent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "624": {"title": "stacked latent attention for multimodal reasoning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fan_Stacked_Latent_Attention_CVPR_2018_paper.html", "abstract": "Attention has shown to be a pivotal development in deep learning and has been used for a multitude o\nf multimodal learning tasks such as visual question answering and image captioning. In this work, we\n pinpoint the potential limitations to the design of a traditional attention model. We identify that\n 1) current attention mechanisms discard the latent information from intermediate reasoning, losing \nthe positional information already captured by the attention heatmaps and 2) stacked attention, a co\nmmon way to improve spatial reasoning, may have suboptimal performance because of the vanishing grad\nient problem. We introduce a novel attention architecture to address these problems, in which all sp\natial configuration information contained in the intermediate reasoning process is retained in a pat\nhway of convolutional layers. We show that this new attention leads to substantial improvements in m\nultiple multimodal reasoning tasks, including achieving single model performance without using exter\nnal knowledge comparable to the state-of-the-art on the VQA dataset, as well as clear gains for the \nimage captioning task.", "cite_num": 5}, "474": {"title": "monocular relative depth perception with web stereo data supervision", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xian_Monocular_Relative_Depth_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "361": {"title": "generative adversarial learning towards fast weakly supervised detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Generative_Adversarial_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "716": {"title": "transductive unbiased embedding for zero-shot learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Transductive_Unbiased_Embedding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "147": {"title": "instance embedding transfer to unsupervised video object segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Instance_Embedding_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "189": {"title": "stargan: unified generative adversarial networks for multi-domain image-to-image translation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Choi_StarGAN_Unified_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "346": {"title": "fast and accurate online video object segmentation via tracking parts", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_Fast_and_Accurate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "249": {"title": "logo synthesis and manipulation with clustered generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sage_Logo_Synthesis_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "169": {"title": "context embedding networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_Context_Embedding_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "67": {"title": "generative modeling using the sliced wasserstein distance", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Deshpande_Generative_Modeling_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "313": {"title": "soccer on your tabletop", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rematas_Soccer_on_Your_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "842": {"title": "referring relationships", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Krishna_Referring_Relationships_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "933": {"title": "future frame prediction for anomaly detection \u2013 a new baseline", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Future_Frame_Prediction_CVPR_2018_paper.html", "abstract": "Anomaly detection in videos refers to the identification of events that do not conform to expected b\nehavior. However, almost all existing methods tackle the problem by minimizing the reconstruction er\nrors of training data, which cannot guarantee a larger reconstruction error for an abnormal event. I\nn this paper, we propose to tackle the anomaly detection problem within a video prediction framework\n. To the best of our knowledge, this is the first work that leverages the difference between a predi\ncted future frame and its ground truth to detect an abnormal event. To predict a future frame with h\nigher quality for normal events, other than the commonly used appearance (spatial) constraints on in\ntensity and gradient, we also introduce a motion (temporal) constraint in video prediction by enforc\ning the optical flow between predicted frames and ground truth frames to be consistent, and this is \nthe first work that introduces a temporal constraint into the video prediction task. Such spatial an\nd motion constraints facilitate the future frame prediction for normal events, and consequently faci\nlitate to identify those abnormal events that do not conform the expectation. Extensive experiments \non both a toy dataset and some publicly available datasets validate the effectiveness of our method \nin terms of robustness to the uncertainty in normal events and the sensitivity to abnormal events", "cite_num": 5}, "113": {"title": "attention-aware compositional network for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Attention-Aware_Compositional_Network_CVPR_2018_paper.html", "abstract": "Person re-identification (ReID) is to identify pedestrians observed from different camera views base\nd on visual appearance. It is a challenging task due to large pose variations, complex background cl\nutters and severe occlusions. Recently, human pose estimation by predicting joint locations was larg\nely improved in accuracy. It is reasonable to use pose estimation results for handling pose variatio\nns and background clutters, and such attempts have obtained great improvement in ReID performance. H\nowever, we argue that the pose information was not well utilized and hasn't yet been fully exploited\n for person ReID. #R##N#In this work, we introduce a novel framework called Attention-Aware Composit\nional Network (AACN) for person ReID. AACN consists of two main components: Pose-guided Part Attenti\non (PPA) and Attention-aware Feature Composition (AFC). PPA is learned and applied to mask out undes\nirable background features in pedestrian feature maps. Furthermore, pose-guided visibility scores ar\ne estimated for body parts to deal with part occlusion in the proposed AFC module. Extensive experim\nents with ablation analysis show the effectiveness of our method, and state-of-the-art results are a\nchieved on several public datasets, including Market-1501, CUHK03, CUHK01, SenseReID, CUHK03-NP and \nDukeMTMC-reID.", "cite_num": 19}, "4": {"title": "semantic visual localization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Schonberger_Semantic_Visual_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "194": {"title": "inferring semantic layout for hierarchical text-to-image synthesis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hong_Inferring_Semantic_Layout_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "789": {"title": "differential attention for visual question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Patro_Differential_Attention_for_CVPR_2018_paper.html", "abstract": "In this paper we aim to answer questions based on images when provided with a dataset of question-an\nswer pairs for a number of images during training. A number of methods have focused on solving this \nproblem by using image based attention. This is done by focusing on a specific part of the image whi\nle answering the question. Humans also do so when solving this problem. However, the regions that th\ne previous systems focus on are not correlated with the regions that humans focus on. The accuracy i\ns limited due to this drawback. In this paper, we propose to solve this problem by using an exemplar\n based method. We obtain one or more supporting and opposing exemplars to obtain a differential atte\nntion region. This differential attention is closer to human attention than other image based attent\nion methods. It also helps in obtaining improved accuracy when answering questions. The method is ev\naluated on challenging benchmark datasets. We perform better than other image based attention method\ns and are competitive with other state of the art methods that focus on both image and questions.", "cite_num": 9}, "576": {"title": "squeeze-and-excitation networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "201": {"title": "art of singular vectors and universal adversarial perturbations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Khrulkov_Art_of_Singular_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "504": {"title": "megdet: a large mini-batch object detector", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Peng_MegDet_A_Large_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "124": {"title": "interactive image segmentation with latent diversity", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Interactive_Image_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "790": {"title": "where and why are they looking? jointly inferring human attention and intentions in complex tasks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Where_and_Why_CVPR_2018_paper.html", "abstract": "This paper addresses a new problem - jointly inferring human attention, intentions, and tasks from v\nideos. Given an RGB-D video where a human performs a task, we answer three questions simultaneously:\n 1) where the human is looking - attention prediction; 2) why the human is looking there - intention\n prediction; and 3) what task the human is performing - task recognition. We propose a hierarchical \nmodel of human-attention-object (HAO) which represents tasks, intentions, and attention under a unif\nied framework. A task is represented as sequential intentions which transition to each other. An int\nention is composed of the human pose, attention, and objects. A beam search algorithm is adopted for\n inference on the HAO graph to output the attention, intention, and task results. We built a new vid\neo dataset of tasks, intentions, and attention. It contains 14 task classes, 70 intention categories\n, 28 object classes, 809 videos, and approximately 330,000 frames. Experiments show that our approac\nh outperforms existing approaches.", "cite_num": -1}, "586": {"title": "analyzing filters toward efficient convnet", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kobayashi_Analyzing_Filters_Toward_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "629": {"title": "maximum classifier discrepancy for unsupervised domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Saito_Maximum_Classifier_Discrepancy_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "498": {"title": "deep parametric continuous convolutional neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Deep_Parametric_Continuous_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "509": {"title": "environment upgrade reinforcement learning for non-differentiable multi-stage pipelines", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xie_Environment_Upgrade_Reinforcement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "931": {"title": "deep reinforcement learning of region proposal networks for object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pirinen_Deep_Reinforcement_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "56": {"title": "what makes a video a video: analyzing temporal information in video understanding models and datasets", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_What_Makes_a_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "369": {"title": "faceid-gan: learning a symmetry three-player gan for identity-preserving face synthesis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_FaceID-GAN_Learning_a_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "892": {"title": "sketch-a-classifier: sketch-based photo classifier generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Sketch-a-Classifier_Sketch-Based_Photo_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "378": {"title": "actor and observer: joint modeling of first and third-person videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sigurdsson_Actor_and_Observer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "860": {"title": "multimodal explanations: justifying decisions and pointing to the evidence", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Park_Multimodal_Explanations_Justifying_CVPR_2018_paper.html", "abstract": "Deep models that are both effective and explainable are desirable in many settings; prior explainabl\ne models have been unimodal, offering either image-based visualization of attention weights or text-\nbased generation of post-hoc justifications. We propose a multimodal approach to explanation, and ar\ngue that the two modalities provide complementary explanatory strengths. We collect two new datasets\n to define and evaluate this task, and propose a novel model which can provide joint textual rationa\nle generation and attention visualization. Our datasets define visual and textual justifications of \na classification decision for activity recognition tasks (ACT-X) and for visual question answering t\nasks (VQA-X). We quantitatively show that training with the textual explanations not only yields bet\nter textual justification models, but also better localizes the evidence that supports the decision.\n We also qualitatively show cases where visual explanation is more insightful than textual explanati\non, and vice versa, supporting our thesis that multimodal explanation models offer significant benef\nits over unimodal approaches.", "cite_num": 30}, "961": {"title": "detect globally, refine locally: a novel approach to saliency detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Detect_Globally_Refine_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "785": {"title": "light field intrinsics with a deep encoder-decoder network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Alperovich_Light_Field_Intrinsics_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "638": {"title": "sim2real viewpoint invariant visual servoing by recurrent control", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sadeghi_Sim2Real_Viewpoint_Invariant_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "928": {"title": "motion segmentation by exploiting complementary geometric models", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Motion_Segmentation_by_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "409": {"title": "decidenet: counting varying density crowds through attention guided detection and density estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_DecideNet_Counting_Varying_CVPR_2018_paper.html", "abstract": "In real-world crowd counting applications, the crowd densities vary greatly in spatial and temporal \ndomains. A detection based counting method will estimate crowds accurately in low density scenes, wh\nile its reliability in congested areas is downgraded. A regression based approach, on the other hand\n, captures the general density information in crowded regions. Without knowing the location of each \nperson, it tends to overestimate the count in low density areas. Thus, exclusively using either one \nof them is not sufficient to handle all kinds of scenes with varying densities. To address this issu\ne, a novel end-to-end crowd counting framework, named DecideNet (DEteCtIon and Density Estimation Ne\ntwork) is proposed. It can adaptively decide the appropriate counting mode for different locations o\nn the image based on its real density conditions. DecideNet starts with estimating the crowd density\n by generating detection and regression based density maps separately. To capture inevitable variati\non in densities, it incorporates an attention module, meant to adaptively assess the reliability of \nthe two types of estimations. The final crowd counts are obtained with the guidance of the attention\n module to adopt suitable estimations from the two kinds of density maps. Experimental results show \nthat our method achieves state-of-the-art performance on three challenging crowd counting datasets.", "cite_num": -1}, "332": {"title": "illuminant spectra-based source separation using flash photography", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hui_Illuminant_Spectra-Based_Source_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "270": {"title": "learning distributions of shape trajectories from longitudinal datasets: a hierarchical model on a manifold of diffeomorphisms", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bone_Learning_Distributions_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "351": {"title": "multi-level fusion based 3d object detection from monocular images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Multi-Level_Fusion_Based_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "304": {"title": "jerk-aware video acceleration magnification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Takeda_Jerk-Aware_Video_Acceleration_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "230": {"title": "benchmarking 6dof outdoor visual localization in changing conditions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sattler_Benchmarking_6DOF_Outdoor_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "663": {"title": "progressive attention guided recurrent network for salient object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Progressive_Attention_Guided_CVPR_2018_paper.html", "abstract": "Effective convolutional features play an important role in saliency estimation but how to learn powe\nrful features for saliency is still a challenging task. FCN-based methods directly apply multi-level\n convolutional features without distinction, which leads to sub-optimal results due to the distracti\non from redundant details. In this paper, we propose a novel attention guided network which selectiv\nely integrates multi-level contextual information in a progressive manner. Attentive features genera\nted by our network can alleviate distraction of background thus achieve better performance. On the o\nther hand, it is observed that most of existing algorithms conduct salient object detection by explo\niting side-output features of the backbone feature extraction network. However, shallower layers of \nbackbone network lack the ability to obtain global semantic information, which limits the effective \nfeature learning. To address the problem, we introduce multi-path recurrent feedback to enhance our \nproposed progressive attention driven framework. Through multi-path recurrent connections, global se\nmantic information from the top convolutional layer is transferred to shallower layers, which intrin\nsically refines the entire network. Experimental results on six benchmark datasets demonstrate that \nour algorithm performs favorably against the state-of-the-art approaches.", "cite_num": 38}, "769": {"title": "blazingly fast video object segmentation with pixel-wise metric learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Blazingly_Fast_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "952": {"title": "cnn driven sparse multi-level b-spline image registration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jiang_CNN_Driven_Sparse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "792": {"title": "quantization and training of neural networks for efficient integer-arithmetic-only inference", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jacob_Quantization_and_Training_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "841": {"title": "foldingnet: point cloud auto-encoder via deep grid deformation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_FoldingNet_Point_Cloud_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "603": {"title": "density adaptive point set registration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lawin_Density_Adaptive_Point_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "830": {"title": "distort-and-recover: color enhancement using deep reinforcement learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Park_Distort-and-Recover_Color_Enhancement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "281": {"title": "graph-cut ransac", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Barath_Graph-Cut_RANSAC_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "336": {"title": "image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Deng_Image-Image_Domain_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "693": {"title": "bottom-up and top-down attention for image captioning and visual question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.html", "abstract": "Top-down visual attention mechanisms have been used extensively in image captioning and visual quest\nion answering (VQA) to enable deeper image understanding through fine-grained analysis and even mult\niple steps of reasoning. In this work, we propose a combined bottom-up and top-down attention mechan\nism that enables attention to be calculated at the level of objects and other salient image regions.\n This is the natural basis for attention to be considered. Within our approach, the bottom-up mechan\nism (based on Faster R-CNN) proposes image regions, each with an associated feature vector, while th\ne top-down mechanism determines feature weightings. Applying this approach to image captioning, our \nresults on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / S\nPICE / BLEU-4 scores of 117.9, 21.5 and 36.9, respectively. Demonstrating the broad applicability of\n the method, applying the same approach to VQA we obtain first place in the 2017 VQA Challenge.", "cite_num": 177}, "916": {"title": "shift: a zero flop, zero parameter alternative to spatial convolutions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Shift_A_Zero_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "631": {"title": "csrnet: dilated convolutional neural networks for understanding the highly congested scenes", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_CSRNet_Dilated_Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "316": {"title": "segan: segmenting and generating the invisible", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ehsani_SeGAN_Segmenting_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "879": {"title": "towards dense object tracking in a 2d honeybee hive", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bozek_Towards_Dense_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "538": {"title": "bidirectional retrieval made simple", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wehrmann_Bidirectional_Retrieval_Made_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "258": {"title": "adversarially occluded samples for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Adversarially_Occluded_Samples_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "420": {"title": "efficient optimization for rank-based loss functions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mohapatra_Efficient_Optimization_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "652": {"title": "wasserstein introspective neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_Wasserstein_Introspective_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "267": {"title": "reconstruction network for video captioning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Reconstruction_Network_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "669": {"title": "can spatiotemporal 3d cnns retrace the history of 2d cnns and imagenet?", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hara_Can_Spatiotemporal_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "530": {"title": "learned shape-tailored descriptors for segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Khan_Learned_Shape-Tailored_Descriptors_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "799": {"title": "coding kendall's shape trajectories for 3d action recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tanfous_Coding_Kendalls_Shape_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "711": {"title": "sbnet: sparse blocks network for fast inference", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ren_SBNet_Sparse_Blocks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "88": {"title": "oatm: occlusion aware template matching by consensus set maximization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Korman_OATM_Occlusion_Aware_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "481": {"title": "end-to-end learning of keypoint detector and descriptor for pose invariant 3d matching", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Georgakis_End-to-End_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "31": {"title": "rotationnet: joint object categorization and pose estimation using multiviews from unsupervised viewpoints", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kanezaki_RotationNet_Joint_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "122": {"title": "learning rich features for image manipulation detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Learning_Rich_Features_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "595": {"title": "geometry-aware network for non-rigid shape prediction from a single view", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pumarola_Geometry-Aware_Network_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "954": {"title": "large-scale point cloud semantic segmentation with superpoint graphs", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Landrieu_Large-Scale_Point_Cloud_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "176": {"title": "pose transferrable person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Pose_Transferrable_Person_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "955": {"title": "exploit the unknown gradually: one-shot video-based person re-identification by stepwise learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Exploit_the_Unknown_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "175": {"title": "ivqa: inverse visual question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_IVQA_Inverse_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "956": {"title": "divide and grow: capturing huge diversity in crowd images with incrementally growing cnn", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sam_Divide_and_Grow_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "869": {"title": "a robust method for strong rolling shutter effects correction using lines with automatic feature selection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lao_A_Robust_Method_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "104": {"title": "optimal structured light \u00e0 la carte", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mirdehghan_Optimal_Structured_Light_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "282": {"title": "clinical skin lesion diagnosis using representations inspired by dermatologist criteria", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Clinical_Skin_Lesion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "196": {"title": "low-latency video semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Low-Latency_Video_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "114": {"title": "real-world anomaly detection in surveillance videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sultani_Real-World_Anomaly_Detection_CVPR_2018_paper.html", "abstract": "Surveillance videos are able to capture a variety of realistic anomalies. In this paper, we propose \nto learn anomalies by exploiting both normal and anomalous videos. To avoid annotating the anomalous\n segments or clips in training videos, which is very time consuming, we propose to learn anomaly thr\nough the deep multiple instance ranking framework by leveraging weakly labeled training videos, i.e.\n the training labels (anomalous or normal) are at video-level instead of clip-level. In our approach\n, we consider normal and anomalous videos as bags and video segments as instances in multiple instan\nce learning (MIL), and automatically learn a deep anomaly ranking model that predicts high anomaly s\ncores for anomalous video segments. Furthermore, we introduce sparsity and temporal smoothness const\nraints in the ranking loss function to better localize anomaly during training. We also introduce a \nnew large-scale first of its kind dataset of 128 hours of videos. It consists of 1900 long and untri\nmmed real-world surveillance videos, with 13 realistic anomalies such as fighting, road accident, bu\nrglary, robbery, etc. as well as normal activities. This dataset can be used for two tasks. First, g\neneral anomaly detection considering all anomalies in one group and all normal activities in another\n group. Second, for recognizing each of 13 anomalous activities. Our experimental results show that \nour MIL method for anomaly detection achieves significant improvement on anomaly detection performan\nce as compared to the state-of-the-art approaches. We provide the results of several recent deep lea\nrning baselines on anomalous activity recognition. The low recognition performance of these baseline\ns reveals that our dataset is very challenging and opens more opportunities for future work.", "cite_num": 17}, "39": {"title": "radially-distorted conjugate translations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pritts_Radially-Distorted_Conjugate_Translations_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "807": {"title": "kippi: kinetic polygonal partitioning of images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bauchet_KIPPI_KInetic_Polygonal_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "442": {"title": "recognizing human actions as the evolution of pose estimation maps", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Recognizing_Human_Actions_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "403": {"title": "one-shot action localization by learning sequence matching network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_One-Shot_Action_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "971": {"title": "learning to look around: intelligently exploring unseen environments for unknown tasks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jayaraman_Learning_to_Look_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "252": {"title": "through-wall human pose estimation using radio signals", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Through-Wall_Human_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "388": {"title": "multi-task learning by maximizing statistical dependence", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mejjati_Multi-Task_Learning_by_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "840": {"title": "a hierarchical generative model for eye image synthesis and eye gaze estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_A_Hierarchical_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "718": {"title": "stochastic downsampling for cost-adjustable inference and improved regularization in convolutional networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kuen_Stochastic_Downsampling_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "470": {"title": "interpret neural networks by identifying critical data routing paths", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Interpret_Neural_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "21": {"title": "learning to see in the dark", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Learning_to_See_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "911": {"title": "occlusion-aware rolling shutter rectification of 3d scenes", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vasu_Occlusion-Aware_Rolling_Shutter_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "76": {"title": "aperture supervision for monocular depth estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Srinivasan_Aperture_Supervision_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "712": {"title": "intrinsic image transformation via scale space decomposition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_Intrinsic_Image_Transformation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "529": {"title": "representing and learning high dimensional data with the optimal transport map from a probabilistic viewpoint", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Park_Representing_and_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "671": {"title": "multi-view harmonized bilinear network for 3d object recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Multi-View_Harmonized_Bilinear_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "264": {"title": "a pid controller approach for stochastic optimization of deep networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/An_A_PID_Controller_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "854": {"title": "context contrasted feature and gated multi-scale aggregation for scene segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ding_Context_Contrasted_Feature_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "706": {"title": "augmenting crowd-sourced 3d reconstructions using semantic detections", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Price_Augmenting_Crowd-Sourced_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "105": {"title": "hybrid camera pose estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Camposeco_Hybrid_Camera_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "311": {"title": "epinet: a fully-convolutional neural network using epipolar geometry for depth from light field images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shin_EPINET_A_Fully-Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "315": {"title": "learning dual convolutional neural networks for low-level vision", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pan_Learning_Dual_Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "556": {"title": "feature super-resolution: make machine see more clearly", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tan_Feature_Super-Resolution_Make_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "726": {"title": "semstyle: learning to generate stylised image captions using unaligned text", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mathews_SemStyle_Learning_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "798": {"title": "stacked conditional generative adversarial networks for jointly learning shadow detection and shadow removal", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Stacked_Conditional_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "144": {"title": "inloc: indoor visual localization with dense matching and view synthesis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Taira_InLoc_Indoor_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "899": {"title": "deep face detector adaptation without negative transfer or catastrophic forgetting", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jamal_Deep_Face_Detector_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "781": {"title": "picanet: learning pixel-wise contextual attention for saliency detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_PiCANet_Learning_Pixel-Wise_CVPR_2018_paper.html", "abstract": "Contexts play an important role in the saliency detection task. However, given a context region, not\n all contextual information is helpful for the final task. In this paper, we propose a novel pixel-w\nise contextual attention network, i.e., the PiCANet, to learn to selectively attend to informative c\nontext locations for each pixel. Specifically, for each pixel, it can generate an attention map in w\nhich each attention weight corresponds to the contextual relevance at each context location. An atte\nnded contextual feature can then be constructed by selectively aggregating the contextual informatio\nn. We formulate the proposed PiCANet in both global and local forms to attend to global and local co\nntexts, respectively. Both models are fully differentiable and can be embedded into CNNs for joint t\nraining. We also incorporate the proposed models with the U-Net architecture to detect salient objec\nts. Extensive experiments show that the proposed PiCANets can consistently improve saliency detectio\nn performance. The global and local PiCANets facilitate learning global contrast and homogeneousness\n, respectively. As a result, our saliency model can detect salient objects more accurately and unifo\nrmly, thus performing favorably against the state-of-the-art methods.", "cite_num": -1}, "939": {"title": "teaching categories to human learners with visual explanations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Aodha_Teaching_Categories_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "888": {"title": "learning to adapt structured output space for semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tsai_Learning_to_Adapt_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "111": {"title": "unsupervised feature learning via non-parametric instance discrimination", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "877": {"title": "hand pointnet: 3d hand pose estimation using point sets", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ge_Hand_PointNet_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "344": {"title": "on the robustness of semantic segmentation models to adversarial attacks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Arnab_On_the_Robustness_CVPR_2018_paper.html", "abstract": "Deep Neural Networks (DNNs) have been demonstrated to perform exceptionally well on most recognition\n tasks such as image classification and segmentation. However, they have also been shown to be vulne\nrable to adversarial examples. This phenomenon has recently attracted a lot of attention but it has \nnot been extensively studied on multiple, large-scale datasets and complex tasks such as semantic se\ngmentation which often require more specialised networks with additional components such as CRFs, di\nlated convolutions, skip-connections and multiscale processing. In this paper, we present what to ou\nr knowledge is the first rigorous evaluation of adversarial attacks on modern semantic segmentation \nmodels, using two large-scale datasets. We analyse the effect of different network architectures, mo\ndel capacity and multiscale processing, and show that many observations made on the task of classifi\ncation do not always transfer to this more complex task. Furthermore, we show how mean-field inferen\nce in deep structured models and multiscale processing naturally implement recently proposed adversa\nrial defenses. Our observations will aid future efforts in understanding and defending against adver\nsarial examples. Moreover, in the shorter term, we show which segmentation models should currently b\ne preferred in safety-critical applications due to their inherent robustness.", "cite_num": 0}, "777": {"title": "missing slice recovery for tensors using a low-rank model in embedded space", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yokota_Missing_Slice_Recovery_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "681": {"title": "left-right comparative recurrent model for stereo matching", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jie_Left-Right_Comparative_Recurrent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "17": {"title": "deep spatial feature reconstruction for partial person re-identification: alignment-free approach", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_Deep_Spatial_Feature_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "350": {"title": "glimpse clouds: human activity recognition from unstructured feature points", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baradel_Glimpse_Clouds_Human_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "477": {"title": "densepose: dense human pose estimation in the wild", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Guler_DensePose_Dense_Human_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "547": {"title": "a weighted sparse sampling and smoothing frame transition approach for semantic fast-forward first-person videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Silva_A_Weighted_Sparse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "845": {"title": "monet: deep motion exploitation for video object segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xiao_MoNet_Deep_Motion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "82": {"title": "structure inference net: object detection using scene-level context and instance-level relationships", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Structure_Inference_Net_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "501": {"title": "gibson env: real-world perception for embodied agents", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xia_Gibson_Env_Real-World_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "309": {"title": "a twofold siamese network for real-time object tracking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_A_Twofold_Siamese_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "969": {"title": "dual skipping networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_Dual_Skipping_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "209": {"title": "who let the dogs out? modeling dog behavior from visual data", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ehsani_Who_Let_the_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "729": {"title": "efficient parametrization of multi-domain deep neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rebuffi_Efficient_Parametrization_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "319": {"title": "deep cross-media knowledge transfer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Deep_Cross-Media_Knowledge_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "728": {"title": "on the duality between retinex and image dehazing", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Galdran_On_the_Duality_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "605": {"title": "recognize actions by disentangling components of dynamics", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Recognize_Actions_by_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "202": {"title": "pixor: real-time 3d object detection from point clouds", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_PIXOR_Real-Time_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "673": {"title": "lose the views: limited angle ct reconstruction via implicit sinogram completion", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Anirudh_Lose_the_Views_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "843": {"title": "towards open-set identity preserving face synthesis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bao_Towards_Open-Set_Identity_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "398": {"title": "improving landmark localization with semi-supervised learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Honari_Improving_Landmark_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "453": {"title": "convolutional image captioning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Aneja_Convolutional_Image_Captioning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "539": {"title": "pointfusion: deep sensor fusion for 3d bounding box estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_PointFusion_Deep_Sensor_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "280": {"title": "lego: learning edge with geometry all at once by watching videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_LEGO_Learning_Edge_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "178": {"title": "mobilenetv2: inverted residuals and linear bottlenecks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "283": {"title": "r-fcn-3000 at 30fps: decoupling detection and classification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Singh_R-FCN-3000_at_30fps_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "592": {"title": "toward driving scene understanding: a dataset for learning driver behavior and causal reasoning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ramanishka_Toward_Driving_Scene_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "585": {"title": "so-net: self-organizing network for point cloud analysis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_SO-Net_Self-Organizing_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "424": {"title": "boundary flow: a siamese network that predicts boundary motion without training on motion", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lei_Boundary_Flow_A_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "48": {"title": "3d semantic trajectory reconstruction from 3d pixel continuum", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yoon_3D_Semantic_Trajectory_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "914": {"title": "deep depth completion of a single rgb-d image", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Deep_Depth_Completion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "320": {"title": "towards human-machine cooperation: self-supervised sample mining for object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Towards_Human-Machine_Cooperation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "721": {"title": "beyond grobner bases: basis selection for minimal solvers", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Larsson_Beyond_Grobner_Bases_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "203": {"title": "discriminative learning of latent features for zero-shot recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Discriminative_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "905": {"title": "video based reconstruction of 3d people models", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Alldieck_Video_Based_Reconstruction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "423": {"title": "hsa-rnn: hierarchical structure-adaptive rnn for video summarization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_HSA-RNN_Hierarchical_Structure-Adaptive_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "389": {"title": "a biresolution spectral framework for product quantization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mukherjee_A_Biresolution_Spectral_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "907": {"title": "interpretable video captioning via trajectory structured localization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Interpretable_Video_Captioning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "223": {"title": "multi-cell detection and classification using a generative convolutional model", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yellin_Multi-Cell_Detection_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "609": {"title": "inferring shared attention in social scene videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fan_Inferring_Shared_Attention_CVPR_2018_paper.html", "abstract": "This paper addresses a new problem of inferring shared attention in third-person social scene videos\n. Shared attention is a phenomenon that two or more individuals simultaneously look at a common targ\net in social scenes. Perceiving and identifying shared attention in videos plays crucial roles in so\ncial activities and social scene understanding. We propose a spatial-temporal neural network to dete\nct shared attention intervals in videos and predict shared attention locations in frames. In each vi\ndeo frame, human gaze directions and potential target boxes are two key features for spatially detec\nting shared attention in the social scene. In temporal domain, a convolutional Long Short-Term Memor\ny network utilizes the temporal continuity and transition constraints to optimize the predicted shar\ned attention heatmap. We collect a new dataset VideoCoAtt1 from public TV show videos, containing 38\n0 complex video sequences with more than 492,000 frames that include diverse social scenes for share\nd attention study. Experiments on this dataset show that our model can effectively infer shared atte\nntion in videos. We also empirically verify the effectiveness of different components in our model.", "cite_num": 3}, "53": {"title": "nonlinear 3d face morphable model", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tran_Nonlinear_3D_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "493": {"title": "learning to evaluate image captioning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cui_Learning_to_Evaluate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "870": {"title": "lstm pose machines", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_LSTM_Pose_Machines_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "216": {"title": "learning from synthetic data: addressing domain shift for semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sankaranarayanan_Learning_From_Synthetic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "966": {"title": "finding beans in burgers: deep semantic-visual embedding with localization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Engilberge_Finding_Beans_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "472": {"title": "multi-scale weighted nuclear norm image restoration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yair_Multi-Scale_Weighted_Nuclear_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "139": {"title": "visual question generation as dual task of visual question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Visual_Question_Generation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "967": {"title": "deep image prior", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ulyanov_Deep_Image_Prior_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "443": {"title": "multi-scale location-aware kernel representation for object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Multi-Scale_Location-Aware_Kernel_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "301": {"title": "learning to segment every thing", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Learning_to_Segment_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "748": {"title": "five-point fundamental matrix estimation for uncalibrated cameras", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Barath_Five-Point_Fundamental_Matrix_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "445": {"title": "style aggregated network for facial landmark detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dong_Style_Aggregated_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "856": {"title": "boosting self-supervised learning via knowledge transfer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Noroozi_Boosting_Self-Supervised_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "43": {"title": "parallel attention: a unified framework for visual object discovery through dialogs and queries", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhuang_Parallel_Attention_A_CVPR_2018_paper.html", "abstract": "Recognising objects according to a pre-defined fixed set of class labels has been well studied in th\ne Computer Vision. There are a great many practical applications where the subjects that may be of i\nnterest are not known beforehand, or so easily delineated, however. In many of these cases natural l\nanguage dialog is a natural way to specify the subject of interest, and the task achieving this capa\nbility (a.k.a, Referring Expression Comprehension) has recently attracted attention. To this end we \npropose a unified framework, the ParalleL AttentioN (PLAN) network, to discover the object in an ima\nge that is being referred to in variable length natural expression descriptions, from short phrases \nquery to long multi-round dialogs. The PLAN network has two attention mechanisms that relate parts o\nf the expressions to both the global visual content and also directly to object candidates. Furtherm\nore, the attention mechanisms are recurrent, making the referring process visualizable and explainab\nle. The attended information from these dual sources are combined to reason about the referred objec\nt. These two attention mechanisms can be trained in parallel and we find the combined system outperf\norms the state-of-art on several benchmarked datasets with different length language input, such as \nRefCOCO, RefCOCO+ and GuessWhat?!.", "cite_num": -1}, "757": {"title": "beyond holistic object recognition: enriching image understanding with part states", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lu_Beyond_Holistic_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "837": {"title": "wrapped gaussian process regression on riemannian manifolds", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mallasto_Wrapped_Gaussian_Process_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "46": {"title": "spline error weighting for robust visual-inertial fusion", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ovren_Spline_Error_Weighting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "399": {"title": "unsupervised domain adaptation with similarity learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pinheiro_Unsupervised_Domain_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "427": {"title": "scale-transferrable object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Scale-Transferrable_Object_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "0": {"title": "carfusion: combining point tracking and part detection for dynamic 3d reconstruction of vehicles", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Reddy_CarFusion_Combining_Point_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "200": {"title": "encoding crowd interaction with deep neural network for pedestrian trajectory prediction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Encoding_Crowd_Interaction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "421": {"title": "disentangling factors of variation by mixing them", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Disentangling_Factors_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "305": {"title": "now you shake me: towards automatic 4d cinema", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Now_You_Shake_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "447": {"title": "recurrent residual module for fast inference in videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pan_Recurrent_Residual_Module_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "437": {"title": "analysis of hand segmentation in the wild", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Urooj_Analysis_of_Hand_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "454": {"title": "tensorize, factorize and regularize: robust visual relationship learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hwang_Tensorize_Factorize_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "901": {"title": "tags2parts: discovering semantic regions from shape tags", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Muralikrishnan_Tags2Parts_Discovering_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "947": {"title": "pairedcyclegan: asymmetric style transfer for applying and removing makeup", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_PairedCycleGAN_Asymmetric_Style_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "783": {"title": "explicit loss-error-aware quantization for low-bit deep neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Explicit_Loss-Error-Aware_Quantization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "329": {"title": "learning answer embeddings for visual question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Learning_Answer_Embeddings_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "446": {"title": "flow guided recurrent neural encoder for video salient object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Flow_Guided_Recurrent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "276": {"title": "pointwise convolutional neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hua_Pointwise_Convolutional_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "314": {"title": "deep learning of graph matching", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zanfir_Deep_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "887": {"title": "joint pose and expression modeling for facial expression recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Joint_Pose_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "581": {"title": "neural 3d mesh renderer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kato_Neural_3D_Mesh_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "903": {"title": "very large-scale global sfm by distributed motion averaging", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_Very_Large-Scale_Global_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "451": {"title": "consensus maximization for semantic region correspondences", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Speciale_Consensus_Maximization_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "483": {"title": "a network architecture for point cloud classification via automatic depth images generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Roveri_A_Network_Architecture_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "324": {"title": "optimizing video object detection via a scale-time lattice", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Optimizing_Video_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "572": {"title": "clcnet: improving the efficiency of convolutional neural network using channel local convolutions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_ClcNet_Improving_the_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "754": {"title": "a papier-m\u00e2ch\u00e9 approach to learning 3d surface generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Groueix_A_Papier-Mache_Approach_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "359": {"title": "hierarchical novelty detection for visual object recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_Hierarchical_Novelty_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "278": {"title": "exploiting transitivity for learning person re-identification models on a budget", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Roy_Exploiting_Transitivity_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "372": {"title": "feastnet: feature-steered graph convolutions for 3d shape analysis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Verma_FeaStNet_Feature-Steered_Graph_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "449": {"title": "shufflenet: an extremely efficient convolutional neural network for mobile devices", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "108": {"title": "mining point cloud local structures by kernel correlation and graph pooling", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Mining_Point_Cloud_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "766": {"title": "learning visual knowledge memory networks for visual question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Su_Learning_Visual_Knowledge_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "405": {"title": "fast and robust estimation for unit-norm constrained linear fitting problems", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ikami_Fast_and_Robust_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "211": {"title": "webly supervised learning meets zero-shot learning: a hybrid approach for fine-grained classification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Niu_Webly_Supervised_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "922": {"title": "two can play this game: visual dialog with discriminative question generation and answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jain_Two_Can_Play_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "847": {"title": "learning and using the arrow of time", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Learning_and_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "750": {"title": "learning from noisy web data with category-level supervision", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Niu_Learning_From_Noisy_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "418": {"title": "multi-cue correlation filters for robust visual tracking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Multi-Cue_Correlation_Filters_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "375": {"title": "probabilistic joint face-skull modelling for facial reconstruction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Madsen_Probabilistic_Joint_Face-Skull_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "212": {"title": "efficient and deep person re-identification using multi-level similarity", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Guo_Efficient_and_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "275": {"title": "learning to sketch with shortcut cycle consistency", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Learning_to_Sketch_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "240": {"title": "perturbative neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Juefei-Xu_Perturbative_Neural_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "413": {"title": "nestednet: learning nested sparse structures in deep neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_NestedNet_Learning_Nested_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "517": {"title": "matching pixels using co-occurrence statistics", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kat_Matching_Pixels_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "131": {"title": "nisp: pruning networks using neuron importance score propagation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_NISP_Pruning_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "349": {"title": "deep marching cubes: learning explicit surface representations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liao_Deep_Marching_Cubes_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "723": {"title": "amnet: memorability estimation with attention", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fajtl_AMNet_Memorability_Estimation_CVPR_2018_paper.html", "abstract": "In this paper we present the design and evaluation of an end-to-end trainable, deep neural network w\nith a visual attention mechanism for memorability estimation in still images. We analyze the suitabi\nlity of transfer learning of deep models from image classification to the memorability task. Further\n on we study the impact of the attention mechanism on the memorability estimation and evaluate our n\network on the SUN Memorability and the LaMem datasets. Our network outperforms the existing state of\n the art models on both datasets in terms of the Spearman's rank correlation as well as the mean squ\nared error, closely matching human consistency.", "cite_num": 4}, "1": {"title": "deep learning under privileged information using heteroscedastic dropout", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lambert_Deep_Learning_Under_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "519": {"title": "convolutional neural networks with alternately updated clique", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Convolutional_Neural_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "793": {"title": "learning strict identity mappings in deep residual networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Learning_Strict_Identity_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "610": {"title": "feature mapping for learning fast and accurate 3d pose inference from synthetic images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rad_Feature_Mapping_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "709": {"title": "spatially-adaptive filter units for deep neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tabernik_Spatially-Adaptive_Filter_Units_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "380": {"title": "phasenet for video frame interpolation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Meyer_PhaseNet_for_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "487": {"title": "temporal deformable residual networks for action segmentation in videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lei_Temporal_Deformable_Residual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "96": {"title": "partial transfer learning with selective adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Partial_Transfer_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "260": {"title": "learning deep structured active contours end-to-end", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Marcos_Learning_Deep_Structured_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "133": {"title": "domain generalization with adversarial feature learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Domain_Generalization_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "528": {"title": "sgpn: similarity group proposal network for 3d point cloud instance segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_SGPN_Similarity_Group_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "387": {"title": "dels-3d: deep localization and segmentation with a 3d semantic map", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_DeLS-3D_Deep_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "926": {"title": "roadtracer: automatic extraction of road networks from aerial images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bastani_RoadTracer_Automatic_Extraction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "97": {"title": "multimodal visual concept learning with weakly supervised techniques", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bouritsas_Multimodal_Visual_Concept_CVPR_2018_paper.html", "abstract": "Despite the availability of a huge amount of video data accompanied by descriptive texts, it is not \nalways easy to exploit the information contained in natural language in order to automatically recog\nnize video concepts. Towards this goal, in this paper we use textual cues as means of supervision, i\nntroducing two weakly supervised techniques that extend the Multiple Instance Learning (MIL) framewo\nrk: the Fuzzy Sets Multiple Instance Learning (FSMIL) and the Probabilistic Labels Multiple Instance\n Learning (PLMIL). The former encodes the spatio-temporal imprecision of the linguistic descriptions\n with Fuzzy Sets, while the latter models different interpretations of each description's semantics \nwith Probabilistic Labels, both formulated through a convex optimization algorithm. In addition, we \nprovide a novel technique to extract weak labels in the presence of complex semantics, that consists\n of semantic similarity computations. We evaluate our methods on two distinct problems, namely face \nand action recognition, in the challenging and realistic setting of movies accompanied by their scre\nenplays, contained in the COGNIMUSE database. We show that, on both tasks, our method considerably o\nutperforms a state-of-the-art weakly supervised approach, as well as other baselines.", "cite_num": 2}, "226": {"title": "globally optimal inlier set maximization for atlanta frame estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Joo_Globally_Optimal_Inlier_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "352": {"title": "3d human pose estimation in the wild by adversarial learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_3D_Human_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "162": {"title": "efficient subpixel refinement with symbolic linear predictors", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lui_Efficient_Subpixel_Refinement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "68": {"title": "a hybrid l1-l0 layer decomposition model for tone mapping", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liang_A_Hybrid_l1-l0_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "515": {"title": "are you talking to me? reasoned visual dialog generation through adversarial learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Are_You_Talking_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "838": {"title": "pseudo mask augmented object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Pseudo_Mask_Augmented_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "106": {"title": "masklab: instance segmentation by refining object detection with semantic and direction features", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_MaskLab_Instance_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "38": {"title": "lime: live intrinsic material estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Meka_LIME_Live_Intrinsic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "786": {"title": "voxelnet: end-to-end learning for point cloud based 3d object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_VoxelNet_End-to-End_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "917": {"title": "towards high performance video object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_Towards_High_Performance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "707": {"title": "adversarial complementary learning for weakly supervised object localization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Adversarial_Complementary_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "130": {"title": "surface networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kostrikov_Surface_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "274": {"title": "unsupervised learning of depth and ego-motion from monocular video using 3d geometric constraints", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mahjourian_Unsupervised_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "536": {"title": "cross-dataset adaptation for visual question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chao_Cross-Dataset_Adaptation_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "628": {"title": "enhancing the spatial resolution of stereo images using a parallax prior", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jeon_Enhancing_the_Spatial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "828": {"title": "adversarially learned one-class classifier for novelty detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sabokrou_Adversarially_Learned_One-Class_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "28": {"title": "feature selective networks for object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhai_Feature_Selective_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "317": {"title": "im2pano3d: extrapolating 360\u00b0 structure and semantics beyond the field of view", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Im2Pano3D_Extrapolating_360deg_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "747": {"title": "weakly supervised action localization by sparse temporal pooling network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nguyen_Weakly_Supervised_Action_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "146": {"title": "decorrelated batch normalization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Decorrelated_Batch_Normalization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "635": {"title": "lidar-video driving dataset: learning driving policies effectively", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "373": {"title": "detail-preserving pooling in deep networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Saeedan_Detail-Preserving_Pooling_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "123": {"title": "motion-appearance co-memory networks for video question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gao_Motion-Appearance_Co-Memory_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "327": {"title": "analytical modeling of vanishing points and curves in catadioptric cameras", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Miraldo_Analytical_Modeling_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "355": {"title": "resource aware person re-identification across multiple resolutions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Resource_Aware_Person_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "568": {"title": "excitation backprop for rnns", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bargal_Excitation_Backprop_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "112": {"title": "transferable joint attribute-identity deep learning for unsupervised person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Transferable_Joint_Attribute-Identity_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "298": {"title": "sketchmate: deep hashing for million-scale human sketch retrieval", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_SketchMate_Deep_Hashing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "591": {"title": "mobile video object detection with temporally-aware feature maps", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Mobile_Video_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "878": {"title": "learning to estimate 3d human pose and shape from a single color image", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pavlakos_Learning_to_Estimate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "60": {"title": "dense 3d regression for hand pose estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wan_Dense_3D_Regression_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "407": {"title": "cross-modal deep variational hand pose estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Spurr_Cross-Modal_Deep_Variational_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "444": {"title": "sketchygan: towards diverse and realistic sketch to image synthesis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_SketchyGAN_Towards_Diverse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "532": {"title": "a variational u-net for conditional appearance and shape generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Esser_A_Variational_U-Net_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "526": {"title": "few-shot image recognition by predicting parameters from activations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qiao_Few-Shot_Image_Recognition_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "655": {"title": "boosting adversarial attacks with momentum", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dong_Boosting_Adversarial_Attacks_CVPR_2018_paper.html", "abstract": "Deep neural networks are vulnerable to adversarial examples, which poses security concerns on these \nalgorithms due to the potentially severe consequences. Adversarial attacks serve as an important sur\nrogate to evaluate the robustness of deep learning models before they are deployed. However, most of\n existing adversarial attacks can only fool a black-box model with a low success rate. To address th\nis issue, we propose a broad class of momentum-based iterative  algorithms to boost adversarial atta\ncks. By integrating the momentum term into the iterative process for attacks, our methods can stabil\nize update directions and escape from poor local maxima during the iterations, resulting in more tra\nnsferable adversarial examples. To further improve the success rates for black-box attacks, we apply\n momentum iterative algorithms to an ensemble of models, and show that the adversarially trained mod\nels with a strong defense ability are also vulnerable to our black-box attacks. We hope that the pro\nposed methods will serve as a benchmark for evaluating the robustness of various deep models and def\nense methods. With this method, we won the first places in NIPS 2017 Non-targeted Adversarial Attack\n and Targeted Adversarial Attack competitions.", "cite_num": 0}, "392": {"title": "generative adversarial perturbations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Poursaeed_Generative_Adversarial_Perturbations_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "626": {"title": "deep texture manifold for ground terrain recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xue_Deep_Texture_Manifold_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "667": {"title": "face aging with identity-preserved conditional generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Face_Aging_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "763": {"title": "visual grounding via accumulated attention", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Deng_Visual_Grounding_via_CVPR_2018_paper.html", "abstract": "Visual Grounding (VG) aims to locate the most relevant object or region in an image, based on a natu\nral language query. The query can be a phrase, a sentence or even a multi-round dialogue. There are \nthree main challenges in VG: 1) what is the main focus in a query; 2) how to understand an image; 3)\n how to locate an object. Most existing methods combine all the information curtly, which may suffer\n from the problem of information redundancy (i.e. ambiguous query, complicated image and a large num\nber of objects). In this paper, we formulate these challenges as three attention problems and propos\ne an accumulated attention (A-ATT) mechanism to reason among them jointly. Our A-ATT mechanism can c\nircularly accumulate the attention for useful information in image, query, and objects, while the no\nises are ignored gradually. We evaluate the performance of A-ATT on four popular datasets (namely Re\nfer-COCO, ReferCOCO+, ReferCOCOg, and Guesswhat?!), and the experimental results show the superiorit\ny of the proposed method in term of accuracy.", "cite_num": 15}, "942": {"title": "residual dense network for image super-resolution", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Residual_Dense_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "99": {"title": "learning a discriminative feature network for semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Learning_a_Discriminative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "438": {"title": "self-supervised adversarial hashing networks for cross-modal retrieval", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Self-Supervised_Adversarial_Hashing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "192": {"title": "structure from recurrent motion: from rigidity to recurrency", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Structure_From_Recurrent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "851": {"title": "from lifestyle vlogs to everyday interactions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fouhey_From_Lifestyle_Vlogs_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "662": {"title": "decoupled networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Decoupled_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "254": {"title": "3d-rcnn: instance-level 3d object reconstruction via render-and-compare", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kundu_3D-RCNN_Instance-Level_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "924": {"title": "mean-variance loss for deep age estimation from a face", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pan_Mean-Variance_Loss_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "293": {"title": "cnn in mrf: video object segmentation via inference in a cnn-based higher-order spatio-temporal mrf", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bao_CNN_in_MRF_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "727": {"title": "learning for disparity estimation through feature constancy", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liang_Learning_for_Disparity_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "950": {"title": "unsupervised sparse dirichlet-net for hyperspectral image super-resolution", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qu_Unsupervised_Sparse_Dirichlet-Net_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "676": {"title": "mesoscopic facial geometry inference using deep neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huynh_Mesoscopic_Facial_Geometry_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "257": {"title": "real-time monocular depth estimation using synthetic data with domain adaptation via image style transfer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Atapour-Abarghouei_Real-Time_Monocular_Depth_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "391": {"title": "a prior-less method for multi-face tracking in unconstrained videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_A_Prior-Less_Method_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "852": {"title": "recovering realistic texture in image super-resolution by deep spatial feature transform", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Recovering_Realistic_Texture_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "224": {"title": "pointgrid: a deep network for 3d shape understanding", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Le_PointGrid_A_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "787": {"title": "language-based image editing with recurrent attentive models", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Language-Based_Image_Editing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "596": {"title": "cbmv: a coalesced bidirectional matching volume for disparity estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Batsos_CBMV_A_Coalesced_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "776": {"title": "3d semantic segmentation with submanifold sparse convolutional networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Graham_3D_Semantic_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "394": {"title": "guide me: interacting with deep networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rupprecht_Guide_Me_Interacting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "215": {"title": "an analysis of scale invariance in object detection \u00ad snip", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Singh_An_Analysis_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "974": {"title": "dynamic-structured semantic propagation network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liang_Dynamic-Structured_Semantic_Propagation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "335": {"title": "a constrained deep neural network for ordinal regression", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_A_Constrained_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "152": {"title": "video captioning via hierarchical reinforcement learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Video_Captioning_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "621": {"title": "planar shape detection at structural scales", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fang_Planar_Shape_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "699": {"title": "blind predicting similar quality map for image quality assessment", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pan_Blind_Predicting_Similar_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "882": {"title": "a revised underwater image formation model", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Akkaynak_A_Revised_Underwater_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "66": {"title": "planenet: piece-wise planar reconstruction from a single rgb image", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_PlaneNet_Piece-Wise_Planar_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "2": {"title": "deep spatio-temporal random fields for efficient video segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chandra_Deep_Spatio-Temporal_Random_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "571": {"title": "deep ordinal regression network for monocular depth estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fu_Deep_Ordinal_Regression_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "735": {"title": "sparse, smart contours to represent and edit images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dekel_Sparse_Smart_Contours_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "198": {"title": "super-fan: integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with gans", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bulat_Super-FAN_Integrated_Facial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "40": {"title": "revisiting knowledge transfer for training object class detectors", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Uijlings_Revisiting_Knowledge_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "459": {"title": "fast and furious: real time end-to-end 3d detection, tracking and motion forecasting with a single convolutional net", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_Fast_and_Furious_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "606": {"title": "recurrent slice networks for 3d segmentation of point clouds", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Recurrent_Slice_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "5": {"title": "arbitrary style transfer with deep feature reshuffle", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gu_Arbitrary_Style_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "145": {"title": "crowd counting with deep negative correlation learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shi_Crowd_Counting_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "756": {"title": "multi-image semantic matching by mining consistent features", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Multi-Image_Semantic_Matching_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "645": {"title": "multi-evidence filtering and fusion for multi-label classification, object detection and semantic segmentation based on weakly supervised learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ge_Multi-Evidence_Filtering_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "406": {"title": "fast and accurate single image super-resolution via information distillation network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hui_Fast_and_Accurate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "206": {"title": "fast video object segmentation by reference-guided mask propagation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Oh_Fast_Video_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "11": {"title": "improving object localization with fitness nms and bounded iou loss", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tychsen-Smith_Improving_Object_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "250": {"title": "hierarchical recurrent attention networks for structured online maps", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Homayounfar_Hierarchical_Recurrent_Attention_CVPR_2018_paper.html", "abstract": "In this paper, we tackle the problem of online road network extraction from sparse 3D point clouds. \nOur method is inspired by how an annotator builds a lane graph, by first identifying how many lanes \nthere are and then drawing each one in turn. We develop a hierarchical recurrent network that attend\ns to initial regions of a lane boundary and traces them out completely by outputting a structured po\nly-line. We also propose a novel differentiable loss function that measures the deviation of the edg\nes of the ground truth polylines and their predictions. This is more suitable than distances on vert\nices, as there exists many ways to draw equivalent polylines. We demonstrate the effectiveness of ou\nr method on a 90 km stretch of highway, and show that we can recover the right topology 92% of the t\nime.", "cite_num": 4}, "73": {"title": "dynamic scene deblurring using spatially variant recurrent neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Dynamic_Scene_Deblurring_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "894": {"title": "end-to-end convolutional semantic embeddings", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/You_End-to-End_Convolutional_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "232": {"title": "beyond the pixel-wise loss for topology-aware delineation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mosinska_Beyond_the_Pixel-Wise_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "659": {"title": "grounding referring expressions in images by variational context", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Grounding_Referring_Expressions_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "64": {"title": "semantic video segmentation by gated recurrent flow propagation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nilsson_Semantic_Video_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "806": {"title": "inferring light fields from shadows", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baradad_Inferring_Light_Fields_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "618": {"title": "global versus localized generative adversarial nets", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Global_Versus_Localized_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "820": {"title": "structured attention guided convolutional neural fields for monocular depth estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Structured_Attention_Guided_CVPR_2018_paper.html", "abstract": "Recent works have shown the benefit of integrating Conditional Random Fields (CRFs) models into deep\n architectures for improving pixel-level prediction tasks. Following this line of research, in this \npaper we introduce a novel approach for monocular depth estimation. Similarly to previous works, our\n method employs a continuous CRF to fuse multi-scale information derived from different layers of a \nfront-end Convolutional Neural Network (CNN). Differently from past works, our approach benefits fro\nm a structured attention model which automatically regulates the amount of information transferred b\netween corresponding features at different scales. Importantly, the proposed attention model is seam\nlessly integrated into the CRF, allowing end-to-end training of the entire architecture. Our extensi\nve experimental evaluation demonstrates the effectiveness of the proposed method which is competitiv\ne with previous methods on the KITTI benchmark and outperforms the state of the art on the NYU Depth\n V2 dataset.", "cite_num": 19}, "650": {"title": "fully convolutional adaptation networks for semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Fully_Convolutional_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "20": {"title": "going from image to video saliency: augmenting image salience with dynamic attentional push", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gorji_Going_From_Image_CVPR_2018_paper.html", "abstract": "We present a novel method to incorporate the recent advent in static saliency models to predict the \nsaliency in videos. Our model augments the static saliency models with the Attentional Push effect o\nf the photographer and the scene actors in a shared attention setting. We demonstrate that not only \nit is imperative to use static Attentional Push cues, noticeable performance improvement is achievab\nle by learning the time-varying nature of Attentional Push. We propose a multi-stream Convolutional \nLong Short-Term Memory network (ConvLSTM) structure which augments state-of-the-art in static salien\ncy models with dynamic Attentional Push. Our network contains four pathways, a saliency pathway and \nthree Attentional Push pathways. The multi-pathway structure is followed by an augmenting convnet th\nat learns to combine the complementary and time-varying outputs of the ConvLSTMs by minimizing the r\nelative entropy between the augmented saliency and viewers fixation patterns on videos. We evaluate \nour model by comparing the performance of several augmented static saliency models with state-of-the\n-art in spatiotemporal saliency on three largest dynamic eye tracking datasets, HOLLYWOOD2, UCF-Spor\nt and DIEM. Experimental results illustrates that solid performance gain is achievable using the pro\nposed methodology.", "cite_num": 6}, "159": {"title": "learning a discriminative filter bank within a cnn for fine-grained recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Learning_a_Discriminative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "58": {"title": "visual feature attribution using wasserstein gans", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baumgartner_Visual_Feature_Attribution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "341": {"title": "generating synthetic x-ray images of a person from the surface geometry", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Teixeira_Generating_Synthetic_X-Ray_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "977": {"title": "gvcnn: group-view convolutional neural networks for 3d shape recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Feng_GVCNN_Group-View_Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "251": {"title": "video rain streak removal by multiscale convolutional sparse coding", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Video_Rain_Streak_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "622": {"title": "a low power, high throughput, fully event-based stereo system", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Andreopoulos_A_Low_Power_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "306": {"title": "a pose-sensitive embedding for person re-identification with expanded cross neighborhood re-ranking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sarfraz_A_Pose-Sensitive_Embedding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "330": {"title": "ganerated hands for real-time 3d hand tracking from monocular rgb", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mueller_GANerated_Hands_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "87": {"title": "dynamic graph generation network: generating relational knowledge from diagrams", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_Dynamic_Graph_Generation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "873": {"title": "salient object detection driven by fixation prediction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Salient_Object_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "531": {"title": "pose-robust face recognition via deep residual equivariant mapping", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Pose-Robust_Face_Recognition_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "422": {"title": "tangent convolutions for dense prediction in 3d", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "719": {"title": "cosface: large margin cosine loss for deep face recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_CosFace_Large_Margin_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "589": {"title": "matching adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mattyus_Matching_Adversarial_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "665": {"title": "occlusion aware unsupervised learning of optical flow", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Occlusion_Aware_Unsupervised_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "876": {"title": "learning intrinsic image decomposition from watching the world", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Learning_Intrinsic_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "780": {"title": "between-class learning for image classification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tokozume_Between-Class_Learning_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "535": {"title": "uncalibrated photometric stereo under natural illumination", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mo_Uncalibrated_Photometric_Stereo_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "814": {"title": "learning spatial-temporal regularized correlation filters for visual tracking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Learning_Spatial-Temporal_Regularized_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "507": {"title": "low-shot learning with large-scale diffusion", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Douze_Low-Shot_Learning_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "761": {"title": "thoracic disease identification and localization with limited supervision", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Thoracic_Disease_Identification_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "238": {"title": "cross-domain self-supervised multi-task feature learning using synthetic imagery", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ren_Cross-Domain_Self-Supervised_Multi-Task_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "117": {"title": "dual attention matching network for context-aware feature sequence based person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Si_Dual_Attention_Matching_CVPR_2018_paper.html", "abstract": "Typical person re-identification (ReID) methods usually describe each pedestrian with a single featu\nre vector and match them in a task-specific metric space. However, the methods based on a single fea\nture vector are not sufficient enough to overcome visual ambiguity, which frequently occurs in real \nscenario. In this paper, we propose a novel end-to-end trainable framework, called Dual ATtention Ma\ntching network (DuATM), to learn context-aware feature sequences and perform attentive sequence comp\narison simultaneously. The core component of our DuATM framework is a dual attention mechanism, in w\nhich both intra-sequence and inter-sequence attention strategies are used for feature refinement and\n feature-pair alignment, respectively. Thus, detailed visual cues contained in the intermediate feat\nure sequences can be automatically exploited and properly compared. We train the proposed DuATM netw\nork as a siamese network via a triplet loss assisted with a de-correlation loss and a cross-entropy \nloss. We conduct extensive experiments on both image and video based ReID benchmark datasets. Experi\nmental results demonstrate the significant advantages of our approach compared to the state-of-the-a\nrt methods.", "cite_num": -1}, "502": {"title": "deep lesion graphs in the wild: relationship learning and organization of significant radiology image findings in a diverse large-scale lesion database", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yan_Deep_Lesion_Graphs_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "271": {"title": "rethinking the faster r-cnn architecture for temporal action localization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chao_Rethinking_the_Faster_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "541": {"title": "ordinal depth supervision for 3d human pose estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pavlakos_Ordinal_Depth_Supervision_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "195": {"title": "cross-domain weakly-supervised object detection through progressive domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "741": {"title": "social gan: socially acceptable trajectories with generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gupta_Social_GAN_Socially_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "683": {"title": "deeply learned filter response functions for hyperspectral reconstruction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nie_Deeply_Learned_Filter_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "657": {"title": "optimizing filter size in convolutional neural networks for facial action unit recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Han_Optimizing_Filter_Size_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "337": {"title": "seeing small faces from robust anchor's perspective", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_Seeing_Small_Faces_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "410": {"title": "depth-aware stereo video retargeting", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Depth-Aware_Stereo_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "488": {"title": "estimation of camera locations in highly corrupted scenarios: all about that base, no shape trouble", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shi_Estimation_of_Camera_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "401": {"title": "reinforcement cutting-agent learning for video object segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Han_Reinforcement_Cutting-Agent_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "561": {"title": "the inaturalist species classification and detection dataset", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Van_Horn_The_INaturalist_Species_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "906": {"title": "solving the perspective-2-point problem for flying-camera photo composition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lan_Solving_the_Perspective-2-Point_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "884": {"title": "memory based online learning of deep representations from video streams", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pernici_Memory_Based_Online_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "425": {"title": "deep cost-sensitive and order-preserving feature learning for cross-population age estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Deep_Cost-Sensitive_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "506": {"title": "learning 3d shape completion from laser scan data with weak supervision", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Stutz_Learning_3D_Shape_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "259": {"title": "erase or fill? deep joint recurrent rain removal and reconstruction in videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Erase_or_Fill_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "573": {"title": "synthesizing images of humans in unseen poses", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Balakrishnan_Synthesizing_Images_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "368": {"title": "learning pose specific representations by predicting different views", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Poier_Learning_Pose_Specific_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "34": {"title": "syq: learning symmetric quantization for efficient deep neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Faraone_SYQ_Learning_Symmetric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "578": {"title": "edit probability for scene text recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bai_Edit_Probability_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "217": {"title": "generating a fusion image: one's identity and another's shape", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Joo_Generating_a_Fusion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "594": {"title": "feedback-prop: convolutional neural network inference under partial evidence", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Feedback-Prop_Convolutional_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "523": {"title": "gaze prediction in dynamic 360\u00b0 immersive videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Gaze_Prediction_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "505": {"title": "end-to-end flow correlation tracking with spatial-temporal attention", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_End-to-End_Flow_Correlation_CVPR_2018_paper.html", "abstract": "Discriminative correlation filters (DCF) with deep convolutional features have achieved favorable pe\nrformance in recent tracking benchmarks. However, most of existing DCF trackers only consider appear\nance features of current frame, and hardly benefit from motion and inter-frame information. The lack\n of temporal information degrades the tracking performance during challenges such as partial occlusi\non and deformation. In this paper, we propose the FlowTrack, which focuses on making use of the rich\n flow information in consecutive frames to improve the feature representation and the tracking accur\nacy. The FlowTrack formulates individual components, including optical flow estimation, feature extr\naction, aggregation and correlation filters tracking as special layers in network. To the best of ou\nr knowledge, this is the first work to jointly train flow and tracking task in deep learning framewo\nrk. Then the historical feature maps at predefined intervals are warped and aggregated with current \nones by the guiding of flow. For adaptive aggregation, we propose a novel spatial-temporal attention\n mechanism. In experiments, the proposed method achieves leading performance on OTB2013, OTB2015, VO\nT2015 and VOT2016.", "cite_num": 20}, "140": {"title": "preserving semantic relations for zero-shot learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Annadani_Preserving_Semantic_Relations_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "182": {"title": "diversity regularized spatiotemporal attention for video-based person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Diversity_Regularized_Spatiotemporal_CVPR_2018_paper.html", "abstract": "Video-based person re-identification matches video clips of people across non-overlapping cameras. M\nost existing methods tackle this problem by encoding each video frame in its entirety and computing \nan aggregate representation across all frames. In practice, people are often partially occluded, whi\nch can corrupt the extracted features. Instead, we propose a new spatiotemporal attention model that\n automatically discovers a diverse set of distinctive body parts. This allows useful information to \nbe extracted from all frames without succumbing to occlusions and misalignments. The network learns \nmultiple spatial attention models and employs a diversity regularization term to ensure multiple mod\nels do not discover the same body part. Features extracted from local image regions are organized by\n spatial attention model and are combined using temporal attention. As a result, the network learns \nlatent representations of the face, torso and other body parts using the best available image patche\ns from the entire video sequence. Extensive evaluations on three datasets show that our framework ou\ntperforms the state-of-the-art approaches by large margins on multiple metrics.", "cite_num": 11}, "484": {"title": "rethinking feature distribution for loss functions in image classification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wan_Rethinking_Feature_Distribution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "679": {"title": "coco-stuff: thing and stuff classes in context", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Caesar_COCO-Stuff_Thing_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "383": {"title": "when will you do what? - anticipating temporal occurrences of activities", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Abu_Farha_When_Will_You_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "920": {"title": "fusing crowd density maps and visual object trackers for people tracking in crowd scenes", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ren_Fusing_Crowd_Density_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "773": {"title": "an end-to-end textspotter with explicit alignment and attention", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_An_End-to-End_TextSpotter_CVPR_2018_paper.html", "abstract": "Text detection and recognition in natural images have long been considered as two separate tasks tha\nt are processed sequentially. Jointly training two tasks is non-trivial due to significant differenc\nes in learning difficulties and convergence rates. In this work, we present a conceptually simple ye\nt efficient framework that simultaneously processes the two tasks in a united framework. Our main co\nntributions are three-fold: (1) we propose a novel text-alignment layer that allows it to precisely \ncompute convolutional features of a text instance in arbitrary orientation, which is the key to boos\nt the performance; (2) a character attention mechanism is introduced by using character spatial info\nrmation as explicit supervision, leading to large improvements in recognition; (3) two technologies,\n together with a new RNN branch for word recognition, are integrated seamlessly into a single model \nwhich is end-to-end trainable. This allows the two tasks to work collaboratively by sharing convolut\nional features, which is critical to identify challenging text instances. Our model obtains impressi\nve results in end-to-end recognition on the ICDAR 2015 [19], significantly advancing the most recent\n results [2], with improvements of F-measure from (0.54, 0.51, 0.47) to (0.82, 0.77, 0.63), by using\n a strong, weak and generic lexicon respectively. Thanks to joint training, our method can also serv\ne as a good detector by achieving a new state-of-the-art detection performance on related benchmarks\n. Code is available at https://github.com/tonghe90/textspotter.", "cite_num": 14}, "261": {"title": "lean multiclass crowdsourcing", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Van_Horn_Lean_Multiclass_Crowdsourcing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "935": {"title": "splinecnn: fast geometric deep learning with continuous b-spline kernels", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fey_SplineCNN_Fast_Geometric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "853": {"title": "feature space transfer for data augmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Feature_Space_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "815": {"title": "reflection removal for large-scale 3d point clouds", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yun_Reflection_Removal_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "949": {"title": "\u201czero-shot\u201d super-resolution using deep internal learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shocher_Zero-Shot_Super-Resolution_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "533": {"title": "deep unsupervised saliency detection: a multiple noisy labeling perspective", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Deep_Unsupervised_Saliency_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "941": {"title": "relation networks for object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Relation_Networks_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "943": {"title": "inverse composition discriminative optimization for point cloud registration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vongkulbhisal_Inverse_Composition_Discriminative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "567": {"title": "egocentric basketball motion planning from a single first-person image", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bertasius_Egocentric_Basketball_Motion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "795": {"title": "tom-net: learning transparent object matting from a single image", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_TOM-Net_Learning_Transparent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "702": {"title": "geometry aware constrained optimization techniques for deep learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Roy_Geometry_Aware_Constrained_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "142": {"title": "deep extreme cut: from extreme points to object segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Maninis_Deep_Extreme_Cut_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "362": {"title": "2d/3d pose estimation and action recognition using multitask deep learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luvizon_2D3D_Pose_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "555": {"title": "unsupervised training for 3d morphable model regression", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Genova_Unsupervised_Training_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "557": {"title": "modulated convolutional networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Modulated_Convolutional_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "287": {"title": "learning a discriminative prior for blind image deblurring", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Learning_a_Discriminative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "808": {"title": "deep mutual learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Deep_Mutual_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "705": {"title": "disentangling 3d pose in a dendritic cnn for unconstrained 2d face alignment", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kumar_Disentangling_3D_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "710": {"title": "learning facial action units from web images with scalable weakly supervised clustering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Learning_Facial_Action_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "72": {"title": "disentangling features in 3d face shapes for joint face reconstruction and recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Disentangling_Features_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "545": {"title": "image correction via deep reciprocating hdr transformation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Image_Correction_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "163": {"title": "potion: pose motion representation for action recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Choutas_PoTion_Pose_MoTion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "826": {"title": "residual parameter transfer for deep domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rozantsev_Residual_Parameter_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "608": {"title": "motion-guided cascaded refinement network for video object segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Motion-Guided_Cascaded_Refinement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "101": {"title": "learning to understand image blur", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Learning_to_Understand_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "119": {"title": "robust physical-world attacks on deep learning visual classification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Eykholt_Robust_Physical-World_Attacks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "236": {"title": "learning to localize sound source in visual scenes", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Senocak_Learning_to_Localize_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "771": {"title": "finding tiny faces in the wild with generative adversarial network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bai_Finding_Tiny_Faces_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "758": {"title": "triplet-center loss for multi-view 3d object retrieval", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_Triplet-Center_Loss_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "98": {"title": "condensenet: an efficient densenet using learned group convolutions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_CondenseNet_An_Efficient_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "550": {"title": "high performance visual tracking with siamese region proposal network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_High_Performance_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "90": {"title": "weakly supervised facial action unit recognition through adversarial training", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Peng_Weakly_Supervised_Facial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "817": {"title": "multistage adversarial losses for pose-based human image synthesis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Si_Multistage_Adversarial_Losses_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "951": {"title": "high-order tensor regularization with application to attribute ranking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_High-Order_Tensor_Regularization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "524": {"title": "ol\u00e9: orthogonal low-rank embedding - a plug and play geometric loss for deep learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lezama_OLE_Orthogonal_Low-Rank_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "858": {"title": "weakly supervised learning of single-cell feature embeddings", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Caicedo_Weakly_Supervised_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "74": {"title": "image generation from scene graphs", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Johnson_Image_Generation_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "762": {"title": "scalable and effective deep cca via soft decorrelation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_Scalable_and_Effective_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "598": {"title": "pad-net: multi-tasks guided prediction-and-distillation network for simultaneous depth estimation and scene parsing", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_PAD-Net_Multi-Tasks_Guided_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "404": {"title": "weakly supervised instance segmentation using class peak response", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Weakly_Supervised_Instance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "927": {"title": "object referring in videos with language and human gaze", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vasudevan_Object_Referring_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "365": {"title": "learning deep models for face anti-spoofing: binary or auxiliary supervision", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Learning_Deep_Models_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "644": {"title": "surfconv: bridging 3d and 2d convolution for rgbd images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chu_SurfConv_Bridging_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "811": {"title": "megadepth: learning single-view depth prediction from internet photos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_MegaDepth_Learning_Single-View_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "243": {"title": "what have we learned from deep representations for action recognition?", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Feichtenhofer_What_Have_We_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "430": {"title": "end-to-end recovery of human shape and pose", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kanazawa_End-to-End_Recovery_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "867": {"title": "real-world repetition estimation by div, grad and curl", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Runia_Real-World_Repetition_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "544": {"title": "sparse photometric 3d face reconstruction guided by morphable models", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Sparse_Photometric_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "639": {"title": "zero-shot recognition via semantic embeddings and knowledge graphs", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Zero-Shot_Recognition_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "514": {"title": "end-to-end learning of motion representation for video understanding", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fan_End-to-End_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "717": {"title": "ds*: tighter lifting-free convex relaxations for quadratic matching problems", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bernard_DS_Tighter_Lifting-Free_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "126": {"title": "multi-shot pedestrian re-identification via sequential decision making", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Multi-Shot_Pedestrian_Re-Identification_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "731": {"title": "fooling vision and language models despite localization and attention mechanism", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Fooling_Vision_and_CVPR_2018_paper.html", "abstract": "Adversarial attacks are known to succeed on classifiers, but it has been an open question whether mo\nre complex vision systems are vulnerable. In this paper, we study adversarial examples for vision an\nd language models, which incorporate natural language understanding and complex structures such as a\nttention, localization, and modular architectures. In particular, we investigate attacks on a dense \ncaptioning model and on two visual question answering (VQA) models. Our evaluation shows that we can\n generate adversarial examples with a high success rate (i.e., > 90%) for these models. Our work she\nds new light on understanding adversarial attacks on vision systems which have a language component \nand shows that attention, bounding box localization, and compositional internal structures are vulne\nrable to adversarial attacks. These observations will inform future work towards building effective \ndefenses.", "cite_num": 9}, "322": {"title": "a fast resection-intersection method for the known rotation problem", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_A_Fast_Resection-Intersection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "210": {"title": "separating style and content for generalized style transfer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Separating_Style_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "678": {"title": "regularizing rnns for caption generation by reconstructing the past with the present", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Regularizing_RNNs_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "565": {"title": "crrn: multi-scale guided concurrent reflection removal network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wan_CRRN_Multi-Scale_Guided_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "499": {"title": "learning steerable filters for rotation equivariant cnns", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Weiler_Learning_Steerable_Filters_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "462": {"title": "liteflownet: a lightweight convolutional neural network for optical flow estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hui_LiteFlowNet_A_Lightweight_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "703": {"title": "interpretable convolutional neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Interpretable_Convolutional_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "269": {"title": "human semantic parsing for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kalayeh_Human_Semantic_Parsing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "466": {"title": "deep density clustering of unconstrained faces", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_Deep_Density_Clustering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "623": {"title": "conditional generative adversarial network for structured domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hong_Conditional_Generative_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "433": {"title": "road: reality oriented adaptation for semantic segmentation of urban scenes", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_ROAD_Reality_Oriented_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "666": {"title": "divide and conquer for full-resolution light field deblurring", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mohan_Divide_and_Conquer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "643": {"title": "actor and action video segmentation from a sentence", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gavrilyuk_Actor_and_Action_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "273": {"title": "modifying non-local variations across multiple views", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tlusty_Modifying_Non-Local_Variations_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "100": {"title": "attngan: fine-grained text to image generation with attentional generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_AttnGAN_Fine-Grained_Text_CVPR_2018_paper.html", "abstract": "In this paper, we propose an Attentional Generative Adversarial Network (AttnGAN) that allows attent\nion-driven, multi-stage refinement for fine-grained text-to-image generation. With a novel attention\nal generative network, the AttnGAN can synthesize fine-grained details at different subregions of th\ne image by paying attentions to the relevant words in the natural language description. In addition,\n a deep attentional multimodal similarity model is proposed to compute a fine-grained image-text mat\nching loss for training the generator. The proposed AttnGAN significantly outperforms the previous s\ntate of the art, boosting the best reported inception score by 14.14% on the CUB dataset and 170.25%\n on the more challenging COCO dataset. A detailed analysis is also performed by visualizing the atte\nntion layers of the AttnGAN. It for the first time shows that the layered attentional GAN is able to\n automatically select the condition at the word level for generating different parts of the image.", "cite_num": -1}, "857": {"title": "flipdial: a generative model for two-way visual dialogue", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Massiceti_FlipDial_A_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "552": {"title": "learning to promote saliency detectors", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zeng_Learning_to_Promote_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "177": {"title": "hydranets: specialized dynamic architectures for efficient inference", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mullapudi_HydraNets_Specialized_Dynamic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "796": {"title": "ssnet: scale selection network for online 3d action prediction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_SSNet_Scale_Selection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "414": {"title": "empirical study of the topology and geometry of deep networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fawzi_Empirical_Study_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "292": {"title": "revisiting salient object detection: simultaneous detection, ranking, and subitizing of multiple salient objects", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Islam_Revisiting_Salient_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "904": {"title": "local descriptors optimized for average precision", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_Local_Descriptors_Optimized_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "700": {"title": "learning monocular 3d human pose estimation from multi-view images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rhodin_Learning_Monocular_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "836": {"title": "salience guided depth calibration for perceptually optimized compressive light field 3d display", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Salience_Guided_Depth_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "207": {"title": "attend and interact: higher-order object interactions for video understanding", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ma_Attend_and_Interact_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "402": {"title": "first-person hand action benchmark with rgb-d videos and 3d hand pose annotations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Garcia-Hernando_First-Person_Hand_Action_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "467": {"title": "don't just assume; look and answer: overcoming priors for visual question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Agrawal_Dont_Just_Assume_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "471": {"title": "person transfer gan to bridge domain gap for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Person_Transfer_GAN_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "612": {"title": "guided proofreading of automatic segmentations for connectomics", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Haehn_Guided_Proofreading_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "770": {"title": "making convolutional networks recurrent for visual sequence learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Making_Convolutional_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "921": {"title": "low-shot learning with imprinted weights", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Low-Shot_Learning_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "376": {"title": "geometry-aware scene text detection with instance transformation network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Geometry-Aware_Scene_Text_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "156": {"title": "independently recurrent neural network (indrnn): building a longer and deeper rnn", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Independently_Recurrent_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "646": {"title": "single image dehazing via conditional generative adversarial network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Single_Image_Dehazing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "938": {"title": "deep back-projection networks for super-resolution", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Haris_Deep_Back-Projection_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "186": {"title": "attention clusters: purely attention based local feature integration for video classification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Long_Attention_Clusters_Purely_CVPR_2018_paper.html", "abstract": "Recently, substantial research effort has focused on how to apply CNNs or RNNs to better capture tem\nporal patterns in videos, so as to improve the accuracy of video classification. In this paper, howe\nver, we show that temporal information, especially longer-term patterns, may not be necessary to ach\nieve competitive results on common trimmed video classification datasets. We investigate the potenti\nal of a purely attention based local feature integration. Accounting for the characteristics of such\n features in video classification, we propose a local feature integration framework based on attenti\non clusters, and introduce a shifting operation to capture more diverse signals. We carefully analyz\ne and compare the effect of different attention mechanisms, cluster sizes, and the use of the shifti\nng operation, and also investigate the combination of attention clusters for multimodal integration.\n We demonstrate the effectiveness of our framework on three real-world video classification datasets\n. Our model achieves competitive results across all of these. In particular, on the large-scale Kine\ntics dataset, our framework obtains an excellent single model accuracy of 79.4% in terms of the top-\n1 and 94.0% in terms of the top-5 accuracy on the validation set.", "cite_num": 30}, "601": {"title": "accurate and diverse sampling of sequences based on a \u201cbest of many\u201d sample objective", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bhattacharyya_Accurate_and_Diverse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "919": {"title": "learning superpixels with segmentation-aware affinity loss", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tu_Learning_Superpixels_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "303": {"title": "structured set matching networks for one-shot part labeling", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Choi_Structured_Set_Matching_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "367": {"title": "deepmvs: learning multi-view stereopsis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_DeepMVS_Learning_Multi-View_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "863": {"title": "attentional shapecontextnet for point cloud recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xie_Attentional_ShapeContextNet_for_CVPR_2018_paper.html", "abstract": "We tackle the problem of point cloud recognition. Unlike previous approaches where a point cloud is \neither converted into a volume/image or represented independently in a permutation-invariant set, we\n develop a new representation by adopting the concept of shape context as the building block in our \nnetwork design. The resulting model, called ShapeContextNet, consists of a hierarchy with modules no\nt relying on a fixed grid while still enjoying properties similar to those in convolutional neural n\networks - being able to capture and propagate the object part information. In addition, we find insp\niration from self-attention based models to include a simple yet effective contextual modeling mecha\nnism - making the contextual region selection, the feature aggregation, and the feature transformati\non process fully automatic. ShapeContextNet is an end-to-end model that can be applied to the genera\nl point cloud classification and segmentation problems. We observe competitive results on a number o\nf benchmark datasets.", "cite_num": 16}, "580": {"title": "geometric multi-model fitting with a convex relaxation algorithm", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Amayo_Geometric_Multi-Model_Fitting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "227": {"title": "pose: pseudo object space error for initialization-free bundle adjustment", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hong_pOSE_Pseudo_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "14": {"title": "deep cauchy hashing for hamming space retrieval", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Deep_Cauchy_Hashing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "47": {"title": "geometry-aware deep network for single-image novel view synthesis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Geometry-Aware_Deep_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "497": {"title": "layoutnet: reconstructing the 3d room layout from a single rgb image", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zou_LayoutNet_Reconstructing_the_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "439": {"title": "inversefacenet: deep monocular inverse face rendering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_InverseFaceNet_Deep_Monocular_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "540": {"title": "optical flow guided feature: a fast and robust motion representation for video action recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Optical_Flow_Guided_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "129": {"title": "gated fusion network for single image dehazing", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ren_Gated_Fusion_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "120": {"title": "bidirectional attentive fusion with context gating for dense video captioning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Bidirectional_Attentive_Fusion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "560": {"title": "splatnet: sparse lattice networks for point cloud processing", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Su_SPLATNet_Sparse_Lattice_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "436": {"title": "probabilistic plant modeling via multi-view image-to-image translation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Isokane_Probabilistic_Plant_Modeling_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "19": {"title": "learning attentions: residual attentional siamese network for high performance online visual tracking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Learning_Attentions_Residual_CVPR_2018_paper.html", "abstract": "Offline training for object tracking has recently shown great potentials in balancing tracking accur\nacy and speed. However, it is still difficult to adapt an offline trained model to a target tracked \nonline. This work presents a Residual Attentional Siamese Network (RASNet) for high performance obje\nct tracking. The RASNet model reformulates the correlation filter within a Siamese tracking framewor\nk, and introduces different kinds of the attention mechanisms to adapt the model without updating th\ne model online. In particular, by exploiting the offline trained general attention, the target adapt\ned residual attention, and the channel favored feature attention, the RASNet not only mitigates the \nover-fitting problem in deep network training, but also enhances its discriminative capacity and ada\nptability due to the separation of representation learning and discriminator learning. The proposed \ndeep architecture is trained from end to end and takes full advantage of the rich spatial temporal i\nnformation to achieve robust visual tracking. Experimental results on two latest benchmarks, OTB-201\n5 and VOT2017, show that the RASNet tracker has the state-of-the-art tracking accuracy while runs at\n more than 80 frames per second.", "cite_num": -1}, "965": {"title": "customized image narrative generation via interactive visual question generation and answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shin_Customized_Image_Narrative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "299": {"title": "look, imagine and match: improving textual-visual cross-modal retrieval with generative models", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gu_Look_Imagine_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "802": {"title": "total capture: a 3d deformation model for tracking faces, hands, and bodies", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Joo_Total_Capture_A_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "844": {"title": "hashing as tie-aware learning to rank", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_Hashing_as_Tie-Aware_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "154": {"title": "learning deep descriptors with scale-aware triplet networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Keller_Learning_Deep_Descriptors_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "432": {"title": "learning semantic concepts and order for image and sentence matching", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Learning_Semantic_Concepts_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "647": {"title": "monet: moments embedding network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gou_MoNet_Moments_Embedding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "469": {"title": "weakly-supervised semantic segmentation network with deep seeded region growing", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Weakly-Supervised_Semantic_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "962": {"title": "frustum pointnets for 3d object detection from rgb-d data", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Frustum_PointNets_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "910": {"title": "recurrent saliency transformation network: incorporating multi-stage visual cues for small organ segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Recurrent_Saliency_Transformation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "456": {"title": "appearance-and-relation networks for video classification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Appearance-and-Relation_Networks_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "197": {"title": "compressed video action recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Compressed_Video_Action_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "476": {"title": "conditional probability models for deep image compression", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mentzer_Conditional_Probability_Models_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "963": {"title": "single-shot refinement neural network for object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Single-Shot_Refinement_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "658": {"title": "a minimalist approach to type-agnostic detection of quadrics in point clouds", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Birdal_A_Minimalist_Approach_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "755": {"title": "learning attribute representations with localization for flexible fashion search", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ak_Learning_Attribute_Representations_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "256": {"title": "multi-view consistency as supervisory signal for learning shape and pose prediction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tulsiani_Multi-View_Consistency_as_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "218": {"title": "unifying identification and context learning for person recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Unifying_Identification_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "78": {"title": "4dfab: a large scale 4d database for facial expression analysis and biometric applications", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_4DFAB_A_Large_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "732": {"title": "the power of ensembles for active learning in image classification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Beluch_The_Power_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "59": {"title": "towards effective low-bitwidth convolutional neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhuang_Towards_Effective_Low-Bitwidth_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "116": {"title": "re-weighted adversarial adaptation network for unsupervised domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Re-Weighted_Adversarial_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "136": {"title": "pyramid stereo matching network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_Pyramid_Stereo_Matching_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "861": {"title": "neural style transfer via meta networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Neural_Style_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "686": {"title": "modeling facial geometry using compositional vaes", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bagautdinov_Modeling_Facial_Geometry_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "385": {"title": "morphnet: fast & simple resource-constrained structure learning of deep networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gordon_MorphNet_Fast__CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "548": {"title": "a common framework for interactive texture transfer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Men_A_Common_Framework_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "714": {"title": "audio to body dynamics", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shlizerman_Audio_to_Body_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "809": {"title": "multi-oriented scene text detection via corner localization and region segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lyu_Multi-Oriented_Scene_Text_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "231": {"title": "mx-lstm: mixing tracklets and vislets to jointly forecast trajectories and head poses", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hasan_MX-LSTM_Mixing_Tracklets_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "285": {"title": "learning latent super-events to detect multiple activities in videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Piergiovanni_Learning_Latent_Super-Events_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "583": {"title": "denseaspp for semantic segmentation in street scenes", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "457": {"title": "aligning infinite-dimensional covariance matrices in reproducing kernel hilbert spaces for domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Aligning_Infinite-Dimensional_Covariance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "193": {"title": "pieapp: perceptual image-error assessment through pairwise preference", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Prashnani_PieAPP_Perceptual_Image-Error_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "704": {"title": "from source to target and back: symmetric bi-directional adaptive gan", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Russo_From_Source_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "739": {"title": "pwc-net: cnns for optical flow using pyramid, warping, and cost volume", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_PWC-Net_CNNs_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "166": {"title": "a causal and-or graph model for visibility fluent reasoning in tracking interacting objects", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_A_Causal_And-Or_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "262": {"title": "im2struct: recovering 3d shape structure from a single rgb image", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Niu_Im2Struct_Recovering_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "263": {"title": "a face-to-face neural conversation model", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chu_A_Face-to-Face_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "244": {"title": "generative adversarial image synthesis with decision tree latent controller", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kaneko_Generative_Adversarial_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "812": {"title": "learning markov clustering networks for scene text detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Learning_Markov_Clustering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "36": {"title": "trapping light for time of flight", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Trapping_Light_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "768": {"title": "nonlocal low-rank tensor factor analysis for image restoration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Nonlocal_Low-Rank_Tensor_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "648": {"title": "depth and transient imaging with compressive spad array cameras", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Depth_and_Transient_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "288": {"title": "tips and tricks for visual question answering: learnings from the 2017 challenge", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Teney_Tips_and_Tricks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "400": {"title": "densely connected pyramid dehazing network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Densely_Connected_Pyramid_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "102": {"title": "self-supervised feature learning by learning to spot artifacts", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jenni_Self-Supervised_Feature_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "339": {"title": "facial expression recognition by de-expression residue learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Facial_Expression_Recognition_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "737": {"title": "robust video content alignment and compensation for rain removal in a cnn framework", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Robust_Video_Content_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "800": {"title": "people, penguins and petri dishes: adapting object counting models to new visual domains and object types without forgetting", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Marsden_People_Penguins_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "569": {"title": "embodied question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Das_Embodied_Question_Answering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "752": {"title": "image collection pop-up: 3d reconstruction and clustering of rigid and non-rigid categories", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Agudo_Image_Collection_Pop-Up_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "764": {"title": "multi-task adversarial network for disentangled feature learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Multi-Task_Adversarial_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "103": {"title": "aon: towards arbitrarily-oriented text recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_AON_Towards_Arbitrarily-Oriented_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "821": {"title": "deformation aware image compression", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shaham_Deformation_Aware_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "386": {"title": "w2f: a weakly-supervised to fully-supervised framework for object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_W2F_A_Weakly-Supervised_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "357": {"title": "deblurgan: blind motion deblurring using conditional adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kupyn_DeblurGAN_Blind_Motion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "688": {"title": "learning compressible 360\u00b0 video isomers", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Su_Learning_Compressible_360deg_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "804": {"title": "a neural multi-sequence alignment technique (neumatch)", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dogan_A_Neural_Multi-Sequence_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "356": {"title": "ffnet: video fast-forwarding via reinforcement learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lan_FFNet_Video_Fast-Forwarding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "109": {"title": "a deeper look at power normalizations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Koniusz_A_Deeper_Look_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "71": {"title": "human-centric indoor scene synthesis using stochastic grammar", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Human-Centric_Indoor_Scene_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "181": {"title": "pulling actions out of context: explicit separation for effective combination", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Pulling_Actions_out_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "562": {"title": "context-aware deep feature compression for high-speed visual tracking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Choi_Context-Aware_Deep_Feature_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "160": {"title": "texturegan: controlling deep image synthesis with texture patches", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xian_TextureGAN_Controlling_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "875": {"title": "person re-identification with cascaded pairwise convolutions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Person_Re-Identification_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "127": {"title": "vision-and-language navigation: interpreting visually-grounded navigation instructions in real environments", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "225": {"title": "geometric robustness of deep networks: analysis and improvement", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kanbak_Geometric_Robustness_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "480": {"title": "wildtrack: a multi-camera hd dataset for dense unscripted pedestrian detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chavdarova_WILDTRACK_A_Multi-Camera_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "584": {"title": "demo2vec: reasoning object affordances from online videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fang_Demo2Vec_Reasoning_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "881": {"title": "improving occlusion and hard negative handling for single-stage pedestrian detectors", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Noh_Improving_Occlusion_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "670": {"title": "multi-level factorisation net for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_Multi-Level_Factorisation_Net_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "219": {"title": "geometry-aware learning of maps for camera localization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Brahmbhatt_Geometry-Aware_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "121": {"title": "learning descriptor networks for 3d shape synthesis and analysis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xie_Learning_Descriptor_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "590": {"title": "viewpoint-aware attentive multi-view inference for vehicle re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Viewpoint-Aware_Attentive_Multi-View_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "165": {"title": "stereoscopic neural style transfer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Stereoscopic_Neural_Style_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "494": {"title": "learning intelligent dialogs for bounding box annotation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Konyushkova_Learning_Intelligent_Dialogs_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "975": {"title": "trust your model: light field depth estimation with inline occlusion handling", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Schilling_Trust_Your_Model_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "825": {"title": "3d registration of curves and surfaces using local differential information", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Raposo_3D_Registration_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "742": {"title": "single-shot object detection with enriched semantics", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Single-Shot_Object_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "701": {"title": "multispectral image intrinsic decomposition via subspace constraint", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Multispectral_Image_Intrinsic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "150": {"title": "adadepth: unsupervised content congruent adaptation for depth estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kundu_AdaDepth_Unsupervised_content_cvpr_2018_paper.html", "abstract": "", "cite_num": -1}, "794": {"title": "easy identification from better constraints: multi-shot person re-identification from reference constraints", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Easy_Identification_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "158": {"title": "geonet: unsupervised learning of dense depth, optical flow and camera pose", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yin_GeoNet_Unsupervised_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "290": {"title": "tienet: text-image embedding network for common thorax disease classification and reporting in chest x-rays", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_TieNet_Text-Image_Embedding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "79": {"title": "multi-task learning using uncertainty to weigh losses for scene geometry and semantics", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "846": {"title": "a two-step disentanglement method", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hadad_A_Two-Step_Disentanglement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "864": {"title": "towards pose invariant face recognition in the wild", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Towards_Pose_Invariant_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "245": {"title": "domain adaptive faster r-cnn for object detection in the wild", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Domain_Adaptive_Faster_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "575": {"title": "learning to parse wireframes in images of man-made environments", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Learning_to_Parse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "512": {"title": "good view hunting: learning photo composition from dense view pairs", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Good_View_Hunting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "913": {"title": "reward learning from narrated demonstrations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tung_Reward_Learning_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "692": {"title": "camera style adaptation for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhong_Camera_Style_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "925": {"title": "inference in higher order mrf-map problems with small and large cliques", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shanu_Inference_in_Higher_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "527": {"title": "occluded pedestrian detection through guided attention in cnns", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Occluded_Pedestrian_Detection_CVPR_2018_paper.html", "abstract": "Pedestrian detection has progressed significantly in the last years. However, occluded people are no\ntoriously hard to detect, as their appearance varies substantially depending on a wide range of occl\nusion patterns. In this paper, we aim to propose a simple and compact method based on the FasterRCNN\n architecture for occluded pedestrian detection. We start with interpreting CNN channel features of \na pedestrian detector, and we find that different channels activate responses for different body par\nts respectively. These findings motivate us to employ an attention mechanism across channels to repr\nesent various occlusion patterns in one single model, as each occlusion pattern can be formulated as\n some specific combination of body parts. Therefore, an attention network with self or external guid\nances is proposed as an add-on to the baseline FasterRCNN detector. When evaluating on the heavy occ\nlusion subset, we achieve a significant improvement of 8pp to the baseline FasterRCNN detector on Ci\ntyPersons and on Caltech we outperform the state-of-the-art method by 4pp.", "cite_num": 24}, "656": {"title": "large scale fine-grained categorization and domain-specific transfer learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "9": {"title": "jointly localizing and describing events for dense video captioning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Jointly_Localizing_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "697": {"title": "vital: visual tracking via adversarial learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_VITAL_VIsual_Tracking_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "85": {"title": "pu-net: point cloud upsampling network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_PU-Net_Point_Cloud_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "397": {"title": "self-supervised multi-level face model learning for monocular reconstruction at over 250 hz", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tewari_Self-Supervised_Multi-Level_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "537": {"title": "baseline desensitizing in translation averaging", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhuang_Baseline_Desensitizing_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "690": {"title": "learning structure and strength of cnn filters for small sample size training", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Keshari_Learning_Structure_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "508": {"title": "cvm-net: cross-view matching network for image-based ground-to-aerial geo-localization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_CVM-Net_Cross-View_Matching_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "880": {"title": "pose-guided photorealistic face rotation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Pose-Guided_Photorealistic_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "29": {"title": "deep cocktail network: multi-source unsupervised domain adaptation with category shift", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Deep_Cocktail_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "23": {"title": "robust facial landmark detection via a fully-convolutional local-global context network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Merget_Robust_Facial_Landmark_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "94": {"title": "feature quantization for defending against distortion of images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Feature_Quantization_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "91": {"title": "direct shape regression networks for end-to-end face alignment", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Miao_Direct_Shape_Regression_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "775": {"title": "continuous relaxation of map inference: a nonconvex perspective", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Le-Huu_Continuous_Relaxation_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "326": {"title": "progressively complementarity-aware fusion network for rgb-d salient object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Progressively_Complementarity-Aware_Fusion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "745": {"title": "weakly and semi supervised human body part parsing via pose-guided knowledge transfer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fang_Weakly_and_Semi_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "148": {"title": "photographic text-to-image synthesis with a hierarchically-nested adversarial network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Photographic_Text-to-Image_Synthesis_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "33": {"title": "link and code: fast indexing with graphs and compact regression codes", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Douze_Link_and_Code_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "185": {"title": "adversarial feature augmentation for unsupervised domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Volpi_Adversarial_Feature_Augmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "722": {"title": "net2vec: quantifying and explaining how concepts are encoded by filters in deep neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fong_Net2Vec_Quantifying_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "321": {"title": "repulsion loss: detecting pedestrians in a crowd", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Repulsion_Loss_Detecting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "746": {"title": "codeslam \u2014 learning a compact, optimisable representation for dense visual slam", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bloesch_CodeSLAM_--_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "577": {"title": "on the importance of label quality for semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zlateski_On_the_Importance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "239": {"title": "statistical tomography of microscopic life", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Levis_Statistical_Tomography_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "715": {"title": "zero-shot kernel learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Zero-Shot_Kernel_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "593": {"title": "efficient interactive annotation of segmentation datasets with polygon-rnn++", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Acuna_Efficient_Interactive_Annotation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "347": {"title": "factoring shape, pose, and layout from the 2d image of a 3d scene", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tulsiani_Factoring_Shape_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "959": {"title": "bootstrapping the performance of webly supervised semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Bootstrapping_the_Performance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "32": {"title": "matryoshka networks: predicting 3d geometry via nested shape layers", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Richter_Matryoshka_Networks_Predicting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "279": {"title": "zigzag learning for weakly supervised object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Zigzag_Learning_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "234": {"title": "the lov\u00e1sz-softmax loss: a tractable surrogate for the optimization of the intersection-over-union measure in neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Berman_The_LovaSz-Softmax_Loss_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "390": {"title": "raynet: learning volumetric 3d reconstruction with ray potentials", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Paschalidou_RayNet_Learning_Volumetric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "973": {"title": "docunet: document image unwarping via a stacked u-net", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ma_DocUNet_Document_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "640": {"title": "dvqa: understanding data visualizations via question answering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kafle_DVQA_Understanding_Data_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "458": {"title": "frame-recurrent video super-resolution", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sajjadi_Frame-Recurrent_Video_Super-Resolution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "325": {"title": "cascade r-cnn: delving into high quality object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cai_Cascade_R-CNN_Delving_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "682": {"title": "\u201clearning-compression\u201d algorithms for neural net pruning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Carreira-Perpinan_Learning-Compression_Algorithms_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "138": {"title": "tell me where to look: guided attention inference network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Tell_Me_Where_CVPR_2018_paper.html", "abstract": "Weakly supervised learning with only coarse labels can obtain visual explanations of deep neural net\nwork such as attention maps by back-propagating gradients. These attention maps are then available a\ns priors for tasks such as object localization and semantic segmentation. In one common framework we\n address three shortcomings of previous approaches in modeling such attention maps: We (1) first tim\ne make attention maps an explicit and natural component of the end-to-end training, (2) provide self\n-guidance directly on these maps by exploring supervision form the network itself to improve them, a\nnd (3) seamlessly bridge the gap between using weak and extra supervision if available. Despite its \nsimplicity, experiments on the semantic segmentation task demonstrate the effectiveness of our metho\nds. We clearly surpass the state-of-the-art on Pascal VOC 2012 val. and test set. Besides, the propo\nsed framework provides a way not only explaining the focus of the learner but also feeding back with\n direct guidance towards specific tasks. Under mild assumptions our method can also be understood as\n a plug-in to existing weakly supervised learners to improve their generalization performance.", "cite_num": 21}, "51": {"title": "improving color reproduction accuracy on cameras", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Karaimer_Improving_Color_Reproduction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "918": {"title": "fine-grained video captioning for sports narrative", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Fine-Grained_Video_Captioning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "42": {"title": "gagan: geometry-aware generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kossaifi_GAGAN_Geometry-Aware_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "627": {"title": "an efficient and provable approach for mixture proportion estimation using linear independence assumption", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_An_Efficient_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "833": {"title": "deep material-aware cross-spectral stereo matching", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhi_Deep_Material-Aware_Cross-Spectral_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "134": {"title": "deep adversarial subspace clustering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Deep_Adversarial_Subspace_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "733": {"title": "long-term on-board prediction of people in traffic scenes under uncertainty", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bhattacharyya_Long-Term_On-Board_Prediction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "296": {"title": "multiple granularity group interaction prediction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yao_Multiple_Granularity_Group_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "168": {"title": "controllable video generation with sparse trajectories", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hao_Controllable_Video_Generation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "559": {"title": "dynamic few-shot visual learning without forgetting", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gidaris_Dynamic_Few-Shot_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "25": {"title": "diversenet: when one right answer is not enough", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Firman_DiverseNet_When_One_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "377": {"title": "unsupervised person image synthesis in arbitrary poses", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pumarola_Unsupervised_Person_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "570": {"title": "weakly-supervised deep convolutional neural network learning for facial action unit intensity estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Weakly-Supervised_Deep_Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "338": {"title": "ava: a video dataset of spatio-temporally localized atomic visual actions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gu_AVA_A_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "613": {"title": "textbook question answering under instructor guidance with memory networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Textbook_Question_Answering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "691": {"title": "clusternet: detecting small objects in large scenes by exploiting spatio-temporal information", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/LaLonde_ClusterNet_Detecting_Small_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "172": {"title": "viewpoint-aware video summarization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kanehira_Viewpoint-Aware_Video_Summarization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "228": {"title": "multi-label zero-shot learning with structured knowledge graphs", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_Multi-Label_Zero-Shot_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "10": {"title": "lightweight probabilistic deep networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gast_Lightweight_Probabilistic_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "6": {"title": "robust classification with convolutional prototype learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Robust_Classification_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "831": {"title": "attentive generative adversarial network for raindrop removal from a single image", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qian_Attentive_Generative_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "61": {"title": "high-speed tracking with multi-kernel correlation filters", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tang_High-Speed_Tracking_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "797": {"title": "objects as context for detecting their semantic parts", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gonzalez-Garcia_Objects_as_Context_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "22": {"title": "self-supervised learning of geometrically stable features through probabilistic introspection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Novotny_Self-Supervised_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "872": {"title": "kernelized subspace pooling for deep local descriptors", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Kernelized_Subspace_Pooling_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "478": {"title": "robust hough transform based 3d reconstruction from circular light fields", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vianello_Robust_Hough_Transform_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "295": {"title": "mattnet: modular attention network for referring expression comprehension", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_MAttNet_Modular_Attention_CVPR_2018_paper.html", "abstract": "In this paper, we address referring expression comprehension: localizing an image region described b\ny a natural language expression. While most recent work treats expressions as a single unit, we prop\nose to decompose them into three modular components related to subject appearance, location, and rel\nationship to other objects. This allows us to flexibly adapt to expressions containing different typ\nes of information in an end-to-end framework. In our model, which we call the Modular Attention Netw\nork (MAttNet), two types of attention are utilized: language-based attention that learns the module \nweights as well as the word/phrase attention that each module should focus on; and visual attention \nthat allows the subject and relationship modules to focus on relevant image components. Module weigh\nts combine scores from all three modules dynamically to output an overall score. Experiments show th\nat MAttNet outperforms previous state-of-art methods by a large margin on both bounding-box-level an\nd pixel-level comprehension tasks.", "cite_num": 23}, "381": {"title": "high-resolution image synthesis and semantic manipulation with conditional gans", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_High-Resolution_Image_Synthesis_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "92": {"title": "deep semantic face deblurring", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Semantic_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "473": {"title": "learning patch reconstructability for accelerating multi-view stereo", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Poms_Learning_Patch_Reconstructability_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "179": {"title": "camera pose estimation with unknown principal point", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Larsson_Camera_Pose_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "968": {"title": "revisiting dilated convolution: a simple approach for weakly- and semi-supervised semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Revisiting_Dilated_Convolution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "614": {"title": "zoom and learn: generalizing deep stereo matching to novel domains", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pang_Zoom_and_Learn_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "167": {"title": "large-scale distance metric learning with uncertainty", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qian_Large-Scale_Distance_Metric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "80": {"title": "single-image depth estimation based on fourier domain analysis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_Single-Image_Depth_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "44": {"title": "recurrent pixel embedding for instance grouping", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kong_Recurrent_Pixel_Embedding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "173": {"title": "weakly-supervised semantic segmentation by iteratively mining common object features", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Weakly-Supervised_Semantic_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "15": {"title": "joint optimization framework for learning with noisy labels", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tanaka_Joint_Optimization_Framework_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "170": {"title": "exploring disentangled feature representation beyond face identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Exploring_Disentangled_Feature_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "813": {"title": "zero-shot visual recognition using semantics-preserving adversarial embedding networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Zero-Shot_Visual_Recognition_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "382": {"title": "weakly-supervised action segmentation with iterative soft boundary assignment", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ding_Weakly-Supervised_Action_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "725": {"title": "learning depth from monocular videos using direct methods", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Learning_Depth_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "118": {"title": "content-sensitive supervoxels via uniform tessellations on video manifolds", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yi_Content-Sensitive_Supervoxels_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "272": {"title": "local and global optimization techniques in graph-based clustering", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ikami_Local_and_Global_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "348": {"title": "efficient large-scale approximate nearest neighbor search on opencl fpga", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Efficient_Large-Scale_Approximate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "30": {"title": "fast spectral ranking for similarity search", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Iscen_Fast_Spectral_Ranking_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "54": {"title": "a memory network approach for story-based temporal summarization of 360\u00b0 videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_A_Memory_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "868": {"title": "two-stream convolutional networks for dynamic texture synthesis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tesfaldet_Two-Stream_Convolutional_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "930": {"title": "monocular 3d pose and shape estimation of multiple people in natural scenes - the importance of multiple scene constraints", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zanfir_Monocular_3D_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "542": {"title": "learning to compare: relation network for few-shot learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sung_Learning_to_Compare_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "27": {"title": "interleaved structured sparse convolutional neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xie_Interleaved_Structured_Sparse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "151": {"title": "seeing voices and hearing faces: cross-modal biometric matching", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nagrani_Seeing_Voices_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "743": {"title": "single image reflection separation with perceptual losses", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Single_Image_Reflection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "582": {"title": "the best of both worlds: combining cnns and geometric constraints for hierarchical motion segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bideau_The_Best_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "978": {"title": "adversarial data programming: using gans to relax the bottleneck of curated labeled data", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pal_Adversarial_Data_Programming_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "371": {"title": "on the convergence of patchmatch and its variants", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ehret_On_the_Convergence_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "684": {"title": "categorizing concepts with basic level for vision-to-language", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Categorizing_Concepts_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "16": {"title": "visual question answering with memory-augmented networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ma_Visual_Question_Answering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "115": {"title": "alive caricature from 2d to 3d", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Alive_Caricature_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "885": {"title": "learning generative convnets via multi-grid modeling and sampling", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gao_Learning_Generative_ConvNets_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "520": {"title": "every smile is unique: landmark-guided diverse smile generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Every_Smile_Is_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "696": {"title": "rolling shutter and radial distortion are features for high frame rate multi-camera tracking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bapat_Rolling_Shutter_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "187": {"title": "the perception-distortion tradeoff", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Blau_The_Perception-Distortion_Tradeoff_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "641": {"title": "deep adversarial metric learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Duan_Deep_Adversarial_Metric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "492": {"title": "wide compression: tensor ring nets", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Wide_Compression_Tensor_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "554": {"title": "generalized zero-shot learning via synthesized examples", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Verma_Generalized_Zero-Shot_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "490": {"title": "revisiting deep intrinsic image decompositions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fan_Revisiting_Deep_Intrinsic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "564": {"title": "leveraging unlabeled data for crowd counting by learning to rank", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Leveraging_Unlabeled_Data_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "69": {"title": "stochastic variational inference with gradient linearization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Plotz_Stochastic_Variational_Inference_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "855": {"title": "normalized cut loss for weakly-supervised cnn segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tang_Normalized_Cut_Loss_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "434": {"title": "defocus blur detection via multi-stream bottom-top-bottom fully convolutional network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Defocus_Blur_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "632": {"title": "deep sparse coding for invariant multimodal halle berry neurons", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_Deep_Sparse_Coding_CVPR_2018_paper.html", "abstract": "Deep feed-forward convolutional neural networks (CNNs) have become ubiquitous in virtually all machi\nne learning and computer vision challenges; however, advancements in CNNs have arguably reached an e\nngineering saturation point where incremental novelty results in minor performance gains. Although t\nhere is evidence that object classification has reached human levels on narrowly defined tasks, for \ngeneral applications, the biological visual system is far superior to that of any computer. Research\n reveals there are numerous missing components in feed-forward deep neural networks that are critica\nl in mammalian vision. The brain does not work solely in a feed-forward fashion, but rather all of t\nhe neurons are in competition with each other; neurons are integrating information in a bottom up an\nd top down fashion and incorporating expectation and feedback in the modeling process. Furthermore, \nour visual cortex is working in tandem with our parietal lobe, integrating sensory information from \nvarious modalities.", "cite_num": 0}, "75": {"title": "visual to sound: generating natural sound for videos in the wild", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Visual_to_Sound_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "897": {"title": "cube padding for weakly-supervised saliency prediction in 360\u00b0 videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_Cube_Padding_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "740": {"title": "learning to detect features in texture images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Learning_to_Detect_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "135": {"title": "context encoding for semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Context_Encoding_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "784": {"title": "cartoongan: generative adversarial networks for photo cartoonization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "26": {"title": "nag: network for adversary generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mopuri_NAG_Network_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "574": {"title": "learning to find good correspondences", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yi_Learning_to_Find_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "62": {"title": "polarimetric dense monocular slam", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Polarimetric_Dense_Monocular_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "744": {"title": "jointly optimize data augmentation and network training: adversarial data augmentation in human pose estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Peng_Jointly_Optimize_Data_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "525": {"title": "efficient, sparse representation of manifold distance matrices for classical scaling", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Turek_Efficient_Sparse_Representation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "213": {"title": "document enhancement using visibility detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kligler_Document_Enhancement_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "602": {"title": "variational autoencoders for deforming 3d mesh models", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tan_Variational_Autoencoders_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "435": {"title": "dynamic zoom-in network for fast object detection in large images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gao_Dynamic_Zoom-In_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "265": {"title": "conditional image-to-image translation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_Conditional_Image-to-Image_Translation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "866": {"title": "label denoising adversarial network (ldan) for inverse lighting of faces", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Label_Denoising_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "720": {"title": "data distillation: towards omni-supervised learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Radosavovic_Data_Distillation_Towards_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "247": {"title": "path aggregation network for instance segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Path_Aggregation_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "180": {"title": "im2flow: motion hallucination from static images for action recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gao_Im2Flow_Motion_Hallucination_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "183": {"title": "importance weighted adversarial nets for partial domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Importance_Weighted_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "936": {"title": "avatar-net: multi-scale zero-shot style transfer by feature decoration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "343": {"title": "semi-parametric image synthesis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Semi-Parametric_Image_Synthesis_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "801": {"title": "learning time/memory-efficient deep architectures with budgeted super networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Veniat_Learning_TimeMemory-Efficient_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "489": {"title": "xunit: learning a spatial activation function for efficient image restoration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kligvasser_xUnit_Learning_a_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "759": {"title": "learning pixel-level semantic affinity with image-level supervision for weakly supervised semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ahn_Learning_Pixel-Level_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "642": {"title": "future person localization in first-person videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yagi_Future_Person_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "674": {"title": "memory matching networks for one-shot image recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cai_Memory_Matching_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "960": {"title": "image super-resolution via dual-state recurrent networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Han_Image_Super-Resolution_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "214": {"title": "augmented skeleton space transfer for depth-based hand pose estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baek_Augmented_Skeleton_Space_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "37": {"title": "real-time rotation-invariant face detection with progressive calibration networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shi_Real-Time_Rotation-Invariant_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "184": {"title": "practical block-wise neural network architecture generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhong_Practical_Block-Wise_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "384": {"title": "seednet: automatic seed generation with deep reinforcement learning for robust interactive segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_SeedNet_Automatic_Seed_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "222": {"title": "learning by asking questions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Misra_Learning_by_Asking_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "765": {"title": "creating capsule wardrobes from fashion images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hsiao_Creating_Capsule_Wardrobes_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "563": {"title": "a closer look at spatiotemporal convolutions for action recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tran_A_Closer_Look_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "782": {"title": "virtualhome: simulating household activities via programs", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Puig_VirtualHome_Simulating_Household_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "464": {"title": "attentive fashion grammar network for fashion landmark detection and clothing category classification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Attentive_Fashion_Grammar_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "161": {"title": "group consistent similarity learning via deep crf for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Group_Consistent_Similarity_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "354": {"title": "moviegraphs: towards understanding human-centric situations from videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vicol_MovieGraphs_Towards_Understanding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "49": {"title": "emotional attention: a study of image sentiment and visual attention", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fan_Emotional_Attention_A_CVPR_2018_paper.html", "abstract": "Image sentiment influences visual perception. Emotion-eliciting stimuli such as happy faces and pois\nonous snakes are generally prioritized in human attention. However, little research has evaluated th\ne interrelationships of image sentiment and visual saliency. In this paper, we present the first stu\ndy to focus on the relation between emotional properties of an image and visual attention. We first \ncreate the EMOtional attention dataset (EMOd). It is a diverse set of emotion-eliciting images, and \neach image has (1) eye-tracking data collected from 16 subjects, (2) intensive image context labels \nincluding object contour, object sentiment, object semantic category, and high-level perceptual attr\nibutes such as image aesthetics and elicited emotions. We perform extensive analyses on EMOd to iden\ntify how image sentiment relates to human attention. We discover an emotion prioritization effect: f\nor our images, emotion-eliciting content attracts human attention strongly, but such advantage dimin\nishes dramatically after initial fixation. Aiming to model the human emotion prioritization computat\nionally, we design a deep neural network for saliency prediction, which includes a novel subnetwork \nthat learns the spatial and semantic context of the image scene. The proposed network outperforms th\ne state-of-the-art on three benchmark datasets, by effectively capturing the relative importance of \nhuman attention within an image. The code, models, and dataset are available online at https://nus-s\nesame.top/emotionalattention/.", "cite_num": 1}, "428": {"title": "rotation-sensitive regression for oriented scene text detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liao_Rotation-Sensitive_Regression_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "65": {"title": "groupcap: group-based image captioning with structured relevance and diversity constraints", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_GroupCap_Group-Based_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "52": {"title": "anticipating traffic accidents with adaptive loss and large-scale incident db", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Suzuki_Anticipating_Traffic_Accidents_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "553": {"title": "a unifying contrast maximization framework for event cameras, with applications to motion, depth, and optical flow estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gallego_A_Unifying_Contrast_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "266": {"title": "taskonomy: disentangling task transfer learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zamir_Taskonomy_Disentangling_Task_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "291": {"title": "st-gan: spatial transformer generative adversarial networks for image compositing", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "902": {"title": "a high-quality denoising dataset for smartphone cameras", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Abdelhamed_A_High-Quality_Denoising_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "891": {"title": "discriminability objective for training descriptive captions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_Discriminability_Objective_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "468": {"title": "recurrent scene parsing with perspective understanding in the loop", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kong_Recurrent_Scene_Parsing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "958": {"title": "end-to-end dense video captioning with masked transformer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_End-to-End_Dense_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "522": {"title": "crowd counting via adversarial cross-scale consistency pursuit", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Crowd_Counting_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "767": {"title": "burst denoising with kernel prediction networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mildenhall_Burst_Denoising_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "511": {"title": "collaborative and adversarial network for unsupervised domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Collaborative_and_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "495": {"title": "multi-content gan for few-shot font style transfer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Azadi_Multi-Content_GAN_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "736": {"title": "posetrack: a benchmark for human pose estimation and tracking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Andriluka_PoseTrack_A_Benchmark_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "677": {"title": "compassionately conservative balanced cuts for image segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cahill_Compassionately_Conservative_Balanced_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "328": {"title": "scale-recurrent network for deep image deblurring", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tao_Scale-Recurrent_Network_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "242": {"title": "poseflow: a deep motion representation for understanding human behaviors in videos", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_PoseFlow_A_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "408": {"title": "quantization of fully convolutional networks for accurate biomedical image segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Quantization_of_Fully_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "915": {"title": "weakly supervised phrase localization with multi-scale anchored transformer network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Weakly_Supervised_Phrase_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "358": {"title": "harmonious attention network for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Harmonious_Attention_Network_CVPR_2018_paper.html", "abstract": "Existing person re-identification (re-id) methods either assume the availability of well-aligned per\nson bounding box images as model input or rely on constrained attention selection mechanisms to cali\nbrate misaligned images. They are therefore sub-optimal for re-id matching in arbitrarily aligned pe\nrson images potentially with large human pose variations and unconstrained auto-detection errors. In\n this work, we show the advantages of jointly learning attention selection and feature representatio\nn in a Convolutional Neural Network (CNN) by maximising the complementary information of different l\nevels of visual attention subject to re-id discriminative learning constraints. Specifically, we for\nmulate a novel Harmonious Attention CNN (HA-CNN) model for joint learning of soft pixel attention an\nd hard regional attention along with simultaneous optimisation of feature representations, dedicated\n to optimise person re-id in uncontrolled (misaligned) images. Extensive comparative evaluations val\nidate the superiority of this new HA-CNN model for person re-id over a wide variety of state-of-the-\nart methods on three large-scale benchmarks including CUHK03, Market-1501, and DukeMTMC-ReID.", "cite_num": 78}, "205": {"title": "non-blind deblurring: handling kernel uncertainty with cnns", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vasu_Non-Blind_Deblurring_Handling_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "396": {"title": "discovering point lights with intensity distance fields", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Discovering_Point_Lights_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "751": {"title": "robust depth estimation from auto bracketed images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Im_Robust_Depth_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "479": {"title": "single view stereo matching", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_Single_View_Stereo_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "45": {"title": "alternating-stereo vins: observability analysis and performance evaluation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Paul_Alternating-Stereo_VINS_Observability_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "204": {"title": "egocentric activity recognition on a budget", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Possas_Egocentric_Activity_Recognition_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "772": {"title": "ring loss: convex feature normalization for face recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zheng_Ring_Loss_Convex_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "233": {"title": "deep end-to-end time-of-flight imaging", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Su_Deep_End-to-End_Time-of-Flight_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "588": {"title": "unsupervised deep generative adversarial hashing network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dizaji_Unsupervised_Deep_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "625": {"title": "improved lossy image compression with priming and spatially adaptive bit rates for recurrent networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Johnston_Improved_Lossy_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "220": {"title": "geometry guided convolutional neural networks for self-supervised video representation learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gan_Geometry_Guided_Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "461": {"title": "pixels, voxels, and views: a study of shape representations for single view 3d object shape prediction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shin_Pixels_Voxels_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "132": {"title": "ldmnet: low dimensional manifold regularized neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_LDMNet_Low_Dimensional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "199": {"title": "self-calibrating polarising radiometric calibration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Teo_Self-Calibrating_Polarising_Radiometric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "862": {"title": "structured uncertainty prediction networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dorta_Structured_Uncertainty_Prediction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "896": {"title": "deflecting adversarial attacks with pixel deflection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Prakash_Deflecting_Adversarial_Attacks_CVPR_2018_paper.html", "abstract": "CNNs are poised to become integral parts of many critical systems. Despite their robustness to natur\nal variations, image pixel values can be manipulated, via small, carefully crafted, imperceptible pe\nrturbations, to cause a model to misclassify images. We present an algorithm to process an image so \nthat classification accuracy is significantly preserved in the presence of such adversarial manipula\ntions. Image classifiers tend to be robust to natural noise, and adversarial attacks tend to be agno\nstic to object location. These observations motivate our strategy, which leverages model robustness \nto defend against adversarial perturbations by forcing the image to match natural image statistics. \nOur algorithm locally corrupts the image by redistributing pixel values via a process we term pixel \ndeflection. A subsequent wavelet-based denoising operation softens this corruption, as well as some \nof the adversarial changes. We demonstrate experimentally that the combination of these techniques e\nnables the effective recovery of the true class, against a variety of robust attacks. Our results co\nmpare favorably with current state-of-the-art defenses, without requiring retraining or modifying th\ne CNN.", "cite_num": 0}, "417": {"title": "facelet-bank for fast portrait manipulation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Facelet-Bank_for_Fast_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "859": {"title": "detecting and recognizing human-object interactions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gkioxari_Detecting_and_Recognizing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "779": {"title": "dynamic feature learning for partial face recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_Dynamic_Feature_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "680": {"title": "learning globally optimized object detector via policy gradient", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rao_Learning_Globally_Optimized_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "849": {"title": "learning spatial-aware regressions for visual tracking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Learning_Spatial-Aware_Regressions_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "155": {"title": "duplex generative adversarial network for unsupervised domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Duplex_Generative_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "426": {"title": "min-entropy latent model for weakly supervised object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wan_Min-Entropy_Latent_Model_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "57": {"title": "indoor rgb-d compass from a single line and plane", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_Indoor_RGB-D_Compass_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "653": {"title": "cross-view image synthesis using conditional gans", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Regmi_Cross-View_Image_Synthesis_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "440": {"title": "non-local neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "660": {"title": "mocogan: decomposing motion and content for video generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tulyakov_MoCoGAN_Decomposing_Motion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "248": {"title": "deformable shape completion with graph convolutional autoencoders", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Litany_Deformable_Shape_Completion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "268": {"title": "structure preserving video prediction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Structure_Preserving_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "543": {"title": "learning deep sketch abstraction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Muhammad_Learning_Deep_Sketch_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "636": {"title": "revisiting video saliency: a large-scale benchmark and a new model", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Revisiting_Video_Saliency_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "340": {"title": "mapnet: an allocentric spatial memory for mapping environments", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Henriques_MapNet_An_Allocentric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "957": {"title": "neural motifs: scene graph parsing with global context", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zellers_Neural_Motifs_Scene_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "893": {"title": "disentangling structure and aesthetics for style-aware image completion", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gilbert_Disentangling_Structure_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "13": {"title": "dimensionality's blessing: clustering images by underlying distribution", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_Dimensionalitys_Blessing_Clustering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "566": {"title": "focus manipulation detection via photometric histogram analysis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Focus_Manipulation_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "277": {"title": "cleannet: transfer learning for scalable image classifier training with label noise", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_CleanNet_Transfer_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "834": {"title": "the unreasonable effectiveness of deep features as a perceptual metric", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_The_Unreasonable_Effectiveness_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "342": {"title": "knowledge aided consistency for weakly supervised phrase grounding", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Knowledge_Aided_Consistency_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "934": {"title": "deep photo enhancer: unpaired learning for image enhancement from photographs with gans", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Deep_Photo_Enhancer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "805": {"title": "detach and adapt: learning cross-domain disentangled deep representation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Detach_and_Adapt_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "724": {"title": "da-gan: instance-level image translation by deep attention generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ma_DA-GAN_Instance-Level_Image_CVPR_2018_paper.html", "abstract": "Unsupervised image translation, which aims in translating two independent sets of images, is challen\nging in discovering the correct correspondences without paired data. Existing works build upon Gener\native Adversarial Networks (GANs) such that the distribution of the translated images are indistingu\nishable from the distribution of the target set. However, such set-level constraints cannot learn th\ne instance-level correspondences (e.g. aligned semantic parts in object transfiguration task). This \nlimitation often results in false positives (e.g. geometric or semantic artifacts), and further lead\ns to mode collapse problem. To address the above issues, we propose a novel framework for instance-l\nevel image translation by Deep Attention GAN (DA-GAN). Such a design enables DA-GAN to decompose the\n task of translating samples from two sets into translating instances in a highly-structured latent \nspace. Specifically, we jointly learn a deep attention encoder, and the instance-level correspondenc\nes could be consequently discovered through attending on the learned instances. Therefore, the const\nraints could be exploited on both set-level and instance-level. Comparisons against several state-of\n-the-arts demonstrate the superiority of our approach, and the broad application capability, e.g, po\nse morphing, data augmentation, etc., pushes the margin of domain translation problem.1", "cite_num": -1}, "788": {"title": "learning to generate time-lapse videos using multi-stage dynamic generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xiong_Learning_to_Generate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "500": {"title": "real-time seamless single shot 6d object pose prediction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tekin_Real-Time_Seamless_Single_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "83": {"title": "unsupervised cross-dataset person re-identification by transfer learning of spatial-temporal patterns", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lv_Unsupervised_Cross-Dataset_Person_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "940": {"title": "tagging like humans: diverse and distinct image annotation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Tagging_Like_Humans_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "455": {"title": "sobolevfusion: 3d reconstruction of scenes undergoing free non-rigid motion", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Slavcheva_SobolevFusion_3D_Reconstruction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "672": {"title": "human appearance transfer", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zanfir_Human_Appearance_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "12": {"title": "pix3d: dataset and methods for single-image 3d shape modeling", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Pix3D_Dataset_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "294": {"title": "learning less is more - 6d camera localization via 3d surface regression", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Brachmann_Learning_Less_Is_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "633": {"title": "who's better? who's best? pairwise deep ranking for skill determination", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Doughty_Whos_Better_Whos_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "604": {"title": "translating and segmenting multimodal medical volumes with cycle- and shape-consistency generative adversarial network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Translating_and_Segmenting_CVPR_2018_paper.html", "abstract": "Synthesized medical images have several important applications, e.g., as an intermedium in cross-mod\nality image registration and as supplementary training samples to boost the generalization capabilit\ny of a classifier. Especially, synthesized computed tomography (CT) data can provide X-ray attenuati\non map for radiation therapy planning. In this work, we propose a generic cross-modality synthesis a\npproach with the following targets: 1) synthesizing realistic looking 3D images using unpaired train\ning data, 2) ensuring consistent anatomical structures, which could be changed by geometric distorti\non in cross-modality synthesis and 3) improving volume segmentation by using synthetic data for moda\nlities with limited training samples. We show that these goals can be achieved with an end-to-end 3D\n convolutional neural network (CNN) composed of mutually-beneficial generators and segmentors for im\nage synthesis and segmentation tasks. The generators are trained with an adversarial loss, a cycle-c\nonsistency loss, and also a shape-consistency loss, which is supervised by segmentors, to reduce the\n geometric distortion. From the segmentation view, the segmentors are boosted by synthetic data from\n generators in an online manner. Generators and segmentors prompt each other alternatively in an end\n-to-end training fashion. With extensive experiments on a dataset including a total of 4,496 CT and \nmagnetic resonance imaging (MRI) cardiovascular volumes, we show both tasks are beneficial to each o\nther and coupling these two tasks results in better performance than solving them exclusively.", "cite_num": 33}, "661": {"title": "fast monte-carlo localization on aerial vehicles using approximate continuous belief representations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dhawale_Fast_Monte-Carlo_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "634": {"title": "3d pose estimation and 3d model retrieval for objects in the wild", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Grabner_3D_Pose_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "255": {"title": "automatic 3d indoor scene modeling from single panorama", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Automatic_3D_Indoor_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "297": {"title": "hyperparameter optimization for tracking with continuous deep q-learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dong_Hyperparameter_Optimization_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "323": {"title": "connecting pixels to privacy and utility: automatic redaction of private information in images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Orekondy_Connecting_Pixels_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "465": {"title": "super slomo: high quality estimation of multiple intermediate frames for video interpolation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jiang_Super_SloMo_High_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "518": {"title": "image to image translation for domain adaptation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Murez_Image_to_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "93": {"title": "classifier learning with prior probabilities for facial action unit recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Classifier_Learning_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "300": {"title": "deep group-shuffling random walk for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Group-Shuffling_Random_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "810": {"title": "learning convolutional networks for content-weighted image compression", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Learning_Convolutional_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "944": {"title": "partially shared multi-task convolutional neural network with local constraint for face attribute learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Partially_Shared_Multi-Task_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "310": {"title": "boosting domain adaptation by discovering latent domains", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mancini_Boosting_Domain_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "824": {"title": "correlation tracking via joint discrimination and reliability learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Correlation_Tracking_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "360": {"title": "a2-rl: aesthetics aware reinforcement learning for image cropping", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_A2-RL_Aesthetics_Aware_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "730": {"title": "learning transferable architectures for scalable image recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zoph_Learning_Transferable_Architectures_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "619": {"title": "neural sign language translation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Camgoz_Neural_Sign_Language_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "3": {"title": "dense decoder shortcut connections for single-pass semantic segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bilinski_Dense_Decoder_Shortcut_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "865": {"title": "texture mapping for 3d reconstruction with rgb-d sensor", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fu_Texture_Mapping_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "832": {"title": "4d human body correspondences from panoramic depth maps", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_4D_Human_Body_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "460": {"title": "bilateral ordinal relevance multi-instance regression for facial action unit intensity estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Bilateral_Ordinal_Relevance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "617": {"title": "visual question reasoning on general dependency tree", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Visual_Question_Reasoning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "708": {"title": "efficient video object segmentation via network modulation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Efficient_Video_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "713": {"title": "clear: cumulative learning for one-shot one-class image recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kozerawski_CLEAR_Cumulative_LEARning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "599": {"title": "graphbit: bitwise interaction mining via deep reinforcement learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Duan_GraphBit_Bitwise_Interaction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "286": {"title": "hallucinated-iqa: no-reference image quality assessment via adversarial learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_Hallucinated-IQA_No-Reference_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "50": {"title": "iterative learning with open-set noisy labels", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Iterative_Learning_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "237": {"title": "unsupervised discovery of object landmarks as structural representations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Unsupervised_Discovery_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "597": {"title": "learning compact recurrent neural networks with block-term tensor decomposition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ye_Learning_Compact_Recurrent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "334": {"title": "scancomplete: large-scale scene completion and semantic segmentation for 3d scans", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dai_ScanComplete_Large-Scale_Scene_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "63": {"title": "efficient diverse ensemble for discriminative co-tracking", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Meshgi_Efficient_Diverse_Ensemble_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "976": {"title": "dota: a large-scale dataset for object detection in aerial images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xia_DOTA_A_Large-Scale_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "886": {"title": "towards universal representation for unseen action recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_Towards_Universal_Representation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "143": {"title": "analytic expressions for probabilistic moments of pl-dnn with gaussian input", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bibi_Analytic_Expressions_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "753": {"title": "viton: an image-based virtual try-on network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Han_VITON_An_Image-Based_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "412": {"title": "fast end-to-end trainable guided filter", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Fast_End-to-End_Trainable_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "558": {"title": "extreme 3d face reconstruction: seeing through occlusions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tran_Extreme_3D_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "208": {"title": "packnet: adding multiple tasks to a single network by iterative pruning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mallya_PackNet_Adding_Multiple_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "734": {"title": "wing loss for robust facial landmark localisation with convolutional neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Feng_Wing_Loss_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "850": {"title": "towards a mathematical understanding of the difficulty in learning with feedforward neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Towards_a_Mathematical_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "937": {"title": "unsupervised learning of monocular depth estimation and visual odometry with deep feature reconstruction", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhan_Unsupervised_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "516": {"title": "mining on manifolds: metric learning without labels", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Iscen_Mining_on_Manifolds_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "649": {"title": "in-place activated batchnorm for memory-optimized training of dnns", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bulo_In-Place_Activated_BatchNorm_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "513": {"title": "learning a single convolutional super-resolution network for multiple degradations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Learning_a_Single_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "551": {"title": "eye in-painting with exemplar generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dolhansky_Eye_In-Painting_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "364": {"title": "manifold learning in quotient spaces", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mehr_Manifold_Learning_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "948": {"title": "multi-frame quality enhancement for compressed video", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Multi-Frame_Quality_Enhancement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "900": {"title": "mask-guided contrastive attention model for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Mask-Guided_Contrastive_Attention_CVPR_2018_paper.html", "abstract": "Person Re-identification (ReID) is an important yet challenging task in computer vision. Due to the \ndiverse background clutters, variations on viewpoints and body poses, it is far from solved. How to \nextract discriminative and robust features invariant to background clutters is the core problem. In \nthis paper, we first introduce the binary segmentation masks to construct synthetic RGB-Mask pairs a\ns inputs, then we design a mask-guided contrastive attention model (MGCAM) to learn features separat\nely from the body and background regions. Moreover, we propose a novel region-level triplet loss to \nrestrain the features learnt from different regions, i.e., pulling the features from the full image \nand body region close, whereas pushing the features from backgrounds away. We may be the first one t\no successfully introduce the binary mask into person ReID task and the first one to propose region-l\nevel contrastive learning. We evaluate the proposed method on three public datasets, including MARS,\n Market-1501 and CUHK03. Extensive experimental results show that the proposed method is effective a\nnd achieves the state-of-the-art results. Mask and code will be released upon request.", "cite_num": 42}, "895": {"title": "scalable dense non-rigid structure-from-motion: a grassmannian perspective", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kumar_Scalable_Dense_Non-Rigid_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "345": {"title": "sos-rsc: a sum-of-squares polynomial approach to robustifying subspace clustering algorithms", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sznaier_SoS-RSC_A_Sum-of-Squares_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "190": {"title": "density-aware single image de-raining using a multi-stream dense network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Density-Aware_Single_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "600": {"title": "unsupervised learning and segmentation of complex activities from video", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sener_Unsupervised_Learning_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "890": {"title": "weakly supervised coupled networks for visual sentiment analysis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Weakly_Supervised_Coupled_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "654": {"title": "deformable gans for pose-based human image generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Siarohin_Deformable_GANs_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "651": {"title": "deep layer aggregation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Deep_Layer_Aggregation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "946": {"title": "curve reconstruction via the global statistics of natural curves", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Barnea_Curve_Reconstruction_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "615": {"title": "look at boundary: a boundary-aware face alignment algorithm", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Look_at_Boundary_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "107": {"title": "seeing temporal modulation of lights from standard cameras", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sakakibara_Seeing_Temporal_Modulation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "302": {"title": "uv-gan: adversarial facial uv map completion for pose-invariant face recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Deng_UV-GAN_Adversarial_Facial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "171": {"title": "view extrapolation of human body from a single image", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_View_Extrapolation_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "333": {"title": "iterative visual reasoning beyond convolutions", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Iterative_Visual_Reasoning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "308": {"title": "doublefusion: real-time capture of human performances with inner body shapes from a single depth sensor", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_DoubleFusion_Real-Time_Capture_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "510": {"title": "regularizing deep networks by modeling and predicting label structure", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mostajabi_Regularizing_Deep_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "932": {"title": "beyond trade-off: accelerate fcn-based face detector with higher accuracy", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Beyond_Trade-Off_Accelerate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "695": {"title": "ista-net: interpretable optimization-inspired deep network for image compressive sensing", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_ISTA-Net_Interpretable_Optimization-Inspired_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "827": {"title": "learning multi-instance enriched image representations via non-greedy ratio maximization of the l1-norm distances", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Learning_Multi-Instance_Enriched_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "909": {"title": "features for multi-target multi-camera tracking and re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ristani_Features_for_Multi-Target_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "411": {"title": "improvements to context based self-supervised learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mundhenk_Improvements_to_Context_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "579": {"title": "vizwiz grand challenge: answering visual questions from blind people", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gurari_VizWiz_Grand_Challenge_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "307": {"title": "an unsupervised learning model for deformable medical image registration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Balakrishnan_An_Unsupervised_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "174": {"title": "sint++: robust visual tracking via adversarial positive instance generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_SINT_Robust_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "366": {"title": "classification-driven dynamic image enhancement", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sharma_Classification-Driven_Dynamic_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "164": {"title": "anatomical priors in convolutional networks for unsupervised biomedical segmentation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dalca_Anatomical_Priors_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "89": {"title": "two-step quantization for low-bit neural networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Two-Step_Quantization_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "77": {"title": "deepvoting: a robust and explainable deep network for semantic part detection under partial occlusion", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_DeepVoting_A_Robust_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "760": {"title": "unsupervised textual grounding: linking words to image concepts", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yeh_Unsupervised_Textual_Grounding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "153": {"title": "image blind denoising with generative adversarial network based noise modeling", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Image_Blind_Denoising_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "953": {"title": "context-aware synthesis for video frame interpolation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Niklaus_Context-Aware_Synthesis_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "620": {"title": "discrete-continuous admm for transductive inference in higher-order mrfs", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Laude_Discrete-Continuous_ADMM_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "848": {"title": "clip-q: deep network compression learning by in-parallel pruning-quantization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tung_CLIP-Q_Deep_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "923": {"title": "universal denoising networks : a novel cnn architecture for image denoising", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lefkimmiatis_Universal_Denoising_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "972": {"title": "neuralnetwork-viterbi: a framework for weakly supervised video learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Richard_NeuralNetwork-Viterbi_A_Framework_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "374": {"title": "defense against universal adversarial perturbations", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Akhtar_Defense_Against_Universal_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "496": {"title": "feature generating networks for zero-shot learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xian_Feature_Generating_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "664": {"title": "generative image inpainting with contextual attention", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Generative_Image_Inpainting_CVPR_2018_paper.html", "abstract": "Recent deep learning based approaches have shown promising results on image inpainting for the chall\nenging task of filling in large missing regions in an image. These methods can generate visually pla\nusible image structures and textures, but often create distorted structures or blurry textures incon\nsistent with surrounding areas. This is mainly due to ineffectiveness of convolutional neural networ\nks in explicitly borrowing or copying information from distant spatial locations. On the other hand,\n traditional texture and patch synthesis approaches are particularly suitable when it needs to borro\nw textures from the surrounding regions. Motivated by these observations, we propose a new deep gene\nrative model-based approach which can not only synthesize novel image structures but also explicitly\n utilize surrounding image features as references during network training to make better predictions\n. The model is a feed-forward, fully convolutional neural network which can process images with mult\niple holes at arbitrary locations and with variable sizes during the test time. Experiments on multi\nple datasets including faces, textures and natural images demonstrate that the proposed approach gen\nerates higher-quality inpainting results than existing ones. Code and trained models will be release\nd.", "cite_num": 81}, "546": {"title": "disentangled person image generation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ma_Disentangled_Person_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "229": {"title": "end-to-end deep kronecker-product matching for person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_End-to-End_Deep_Kronecker-Product_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "791": {"title": "dynamic video segmentation network", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Dynamic_Video_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "416": {"title": "deep diffeomorphic transformer networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Detlefsen_Deep_Diffeomorphic_Transformer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "188": {"title": "m3: multimodal memory modelling for video captioning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_M3_Multimodal_Memory_CVPR_2018_paper.html", "abstract": "Video captioning which automatically translates video clips into natural language sentences is a ver\ny important task in computer vision. By virtue of recent deep learning technologies, video captionin\ng has made great progress. However, learning an effective mapping from the visual sequence space to \nthe language space is still a challenging problem due to the long-term multimodal dependency modelli\nng and semantic misalignment. Inspired by the facts that memory modelling poses potential advantages\n to long-term sequential problems [35] and working memory is the key factor of visual attention [33]\n, we propose a Multimodal Memory Model (M3) to describe videos, which builds a visual and textual sh\nared memory to model the long-term visual-textual dependency and further guide visual attention on d\nescribed visual targets to solve visual-textual alignments. Specifically, similar to [10], the propo\nsed M3 attaches an external memory to store and retrieve both visual and textual contents by interac\nting with video and sentence with multiple read and write operations. To evaluate the proposed model\n, we perform experiments on two public datasets: MSVD and MSR-VTT. The experimental results demonstr\nate that our method outperforms most of the state-of-the-art methods in terms of BLEU and METEOR.", "cite_num": 12}, "908": {"title": "blockdrop: dynamic inference paths in residual networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_BlockDrop_Dynamic_Inference_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "637": {"title": "hats: histograms of averaged time surfaces for robust event-based object classification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sironi_HATS_Histograms_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "137": {"title": "distributable consistent multi-object matching", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Distributable_Consistent_Multi-Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "970": {"title": "coupled end-to-end transfer learning with generalized fisher information", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Coupled_End-to-End_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "24": {"title": "multi-agent diverse generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ghosh_Multi-Agent_Diverse_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "587": {"title": "a generative adversarial approach for zero-shot learning from noisy texts", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_A_Generative_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "818": {"title": "convolutional sequence to sequence model for human dynamics", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Convolutional_Sequence_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "246": {"title": "pointnetvlad: deep point cloud based retrieval for large-scale place recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "485": {"title": "a certifiably globally optimal solution to the non-minimal relative pose problem", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Briales_A_Certifiably_Globally_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "331": {"title": "ppfnet: global context aware local features for robust 3d point matching", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Deng_PPFNet_Global_Context_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "81": {"title": "cnn based learning using reflection and retinex models for intrinsic image decomposition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baslamisli_CNN_Based_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "482": {"title": "unsupervised correlation analysis", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hoshen_Unsupervised_Correlation_Analysis_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "452": {"title": "deep hashing via discrepancy minimization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Deep_Hashing_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "125": {"title": "referring image segmentation via recurrent refinement networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Referring_Image_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "898": {"title": "tracking multiple objects outside the line of sight using speckle imaging", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Smith_Tracking_Multiple_Objects_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "253": {"title": "bpgrad: towards global optimality in deep learning via branch and pruning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_BPGrad_Towards_Global_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "874": {"title": "active fixation control to predict saccade sequences", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wloka_Active_Fixation_Control_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "823": {"title": "event-based vision meets deep learning on steering prediction for self-driving cars", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Maqueda_Event-Based_Vision_Meets_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "353": {"title": "learning compositional visual concepts with mutual consistency", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gong_Learning_Compositional_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "448": {"title": "what do deep networks like to see?", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Palacio_What_Do_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "503": {"title": "natural and effective obfuscation by head inpainting", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Natural_and_Effective_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "964": {"title": "fight ill-posedness with ill-posedness: single-shot variational depth super-resolution from shading", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Haefner_Fight_Ill-Posedness_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "395": {"title": "non-linear temporal subspace representations for activity recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cherian_Non-Linear_Temporal_Subspace_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "929": {"title": "functional map of the world", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Christie_Functional_Map_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "318": {"title": "action sets: weakly supervised action segmentation without ordering constraints", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Richard_Action_Sets_Weakly_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "871": {"title": "csgnet: neural shape parser for constructive solid geometry", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sharma_CSGNet_Neural_Shape_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "689": {"title": "a perceptual measure for deep single image camera calibration", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hold-Geoffroy_A_Perceptual_Measure_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "128": {"title": "video person re-identification with competitive snippet-similarity aggregation and co-attentive snippet embedding", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Video_Person_Re-Identification_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "363": {"title": "deep regression forests for age estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Regression_Forests_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "486": {"title": "gesture recognition: focus on the hands", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Narayana_Gesture_Recognition_Focus_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "157": {"title": "smooth neighbors on teacher graphs for semi-supervised learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_Smooth_Neighbors_on_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "694": {"title": "separating self-expression and visual content in hashtag supervision", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Veit_Separating_Self-Expression_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "415": {"title": "rotation averaging and strong duality", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Eriksson_Rotation_Averaging_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "738": {"title": "a bi-directional message passing model for salient object detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_A_Bi-Directional_Message_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "370": {"title": "eliminating background-bias for robust person re-identification", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tian_Eliminating_Background-Bias_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "95": {"title": "cascaded pyramid network for multi-person pose estimation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Cascaded_Pyramid_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "431": {"title": "shape from shading through shape evolution", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Shape_From_Shading_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "289": {"title": "3d human sensing, action and emotion recognition in robot assisted therapy of children with autism", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Marinoiu_3D_Human_Sensing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "883": {"title": "latent ransac", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Korman_Latent_RANSAC_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "429": {"title": "crafting a toolchain for image restoration by deep reinforcement learning", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Crafting_a_Toolchain_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "698": {"title": "neural kinematic networks for unsupervised motion retargetting", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Villegas_Neural_Kinematic_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "819": {"title": "iqa: visual question answering in interactive environments", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gordon_IQA_Visual_Question_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "221": {"title": "supervision-by-registration: an unsupervised approach to improve the precision of facial landmark detectors", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dong_Supervision-by-Registration_An_Unsupervised_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "829": {"title": "learning face age progression: a pyramid architecture of gans", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Learning_Face_Age_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "912": {"title": "deep video super-resolution network using dynamic upsampling filters without explicit motion compensation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "70": {"title": "low-shot learning from imaginary data", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Low-Shot_Learning_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "803": {"title": "lions and tigers and bears: capturing non-rigid, 3d, articulated shape from images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zuffi_Lions_and_Tigers_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "86": {"title": "temporal hallucinating for action recognition with few still images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Temporal_Hallucinating_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "630": {"title": "super-resolving very low-resolution face images with supplementary attributes", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Super-Resolving_Very_Low-Resolution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "685": {"title": "image restoration by estimating frequency distribution of local patches", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yoo_Image_Restoration_by_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "84": {"title": "fsrnet: end-to-end learning face super-resolution with facial priors", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_FSRNet_End-to-End_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "822": {"title": "mix and match networks: encoder-decoder alignment for zero-pair image translation", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Mix_and_Match_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "463": {"title": "v2v-posenet: voxel-to-voxel prediction network for accurate 3d hand and human pose estimation from a single depth map", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Moon_V2V-PoseNet_Voxel-to-Voxel_Prediction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "7": {"title": "learning to act properly: predicting and explaining affordances from images", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chuang_Learning_to_Act_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "534": {"title": "neural baby talk", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lu_Neural_Baby_Talk_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "607": {"title": "photometric stereo in participating media considering shape-dependent forward scatter", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fujimura_Photometric_Stereo_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "521": {"title": "towards faster training of global covariance pooling networks by iterative matrix square root normalization", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Towards_Faster_Training_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "687": {"title": "learning to extract a video sequence from a single motion-blurred image", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jin_Learning_to_Extract_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "55": {"title": "mict: mixed 3d/2d convolutional tube for human action recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_MiCT_Mixed_3D2D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "149": {"title": "zero-shot sketch-image hashing", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Zero-Shot_Sketch-Image_Hashing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "491": {"title": "generate to adapt: aligning domains using generative adversarial networks", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sankaranarayanan_Generate_to_Adapt_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "749": {"title": "direction-aware spatial context features for shadow detection", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Direction-Aware_Spatial_Context_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "774": {"title": "hashgan: deep learning to hash with pair conditional wasserstein gan", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_HashGAN_Deep_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "312": {"title": "time-resolved light transport decomposition for thermal photometric stereo", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tanaka_Time-Resolved_Light_Transport_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "41": {"title": "3d object detection with latent support surfaces", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ren_3D_Object_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "379": {"title": "compare and contrast: learning prominent visual differences", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Compare_and_Contrast_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "549": {"title": "depth-based 3d hand pose estimation: from current achievements to future goals", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yuan_Depth-Based_3D_Hand_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "675": {"title": "sliced wasserstein distance for learning gaussian mixture models", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kolouri_Sliced_Wasserstein_Distance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "611": {"title": "reconstructing thin structures of manifold surfaces by integrating spatial curves", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Reconstructing_Thin_Structures_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "141": {"title": "learning from millions of 3d scans for large-scale 3d face recognition", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gilani_Learning_From_Millions_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "835": {"title": "video representation learning using discriminative pooling", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Video_Representation_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}, "839": {"title": "human pose estimation with parsing induced learner", "conf": "cvpr", "time": "2018", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nie_Human_Pose_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1}}