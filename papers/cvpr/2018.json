{"0": {"title": "embodied question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Das_Embodied_Question_Answering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "1": {"title": "learning by asking questions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Misra_Learning_by_Asking_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "2": {"title": "finding tiny faces in the wild with generative adversarial network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bai_Finding_Tiny_Faces_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "3": {"title": "learning face age progression: a pyramid architecture of gans", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Learning_Face_Age_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "4": {"title": "pairedcyclegan: asymmetric style transfer for applying and removing makeup", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_PairedCycleGAN_Asymmetric_Style_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "5": {"title": "ganerated hands for real-time 3d hand tracking from monocular rgb", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mueller_GANerated_Hands_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "6": {"title": "learning pose specific representations by predicting different views", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Poier_Learning_Pose_Specific_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "7": {"title": "weakly and semi supervised human body part parsing via pose-guided knowledge transfer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fang_Weakly_and_Semi_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "8": {"title": "person transfer gan to bridge domain gap for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Person_Transfer_GAN_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "9": {"title": "cross-modal deep variational hand pose estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Spurr_Cross-Modal_Deep_Variational_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "10": {"title": "disentangled person image generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ma_Disentangled_Person_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "11": {"title": "super-fan: integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with gans", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bulat_Super-FAN_Integrated_Facial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "12": {"title": "multistage adversarial losses for pose-based human image synthesis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Si_Multistage_Adversarial_Losses_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "13": {"title": "rotation averaging and strong duality", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Eriksson_Rotation_Averaging_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "14": {"title": "hybrid camera pose estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Camposeco_Hybrid_Camera_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "15": {"title": "a certifiably globally optimal solution to the non-minimal relative pose problem", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Briales_A_Certifiably_Globally_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "16": {"title": "single view stereo matching", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_Single_View_Stereo_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "17": {"title": "fight ill-posedness with ill-posedness: single-shot variational depth super-resolution from shading", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Haefner_Fight_Ill-Posedness_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "18": {"title": "deep depth completion of a single rgb-d image", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Deep_Depth_Completion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "19": {"title": "multi-view harmonized bilinear network for 3d object recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Multi-View_Harmonized_Bilinear_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "20": {"title": "ppfnet: global context aware local features for robust 3d point matching", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Deng_PPFNet_Global_Context_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "21": {"title": "foldingnet: point cloud auto-encoder via deep grid deformation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_FoldingNet_Point_Cloud_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "22": {"title": "a papier-m\u00e2ch\u00e9 approach to learning 3d surface generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Groueix_A_Papier-Mache_Approach_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "23": {"title": "lego: learning edge with geometry all at once by watching videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_LEGO_Learning_Edge_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "24": {"title": "five-point fundamental matrix estimation for uncalibrated cameras", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Barath_Five-Point_Fundamental_Matrix_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "25": {"title": "pointfusion: deep sensor fusion for 3d bounding box estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_PointFusion_Deep_Sensor_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "26": {"title": "scalable dense non-rigid structure-from-motion: a grassmannian perspective", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kumar_Scalable_Dense_Non-Rigid_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "27": {"title": "gvcnn: group-view convolutional neural networks for 3d shape recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Feng_GVCNN_Group-View_Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "28": {"title": "depth and transient imaging with compressive spad array cameras", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Depth_and_Transient_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "29": {"title": "geonet: geometric neural network for joint depth and surface normal estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_GeoNet_Geometric_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "30": {"title": "real-time seamless single shot 6d object pose prediction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tekin_Real-Time_Seamless_Single_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "31": {"title": "factoring shape, pose, and layout from the 2d image of a 3d scene", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tulsiani_Factoring_Shape_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "32": {"title": "monocular relative depth perception with web stereo data supervision", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xian_Monocular_Relative_Depth_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "33": {"title": "spline error weighting for robust visual-inertial fusion", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ovren_Spline_Error_Weighting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "34": {"title": "single-image depth estimation based on fourier domain analysis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_Single-Image_Depth_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "35": {"title": "unsupervised learning of monocular depth estimation and visual odometry with deep feature reconstruction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhan_Unsupervised_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "36": {"title": "detect-and-track: efficient pose estimation in videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Girdhar_Detect-and-Track_Efficient_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "37": {"title": "supervision-by-registration: an unsupervised approach to improve the precision of facial landmark detectors", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dong_Supervision-by-Registration_An_Unsupervised_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "38": {"title": "diversity regularized spatiotemporal attention for video-based person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Diversity_Regularized_Spatiotemporal_CVPR_2018_paper.html", "abstract": "Video-based person re-identification matches video clips of people across non-overlapping cameras. M\nost existing methods tackle this problem by encoding each video frame in its entirety and computing \nan aggregate representation across all frames. In practice, people are often partially occluded, whi\nch can corrupt the extracted features. Instead, we propose a new spatiotemporal attention model that\n automatically discovers a diverse set of distinctive body parts. This allows useful information to \nbe extracted from all frames without succumbing to occlusions and misalignments. The network learns \nmultiple spatial attention models and employs a diversity regularization term to ensure multiple mod\nels do not discover the same body part. Features extracted from local image regions are organized by\n spatial attention model and are combined using temporal attention. As a result, the network learns \nlatent representations of the face, torso and other body parts using the best available image patche\ns from the entire video sequence. Extensive evaluations on three datasets show that our framework ou\ntperforms the state-of-the-art approaches by large margins on multiple metrics.", "cite_num": 11, "conf": "cvpr", "time": "2018"}, "39": {"title": "style aggregated network for facial landmark detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dong_Style_Aggregated_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "40": {"title": "learning deep models for face anti-spoofing: binary or auxiliary supervision", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Learning_Deep_Models_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "41": {"title": "deep cost-sensitive and order-preserving feature learning for cross-population age estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Deep_Cost-Sensitive_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "42": {"title": "first-person hand action benchmark with rgb-d videos and 3d hand pose annotations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Garcia-Hernando_First-Person_Hand_Action_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "43": {"title": "a pose-sensitive embedding for person re-identification with expanded cross neighborhood re-ranking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sarfraz_A_Pose-Sensitive_Embedding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "44": {"title": "disentangling 3d pose in a dendritic cnn for unconstrained 2d face alignment", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kumar_Disentangling_3D_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "45": {"title": "a hierarchical generative model for eye image synthesis and eye gaze estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_A_Hierarchical_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "46": {"title": "mict: mixed 3d/2d convolutional tube for human action recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_MiCT_Mixed_3D2D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "47": {"title": "learning to estimate 3d human pose and shape from a single color image", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pavlakos_Learning_to_Estimate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "48": {"title": "glimpse clouds: human activity recognition from unstructured feature points", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baradel_Glimpse_Clouds_Human_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "49": {"title": "context-aware deep feature compression for high-speed visual tracking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Choi_Context-Aware_Deep_Feature_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "50": {"title": "correlation tracking via joint discrimination and reliability learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Correlation_Tracking_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "51": {"title": "phasenet for video frame interpolation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Meyer_PhaseNet_for_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "52": {"title": "the best of both worlds: combining cnns and geometric constraints for hierarchical motion segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bideau_The_Best_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "53": {"title": "hyperparameter optimization for tracking with continuous deep q-learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dong_Hyperparameter_Optimization_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "54": {"title": "scale-transferrable object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Scale-Transferrable_Object_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "55": {"title": "a prior-less method for multi-face tracking in unconstrained videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_A_Prior-Less_Method_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "56": {"title": "end-to-end flow correlation tracking with spatial-temporal attention", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_End-to-End_Flow_Correlation_CVPR_2018_paper.html", "abstract": "Discriminative correlation filters (DCF) with deep convolutional features have achieved favorable pe\nrformance in recent tracking benchmarks. However, most of existing DCF trackers only consider appear\nance features of current frame, and hardly benefit from motion and inter-frame information. The lack\n of temporal information degrades the tracking performance during challenges such as partial occlusi\non and deformation. In this paper, we propose the FlowTrack, which focuses on making use of the rich\n flow information in consecutive frames to improve the feature representation and the tracking accur\nacy. The FlowTrack formulates individual components, including optical flow estimation, feature extr\naction, aggregation and correlation filters tracking as special layers in network. To the best of ou\nr knowledge, this is the first work to jointly train flow and tracking task in deep learning framewo\nrk. Then the historical feature maps at predefined intervals are warped and aggregated with current \nones by the guiding of flow. For adaptive aggregation, we propose a novel spatial-temporal attention\n mechanism. In experiments, the proposed method achieves leading performance on OTB2013, OTB2015, VO\nT2015 and VOT2016.", "cite_num": 20, "conf": "cvpr", "time": "2018"}, "57": {"title": "deep texture manifold for ground terrain recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xue_Deep_Texture_Manifold_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "58": {"title": "learning superpixels with segmentation-aware affinity loss", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tu_Learning_Superpixels_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "59": {"title": "interactive image segmentation with latent diversity", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Interactive_Image_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "60": {"title": "the unreasonable effectiveness of deep features as a perceptual metric", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_The_Unreasonable_Effectiveness_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "61": {"title": "local descriptors optimized for average precision", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_Local_Descriptors_Optimized_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "62": {"title": "recovering realistic texture in image super-resolution by deep spatial feature transform", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Recovering_Realistic_Texture_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "63": {"title": "deep extreme cut: from extreme points to object segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Maninis_Deep_Extreme_Cut_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "64": {"title": "learning to parse wireframes in images of man-made environments", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Learning_to_Parse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "65": {"title": "occlusion-aware rolling shutter rectification of 3d scenes", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vasu_Occlusion-Aware_Rolling_Shutter_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "66": {"title": "content-sensitive supervoxels via uniform tessellations on video manifolds", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yi_Content-Sensitive_Supervoxels_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "67": {"title": "intrinsic image transformation via scale space decomposition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_Intrinsic_Image_Transformation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "68": {"title": "learned shape-tailored descriptors for segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Khan_Learned_Shape-Tailored_Descriptors_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "69": {"title": "pad-net: multi-tasks guided prediction-and-distillation network for simultaneous depth estimation and scene parsing", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_PAD-Net_Multi-Tasks_Guided_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "70": {"title": "multi-image semantic matching by mining consistent features", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Multi-Image_Semantic_Matching_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "71": {"title": "density-aware single image de-raining using a multi-stream dense network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Density-Aware_Single_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "72": {"title": "joint cuts and matching of partitions in one graph", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Joint_Cuts_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "73": {"title": "progressive attention guided recurrent network for salient object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Progressive_Attention_Guided_CVPR_2018_paper.html", "abstract": "Effective convolutional features play an important role in saliency estimation but how to learn powe\nrful features for saliency is still a challenging task. FCN-based methods directly apply multi-level\n convolutional features without distinction, which leads to sub-optimal results due to the distracti\non from redundant details. In this paper, we propose a novel attention guided network which selectiv\nely integrates multi-level contextual information in a progressive manner. Attentive features genera\nted by our network can alleviate distraction of background thus achieve better performance. On the o\nther hand, it is observed that most of existing algorithms conduct salient object detection by explo\niting side-output features of the backbone feature extraction network. However, shallower layers of \nbackbone network lack the ability to obtain global semantic information, which limits the effective \nfeature learning. To address the problem, we introduce multi-path recurrent feedback to enhance our \nproposed progressive attention driven framework. Through multi-path recurrent connections, global se\nmantic information from the top convolutional layer is transferred to shallower layers, which intrin\nsically refines the entire network. Experimental results on six benchmark datasets demonstrate that \nour algorithm performs favorably against the state-of-the-art approaches.", "cite_num": 38, "conf": "cvpr", "time": "2018"}, "74": {"title": "fast and accurate single image super-resolution via information distillation network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hui_Fast_and_Accurate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "75": {"title": "hallucinated-iqa: no-reference image quality assessment via adversarial learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_Hallucinated-IQA_No-Reference_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "76": {"title": "nag: network for adversary generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mopuri_NAG_Network_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "77": {"title": "dynamic-structured semantic propagation network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liang_Dynamic-Structured_Semantic_Propagation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "78": {"title": "cross-domain self-supervised multi-task feature learning using synthetic imagery", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ren_Cross-Domain_Self-Supervised_Multi-Task_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "79": {"title": "a two-step disentanglement method", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hadad_A_Two-Step_Disentanglement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "80": {"title": "robust facial landmark detection via a fully-convolutional local-global context network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Merget_Robust_Facial_Landmark_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "81": {"title": "decorrelated batch normalization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Decorrelated_Batch_Normalization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "82": {"title": "learning to sketch with shortcut cycle consistency", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Learning_to_Sketch_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "83": {"title": "towards a mathematical understanding of the difficulty in learning with feedforward neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Towards_a_Mathematical_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "84": {"title": "faceid-gan: learning a symmetry three-player gan for identity-preserving face synthesis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_FaceID-GAN_Learning_a_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "85": {"title": "a constrained deep neural network for ordinal regression", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_A_Constrained_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "86": {"title": "modulated convolutional networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Modulated_Convolutional_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "87": {"title": "learning steerable filters for rotation equivariant cnns", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Weiler_Learning_Steerable_Filters_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "88": {"title": "efficient interactive annotation of segmentation datasets with polygon-rnn++", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Acuna_Efficient_Interactive_Annotation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "89": {"title": "splinecnn: fast geometric deep learning with continuous b-spline kernels", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fey_SplineCNN_Fast_Geometric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "90": {"title": "gagan: geometry-aware generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kossaifi_GAGAN_Geometry-Aware_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "91": {"title": "on the robustness of semantic segmentation models to adversarial attacks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Arnab_On_the_Robustness_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "92": {"title": "feedback-prop: convolutional neural network inference under partial evidence", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Feedback-Prop_Convolutional_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "93": {"title": "super-resolving very low-resolution face images with supplementary attributes", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Super-Resolving_Very_Low-Resolution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "94": {"title": "frustum pointnets for 3d object detection from rgb-d data", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Frustum_PointNets_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "95": {"title": "w2f: a weakly-supervised to fully-supervised framework for object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_W2F_A_Weakly-Supervised_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "96": {"title": "3d object detection with latent support surfaces", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ren_3D_Object_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "97": {"title": "towards faster training of global covariance pooling networks by iterative matrix square root normalization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Towards_Faster_Training_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "98": {"title": "recurrent scene parsing with perspective understanding in the loop", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kong_Recurrent_Scene_Parsing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "99": {"title": "improving occlusion and hard negative handling for single-stage pedestrian detectors", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Noh_Improving_Occlusion_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "100": {"title": "learning to act properly: predicting and explaining affordances from images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chuang_Learning_to_Act_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "101": {"title": "pointwise convolutional neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hua_Pointwise_Convolutional_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "102": {"title": "image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Deng_Image-Image_Domain_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "103": {"title": "a generative adversarial approach for zero-shot learning from noisy texts", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_A_Generative_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "104": {"title": "tensorize, factorize and regularize: robust visual relationship learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hwang_Tensorize_Factorize_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "105": {"title": "transductive unbiased embedding for zero-shot learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Transductive_Unbiased_Embedding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "106": {"title": "hierarchical novelty detection for visual object recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_Hierarchical_Novelty_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "107": {"title": "zero-shot visual recognition using semantics-preserving adversarial embedding networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Zero-Shot_Visual_Recognition_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "108": {"title": "learning rich features for image manipulation detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Learning_Rich_Features_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "109": {"title": "human semantic parsing for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kalayeh_Human_Semantic_Parsing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "110": {"title": "stacked latent attention for multimodal reasoning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fan_Stacked_Latent_Attention_CVPR_2018_paper.html", "abstract": "Attention has shown to be a pivotal development in deep learning and has been used for a multitude o\nf multimodal learning tasks such as visual question answering and image captioning. In this work, we\n pinpoint the potential limitations to the design of a traditional attention model. We identify that\n 1) current attention mechanisms discard the latent information from intermediate reasoning, losing \nthe positional information already captured by the attention heatmaps and 2) stacked attention, a co\nmmon way to improve spatial reasoning, may have suboptimal performance because of the vanishing grad\nient problem. We introduce a novel attention architecture to address these problems, in which all sp\natial configuration information contained in the intermediate reasoning process is retained in a pat\nhway of convolutional layers. We show that this new attention leads to substantial improvements in m\nultiple multimodal reasoning tasks, including achieving single model performance without using exter\nnal knowledge comparable to the state-of-the-art on the VQA dataset, as well as clear gains for the \nimage captioning task.", "cite_num": 5, "conf": "cvpr", "time": "2018"}, "111": {"title": "r-fcn-3000 at 30fps: decoupling detection and classification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Singh_R-FCN-3000_at_30fps_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "112": {"title": "csrnet: dilated convolutional neural networks for understanding the highly congested scenes", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_CSRNet_Dilated_Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "113": {"title": "revisiting knowledge transfer for training object class detectors", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Uijlings_Revisiting_Knowledge_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "114": {"title": "deep sparse coding for invariant multimodal halle berry neurons", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_Deep_Sparse_Coding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "115": {"title": "on the convergence of patchmatch and its variants", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ehret_On_the_Convergence_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "116": {"title": "rethinking the faster r-cnn architecture for temporal action localization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chao_Rethinking_the_Faster_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "117": {"title": "monet: deep motion exploitation for video object segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xiao_MoNet_Deep_Motion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "118": {"title": "video representation learning using discriminative pooling", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Video_Representation_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "119": {"title": "recognizing human actions as the evolution of pose estimation maps", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Recognizing_Human_Actions_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "120": {"title": "video person re-identification with competitive snippet-similarity aggregation and co-attentive snippet embedding", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Video_Person_Re-Identification_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "121": {"title": "mask-guided contrastive attention model for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Mask-Guided_Contrastive_Attention_CVPR_2018_paper.html", "abstract": "Person Re-identification (ReID) is an important yet challenging task in computer vision. Due to the \ndiverse background clutters, variations on viewpoints and body poses, it is far from solved. How to \nextract discriminative and robust features invariant to background clutters is the core problem. In \nthis paper, we first introduce the binary segmentation masks to construct synthetic RGB-Mask pairs a\ns inputs, then we design a mask-guided contrastive attention model (MGCAM) to learn features separat\nely from the body and background regions. Moreover, we propose a novel region-level triplet loss to \nrestrain the features learnt from different regions, i.e., pulling the features from the full image \nand body region close, whereas pushing the features from backgrounds away. We may be the first one t\no successfully introduce the binary mask into person ReID task and the first one to propose region-l\nevel contrastive learning. We evaluate the proposed method on three public datasets, including MARS,\n Market-1501 and CUHK03. Extensive experimental results show that the proposed method is effective a\nnd achieves the state-of-the-art results. Mask and code will be released upon request.", "cite_num": 42, "conf": "cvpr", "time": "2018"}, "122": {"title": "blazingly fast video object segmentation with pixel-wise metric learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Blazingly_Fast_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "123": {"title": "learning to compare: relation network for few-shot learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sung_Learning_to_Compare_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "124": {"title": "coco-stuff: thing and stuff classes in context", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Caesar_COCO-Stuff_Thing_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "125": {"title": "image generation from scene graphs", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Johnson_Image_Generation_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "126": {"title": "deep cauchy hashing for hamming space retrieval", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Deep_Cauchy_Hashing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "127": {"title": "learning to look around: intelligently exploring unseen environments for unknown tasks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jayaraman_Learning_to_Look_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "128": {"title": "multi-scale location-aware kernel representation for object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Multi-Scale_Location-Aware_Kernel_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "129": {"title": "clinical skin lesion diagnosis using representations inspired by dermatologist criteria", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Clinical_Skin_Lesion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "130": {"title": "compare and contrast: learning prominent visual differences", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Compare_and_Contrast_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "131": {"title": "multi-evidence filtering and fusion for multi-label classification, object detection and semantic segmentation based on weakly supervised learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ge_Multi-Evidence_Filtering_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "132": {"title": "hashgan: deep learning to hash with pair conditional wasserstein gan", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_HashGAN_Deep_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "133": {"title": "min-entropy latent model for weakly supervised object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wan_Min-Entropy_Latent_Model_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "134": {"title": "mattnet: modular attention network for referring expression comprehension", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_MAttNet_Modular_Attention_CVPR_2018_paper.html", "abstract": "In this paper, we address referring expression comprehension: localizing an image region described b\ny a natural language expression. While most recent work treats expressions as a single unit, we prop\nose to decompose them into three modular components related to subject appearance, location, and rel\nationship to other objects. This allows us to flexibly adapt to expressions containing different typ\nes of information in an end-to-end framework. In our model, which we call the Modular Attention Netw\nork (MAttNet), two types of attention are utilized: language-based attention that learns the module \nweights as well as the word/phrase attention that each module should focus on; and visual attention \nthat allows the subject and relationship modules to focus on relevant image components. Module weigh\nts combine scores from all three modules dynamically to output an overall score. Experiments show th\nat MAttNet outperforms previous state-of-art methods by a large margin on both bounding-box-level an\nd pixel-level comprehension tasks.", "cite_num": 23, "conf": "cvpr", "time": "2018"}, "135": {"title": "attngan: fine-grained text to image generation with attentional generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_AttnGAN_Fine-Grained_Text_CVPR_2018_paper.html", "abstract": "In this paper, we propose an Attentional Generative Adversarial Network (AttnGAN) that allows attent\nion-driven, multi-stage refinement for fine-grained text-to-image generation. With a novel attention\nal generative network, the AttnGAN can synthesize fine-grained details at different subregions of th\ne image by paying attentions to the relevant words in the natural language description. In addition,\n a deep attentional multimodal similarity model is proposed to compute a fine-grained image-text mat\nching loss for training the generator. The proposed AttnGAN significantly outperforms the previous s\ntate of the art, boosting the best reported inception score by 14.14% on the CUB dataset and 170.25%\n on the more challenging COCO dataset. A detailed analysis is also performed by visualizing the atte\nntion layers of the AttnGAN. It for the first time shows that the layered attentional GAN is able to\n automatically select the condition at the word level for generating different parts of the image.", "cite_num": 77, "conf": "cvpr", "time": "2018"}, "136": {"title": "adversarial complementary learning for weakly supervised object localization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Adversarial_Complementary_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "137": {"title": "conditional generative adversarial network for structured domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hong_Conditional_Generative_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "138": {"title": "groupcap: group-based image captioning with structured relevance and diversity constraints", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_GroupCap_Group-Based_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "139": {"title": "weakly-supervised semantic segmentation by iteratively mining common object features", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Weakly-Supervised_Semantic_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "140": {"title": "bootstrapping the performance of webly supervised semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Bootstrapping_the_Performance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "141": {"title": "deepvoting: a robust and explainable deep network for semantic part detection under partial occlusion", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_DeepVoting_A_Robust_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "142": {"title": "geometry-aware scene text detection with instance transformation network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Geometry-Aware_Scene_Text_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "143": {"title": "optical flow guided feature: a fast and robust motion representation for video action recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Optical_Flow_Guided_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "144": {"title": "motion-guided cascaded refinement network for video object segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Motion-Guided_Cascaded_Refinement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "145": {"title": "a memory network approach for story-based temporal summarization of 360\u00b0 videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_A_Memory_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "146": {"title": "cube padding for weakly-supervised saliency prediction in 360\u00b0 videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_Cube_Padding_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "147": {"title": "appearance-and-relation networks for video classification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Appearance-and-Relation_Networks_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "148": {"title": "excitation backprop for rnns", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bargal_Excitation_Backprop_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "149": {"title": "one-shot action localization by learning sequence matching network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_One-Shot_Action_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "150": {"title": "structure preserving video prediction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Structure_Preserving_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "151": {"title": "person re-identification with cascaded pairwise convolutions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Person_Re-Identification_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "152": {"title": "on the importance of label quality for semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zlateski_On_the_Importance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "153": {"title": "scalable and effective deep cca via soft decorrelation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_Scalable_and_Effective_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "154": {"title": "duplex generative adversarial network for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Duplex_Generative_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "155": {"title": "edit probability for scene text recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bai_Edit_Probability_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "156": {"title": "global versus localized generative adversarial nets", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Global_Versus_Localized_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "157": {"title": "mocogan: decomposing motion and content for video generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tulyakov_MoCoGAN_Decomposing_Motion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "158": {"title": "recurrent residual module for fast inference in videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pan_Recurrent_Residual_Module_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "159": {"title": "improving landmark localization with semi-supervised learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Honari_Improving_Landmark_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "160": {"title": "adversarial data programming: using gans to relax the bottleneck of curated labeled data", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pal_Adversarial_Data_Programming_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "161": {"title": "stochastic variational inference with gradient linearization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Plotz_Stochastic_Variational_Inference_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "162": {"title": "multi-label zero-shot learning with structured knowledge graphs", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_Multi-Label_Zero-Shot_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "163": {"title": "morphnet: fast & simple resource-constrained structure learning of deep networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gordon_MorphNet_Fast__CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "164": {"title": "deep adversarial subspace clustering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Deep_Adversarial_Subspace_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "165": {"title": "towards human-machine cooperation: self-supervised sample mining for object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Towards_Human-Machine_Cooperation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "166": {"title": "discrete-continuous admm for transductive inference in higher-order mrfs", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Laude_Discrete-Continuous_ADMM_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "167": {"title": "robust physical-world attacks on deep learning visual classification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Eykholt_Robust_Physical-World_Attacks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "168": {"title": "generating a fusion image: one's identity and another's shape", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Joo_Generating_a_Fusion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "169": {"title": "learning to promote saliency detectors", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zeng_Learning_to_Promote_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "170": {"title": "image super-resolution via dual-state recurrent networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Han_Image_Super-Resolution_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "171": {"title": "deep back-projection networks for super-resolution", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Haris_Deep_Back-Projection_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "172": {"title": "focus manipulation detection via photometric histogram analysis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Focus_Manipulation_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "173": {"title": "compassionately conservative balanced cuts for image segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cahill_Compassionately_Conservative_Balanced_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "174": {"title": "a high-quality denoising dataset for smartphone cameras", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Abdelhamed_A_High-Quality_Denoising_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "175": {"title": "context-aware synthesis for video frame interpolation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Niklaus_Context-Aware_Synthesis_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "176": {"title": "salient object detection driven by fixation prediction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Salient_Object_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "177": {"title": "enhancing the spatial resolution of stereo images using a parallax prior", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jeon_Enhancing_the_Spatial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "178": {"title": "hats: histograms of averaged time surfaces for robust event-based object classification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sironi_HATS_Histograms_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "179": {"title": "a bi-directional message passing model for salient object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_A_Bi-Directional_Message_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "180": {"title": "matching pixels using co-occurrence statistics", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kat_Matching_Pixels_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "181": {"title": "seednet: automatic seed generation with deep reinforcement learning for robust interactive segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_SeedNet_Automatic_Seed_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "182": {"title": "jerk-aware video acceleration magnification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Takeda_Jerk-Aware_Video_Acceleration_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "183": {"title": "defense against adversarial attacks using high-level representation guided denoiser", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liao_Defense_Against_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "184": {"title": "stacked conditional generative adversarial networks for jointly learning shadow detection and shadow removal", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Stacked_Conditional_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "185": {"title": "image correction via deep reciprocating hdr transformation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Image_Correction_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "186": {"title": "pieapp: perceptual image-error assessment through pairwise preference", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Prashnani_PieAPP_Perceptual_Image-Error_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "187": {"title": "normalized cut loss for weakly-supervised cnn segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tang_Normalized_Cut_Loss_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "188": {"title": "ista-net: interpretable optimization-inspired deep network for image compressive sensing", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_ISTA-Net_Interpretable_Optimization-Inspired_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "189": {"title": "fast end-to-end trainable guided filter", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Fast_End-to-End_Trainable_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "190": {"title": "disentangling structure and aesthetics for style-aware image completion", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gilbert_Disentangling_Structure_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "191": {"title": "learning a discriminative feature network for semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Learning_a_Discriminative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "192": {"title": "kernelized subspace pooling for deep local descriptors", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Kernelized_Subspace_Pooling_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "193": {"title": "pose: pseudo object space error for initialization-free bundle adjustment", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hong_pOSE_Pseudo_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "194": {"title": "deformable shape completion with graph convolutional autoencoders", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Litany_Deformable_Shape_Completion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "195": {"title": "learning from millions of 3d scans for large-scale 3d face recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gilani_Learning_From_Millions_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "196": {"title": "carfusion: combining point tracking and part detection for dynamic 3d reconstruction of vehicles", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Reddy_CarFusion_Combining_Point_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "197": {"title": "deep material-aware cross-spectral stereo matching", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhi_Deep_Material-Aware_Cross-Spectral_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "198": {"title": "augmenting crowd-sourced 3d reconstructions using semantic detections", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Price_Augmenting_Crowd-Sourced_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "199": {"title": "matryoshka networks: predicting 3d geometry via nested shape layers", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Richter_Matryoshka_Networks_Predicting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "200": {"title": "triplet-center loss for multi-view 3d object retrieval", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_Triplet-Center_Loss_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "201": {"title": "learning 3d shape completion from laser scan data with weak supervision", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Stutz_Learning_3D_Shape_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "202": {"title": "end-to-end learning of keypoint detector and descriptor for pose invariant 3d matching", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Georgakis_End-to-End_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "203": {"title": "ice-ba: incremental, consistent and efficient bundle adjustment for visual-inertial slam", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_ICE-BA_Incremental_Consistent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "204": {"title": "geonet: unsupervised learning of dense depth, optical flow and camera pose", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yin_GeoNet_Unsupervised_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "205": {"title": "radially-distorted conjugate translations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pritts_Radially-Distorted_Conjugate_Translations_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "206": {"title": "deep ordinal regression network for monocular depth estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fu_Deep_Ordinal_Regression_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "207": {"title": "analytical modeling of vanishing points and curves in catadioptric cameras", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Miraldo_Analytical_Modeling_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "208": {"title": "learning depth from monocular videos using direct methods", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Learning_Depth_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "209": {"title": "salience guided depth calibration for perceptually optimized compressive light field 3d display", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Salience_Guided_Depth_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "210": {"title": "megadepth: learning single-view depth prediction from internet photos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_MegaDepth_Learning_Single-View_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "211": {"title": "layoutnet: reconstructing the 3d room layout from a single rgb image", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zou_LayoutNet_Reconstructing_the_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "212": {"title": "cbmv: a coalesced bidirectional matching volume for disparity estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Batsos_CBMV_A_Coalesced_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "213": {"title": "zoom and learn: generalizing deep stereo matching to novel domains", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pang_Zoom_and_Learn_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "214": {"title": "exploring disentangled feature representation beyond face identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Exploring_Disentangled_Feature_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "215": {"title": "learning facial action units from web images with scalable weakly supervised clustering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Learning_Facial_Action_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "216": {"title": "human pose estimation with parsing induced learner", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nie_Human_Pose_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "217": {"title": "multi-level factorisation net for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_Multi-Level_Factorisation_Net_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "218": {"title": "attention-aware compositional network for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Attention-Aware_Compositional_Network_CVPR_2018_paper.html", "abstract": "Person re-identification (ReID) is to identify pedestrians observed from different camera views base\nd on visual appearance. It is a challenging task due to large pose variations, complex background cl\nutters and severe occlusions. Recently, human pose estimation by predicting joint locations was larg\nely improved in accuracy. It is reasonable to use pose estimation results for handling pose variatio\nns and background clutters, and such attempts have obtained great improvement in ReID performance. H\nowever, we argue that the pose information was not well utilized and hasn't yet been fully exploited\n for person ReID. #R##N#In this work, we introduce a novel framework called Attention-Aware Composit\nional Network (AACN) for person ReID. AACN consists of two main components: Pose-guided Part Attenti\non (PPA) and Attention-aware Feature Composition (AFC). PPA is learned and applied to mask out undes\nirable background features in pedestrian feature maps. Furthermore, pose-guided visibility scores ar\ne estimated for body parts to deal with part occlusion in the proposed AFC module. Extensive experim\nents with ablation analysis show the effectiveness of our method, and state-of-the-art results are a\nchieved on several public datasets, including Market-1501, CUHK03, CUHK01, SenseReID, CUHK03-NP and \nDukeMTMC-reID.", "cite_num": 19, "conf": "cvpr", "time": "2018"}, "219": {"title": "look at boundary: a boundary-aware face alignment algorithm", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Look_at_Boundary_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "220": {"title": "demo2vec: reasoning object affordances from online videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fang_Demo2Vec_Reasoning_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "221": {"title": "monocular 3d pose and shape estimation of multiple people in natural scenes - the importance of multiple scene constraints", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zanfir_Monocular_3D_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "222": {"title": "3d human sensing, action and emotion recognition in robot assisted therapy of children with autism", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Marinoiu_3D_Human_Sensing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "223": {"title": "facial expression recognition by de-expression residue learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Facial_Expression_Recognition_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "224": {"title": "a causal and-or graph model for visibility fluent reasoning in tracking interacting objects", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_A_Causal_And-Or_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "225": {"title": "weakly supervised facial action unit recognition through adversarial training", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Peng_Weakly_Supervised_Facial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "226": {"title": "non-linear temporal subspace representations for activity recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cherian_Non-Linear_Temporal_Subspace_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "227": {"title": "towards pose invariant face recognition in the wild", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Towards_Pose_Invariant_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "228": {"title": "unifying identification and context learning for person recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Unifying_Identification_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "229": {"title": "jointly optimize data augmentation and network training: adversarial data augmentation in human pose estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Peng_Jointly_Optimize_Data_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "230": {"title": "wing loss for robust facial landmark localisation with convolutional neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Feng_Wing_Loss_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "231": {"title": "multiple granularity group interaction prediction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yao_Multiple_Granularity_Group_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "232": {"title": "social gan: socially acceptable trajectories with generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gupta_Social_GAN_Socially_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "233": {"title": "deep group-shuffling random walk for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Group-Shuffling_Random_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "234": {"title": "transferable joint attribute-identity deep learning for unsupervised person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Transferable_Joint_Attribute-Identity_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "235": {"title": "harmonious attention network for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Harmonious_Attention_Network_CVPR_2018_paper.html", "abstract": "Existing person re-identification (re-id) methods either assume the availability of well-aligned per\nson bounding box images as model input or rely on constrained attention selection mechanisms to cali\nbrate misaligned images. They are therefore sub-optimal for re-id matching in arbitrarily aligned pe\nrson images potentially with large human pose variations and unconstrained auto-detection errors. In\n this work, we show the advantages of jointly learning attention selection and feature representatio\nn in a Convolutional Neural Network (CNN) by maximising the complementary information of different l\nevels of visual attention subject to re-id discriminative learning constraints. Specifically, we for\nmulate a novel Harmonious Attention CNN (HA-CNN) model for joint learning of soft pixel attention an\nd hard regional attention along with simultaneous optimisation of feature representations, dedicated\n to optimise person re-id in uncontrolled (misaligned) images. Extensive comparative evaluations val\nidate the superiority of this new HA-CNN model for person re-id over a wide variety of state-of-the-\nart methods on three large-scale benchmarks including CUHK03, Market-1501, and DukeMTMC-ReID.", "cite_num": 78, "conf": "cvpr", "time": "2018"}, "236": {"title": "real-time rotation-invariant face detection with progressive calibration networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shi_Real-Time_Rotation-Invariant_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "237": {"title": "deep regression forests for age estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Regression_Forests_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "238": {"title": "weakly-supervised deep convolutional neural network learning for facial action unit intensity estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Weakly-Supervised_Deep_Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "239": {"title": "memory based online learning of deep representations from video streams", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pernici_Memory_Based_Online_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "240": {"title": "efficient and deep person re-identification using multi-level similarity", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Guo_Efficient_and_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "241": {"title": "multi-level fusion based 3d object detection from monocular images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Multi-Level_Fusion_Based_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "242": {"title": "a perceptual measure for deep single image camera calibration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hold-Geoffroy_A_Perceptual_Measure_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "243": {"title": "learning to generate time-lapse videos using multi-stage dynamic generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xiong_Learning_to_Generate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "244": {"title": "document enhancement using visibility detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kligler_Document_Enhancement_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "245": {"title": "a weighted sparse sampling and smoothing frame transition approach for semantic fast-forward first-person videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Silva_A_Weighted_Sparse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "246": {"title": "context contrasted feature and gated multi-scale aggregation for scene segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ding_Context_Contrasted_Feature_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "247": {"title": "deep layer aggregation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Deep_Layer_Aggregation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "248": {"title": "convolutional neural networks with alternately updated clique", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Convolutional_Neural_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "249": {"title": "practical block-wise neural network architecture generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhong_Practical_Block-Wise_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "250": {"title": "xunit: learning a spatial activation function for efficient image restoration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kligvasser_xUnit_Learning_a_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "251": {"title": "crafting a toolchain for image restoration by deep reinforcement learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Crafting_a_Toolchain_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "252": {"title": "deformation aware image compression", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shaham_Deformation_Aware_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "253": {"title": "distributable consistent multi-object matching", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Distributable_Consistent_Multi-Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "254": {"title": "residual dense network for image super-resolution", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Residual_Dense_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "255": {"title": "attentive generative adversarial network for raindrop removal from a single image", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qian_Attentive_Generative_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "256": {"title": "fsrnet: end-to-end learning face super-resolution with facial priors", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_FSRNet_End-to-End_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "257": {"title": "burst denoising with kernel prediction networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mildenhall_Burst_Denoising_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "258": {"title": "unsupervised sparse dirichlet-net for hyperspectral image super-resolution", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qu_Unsupervised_Sparse_Dirichlet-Net_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "259": {"title": "dynamic scene deblurring using spatially variant recurrent neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Dynamic_Scene_Deblurring_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "260": {"title": "splatnet: sparse lattice networks for point cloud processing", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Su_SPLATNet_Sparse_Lattice_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "261": {"title": "surface networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kostrikov_Surface_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "262": {"title": "self-supervised multi-level face model learning for monocular reconstruction at over 250 hz", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tewari_Self-Supervised_Multi-Level_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "263": {"title": "codeslam \u2014 learning a compact, optimisable representation for dense visual slam", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bloesch_CodeSLAM_--_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "264": {"title": "sgpn: similarity group proposal network for 3d point cloud instance segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_SGPN_Similarity_Group_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "265": {"title": "planenet: piece-wise planar reconstruction from a single rgb image", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_PlaneNet_Piece-Wise_Planar_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "266": {"title": "deep parametric continuous convolutional neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Deep_Parametric_Continuous_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "267": {"title": "feastnet: feature-steered graph convolutions for 3d shape analysis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Verma_FeaStNet_Feature-Steered_Graph_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "268": {"title": "image collection pop-up: 3d reconstruction and clustering of rigid and non-rigid categories", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Agudo_Image_Collection_Pop-Up_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "269": {"title": "geometry-aware learning of maps for camera localization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Brahmbhatt_Geometry-Aware_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "270": {"title": "recurrent slice networks for 3d segmentation of point clouds", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Recurrent_Slice_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "271": {"title": "depth-based 3d hand pose estimation: from current achievements to future goals", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yuan_Depth-Based_3D_Hand_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "272": {"title": "sobolevfusion: 3d reconstruction of scenes undergoing free non-rigid motion", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Slavcheva_SobolevFusion_3D_Reconstruction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "273": {"title": "adadepth: unsupervised content congruent adaptation for depth estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kundu_AdaDepth_Unsupervised_content_cvpr_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "274": {"title": "learning to find good correspondences", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yi_Learning_to_Find_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "275": {"title": "oatm: occlusion aware template matching by consensus set maximization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Korman_OATM_Occlusion_Aware_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "276": {"title": "deep learning of graph matching", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zanfir_Deep_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "277": {"title": "unsupervised discovery of object landmarks as structural representations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Unsupervised_Discovery_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "278": {"title": "quantization and training of neural networks for efficient integer-arithmetic-only inference", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jacob_Quantization_and_Training_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "279": {"title": "lean multiclass crowdsourcing", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Van_Horn_Lean_Multiclass_Crowdsourcing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "280": {"title": "partial transfer learning with selective adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Partial_Transfer_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "281": {"title": "self-supervised feature learning by learning to spot artifacts", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jenni_Self-Supervised_Feature_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "282": {"title": "ldmnet: low dimensional manifold regularized neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_LDMNet_Low_Dimensional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "283": {"title": "condensenet: an efficient densenet using learned group convolutions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_CondenseNet_An_Efficient_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "284": {"title": "learning deep descriptors with scale-aware triplet networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Keller_Learning_Deep_Descriptors_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "285": {"title": "decoupled networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Decoupled_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "286": {"title": "deep adversarial metric learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Duan_Deep_Adversarial_Metric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "287": {"title": "pu-net: point cloud upsampling network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_PU-Net_Point_Cloud_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "288": {"title": "real-time monocular depth estimation using synthetic data with domain adaptation via image style transfer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Atapour-Abarghouei_Real-Time_Monocular_Depth_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "289": {"title": "learning for disparity estimation through feature constancy", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liang_Learning_for_Disparity_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "290": {"title": "deepmvs: learning multi-view stereopsis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_DeepMVS_Learning_Multi-View_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "291": {"title": "self-calibrating polarising radiometric calibration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Teo_Self-Calibrating_Polarising_Radiometric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "292": {"title": "coding kendall's shape trajectories for 3d action recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tanfous_Coding_Kendalls_Shape_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "293": {"title": "efficient, sparse representation of manifold distance matrices for classical scaling", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Turek_Efficient_Sparse_Representation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "294": {"title": "motion segmentation by exploiting complementary geometric models", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Motion_Segmentation_by_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "295": {"title": "estimation of camera locations in highly corrupted scenarios: all about that base, no shape trouble", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shi_Estimation_of_Camera_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "296": {"title": "4d human body correspondences from panoramic depth maps", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_4D_Human_Body_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "297": {"title": "reconstructing thin structures of manifold surfaces by integrating spatial curves", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Reconstructing_Thin_Structures_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "298": {"title": "multi-view consistency as supervisory signal for learning shape and pose prediction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tulsiani_Multi-View_Consistency_as_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "299": {"title": "probabilistic plant modeling via multi-view image-to-image translation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Isokane_Probabilistic_Plant_Modeling_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "300": {"title": "deep marching cubes: learning explicit surface representations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liao_Deep_Marching_Cubes_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "301": {"title": "tags2parts: discovering semantic regions from shape tags", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Muralikrishnan_Tags2Parts_Discovering_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "302": {"title": "uncalibrated photometric stereo under natural illumination", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mo_Uncalibrated_Photometric_Stereo_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "303": {"title": "robust depth estimation from auto bracketed images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Im_Robust_Depth_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "304": {"title": "free supervision from video games", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Krahenbuhl_Free_Supervision_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "305": {"title": "planar shape detection at structural scales", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fang_Planar_Shape_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "306": {"title": "pix3d: dataset and methods for single-image 3d shape modeling", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Pix3D_Dataset_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "307": {"title": "camera pose estimation with unknown principal point", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Larsson_Camera_Pose_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "308": {"title": "inverse composition discriminative optimization for point cloud registration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vongkulbhisal_Inverse_Composition_Discriminative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "309": {"title": "surfconv: bridging 3d and 2d convolution for rgbd images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chu_SurfConv_Bridging_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "310": {"title": "a fast resection-intersection method for the known rotation problem", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_A_Fast_Resection-Intersection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "311": {"title": "3d pose estimation and 3d model retrieval for objects in the wild", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Grabner_3D_Pose_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "312": {"title": "structure from recurrent motion: from rigidity to recurrency", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Structure_From_Recurrent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "313": {"title": "learning patch reconstructability for accelerating multi-view stereo", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Poms_Learning_Patch_Reconstructability_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "314": {"title": "progressively complementarity-aware fusion network for rgb-d salient object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Progressively_Complementarity-Aware_Fusion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "315": {"title": "pixels, voxels, and views: a study of shape representations for single view 3d object shape prediction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shin_Pixels_Voxels_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "316": {"title": "learning dual convolutional neural networks for low-level vision", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pan_Learning_Dual_Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "317": {"title": "defocus blur detection via multi-stream bottom-top-bottom fully convolutional network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Defocus_Blur_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "318": {"title": "picanet: learning pixel-wise contextual attention for saliency detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_PiCANet_Learning_Pixel-Wise_CVPR_2018_paper.html", "abstract": "Contexts play an important role in the saliency detection task. However, given a context region, not\n all contextual information is helpful for the final task. In this paper, we propose a novel pixel-w\nise contextual attention network, i.e., the PiCANet, to learn to selectively attend to informative c\nontext locations for each pixel. Specifically, for each pixel, it can generate an attention map in w\nhich each attention weight corresponds to the contextual relevance at each context location. An atte\nnded contextual feature can then be constructed by selectively aggregating the contextual informatio\nn. We formulate the proposed PiCANet in both global and local forms to attend to global and local co\nntexts, respectively. Both models are fully differentiable and can be embedded into CNNs for joint t\nraining. We also incorporate the proposed models with the U-Net architecture to detect salient objec\nts. Extensive experiments show that the proposed PiCANets can consistently improve saliency detectio\nn performance. The global and local PiCANets facilitate learning global contrast and homogeneousness\n, respectively. As a result, our saliency model can detect salient objects more accurately and unifo\nrmly, thus performing favorably against the state-of-the-art methods.", "cite_num": 15, "conf": "cvpr", "time": "2018"}, "319": {"title": "curve reconstruction via the global statistics of natural curves", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Barnea_Curve_Reconstruction_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "320": {"title": "what do deep networks like to see?", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Palacio_What_Do_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "321": {"title": "\u201czero-shot\u201d super-resolution using deep internal learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shocher_Zero-Shot_Super-Resolution_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "322": {"title": "detect globally, refine locally: a novel approach to saliency detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Detect_Globally_Refine_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "323": {"title": "beyond the pixel-wise loss for topology-aware delineation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mosinska_Beyond_the_Pixel-Wise_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "324": {"title": "kippi: kinetic polygonal partitioning of images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bauchet_KIPPI_KInetic_Polygonal_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "325": {"title": "image blind denoising with generative adversarial network based noise modeling", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Image_Blind_Denoising_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "326": {"title": "multi-scale weighted nuclear norm image restoration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yair_Multi-Scale_Weighted_Nuclear_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "327": {"title": "monet: moments embedding network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gou_MoNet_Moments_Embedding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "328": {"title": "active fixation control to predict saccade sequences", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wloka_Active_Fixation_Control_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "329": {"title": "densely connected pyramid dehazing network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Densely_Connected_Pyramid_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "330": {"title": "universal denoising networks : a novel cnn architecture for image denoising", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lefkimmiatis_Universal_Denoising_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "331": {"title": "learning convolutional networks for content-weighted image compression", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Learning_Convolutional_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "332": {"title": "deep video super-resolution network using dynamic upsampling filters without explicit motion compensation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "333": {"title": "erase or fill? deep joint recurrent rain removal and reconstruction in videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Erase_or_Fill_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "334": {"title": "flow guided recurrent neural encoder for video salient object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Flow_Guided_Recurrent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "335": {"title": "gated fusion network for single image dehazing", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ren_Gated_Fusion_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "336": {"title": "learning a single convolutional super-resolution network for multiple degradations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Learning_a_Single_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "337": {"title": "non-blind deblurring: handling kernel uncertainty with cnns", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vasu_Non-Blind_Deblurring_Handling_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "338": {"title": "boundary flow: a siamese network that predicts boundary motion without training on motion", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lei_Boundary_Flow_A_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "339": {"title": "learning to see in the dark", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Learning_to_See_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "340": {"title": "bpgrad: towards global optimality in deep learning via branch and pruning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_BPGrad_Towards_Global_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "341": {"title": "perturbative neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Juefei-Xu_Perturbative_Neural_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "342": {"title": "unsupervised correlation analysis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hoshen_Unsupervised_Correlation_Analysis_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "343": {"title": "a biresolution spectral framework for product quantization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mukherjee_A_Biresolution_Spectral_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "344": {"title": "domain adaptive faster r-cnn for object detection in the wild", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Domain_Adaptive_Faster_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "345": {"title": "low-shot learning with large-scale diffusion", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Douze_Low-Shot_Learning_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "346": {"title": "joint pose and expression modeling for facial expression recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Joint_Pose_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "347": {"title": "lightweight probabilistic deep networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gast_Lightweight_Probabilistic_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "348": {"title": "adversarially learned one-class classifier for novelty detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sabokrou_Adversarially_Learned_One-Class_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "349": {"title": "defense against universal adversarial perturbations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Akhtar_Defense_Against_Universal_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "350": {"title": "disentangling factors of variation by mixing them", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Disentangling_Factors_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "351": {"title": "deformable gans for pose-based human image generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Siarohin_Deformable_GANs_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "352": {"title": "hierarchical recurrent attention networks for structured online maps", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Homayounfar_Hierarchical_Recurrent_Attention_CVPR_2018_paper.html", "abstract": "In this paper, we tackle the problem of online road network extraction from sparse 3D point clouds. \nOur method is inspired by how an annotator builds a lane graph, by first identifying how many lanes \nthere are and then drawing each one in turn. We develop a hierarchical recurrent network that attend\ns to initial regions of a lane boundary and traces them out completely by outputting a structured po\nly-line. We also propose a novel differentiable loss function that measures the deviation of the edg\nes of the ground truth polylines and their predictions. This is more suitable than distances on vert\nices, as there exists many ways to draw equivalent polylines. We demonstrate the effectiveness of ou\nr method on a 90 km stretch of highway, and show that we can recover the right topology 92% of the t\nime.", "cite_num": 4, "conf": "cvpr", "time": "2018"}, "353": {"title": "sliced wasserstein distance for learning gaussian mixture models", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kolouri_Sliced_Wasserstein_Distance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "354": {"title": "aligning infinite-dimensional covariance matrices in reproducing kernel hilbert spaces for domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Aligning_Infinite-Dimensional_Covariance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "355": {"title": "clear: cumulative learning for one-shot one-class image recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kozerawski_CLEAR_Cumulative_LEARning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "356": {"title": "local and global optimization techniques in graph-based clustering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ikami_Local_and_Global_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "357": {"title": "multi-task learning by maximizing statistical dependence", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mejjati_Multi-Task_Learning_by_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "358": {"title": "robust classification with convolutional prototype learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Robust_Classification_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "359": {"title": "generative modeling using the sliced wasserstein distance", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Deshpande_Generative_Modeling_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "360": {"title": "learning time/memory-efficient deep architectures with budgeted super networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Veniat_Learning_TimeMemory-Efficient_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "361": {"title": "cross-view image synthesis using conditional gans", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Regmi_Cross-View_Image_Synthesis_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "362": {"title": "sparse, smart contours to represent and edit images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dekel_Sparse_Smart_Contours_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "363": {"title": "anticipating traffic accidents with adaptive loss and large-scale incident db", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Suzuki_Anticipating_Traffic_Accidents_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "364": {"title": "a minimalist approach to type-agnostic detection of quadrics in point clouds", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Birdal_A_Minimalist_Approach_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "365": {"title": "facelet-bank for fast portrait manipulation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Facelet-Bank_for_Fast_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "366": {"title": "visual to sound: generating natural sound for videos in the wild", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Visual_to_Sound_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "367": {"title": "3d-rcnn: instance-level 3d object reconstruction via render-and-compare", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kundu_3D-RCNN_Instance-Level_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "368": {"title": "fast and furious: real time end-to-end 3d detection, tracking and motion forecasting with a single convolutional net", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_Fast_and_Furious_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "369": {"title": "an analysis of scale invariance in object detection \u00ad snip", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Singh_An_Analysis_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "370": {"title": "relation networks for object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Relation_Networks_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "371": {"title": "zero-shot sketch-image hashing", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Zero-Shot_Sketch-Image_Hashing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "372": {"title": "vizwiz grand challenge: answering visual questions from blind people", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gurari_VizWiz_Grand_Challenge_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "373": {"title": "divide and grow: capturing huge diversity in crowd images with incrementally growing cnn", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sam_Divide_and_Grow_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "374": {"title": "structured set matching networks for one-shot part labeling", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Choi_Structured_Set_Matching_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "375": {"title": "self-supervised learning of geometrically stable features through probabilistic introspection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Novotny_Self-Supervised_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "376": {"title": "link and code: fast indexing with graphs and compact regression codes", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Douze_Link_and_Code_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "377": {"title": "textbook question answering under instructor guidance with memory networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Textbook_Question_Answering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "378": {"title": "unsupervised deep generative adversarial hashing network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dizaji_Unsupervised_Deep_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "379": {"title": "vision-and-language navigation: interpreting visually-grounded navigation instructions in real environments", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "380": {"title": "denseaspp for semantic segmentation in street scenes", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "381": {"title": "efficient optimization for rank-based loss functions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mohapatra_Efficient_Optimization_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "382": {"title": "wasserstein introspective neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_Wasserstein_Introspective_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "383": {"title": "taskonomy: disentangling task transfer learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zamir_Taskonomy_Disentangling_Task_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "384": {"title": "maximum classifier discrepancy for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Saito_Maximum_Classifier_Discrepancy_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "385": {"title": "unsupervised feature learning via non-parametric instance discrimination", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "386": {"title": "multi-task adversarial network for disentangled feature learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Multi-Task_Adversarial_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "387": {"title": "learning from synthetic data: addressing domain shift for semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sankaranarayanan_Learning_From_Synthetic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "388": {"title": "empirical study of the topology and geometry of deep networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fawzi_Empirical_Study_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "389": {"title": "boosting domain adaptation by discovering latent domains", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mancini_Boosting_Domain_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "390": {"title": "shape from shading through shape evolution", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Shape_From_Shading_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "391": {"title": "weakly supervised instance segmentation using class peak response", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Weakly_Supervised_Instance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "392": {"title": "collaborative and adversarial network for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Collaborative_and_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "393": {"title": "environment upgrade reinforcement learning for non-differentiable multi-stage pipelines", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xie_Environment_Upgrade_Reinforcement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "394": {"title": "teaching categories to human learners with visual explanations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Aodha_Teaching_Categories_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "395": {"title": "density adaptive point set registration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lawin_Density_Adaptive_Point_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "396": {"title": "left-right comparative recurrent model for stereo matching", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jie_Left-Right_Comparative_Recurrent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "397": {"title": "im2pano3d: extrapolating 360\u00b0 structure and semantics beyond the field of view", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Im2Pano3D_Extrapolating_360deg_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "398": {"title": "polarimetric dense monocular slam", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Polarimetric_Dense_Monocular_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "399": {"title": "a unifying contrast maximization framework for event cameras, with applications to motion, depth, and optical flow estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gallego_A_Unifying_Contrast_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "400": {"title": "modeling facial geometry using compositional vaes", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bagautdinov_Modeling_Facial_Geometry_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "401": {"title": "tangent convolutions for dense prediction in 3d", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "402": {"title": "raynet: learning volumetric 3d reconstruction with ray potentials", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Paschalidou_RayNet_Learning_Volumetric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "403": {"title": "neural 3d mesh renderer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kato_Neural_3D_Mesh_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "404": {"title": "structured attention guided convolutional neural fields for monocular depth estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Structured_Attention_Guided_CVPR_2018_paper.html", "abstract": "Recent works have shown the benefit of integrating Conditional Random Fields (CRFs) models into deep\n architectures for improving pixel-level prediction tasks. Following this line of research, in this \npaper we introduce a novel approach for monocular depth estimation. Similarly to previous works, our\n method employs a continuous CRF to fuse multi-scale information derived from different layers of a \nfront-end Convolutional Neural Network (CNN). Differently from past works, our approach benefits fro\nm a structured attention model which automatically regulates the amount of information transferred b\netween corresponding features at different scales. Importantly, the proposed attention model is seam\nlessly integrated into the CRF, allowing end-to-end training of the entire architecture. Our extensi\nve experimental evaluation demonstrates the effectiveness of the proposed method which is competitiv\ne with previous methods on the KITTI benchmark and outperforms the state of the art on the NYU Depth\n V2 dataset.", "cite_num": 19, "conf": "cvpr", "time": "2018"}, "405": {"title": "automatic 3d indoor scene modeling from single panorama", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Automatic_3D_Indoor_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "406": {"title": "extreme 3d face reconstruction: seeing through occlusions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tran_Extreme_3D_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "407": {"title": "beyond grobner bases: basis selection for minimal solvers", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Larsson_Beyond_Grobner_Bases_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "408": {"title": "lions and tigers and bears: capturing non-rigid, 3d, articulated shape from images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zuffi_Lions_and_Tigers_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "409": {"title": "deep cocktail network: multi-source unsupervised domain adaptation with category shift", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Deep_Cocktail_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "410": {"title": "dota: a large-scale dataset for object detection in aerial images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xia_DOTA_A_Large-Scale_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "411": {"title": "finding beans in burgers: deep semantic-visual embedding with localization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Engilberge_Finding_Beans_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "412": {"title": "feature super-resolution: make machine see more clearly", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tan_Feature_Super-Resolution_Make_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "413": {"title": "clusternet: detecting small objects in large scenes by exploiting spatio-temporal information", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/LaLonde_ClusterNet_Detecting_Small_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "414": {"title": "masklab: instance segmentation by refining object detection with semantic and direction features", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_MaskLab_Instance_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "415": {"title": "hashing as tie-aware learning to rank", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_Hashing_as_Tie-Aware_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "416": {"title": "classification-driven dynamic image enhancement", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sharma_Classification-Driven_Dynamic_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "417": {"title": "knowledge aided consistency for weakly supervised phrase grounding", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Knowledge_Aided_Consistency_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "418": {"title": "who let the dogs out? modeling dog behavior from visual data", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ehsani_Who_Let_the_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "419": {"title": "pseudo mask augmented object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Pseudo_Mask_Augmented_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "420": {"title": "dual skipping networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_Dual_Skipping_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "421": {"title": "memory matching networks for one-shot image recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cai_Memory_Matching_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "422": {"title": "iqa: visual question answering in interactive environments", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gordon_IQA_Visual_Question_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "423": {"title": "pose transferrable person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Pose_Transferrable_Person_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "424": {"title": "large scale fine-grained categorization and domain-specific transfer learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "425": {"title": "data distillation: towards omni-supervised learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Radosavovic_Data_Distillation_Towards_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "426": {"title": "object referring in videos with language and human gaze", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vasudevan_Object_Referring_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "427": {"title": "feature selective networks for object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhai_Feature_Selective_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "428": {"title": "learning a discriminative filter bank within a cnn for fine-grained recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Learning_a_Discriminative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "429": {"title": "grounding referring expressions in images by variational context", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Grounding_Referring_Expressions_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "430": {"title": "dynamic graph generation network: generating relational knowledge from diagrams", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_Dynamic_Graph_Generation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "431": {"title": "a network architecture for point cloud classification via automatic depth images generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Roveri_A_Network_Architecture_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "432": {"title": "towards dense object tracking in a 2d honeybee hive", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bozek_Towards_Dense_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "433": {"title": "long-term on-board prediction of people in traffic scenes under uncertainty", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bhattacharyya_Long-Term_On-Board_Prediction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "434": {"title": "single-shot refinement neural network for object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Single-Shot_Refinement_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "435": {"title": "video captioning via hierarchical reinforcement learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Video_Captioning_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "436": {"title": "tips and tricks for visual question answering: learnings from the 2017 challenge", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Teney_Tips_and_Tricks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "437": {"title": "learning to segment every thing", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Learning_to_Segment_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "438": {"title": "self-supervised adversarial hashing networks for cross-modal retrieval", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Self-Supervised_Adversarial_Hashing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "439": {"title": "parallel attention: a unified framework for visual object discovery through dialogs and queries", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhuang_Parallel_Attention_A_CVPR_2018_paper.html", "abstract": "Recognising objects according to a pre-defined fixed set of class labels has been well studied in th\ne Computer Vision. There are a great many practical applications where the subjects that may be of i\nnterest are not known beforehand, or so easily delineated, however. In many of these cases natural l\nanguage dialog is a natural way to specify the subject of interest, and the task achieving this capa\nbility (a.k.a, Referring Expression Comprehension) has recently attracted attention. To this end we \npropose a unified framework, the ParalleL AttentioN (PLAN) network, to discover the object in an ima\nge that is being referred to in variable length natural expression descriptions, from short phrases \nquery to long multi-round dialogs. The PLAN network has two attention mechanisms that relate parts o\nf the expressions to both the global visual content and also directly to object candidates. Furtherm\nore, the attention mechanisms are recurrent, making the referring process visualizable and explainab\nle. The attended information from these dual sources are combined to reason about the referred objec\nt. These two attention mechanisms can be trained in parallel and we find the combined system outperf\norms the state-of-art on several benchmarked datasets with different length language input, such as \nRefCOCO, RefCOCO+ and GuessWhat?!.", "cite_num": 9, "conf": "cvpr", "time": "2018"}, "440": {"title": "zigzag learning for weakly supervised object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Zigzag_Learning_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "441": {"title": "attentive fashion grammar network for fashion landmark detection and clothing category classification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Attentive_Fashion_Grammar_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "442": {"title": "generalized zero-shot learning via synthesized examples", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Verma_Generalized_Zero-Shot_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "443": {"title": "partially shared multi-task convolutional neural network with local constraint for face attribute learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Partially_Shared_Multi-Task_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "444": {"title": "syq: learning symmetric quantization for efficient deep neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Faraone_SYQ_Learning_Symmetric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "445": {"title": "ds*: tighter lifting-free convex relaxations for quadratic matching problems", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bernard_DS_Tighter_Lifting-Free_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "446": {"title": "deep mutual learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Deep_Mutual_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "447": {"title": "coupled end-to-end transfer learning with generalized fisher information", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Coupled_End-to-End_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "448": {"title": "residual parameter transfer for deep domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rozantsev_Residual_Parameter_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "449": {"title": "high-order tensor regularization with application to attribute ranking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_High-Order_Tensor_Regularization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "450": {"title": "learning to localize sound source in visual scenes", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Senocak_Learning_to_Localize_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "451": {"title": "dynamic few-shot visual learning without forgetting", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gidaris_Dynamic_Few-Shot_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "452": {"title": "two-step quantization for low-bit neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Two-Step_Quantization_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "453": {"title": "improved lossy image compression with priming and spatially adaptive bit rates for recurrent networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Johnston_Improved_Lossy_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "454": {"title": "conditional probability models for deep image compression", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mentzer_Conditional_Probability_Models_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "455": {"title": "deep diffeomorphic transformer networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Detlefsen_Deep_Diffeomorphic_Transformer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "456": {"title": "the lov\u00e1sz-softmax loss: a tractable surrogate for the optimization of the intersection-over-union measure in neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Berman_The_LovaSz-Softmax_Loss_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "457": {"title": "generative adversarial perturbations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Poursaeed_Generative_Adversarial_Perturbations_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "458": {"title": "learning strict identity mappings in deep residual networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Learning_Strict_Identity_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "459": {"title": "geometric robustness of deep networks: analysis and improvement", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kanbak_Geometric_Robustness_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "460": {"title": "view extrapolation of human body from a single image", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_View_Extrapolation_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "461": {"title": "geometry aware constrained optimization techniques for deep learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Roy_Geometry_Aware_Constrained_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "462": {"title": "pointnetvlad: deep point cloud based retrieval for large-scale place recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "463": {"title": "an efficient and provable approach for mixture proportion estimation using linear independence assumption", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_An_Efficient_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "464": {"title": "voxelnet: end-to-end learning for point cloud based 3d object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_VoxelNet_End-to-End_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "465": {"title": "image to image translation for domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Murez_Image_to_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "466": {"title": "mobilenetv2: inverted residuals and linear bottlenecks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "467": {"title": "im2struct: recovering 3d shape structure from a single rgb image", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Niu_Im2Struct_Recovering_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "468": {"title": "trust your model: light field depth estimation with inline occlusion handling", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Schilling_Trust_Your_Model_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "469": {"title": "baseline desensitizing in translation averaging", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhuang_Baseline_Desensitizing_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "470": {"title": "mining point cloud local structures by kernel correlation and graph pooling", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Mining_Point_Cloud_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "471": {"title": "large-scale point cloud semantic segmentation with superpoint graphs", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Landrieu_Large-Scale_Point_Cloud_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "472": {"title": "very large-scale global sfm by distributed motion averaging", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_Very_Large-Scale_Global_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "473": {"title": "scancomplete: large-scale scene completion and semantic segmentation for 3d scans", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dai_ScanComplete_Large-Scale_Scene_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "474": {"title": "solving the perspective-2-point problem for flying-camera photo composition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lan_Solving_the_Perspective-2-Point_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "475": {"title": "reflection removal for large-scale 3d point clouds", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yun_Reflection_Removal_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "476": {"title": "attentional shapecontextnet for point cloud recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xie_Attentional_ShapeContextNet_for_CVPR_2018_paper.html", "abstract": "We tackle the problem of point cloud recognition. Unlike previous approaches where a point cloud is \neither converted into a volume/image or represented independently in a permutation-invariant set, we\n develop a new representation by adopting the concept of shape context as the building block in our \nnetwork design. The resulting model, called ShapeContextNet, consists of a hierarchy with modules no\nt relying on a fixed grid while still enjoying properties similar to those in convolutional neural n\networks - being able to capture and propagate the object part information. In addition, we find insp\niration from self-attention based models to include a simple yet effective contextual modeling mecha\nnism - making the contextual region selection, the feature aggregation, and the feature transformati\non process fully automatic. ShapeContextNet is an end-to-end model that can be applied to the genera\nl point cloud classification and segmentation problems. We observe competitive results on a number o\nf benchmark datasets.", "cite_num": 16, "conf": "cvpr", "time": "2018"}, "477": {"title": "geometry-aware deep network for single-image novel view synthesis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Geometry-Aware_Deep_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "478": {"title": "inversefacenet: deep monocular inverse face rendering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_InverseFaceNet_Deep_Monocular_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "479": {"title": "sparse photometric 3d face reconstruction guided by morphable models", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Sparse_Photometric_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "480": {"title": "texture mapping for 3d reconstruction with rgb-d sensor", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fu_Texture_Mapping_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "481": {"title": "learning less is more - 6d camera localization via 3d surface regression", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Brachmann_Learning_Less_Is_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "482": {"title": "feature mapping for learning fast and accurate 3d pose inference from synthetic images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rad_Feature_Mapping_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "483": {"title": "indoor rgb-d compass from a single line and plane", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_Indoor_RGB-D_Compass_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "484": {"title": "geometry-aware network for non-rigid shape prediction from a single view", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pumarola_Geometry-Aware_Network_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "485": {"title": "sim2real viewpoint invariant visual servoing by recurrent control", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sadeghi_Sim2Real_Viewpoint_Invariant_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "486": {"title": "docunet: document image unwarping via a stacked u-net", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ma_DocUNet_Document_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "487": {"title": "analysis of hand segmentation in the wild", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Urooj_Analysis_of_Hand_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "488": {"title": "roadtracer: automatic extraction of road networks from aerial images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bastani_RoadTracer_Automatic_Extraction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "489": {"title": "alternating-stereo vins: observability analysis and performance evaluation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Paul_Alternating-Stereo_VINS_Observability_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "490": {"title": "soccer on your tabletop", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rematas_Soccer_on_Your_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "491": {"title": "epinet: a fully-convolutional neural network using epipolar geometry for depth from light field images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shin_EPINET_A_Fully-Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "492": {"title": "a hybrid l1-l0 layer decomposition model for tone mapping", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liang_A_Hybrid_l1-l0_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "493": {"title": "deeply learned filter response functions for hyperspectral reconstruction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nie_Deeply_Learned_Filter_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "494": {"title": "crrn: multi-scale guided concurrent reflection removal network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wan_CRRN_Multi-Scale_Guided_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "495": {"title": "single image reflection separation with perceptual losses", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Single_Image_Reflection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "496": {"title": "a robust method for strong rolling shutter effects correction using lines with automatic feature selection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lao_A_Robust_Method_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "497": {"title": "time-resolved light transport decomposition for thermal photometric stereo", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tanaka_Time-Resolved_Light_Transport_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "498": {"title": "efficient diverse ensemble for discriminative co-tracking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Meshgi_Efficient_Diverse_Ensemble_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "499": {"title": "rolling shutter and radial distortion are features for high frame rate multi-camera tracking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bapat_Rolling_Shutter_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "500": {"title": "a twofold siamese network for real-time object tracking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_A_Twofold_Siamese_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "501": {"title": "multi-cue correlation filters for robust visual tracking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Multi-Cue_Correlation_Filters_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "502": {"title": "learning attentions: residual attentional siamese network for high performance online visual tracking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Learning_Attentions_Residual_CVPR_2018_paper.html", "abstract": "Offline training for object tracking has recently shown great potentials in balancing tracking accur\nacy and speed. However, it is still difficult to adapt an offline trained model to a target tracked \nonline. This work presents a Residual Attentional Siamese Network (RASNet) for high performance obje\nct tracking. The RASNet model reformulates the correlation filter within a Siamese tracking framewor\nk, and introduces different kinds of the attention mechanisms to adapt the model without updating th\ne model online. In particular, by exploiting the offline trained general attention, the target adapt\ned residual attention, and the channel favored feature attention, the RASNet not only mitigates the \nover-fitting problem in deep network training, but also enhances its discriminative capacity and ada\nptability due to the separation of representation learning and discriminator learning. The proposed \ndeep architecture is trained from end to end and takes full advantage of the rich spatial temporal i\nnformation to achieve robust visual tracking. Experimental results on two latest benchmarks, OTB-201\n5 and VOT2017, show that the RASNet tracker has the state-of-the-art tracking accuracy while runs at\n more than 80 frames per second.", "cite_num": 41, "conf": "cvpr", "time": "2018"}, "503": {"title": "sint++: robust visual tracking via adversarial positive instance generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_SINT_Robust_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "504": {"title": "high-speed tracking with multi-kernel correlation filters", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tang_High-Speed_Tracking_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "505": {"title": "occlusion aware unsupervised learning of optical flow", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Occlusion_Aware_Unsupervised_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "506": {"title": "revisiting video saliency: a large-scale benchmark and a new model", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Revisiting_Video_Saliency_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "507": {"title": "learning spatial-temporal regularized correlation filters for visual tracking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Learning_Spatial-Temporal_Regularized_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "508": {"title": "multimodal visual concept learning with weakly supervised techniques", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bouritsas_Multimodal_Visual_Concept_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "509": {"title": "efficient large-scale approximate nearest neighbor search on opencl fpga", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Efficient_Large-Scale_Approximate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "510": {"title": "learning a complete image indexing pipeline", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jain_Learning_a_Complete_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "511": {"title": "transparency by design: closing the gap between performance and interpretability in visual reasoning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mascharka_Transparency_by_Design_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "512": {"title": "fooling vision and language models despite localization and attention mechanism", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Fooling_Vision_and_CVPR_2018_paper.html", "abstract": "Adversarial attacks are known to succeed on classifiers, but it has been an open question whether mo\nre complex vision systems are vulnerable. In this paper, we study adversarial examples for vision an\nd language models, which incorporate natural language understanding and complex structures such as a\nttention, localization, and modular architectures. In particular, we investigate attacks on a dense \ncaptioning model and on two visual question answering (VQA) models. Our evaluation shows that we can\n generate adversarial examples with a high success rate (i.e., > 90%) for these models. Our work she\nds new light on understanding adversarial attacks on vision systems which have a language component \nand shows that attention, bounding box localization, and compositional internal structures are vulne\nrable to adversarial attacks. These observations will inform future work towards building effective \ndefenses.", "cite_num": 9, "conf": "cvpr", "time": "2018"}, "513": {"title": "categorizing concepts with basic level for vision-to-language", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Categorizing_Concepts_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "514": {"title": "don't just assume; look and answer: overcoming priors for visual question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Agrawal_Dont_Just_Assume_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "515": {"title": "learning pixel-level semantic affinity with image-level supervision for weakly supervised semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ahn_Learning_Pixel-Level_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "516": {"title": "from lifestyle vlogs to everyday interactions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fouhey_From_Lifestyle_Vlogs_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "517": {"title": "cross-domain weakly-supervised object detection through progressive domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "518": {"title": "rotationnet: joint object categorization and pose estimation using multiviews from unsupervised viewpoints", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kanezaki_RotationNet_Joint_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "519": {"title": "an end-to-end textspotter with explicit alignment and attention", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_An_End-to-End_TextSpotter_CVPR_2018_paper.html", "abstract": "Text detection and recognition in natural images have long been considered as two separate tasks tha\nt are processed sequentially. Jointly training two tasks is non-trivial due to significant differenc\nes in learning difficulties and convergence rates. In this work, we present a conceptually simple ye\nt efficient framework that simultaneously processes the two tasks in a united framework. Our main co\nntributions are three-fold: (1) we propose a novel text-alignment layer that allows it to precisely \ncompute convolutional features of a text instance in arbitrary orientation, which is the key to boos\nt the performance; (2) a character attention mechanism is introduced by using character spatial info\nrmation as explicit supervision, leading to large improvements in recognition; (3) two technologies,\n together with a new RNN branch for word recognition, are integrated seamlessly into a single model \nwhich is end-to-end trainable. This allows the two tasks to work collaboratively by sharing convolut\nional features, which is critical to identify challenging text instances. Our model obtains impressi\nve results in end-to-end recognition on the ICDAR 2015 [19], significantly advancing the most recent\n results [2], with improvements of F-measure from (0.54, 0.51, 0.47) to (0.82, 0.77, 0.63), by using\n a strong, weak and generic lexicon respectively. Thanks to joint training, our method can also serv\ne as a good detector by achieving a new state-of-the-art detection performance on related benchmarks\n. Code is available at https://github.com/tonghe90/textspotter.", "cite_num": 14, "conf": "cvpr", "time": "2018"}, "520": {"title": "wildtrack: a multi-camera hd dataset for dense unscripted pedestrian detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chavdarova_WILDTRACK_A_Multi-Camera_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "521": {"title": "direct shape regression networks for end-to-end face alignment", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Miao_Direct_Shape_Regression_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "522": {"title": "natural and effective obfuscation by head inpainting", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Natural_and_Effective_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "523": {"title": "3d semantic trajectory reconstruction from 3d pixel continuum", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yoon_3D_Semantic_Trajectory_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "524": {"title": "optimizing filter size in convolutional neural networks for facial action unit recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Han_Optimizing_Filter_Size_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "525": {"title": "v2v-posenet: voxel-to-voxel prediction network for accurate 3d hand and human pose estimation from a single depth map", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Moon_V2V-PoseNet_Voxel-to-Voxel_Prediction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "526": {"title": "ring loss: convex feature normalization for face recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zheng_Ring_Loss_Convex_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "527": {"title": "adversarially occluded samples for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Adversarially_Occluded_Samples_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "528": {"title": "classifier learning with prior probabilities for facial action unit recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Classifier_Learning_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "529": {"title": "4dfab: a large scale 4d database for facial expression analysis and biometric applications", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_4DFAB_A_Large_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "530": {"title": "seeing small faces from robust anchor's perspective", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_Seeing_Small_Faces_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "531": {"title": "2d/3d pose estimation and action recognition using multitask deep learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luvizon_2D3D_Pose_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "532": {"title": "dense 3d regression for hand pose estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wan_Dense_3D_Regression_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "533": {"title": "camera style adaptation for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhong_Camera_Style_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "534": {"title": "posetrack: a benchmark for human pose estimation and tracking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Andriluka_PoseTrack_A_Benchmark_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "535": {"title": "exploit the unknown gradually: one-shot video-based person re-identification by stepwise learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Exploit_the_Unknown_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "536": {"title": "pose-robust face recognition via deep residual equivariant mapping", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Pose-Robust_Face_Recognition_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "537": {"title": "decidenet: counting varying density crowds through attention guided detection and density estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_DecideNet_Counting_Varying_CVPR_2018_paper.html", "abstract": "In real-world crowd counting applications, the crowd densities vary greatly in spatial and temporal \ndomains. A detection based counting method will estimate crowds accurately in low density scenes, wh\nile its reliability in congested areas is downgraded. A regression based approach, on the other hand\n, captures the general density information in crowded regions. Without knowing the location of each \nperson, it tends to overestimate the count in low density areas. Thus, exclusively using either one \nof them is not sufficient to handle all kinds of scenes with varying densities. To address this issu\ne, a novel end-to-end crowd counting framework, named DecideNet (DEteCtIon and Density Estimation Ne\ntwork) is proposed. It can adaptively decide the appropriate counting mode for different locations o\nn the image based on its real density conditions. DecideNet starts with estimating the crowd density\n by generating detection and regression based density maps separately. To capture inevitable variati\non in densities, it incorporates an attention module, meant to adaptively assess the reliability of \nthe two types of estimations. The final crowd counts are obtained with the guidance of the attention\n module to adopt suitable estimations from the two kinds of density maps. Experimental results show \nthat our method achieves state-of-the-art performance on three challenging crowd counting datasets.", "cite_num": 23, "conf": "cvpr", "time": "2018"}, "538": {"title": "lstm pose machines", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_LSTM_Pose_Machines_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "539": {"title": "disentangling features in 3d face shapes for joint face reconstruction and recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Disentangling_Features_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "540": {"title": "convolutional sequence to sequence model for human dynamics", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Convolutional_Sequence_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "541": {"title": "gesture recognition: focus on the hands", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Narayana_Gesture_Recognition_Focus_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "542": {"title": "crowd counting via adversarial cross-scale consistency pursuit", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Crowd_Counting_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "543": {"title": "3d human pose estimation in the wild by adversarial learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_3D_Human_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "544": {"title": "cosface: large margin cosine loss for deep face recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_CosFace_Large_Margin_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "545": {"title": "encoding crowd interaction with deep neural network for pedestrian trajectory prediction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Encoding_Crowd_Interaction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "546": {"title": "mean-variance loss for deep age estimation from a face", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pan_Mean-Variance_Loss_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "547": {"title": "probabilistic joint face-skull modelling for facial reconstruction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Madsen_Probabilistic_Joint_Face-Skull_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "548": {"title": "learning latent super-events to detect multiple activities in videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Piergiovanni_Learning_Latent_Super-Events_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "549": {"title": "temporal hallucinating for action recognition with few still images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Temporal_Hallucinating_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "550": {"title": "deep progressive reinforcement learning for skeleton-based action recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tang_Deep_Progressive_Reinforcement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "551": {"title": "gaze prediction in dynamic 360\u00b0 immersive videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Gaze_Prediction_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "552": {"title": "when will you do what? - anticipating temporal occurrences of activities", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Abu_Farha_When_Will_You_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "553": {"title": "fusing crowd density maps and visual object trackers for people tracking in crowd scenes", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ren_Fusing_Crowd_Density_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "554": {"title": "dual attention matching network for context-aware feature sequence based person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Si_Dual_Attention_Matching_CVPR_2018_paper.html", "abstract": "Typical person re-identification (ReID) methods usually describe each pedestrian with a single featu\nre vector and match them in a task-specific metric space. However, the methods based on a single fea\nture vector are not sufficient enough to overcome visual ambiguity, which frequently occurs in real \nscenario. In this paper, we propose a novel end-to-end trainable framework, called Dual ATtention Ma\ntching network (DuATM), to learn context-aware feature sequences and perform attentive sequence comp\narison simultaneously. The core component of our DuATM framework is a dual attention mechanism, in w\nhich both intra-sequence and inter-sequence attention strategies are used for feature refinement and\n feature-pair alignment, respectively. Thus, detailed visual cues contained in the intermediate feat\nure sequences can be automatically exploited and properly compared. We train the proposed DuATM netw\nork as a siamese network via a triplet loss assisted with a de-correlation loss and a cross-entropy \nloss. We conduct extensive experiments on both image and video based ReID benchmark datasets. Experi\nmental results demonstrate the significant advantages of our approach compared to the state-of-the-a\nrt methods.", "cite_num": 32, "conf": "cvpr", "time": "2018"}, "555": {"title": "easy identification from better constraints: multi-shot person re-identification from reference constraints", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Easy_Identification_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "556": {"title": "crowd counting with deep negative correlation learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shi_Crowd_Counting_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "557": {"title": "human appearance transfer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zanfir_Human_Appearance_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "558": {"title": "domain generalization with adversarial feature learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Domain_Generalization_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "559": {"title": "pyramid stereo matching network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_Pyramid_Stereo_Matching_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "560": {"title": "event-based vision meets deep learning on steering prediction for self-driving cars", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Maqueda_Event-Based_Vision_Meets_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "561": {"title": "learning answer embeddings for visual question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Learning_Answer_Embeddings_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "562": {"title": "good view hunting: learning photo composition from dense view pairs", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Good_View_Hunting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "563": {"title": "cleannet: transfer learning for scalable image classifier training with label noise", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lee_CleanNet_Transfer_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "564": {"title": "independently recurrent neural network (indrnn): building a longer and deeper rnn", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Independently_Recurrent_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "565": {"title": "mix and match networks: encoder-decoder alignment for zero-pair image translation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Mix_and_Match_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "566": {"title": "structured uncertainty prediction networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dorta_Structured_Uncertainty_Prediction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "567": {"title": "between-class learning for image classification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tokozume_Between-Class_Learning_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "568": {"title": "adversarial feature augmentation for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Volpi_Adversarial_Feature_Augmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "569": {"title": "generative image inpainting with contextual attention", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Generative_Image_Inpainting_CVPR_2018_paper.html", "abstract": "Recent deep learning based approaches have shown promising results on image inpainting for the chall\nenging task of filling in large missing regions in an image. These methods can generate visually pla\nusible image structures and textures, but often create distorted structures or blurry textures incon\nsistent with surrounding areas. This is mainly due to ineffectiveness of convolutional neural networ\nks in explicitly borrowing or copying information from distant spatial locations. On the other hand,\n traditional texture and patch synthesis approaches are particularly suitable when it needs to borro\nw textures from the surrounding regions. Motivated by these observations, we propose a new deep gene\nrative model-based approach which can not only synthesize novel image structures but also explicitly\n utilize surrounding image features as references during network training to make better predictions\n. The model is a feed-forward, fully convolutional neural network which can process images with mult\niple holes at arbitrary locations and with variable sizes during the test time. Experiments on multi\nple datasets including faces, textures and natural images demonstrate that the proposed approach gen\nerates higher-quality inpainting results than existing ones. Code and trained models will be release\nd.", "cite_num": 81, "conf": "cvpr", "time": "2018"}, "570": {"title": "csgnet: neural shape parser for constructive solid geometry", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sharma_CSGNet_Neural_Shape_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "571": {"title": "conditional image-to-image translation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_Conditional_Image-to-Image_Translation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "572": {"title": "continuous relaxation of map inference: a nonconvex perspective", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Le-Huu_Continuous_Relaxation_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "573": {"title": "feature generating networks for zero-shot learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xian_Feature_Generating_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "574": {"title": "joint optimization framework for learning with noisy labels", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tanaka_Joint_Optimization_Framework_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "575": {"title": "convolutional image captioning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Aneja_Convolutional_Image_Captioning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "576": {"title": "aon: towards arbitrarily-oriented text recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_AON_Towards_Arbitrarily-Oriented_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "577": {"title": "wrapped gaussian process regression on riemannian manifolds", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mallasto_Wrapped_Gaussian_Process_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "578": {"title": "geometry guided convolutional neural networks for self-supervised video representation learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gan_Geometry_Guided_Convolutional_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "579": {"title": "diversenet: when one right answer is not enough", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Firman_DiverseNet_When_One_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "580": {"title": "deep face detector adaptation without negative transfer or catastrophic forgetting", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jamal_Deep_Face_Detector_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "581": {"title": "analyzing filters toward efficient convnet", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kobayashi_Analyzing_Filters_Toward_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "582": {"title": "regularizing deep networks by modeling and predicting label structure", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mostajabi_Regularizing_Deep_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "583": {"title": "in-place activated batchnorm for memory-optimized training of dnns", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bulo_In-Place_Activated_BatchNorm_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "584": {"title": "dvqa: understanding data visualizations via question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kafle_DVQA_Understanding_Data_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "585": {"title": "da-gan: instance-level image translation by deep attention generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ma_DA-GAN_Instance-Level_Image_CVPR_2018_paper.html", "abstract": "Unsupervised image translation, which aims in translating two independent sets of images, is challen\nging in discovering the correct correspondences without paired data. Existing works build upon Gener\native Adversarial Networks (GANs) such that the distribution of the translated images are indistingu\nishable from the distribution of the target set. However, such set-level constraints cannot learn th\ne instance-level correspondences (e.g. aligned semantic parts in object transfiguration task). This \nlimitation often results in false positives (e.g. geometric or semantic artifacts), and further lead\ns to mode collapse problem. To address the above issues, we propose a novel framework for instance-l\nevel image translation by Deep Attention GAN (DA-GAN). Such a design enables DA-GAN to decompose the\n task of translating samples from two sets into translating instances in a highly-structured latent \nspace. Specifically, we jointly learn a deep attention encoder, and the instance-level correspondenc\nes could be consequently discovered through attending on the learned instances. Therefore, the const\nraints could be exploited on both set-level and instance-level. Comparisons against several state-of\n-the-arts demonstrate the superiority of our approach, and the broad application capability, e.g, po\nse morphing, data augmentation, etc., pushes the margin of domain translation problem.1", "cite_num": 12, "conf": "cvpr", "time": "2018"}, "586": {"title": "unsupervised learning of depth and ego-motion from monocular video using 3d geometric constraints", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mahjourian_Unsupervised_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "587": {"title": "fots: fast oriented text spotting with a unified network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_FOTS_Fast_Oriented_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "588": {"title": "mobile video object detection with temporally-aware feature maps", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Mobile_Video_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "589": {"title": "weakly supervised phrase localization with multi-scale anchored transformer network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Weakly_Supervised_Phrase_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "590": {"title": "revisiting oxford and paris: large-scale image retrieval benchmarking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Radenovic_Revisiting_Oxford_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "591": {"title": "cross-dataset adaptation for visual question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chao_Cross-Dataset_Adaptation_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "592": {"title": "globally optimal inlier set maximization for atlanta frame estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Joo_Globally_Optimal_Inlier_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "593": {"title": "end-to-end convolutional semantic embeddings", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/You_End-to-End_Convolutional_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "594": {"title": "referring image segmentation via recurrent refinement networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Referring_Image_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "595": {"title": "two can play this game: visual dialog with discriminative question generation and answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jain_Two_Can_Play_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "596": {"title": "generative adversarial learning towards fast weakly supervised detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Generative_Adversarial_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "597": {"title": "a deeper look at power normalizations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Koniusz_A_Deeper_Look_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "598": {"title": "dimensionality's blessing: clustering images by underlying distribution", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_Dimensionalitys_Blessing_Clustering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "599": {"title": "eliminating background-bias for robust person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tian_Eliminating_Background-Bias_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "600": {"title": "learning to evaluate image captioning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cui_Learning_to_Evaluate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "601": {"title": "single-shot object detection with enriched semantics", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Single-Shot_Object_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "602": {"title": "low-shot learning with imprinted weights", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Low-Shot_Learning_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "603": {"title": "neural motifs: scene graph parsing with global context", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zellers_Neural_Motifs_Scene_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "604": {"title": "variational autoencoders for deforming 3d mesh models", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tan_Variational_Autoencoders_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "605": {"title": "fast monte-carlo localization on aerial vehicles using approximate continuous belief representations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dhawale_Fast_Monte-Carlo_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "606": {"title": "dels-3d: deep localization and segmentation with a 3d semantic map", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_DeLS-3D_Deep_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "607": {"title": "lidar-video driving dataset: learning driving policies effectively", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "608": {"title": "logo synthesis and manipulation with clustered generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sage_Logo_Synthesis_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "609": {"title": "egocentric basketball motion planning from a single first-person image", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bertasius_Egocentric_Basketball_Motion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "610": {"title": "human-centric indoor scene synthesis using stochastic grammar", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Human-Centric_Indoor_Scene_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "611": {"title": "rotation-sensitive regression for oriented scene text detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liao_Rotation-Sensitive_Regression_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "612": {"title": "separating self-expression and visual content in hashtag supervision", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Veit_Separating_Self-Expression_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "613": {"title": "distort-and-recover: color enhancement using deep reinforcement learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Park_Distort-and-Recover_Color_Enhancement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "614": {"title": "im2flow: motion hallucination from static images for action recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gao_Im2Flow_Motion_Hallucination_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "615": {"title": "finding \"it\": weakly-supervised reference-aware visual grounding in instructional videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Finding_It_Weakly-Supervised_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "616": {"title": "actor and action video segmentation from a sentence", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gavrilyuk_Actor_and_Action_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "617": {"title": "egocentric activity recognition on a budget", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Possas_Egocentric_Activity_Recognition_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "618": {"title": "cnn in mrf: video object segmentation via inference in a cnn-based higher-order spatio-temporal mrf", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bao_CNN_in_MRF_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "619": {"title": "action sets: weakly supervised action segmentation without ordering constraints", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Richard_Action_Sets_Weakly_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "620": {"title": "low-latency video semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Low-Latency_Video_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "621": {"title": "fine-grained video captioning for sports narrative", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Fine-Grained_Video_Captioning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "622": {"title": "end-to-end learning of motion representation for video understanding", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fan_End-to-End_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "623": {"title": "compressed video action recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Compressed_Video_Action_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "624": {"title": "features for multi-target multi-camera tracking and re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ristani_Features_for_Multi-Target_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "625": {"title": "ava: a video dataset of spatio-temporally localized atomic visual actions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gu_AVA_A_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "626": {"title": "who's better? who's best? pairwise deep ranking for skill determination", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Doughty_Whos_Better_Whos_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "627": {"title": "mx-lstm: mixing tracklets and vislets to jointly forecast trajectories and head poses", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hasan_MX-LSTM_Mixing_Tracklets_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "628": {"title": "bottom-up and top-down attention for image captioning and visual question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.html", "abstract": "Top-down visual attention mechanisms have been used extensively in image captioning and visual quest\nion answering (VQA) to enable deeper image understanding through fine-grained analysis and even mult\niple steps of reasoning. In this work, we propose a combined bottom-up and top-down attention mechan\nism that enables attention to be calculated at the level of objects and other salient image regions.\n This is the natural basis for attention to be considered. Within our approach, the bottom-up mechan\nism (based on Faster R-CNN) proposes image regions, each with an associated feature vector, while th\ne top-down mechanism determines feature weightings. Applying this approach to image captioning, our \nresults on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / S\nPICE / BLEU-4 scores of 117.9, 21.5 and 36.9, respectively. Demonstrating the broad applicability of\n the method, applying the same approach to VQA we obtain first place in the 2017 VQA Challenge.", "cite_num": 198, "conf": "cvpr", "time": "2018"}, "629": {"title": "improved fusion of visual and language representations by dense symmetric co-attention for visual question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nguyen_Improved_Fusion_of_CVPR_2018_paper.html", "abstract": "A key solution to visual question answering (VQA) exists in how to fuse visual and language features\n extracted from an input image and question. We show that an attention mechanism that enables dense,\n bi-directional interactions between the two modalities contributes to boost accuracy of prediction \nof answers. Specifically, we present a simple architecture that is fully symmetric between visual an\nd language representations, in which each question word attends on image regions and each image regi\non attends on question words. It can be stacked to form a hierarchy for multi-step interactions betw\neen an image-question pair. We show through experiments that the proposed architecture achieves a ne\nw state-of-the-art on VQA and VQA 2.0 despite its small size. We also present qualitative evaluation\n, demonstrating how the proposed attention mechanism can generate reasonable attention maps on image\ns and questions, which leads to the correct answer prediction.", "cite_num": 14, "conf": "cvpr", "time": "2018"}, "630": {"title": "flipdial: a generative model for two-way visual dialogue", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Massiceti_FlipDial_A_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "631": {"title": "are you talking to me? reasoned visual dialog generation through adversarial learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Are_You_Talking_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "632": {"title": "visual question generation as dual task of visual question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Visual_Question_Generation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "633": {"title": "unsupervised textual grounding: linking words to image concepts", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yeh_Unsupervised_Textual_Grounding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "634": {"title": "focal visual-text attention for visual question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liang_Focal_Visual-Text_Attention_CVPR_2018_paper.html", "abstract": "Recent insights on language and vision with neural networks have been successfully applied to simple\n single-image visual question answering. However, to tackle real-life question answering problems on\n multimedia collections such as personal photos, we have to look at whole collections with sequences\n of photos or videos. When answering questions from a large collection, a natural problem is to iden\ntify snippets to support the answer. In this paper, we describe a novel neural network called Focal \nVisual-Text Attention network (FVTA) for collective reasoning in visual question answering, where bo\nth visual and text sequence information such as images and text metadata are presented. FVTA introdu\nces an end-to-end approach that makes use of a hierarchical process to dynamically determine what me\ndia and what time to focus on in the sequential data to answer the question. FVTA can not only answe\nr the questions well but also provides the justifications which the system results are based upon to\n get the answers. FVTA achieves state-of-the-art performance on the MemexQA dataset and competitive \nresults on the MovieQA dataset.", "cite_num": 10, "conf": "cvpr", "time": "2018"}, "635": {"title": "segan: segmenting and generating the invisible", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ehsani_SeGAN_Segmenting_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "636": {"title": "cascade r-cnn: delving into high quality object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cai_Cascade_R-CNN_Delving_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "637": {"title": "learning semantic concepts and order for image and sentence matching", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Learning_Semantic_Concepts_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "638": {"title": "functional map of the world", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Christie_Functional_Map_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "639": {"title": "megdet: a large mini-batch object detector", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Peng_MegDet_A_Large_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "640": {"title": "learning globally optimized object detector via policy gradient", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rao_Learning_Globally_Optimized_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "641": {"title": "photographic text-to-image synthesis with a hierarchically-nested adversarial network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Photographic_Text-to-Image_Synthesis_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "642": {"title": "illuminant spectra-based source separation using flash photography", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hui_Illuminant_Spectra-Based_Source_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "643": {"title": "trapping light for time of flight", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Trapping_Light_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "644": {"title": "the perception-distortion tradeoff", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Blau_The_Perception-Distortion_Tradeoff_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "645": {"title": "label denoising adversarial network (ldan) for inverse lighting of faces", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Label_Denoising_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "646": {"title": "optimal structured light \u00e0 la carte", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mirdehghan_Optimal_Structured_Light_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "647": {"title": "tracking multiple objects outside the line of sight using speckle imaging", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Smith_Tracking_Multiple_Objects_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "648": {"title": "inferring light fields from shadows", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baradad_Inferring_Light_Fields_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "649": {"title": "modifying non-local variations across multiple views", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tlusty_Modifying_Non-Local_Variations_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "650": {"title": "robust video content alignment and compensation for rain removal in a cnn framework", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Robust_Video_Content_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "651": {"title": "sfsnet: learning shape, reflectance and illuminance of faces `in the wild'", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sengupta_SfSNet_Learning_Shape_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "652": {"title": "deep photo enhancer: unpaired learning for image enhancement from photographs with gans", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Deep_Photo_Enhancer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "653": {"title": "lime: live intrinsic material estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Meka_LIME_Live_Intrinsic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "654": {"title": "learning to detect features in texture images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Learning_to_Detect_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "655": {"title": "learning to extract a video sequence from a single motion-blurred image", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jin_Learning_to_Extract_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "656": {"title": "lose the views: limited angle ct reconstruction via implicit sinogram completion", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Anirudh_Lose_the_Views_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "657": {"title": "a common framework for interactive texture transfer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Men_A_Common_Framework_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "658": {"title": "amnet: memorability estimation with attention", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fajtl_AMNet_Memorability_Estimation_CVPR_2018_paper.html", "abstract": "In this paper we present the design and evaluation of an end-to-end trainable, deep neural network w\nith a visual attention mechanism for memorability estimation in still images. We analyze the suitabi\nlity of transfer learning of deep models from image classification to the memorability task. Further\n on we study the impact of the attention mechanism on the memorability estimation and evaluate our n\network on the SUN Memorability and the LaMem datasets. Our network outperforms the existing state of\n the art models on both datasets in terms of the Spearman's rank correlation as well as the mean squ\nared error, closely matching human consistency.", "cite_num": 4, "conf": "cvpr", "time": "2018"}, "659": {"title": "blind predicting similar quality map for image quality assessment", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pan_Blind_Predicting_Similar_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "660": {"title": "deep end-to-end time-of-flight imaging", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Su_Deep_End-to-End_Time-of-Flight_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "661": {"title": "aperture supervision for monocular depth estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Srinivasan_Aperture_Supervision_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "662": {"title": "seeing temporal modulation of lights from standard cameras", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sakakibara_Seeing_Temporal_Modulation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "663": {"title": "statistical tomography of microscopic life", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Levis_Statistical_Tomography_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "664": {"title": "divide and conquer for full-resolution light field deblurring", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mohan_Divide_and_Conquer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "665": {"title": "multispectral image intrinsic decomposition via subspace constraint", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Multispectral_Image_Intrinsic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "666": {"title": "improving color reproduction accuracy on cameras", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Karaimer_Improving_Color_Reproduction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "667": {"title": "a closer look at spatiotemporal convolutions for action recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tran_A_Closer_Look_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "668": {"title": "inferring shared attention in social scene videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fan_Inferring_Shared_Attention_CVPR_2018_paper.html", "abstract": "This paper addresses a new problem of inferring shared attention in third-person social scene videos\n. Shared attention is a phenomenon that two or more individuals simultaneously look at a common targ\net in social scenes. Perceiving and identifying shared attention in videos plays crucial roles in so\ncial activities and social scene understanding. We propose a spatial-temporal neural network to dete\nct shared attention intervals in videos and predict shared attention locations in frames. In each vi\ndeo frame, human gaze directions and potential target boxes are two key features for spatially detec\nting shared attention in the social scene. In temporal domain, a convolutional Long Short-Term Memor\ny network utilizes the temporal continuity and transition constraints to optimize the predicted shar\ned attention heatmap. We collect a new dataset VideoCoAtt1 from public TV show videos, containing 38\n0 complex video sequences with more than 492,000 frames that include diverse social scenes for share\nd attention study. Experiments on this dataset show that our model can effectively infer shared atte\nntion in videos. We also empirically verify the effectiveness of different components in our model.", "cite_num": 3, "conf": "cvpr", "time": "2018"}, "669": {"title": "making convolutional networks recurrent for visual sequence learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Making_Convolutional_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "670": {"title": "real-world anomaly detection in surveillance videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sultani_Real-World_Anomaly_Detection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "671": {"title": "viewpoint-aware attentive multi-view inference for vehicle re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Viewpoint-Aware_Attentive_Multi-View_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "672": {"title": "efficient video object segmentation via network modulation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Efficient_Video_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "673": {"title": "weakly-supervised action segmentation with iterative soft boundary assignment", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ding_Weakly-Supervised_Action_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "674": {"title": "depth-aware stereo video retargeting", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Depth-Aware_Stereo_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "675": {"title": "instance embedding transfer to unsupervised video object segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Instance_Embedding_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "676": {"title": "future frame prediction for anomaly detection \u2013 a new baseline", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Future_Frame_Prediction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "677": {"title": "can spatiotemporal 3d cnns retrace the history of 2d cnns and imagenet?", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hara_Can_Spatiotemporal_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "678": {"title": "dynamic video segmentation network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Dynamic_Video_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "679": {"title": "recognize actions by disentangling components of dynamics", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Recognize_Actions_by_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "680": {"title": "motion-appearance co-memory networks for video question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gao_Motion-Appearance_Co-Memory_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "681": {"title": "learning to understand image blur", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Learning_to_Understand_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "682": {"title": "dense decoder shortcut connections for single-pass semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bilinski_Dense_Decoder_Shortcut_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "683": {"title": "generative adversarial image synthesis with decision tree latent controller", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kaneko_Generative_Adversarial_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "684": {"title": "learning a discriminative prior for blind image deblurring", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Learning_a_Discriminative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "685": {"title": "frame-recurrent video super-resolution", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sajjadi_Frame-Recurrent_Video_Super-Resolution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "686": {"title": "discovering point lights with intensity distance fields", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Discovering_Point_Lights_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "687": {"title": "video rain streak removal by multiscale convolutional sparse coding", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Video_Rain_Streak_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "688": {"title": "stereoscopic neural style transfer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Stereoscopic_Neural_Style_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "689": {"title": "multi-frame quality enhancement for compressed video", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Multi-Frame_Quality_Enhancement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "690": {"title": "cnn based learning using reflection and retinex models for intrinsic image decomposition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baslamisli_CNN_Based_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "691": {"title": "image restoration by estimating frequency distribution of local patches", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yoo_Image_Restoration_by_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "692": {"title": "latent ransac", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Korman_Latent_RANSAC_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "693": {"title": "two-stream convolutional networks for dynamic texture synthesis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tesfaldet_Two-Stream_Convolutional_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "694": {"title": "towards open-set identity preserving face synthesis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bao_Towards_Open-Set_Identity_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "695": {"title": "a revised underwater image formation model", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Akkaynak_A_Revised_Underwater_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "696": {"title": "graph-cut ransac", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Barath_Graph-Cut_RANSAC_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "697": {"title": "temporal deformable residual networks for action segmentation in videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lei_Temporal_Deformable_Residual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "698": {"title": "weakly supervised action localization by sparse temporal pooling network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nguyen_Weakly_Supervised_Action_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "699": {"title": "poseflow: a deep motion representation for understanding human behaviors in videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_PoseFlow_A_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "700": {"title": "ffnet: video fast-forwarding via reinforcement learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lan_FFNet_Video_Fast-Forwarding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "701": {"title": "multi-shot pedestrian re-identification via sequential decision making", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Multi-Shot_Pedestrian_Re-Identification_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "702": {"title": "attend and interact: higher-order object interactions for video understanding", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ma_Attend_and_Interact_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "703": {"title": "where and why are they looking? jointly inferring human attention and intentions in complex tasks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Where_and_Why_CVPR_2018_paper.html", "abstract": "This paper addresses a new problem - jointly inferring human attention, intentions, and tasks from v\nideos. Given an RGB-D video where a human performs a task, we answer three questions simultaneously:\n 1) where the human is looking - attention prediction; 2) why the human is looking there - intention\n prediction; and 3) what task the human is performing - task recognition. We propose a hierarchical \nmodel of human-attention-object (HAO) which represents tasks, intentions, and attention under a unif\nied framework. A task is represented as sequential intentions which transition to each other. An int\nention is composed of the human pose, attention, and objects. A beam search algorithm is adopted for\n inference on the HAO graph to output the attention, intention, and task results. We built a new vid\neo dataset of tasks, intentions, and attention. It contains 14 task classes, 70 intention categories\n, 28 object classes, 809 videos, and approximately 330,000 frames. Experiments show that our approac\nh outperforms existing approaches.", "cite_num": 0, "conf": "cvpr", "time": "2018"}, "704": {"title": "fully convolutional adaptation networks for semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Fully_Convolutional_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "705": {"title": "semantic video segmentation by gated recurrent flow propagation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nilsson_Semantic_Video_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "706": {"title": "interpretable video captioning via trajectory structured localization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Interpretable_Video_Captioning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "707": {"title": "deep hashing via discrepancy minimization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Deep_Hashing_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "708": {"title": "shufflenet: an extremely efficient convolutional neural network for mobile devices", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "709": {"title": "zero-shot recognition via semantic embeddings and knowledge graphs", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Zero-Shot_Recognition_via_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "710": {"title": "referring relationships", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Krishna_Referring_Relationships_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "711": {"title": "improving object localization with fitness nms and bounded iou loss", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tychsen-Smith_Improving_Object_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "712": {"title": "end-to-end deep kronecker-product matching for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_End-to-End_Deep_Kronecker-Product_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "713": {"title": "semantic visual localization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Schonberger_Semantic_Visual_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "714": {"title": "objects as context for detecting their semantic parts", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gonzalez-Garcia_Objects_as_Context_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "715": {"title": "end-to-end weakly-supervised semantic alignment", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rocco_End-to-End_Weakly-Supervised_Semantic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "716": {"title": "dynamic zoom-in network for fast object detection in large images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gao_Dynamic_Zoom-In_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "717": {"title": "learning markov clustering networks for scene text detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Learning_Markov_Clustering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "718": {"title": "deep reinforcement learning of region proposal networks for object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pirinen_Deep_Reinforcement_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "719": {"title": "beyond holistic object recognition: enriching image understanding with part states", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lu_Beyond_Holistic_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "720": {"title": "discriminability objective for training descriptive captions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_Discriminability_Objective_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "721": {"title": "visual question answering with memory-augmented networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ma_Visual_Question_Answering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "722": {"title": "structure inference net: object detection using scene-level context and instance-level relationships", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Structure_Inference_Net_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "723": {"title": "occluded pedestrian detection through guided attention in cnns", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Occluded_Pedestrian_Detection_CVPR_2018_paper.html", "abstract": "Pedestrian detection has progressed significantly in the last years. However, occluded people are no\ntoriously hard to detect, as their appearance varies substantially depending on a wide range of occl\nusion patterns. In this paper, we aim to propose a simple and compact method based on the FasterRCNN\n architecture for occluded pedestrian detection. We start with interpreting CNN channel features of \na pedestrian detector, and we find that different channels activate responses for different body par\nts respectively. These findings motivate us to employ an attention mechanism across channels to repr\nesent various occlusion patterns in one single model, as each occlusion pattern can be formulated as\n some specific combination of body parts. Therefore, an attention network with self or external guid\nances is proposed as an add-on to the baseline FasterRCNN detector. When evaluating on the heavy occ\nlusion subset, we achieve a significant improvement of 8pp to the baseline FasterRCNN detector on Ci\ntyPersons and on Caltech we outperform the state-of-the-art method by 4pp.", "cite_num": 24, "conf": "cvpr", "time": "2018"}, "724": {"title": "reward learning from narrated demonstrations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tung_Reward_Learning_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "725": {"title": "weakly-supervised semantic segmentation network with deep seeded region growing", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Weakly-Supervised_Semantic_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "726": {"title": "potion: pose motion representation for action recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Choutas_PoTion_Pose_MoTion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "727": {"title": "bilateral ordinal relevance multi-instance regression for facial action unit intensity estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Bilateral_Ordinal_Relevance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "728": {"title": "pulling actions out of context: explicit separation for effective combination", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Pulling_Actions_out_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "729": {"title": "dynamic feature learning for partial face recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_Dynamic_Feature_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "730": {"title": "exploiting transitivity for learning person re-identification models on a budget", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Roy_Exploiting_Transitivity_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "731": {"title": "deep spatial feature reconstruction for partial person re-identification: alignment-free approach", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/He_Deep_Spatial_Feature_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "732": {"title": "every smile is unique: landmark-guided diverse smile generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Every_Smile_Is_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "733": {"title": "uv-gan: adversarial facial uv map completion for pose-invariant face recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Deng_UV-GAN_Adversarial_Facial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "734": {"title": "cascaded pyramid network for multi-person pose estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Cascaded_Pyramid_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "735": {"title": "a face-to-face neural conversation model", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chu_A_Face-to-Face_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "736": {"title": "end-to-end recovery of human shape and pose", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kanazawa_End-to-End_Recovery_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "737": {"title": "squeeze-and-excitation networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "738": {"title": "revisiting salient object detection: simultaneous detection, ranking, and subitizing of multiple salient objects", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Islam_Revisiting_Salient_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "739": {"title": "context encoding for semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Context_Encoding_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "740": {"title": "creating capsule wardrobes from fashion images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hsiao_Creating_Capsule_Wardrobes_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "741": {"title": "webly supervised learning meets zero-shot learning: a hybrid approach for fine-grained classification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Niu_Webly_Supervised_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "742": {"title": "look, imagine and match: improving textual-visual cross-modal retrieval with generative models", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gu_Look_Imagine_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "743": {"title": "bidirectional attentive fusion with context gating for dense video captioning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Bidirectional_Attentive_Fusion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "744": {"title": "inloc: indoor visual localization with dense matching and view synthesis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Taira_InLoc_Indoor_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "745": {"title": "towards high performance video object detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_Towards_High_Performance_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "746": {"title": "neural baby talk", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lu_Neural_Baby_Talk_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "747": {"title": "few-shot image recognition by predicting parameters from activations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qiao_Few-Shot_Image_Recognition_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "748": {"title": "iterative visual reasoning beyond convolutions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Iterative_Visual_Reasoning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "749": {"title": "visual question reasoning on general dependency tree", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cao_Visual_Question_Reasoning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "750": {"title": "cvm-net: cross-view matching network for image-based ground-to-aerial geo-localization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_CVM-Net_Cross-View_Matching_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "751": {"title": "revisiting dilated convolution: a simple approach for weakly- and semi-supervised semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Revisiting_Dilated_Convolution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "752": {"title": "low-shot learning from imaginary data", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Low-Shot_Learning_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "753": {"title": "doublefusion: real-time capture of human performances with inner body shapes from a single depth sensor", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_DoubleFusion_Real-Time_Capture_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "754": {"title": "densepose: dense human pose estimation in the wild", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Guler_DensePose_Dense_Human_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "755": {"title": "ordinal depth supervision for 3d human pose estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pavlakos_Ordinal_Depth_Supervision_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "756": {"title": "consensus maximization for semantic region correspondences", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Speciale_Consensus_Maximization_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "757": {"title": "robust hough transform based 3d reconstruction from circular light fields", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vianello_Robust_Hough_Transform_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "758": {"title": "alive caricature from 2d to 3d", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Alive_Caricature_From_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "759": {"title": "nonlinear 3d face morphable model", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tran_Nonlinear_3D_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "760": {"title": "through-wall human pose estimation using radio signals", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_Through-Wall_Human_Pose_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "761": {"title": "what makes a video a video: analyzing temporal information in video understanding models and datasets", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_What_Makes_a_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "762": {"title": "fast video object segmentation by reference-guided mask propagation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Oh_Fast_Video_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "763": {"title": "neuralnetwork-viterbi: a framework for weakly supervised video learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Richard_NeuralNetwork-Viterbi_A_Framework_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "764": {"title": "actor and observer: joint modeling of first and third-person videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sigurdsson_Actor_and_Observer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "765": {"title": "hsa-rnn: hierarchical structure-adaptive rnn for video summarization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhao_HSA-RNN_Hierarchical_Structure-Adaptive_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "766": {"title": "fast and accurate online video object segmentation via tracking parts", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Cheng_Fast_and_Accurate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "767": {"title": "now you shake me: towards automatic 4d cinema", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Now_You_Shake_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "768": {"title": "viewpoint-aware video summarization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kanehira_Viewpoint-Aware_Video_Summarization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "769": {"title": "photometric stereo in participating media considering shape-dependent forward scatter", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fujimura_Photometric_Stereo_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "770": {"title": "direction-aware spatial context features for shadow detection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Direction-Aware_Spatial_Context_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "771": {"title": "discriminative learning of latent features for zero-shot recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Discriminative_Learning_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "772": {"title": "learning to adapt structured output space for semantic segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tsai_Learning_to_Adapt_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "773": {"title": "multi-task learning using uncertainty to weigh losses for scene geometry and semantics", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "774": {"title": "jointly localizing and describing events for dense video captioning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Jointly_Localizing_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "775": {"title": "going from image to video saliency: augmenting image salience with dynamic attentional push", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gorji_Going_From_Image_CVPR_2018_paper.html", "abstract": "We present a novel method to incorporate the recent advent in static saliency models to predict the \nsaliency in videos. Our model augments the static saliency models with the Attentional Push effect o\nf the photographer and the scene actors in a shared attention setting. We demonstrate that not only \nit is imperative to use static Attentional Push cues, noticeable performance improvement is achievab\nle by learning the time-varying nature of Attentional Push. We propose a multi-stream Convolutional \nLong Short-Term Memory network (ConvLSTM) structure which augments state-of-the-art in static salien\ncy models with dynamic Attentional Push. Our network contains four pathways, a saliency pathway and \nthree Attentional Push pathways. The multi-pathway structure is followed by an augmenting convnet th\nat learns to combine the complementary and time-varying outputs of the ConvLSTMs by minimizing the r\nelative entropy between the augmented saliency and viewers fixation patterns on videos. We evaluate \nour model by comparing the performance of several augmented static saliency models with state-of-the\n-art in spatiotemporal saliency on three largest dynamic eye tracking datasets, HOLLYWOOD2, UCF-Spor\nt and DIEM. Experimental results illustrates that solid performance gain is achievable using the pro\nposed methodology.", "cite_num": 6, "conf": "cvpr", "time": "2018"}, "776": {"title": "m3: multimodal memory modelling for video captioning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_M3_Multimodal_Memory_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "777": {"title": "emotional attention: a study of image sentiment and visual attention", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fan_Emotional_Attention_A_CVPR_2018_paper.html", "abstract": "Image sentiment influences visual perception. Emotion-eliciting stimuli such as happy faces and pois\nonous snakes are generally prioritized in human attention. However, little research has evaluated th\ne interrelationships of image sentiment and visual saliency. In this paper, we present the first stu\ndy to focus on the relation between emotional properties of an image and visual attention. We first \ncreate the EMOtional attention dataset (EMOd). It is a diverse set of emotion-eliciting images, and \neach image has (1) eye-tracking data collected from 16 subjects, (2) intensive image context labels \nincluding object contour, object sentiment, object semantic category, and high-level perceptual attr\nibutes such as image aesthetics and elicited emotions. We perform extensive analyses on EMOd to iden\ntify how image sentiment relates to human attention. We discover an emotion prioritization effect: f\nor our images, emotion-eliciting content attracts human attention strongly, but such advantage dimin\nishes dramatically after initial fixation. Aiming to model the human emotion prioritization computat\nionally, we design a deep neural network for saliency prediction, which includes a novel subnetwork \nthat learns the spatial and semantic context of the image scene. The proposed network outperforms th\ne state-of-the-art on three benchmark datasets, by effectively capturing the relative importance of \nhuman attention within an image. The code, models, and dataset are available online at https://nus-s\nesame.top/emotionalattention/.", "cite_num": 1, "conf": "cvpr", "time": "2018"}, "778": {"title": "a low power, high throughput, fully event-based stereo system", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Andreopoulos_A_Low_Power_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "779": {"title": "viton: an image-based virtual try-on network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Han_VITON_An_Image-Based_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "780": {"title": "multi-oriented scene text detection via corner localization and region segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lyu_Multi-Oriented_Scene_Text_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "781": {"title": "multi-content gan for few-shot font style transfer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Azadi_Multi-Content_GAN_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "782": {"title": "audio to body dynamics", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shlizerman_Audio_to_Body_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "783": {"title": "weakly supervised coupled networks for visual sentiment analysis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Weakly_Supervised_Coupled_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "784": {"title": "future person localization in first-person videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yagi_Future_Person_Localization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "785": {"title": "preserving semantic relations for zero-shot learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Annadani_Preserving_Semantic_Relations_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "786": {"title": "show me a story: towards coherent neural story illustration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ravi_Show_Me_a_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "787": {"title": "reconstruction network for video captioning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Reconstruction_Network_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "788": {"title": "fast spectral ranking for similarity search", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Iscen_Fast_Spectral_Ranking_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "789": {"title": "mining on manifolds: metric learning without labels", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Iscen_Mining_on_Manifolds_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "790": {"title": "pixor: real-time 3d object detection from point clouds", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_PIXOR_Real-Time_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "791": {"title": "leveraging unlabeled data for crowd counting by learning to rank", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Leveraging_Unlabeled_Data_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "792": {"title": "zero-shot kernel learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Zero-Shot_Kernel_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "793": {"title": "differential attention for visual question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Patro_Differential_Attention_for_CVPR_2018_paper.html", "abstract": "In this paper we aim to answer questions based on images when provided with a dataset of question-an\nswer pairs for a number of images during training. A number of methods have focused on solving this \nproblem by using image based attention. This is done by focusing on a specific part of the image whi\nle answering the question. Humans also do so when solving this problem. However, the regions that th\ne previous systems focus on are not correlated with the regions that humans focus on. The accuracy i\ns limited due to this drawback. In this paper, we propose to solve this problem by using an exemplar\n based method. We obtain one or more supporting and opposing exemplars to obtain a differential atte\nntion region. This differential attention is closer to human attention than other image based attent\nion methods. It also helps in obtaining improved accuracy when answering questions. The method is ev\naluated on challenging benchmark datasets. We perform better than other image based attention method\ns and are competitive with other state of the art methods that focus on both image and questions.", "cite_num": 9, "conf": "cvpr", "time": "2018"}, "794": {"title": "learning from noisy web data with category-level supervision", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Niu_Learning_From_Noisy_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "795": {"title": "toward driving scene understanding: a dataset for learning driver behavior and causal reasoning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ramanishka_Toward_Driving_Scene_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "796": {"title": "learning attribute representations with localization for flexible fashion search", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ak_Learning_Attribute_Representations_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "797": {"title": "bidirectional retrieval made simple", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wehrmann_Bidirectional_Retrieval_Made_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "798": {"title": "learning multi-instance enriched image representations via non-greedy ratio maximization of the l1-norm distances", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Learning_Multi-Instance_Enriched_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "799": {"title": "learning visual knowledge memory networks for visual question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Su_Learning_Visual_Knowledge_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "800": {"title": "visual grounding via accumulated attention", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Deng_Visual_Grounding_via_CVPR_2018_paper.html", "abstract": "Visual Grounding (VG) aims to locate the most relevant object or region in an image, based on a natu\nral language query. The query can be a phrase, a sentence or even a multi-round dialogue. There are \nthree main challenges in VG: 1) what is the main focus in a query; 2) how to understand an image; 3)\n how to locate an object. Most existing methods combine all the information curtly, which may suffer\n from the problem of information redundancy (i.e. ambiguous query, complicated image and a large num\nber of objects). In this paper, we formulate these challenges as three attention problems and propos\ne an accumulated attention (A-ATT) mechanism to reason among them jointly. Our A-ATT mechanism can c\nircularly accumulate the attention for useful information in image, query, and objects, while the no\nises are ignored gradually. We evaluate the performance of A-ATT on four popular datasets (namely Re\nfer-COCO, ReferCOCO+, ReferCOCOg, and Guesswhat?!), and the experimental results show the superiorit\ny of the proposed method in term of accuracy.", "cite_num": 15, "conf": "cvpr", "time": "2018"}, "801": {"title": "beyond trade-off: accelerate fcn-based face detector with higher accuracy", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Beyond_Trade-Off_Accelerate_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "802": {"title": "packnet: adding multiple tasks to a single network by iterative pruning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mallya_PackNet_Adding_Multiple_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "803": {"title": "repulsion loss: detecting pedestrians in a crowd", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Repulsion_Loss_Detecting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "804": {"title": "neural sign language translation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Camgoz_Neural_Sign_Language_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "805": {"title": "non-local neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "806": {"title": "lamv: learning to align and match videos with kernelized temporal layers", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baraldi_LAMV_Learning_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "807": {"title": "optimizing video object detection via a scale-time lattice", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Optimizing_Video_Object_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "808": {"title": "learning compressible 360\u00b0 video isomers", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Su_Learning_Compressible_360deg_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "809": {"title": "attention clusters: purely attention based local feature integration for video classification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Long_Attention_Clusters_Purely_CVPR_2018_paper.html", "abstract": "Recently, substantial research effort has focused on how to apply CNNs or RNNs to better capture tem\nporal patterns in videos, so as to improve the accuracy of video classification. In this paper, howe\nver, we show that temporal information, especially longer-term patterns, may not be necessary to ach\nieve competitive results on common trimmed video classification datasets. We investigate the potenti\nal of a purely attention based local feature integration. Accounting for the characteristics of such\n features in video classification, we propose a local feature integration framework based on attenti\non clusters, and introduce a shifting operation to capture more diverse signals. We carefully analyz\ne and compare the effect of different attention mechanisms, cluster sizes, and the use of the shifti\nng operation, and also investigate the combination of attention clusters for multimodal integration.\n We demonstrate the effectiveness of our framework on three real-world video classification datasets\n. Our model achieves competitive results across all of these. In particular, on the large-scale Kine\ntics dataset, our framework obtains an excellent single model accuracy of 79.4% in terms of the top-\n1 and 94.0% in terms of the top-5 accuracy on the validation set.", "cite_num": 30, "conf": "cvpr", "time": "2018"}, "810": {"title": "what have we learned from deep representations for action recognition?", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Feichtenhofer_What_Have_We_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "811": {"title": "controllable video generation with sparse trajectories", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hao_Controllable_Video_Generation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "812": {"title": "representing and learning high dimensional data with the optimal transport map from a probabilistic viewpoint", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Park_Representing_and_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "813": {"title": "clip-q: deep network compression learning by in-parallel pruning-quantization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tung_CLIP-Q_Deep_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "814": {"title": "inference in higher order mrf-map problems with small and large cliques", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shanu_Inference_in_Higher_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "815": {"title": "road: reality oriented adaptation for semantic segmentation of urban scenes", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_ROAD_Reality_Oriented_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "816": {"title": "eye in-painting with exemplar generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dolhansky_Eye_In-Painting_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "817": {"title": "clcnet: improving the efficiency of convolutional neural network using channel local convolutions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_ClcNet_Improving_the_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "818": {"title": "towards effective low-bitwidth convolutional neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhuang_Towards_Effective_Low-Bitwidth_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "819": {"title": "stochastic downsampling for cost-adjustable inference and improved regularization in convolutional networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kuen_Stochastic_Downsampling_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "820": {"title": "face aging with identity-preserved conditional generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Face_Aging_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "821": {"title": "unsupervised cross-dataset person re-identification by transfer learning of spatial-temporal patterns", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lv_Unsupervised_Cross-Dataset_Person_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "822": {"title": "feature quantization for defending against distortion of images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Feature_Quantization_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "823": {"title": "tagging like humans: diverse and distinct image annotation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Tagging_Like_Humans_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "824": {"title": "re-weighted adversarial adaptation network for unsupervised domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Re-Weighted_Adversarial_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "825": {"title": "inferring semantic layout for hierarchical text-to-image synthesis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hong_Inferring_Semantic_Layout_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "826": {"title": "regularizing rnns for caption generation by reconstructing the past with the present", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Regularizing_RNNs_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "827": {"title": "unsupervised domain adaptation with similarity learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pinheiro_Unsupervised_Domain_Adaptation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "828": {"title": "learning deep sketch abstraction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Muhammad_Learning_Deep_Sketch_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "829": {"title": "matching adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mattyus_Matching_Adversarial_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "830": {"title": "sos-rsc: a sum-of-squares polynomial approach to robustifying subspace clustering algorithms", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sznaier_SoS-RSC_A_Sum-of-Squares_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "831": {"title": "resource aware person re-identification across multiple resolutions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Resource_Aware_Person_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "832": {"title": "learning and using the arrow of time", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wei_Learning_and_Using_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "833": {"title": "neural style transfer via meta networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Neural_Style_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "834": {"title": "people, penguins and petri dishes: adapting object counting models to new visual domains and object types without forgetting", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Marsden_People_Penguins_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "835": {"title": "hydranets: specialized dynamic architectures for efficient inference", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mullapudi_HydraNets_Specialized_Dynamic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "836": {"title": "sketchmate: deep hashing for million-scale human sketch retrieval", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_SketchMate_Deep_Hashing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "837": {"title": "from source to target and back: symmetric bi-directional adaptive gan", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Russo_From_Source_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "838": {"title": "ol\u00e9: orthogonal low-rank embedding - a plug and play geometric loss for deep learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lezama_OLE_Orthogonal_Low-Rank_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "839": {"title": "efficient parametrization of multi-domain deep neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rebuffi_Efficient_Parametrization_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "840": {"title": "deep density clustering of unconstrained faces", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_Deep_Density_Clustering_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "841": {"title": "geometric multi-model fitting with a convex relaxation algorithm", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Amayo_Geometric_Multi-Model_Fitting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "842": {"title": "fast and robust estimation for unit-norm constrained linear fitting problems", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ikami_Fast_and_Robust_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "843": {"title": "importance weighted adversarial nets for partial domain adaptation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Importance_Weighted_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "844": {"title": "efficient subpixel refinement with symbolic linear predictors", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lui_Efficient_Subpixel_Refinement_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "845": {"title": "scale-recurrent network for deep image deblurring", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tao_Scale-Recurrent_Network_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "846": {"title": "deblurgan: blind motion deblurring using conditional adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kupyn_DeblurGAN_Blind_Motion_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "847": {"title": "a2-rl: aesthetics aware reinforcement learning for image cropping", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_A2-RL_Aesthetics_Aware_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "848": {"title": "single image dehazing via conditional generative adversarial network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Single_Image_Dehazing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "849": {"title": "on the duality between retinex and image dehazing", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Galdran_On_the_Duality_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "850": {"title": "arbitrary style transfer with deep feature reshuffle", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gu_Arbitrary_Style_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "851": {"title": "nonlocal low-rank tensor factor analysis for image restoration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Nonlocal_Low-Rank_Tensor_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "852": {"title": "avatar-net: multi-scale zero-shot style transfer by feature decoration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "853": {"title": "missing slice recovery for tensors using a low-rank model in embedded space", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yokota_Missing_Slice_Recovery_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "854": {"title": "deep semantic face deblurring", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Semantic_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "855": {"title": "graphbit: bitwise interaction mining via deep reinforcement learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Duan_GraphBit_Bitwise_Interaction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "856": {"title": "recurrent saliency transformation network: incorporating multi-stage visual cues for small organ segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Recurrent_Saliency_Transformation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "857": {"title": "thoracic disease identification and localization with limited supervision", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Thoracic_Disease_Identification_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "858": {"title": "quantization of fully convolutional networks for accurate biomedical image segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_Quantization_of_Fully_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "859": {"title": "visual feature attribution using wasserstein gans", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baumgartner_Visual_Feature_Attribution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "860": {"title": "total capture: a 3d deformation model for tracking faces, hands, and bodies", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Joo_Total_Capture_A_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "861": {"title": "augmented skeleton space transfer for depth-based hand pose estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Baek_Augmented_Skeleton_Space_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "862": {"title": "synthesizing images of humans in unseen poses", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Balakrishnan_Synthesizing_Images_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "863": {"title": "ssnet: scale selection network for online 3d action prediction", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_SSNet_Scale_Selection_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "864": {"title": "detecting and recognizing human-object interactions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gkioxari_Detecting_and_Recognizing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "865": {"title": "unsupervised learning and segmentation of complex activities from video", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sener_Unsupervised_Learning_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "866": {"title": "unsupervised training for 3d morphable model regression", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Genova_Unsupervised_Training_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "867": {"title": "video based reconstruction of 3d people models", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Alldieck_Video_Based_Reconstruction_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "868": {"title": "pose-guided photorealistic face rotation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Pose-Guided_Photorealistic_Face_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "869": {"title": "mesoscopic facial geometry inference using deep neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huynh_Mesoscopic_Facial_Geometry_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "870": {"title": "hand pointnet: 3d hand pose estimation using point sets", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ge_Hand_PointNet_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "871": {"title": "seeing voices and hearing faces: cross-modal biometric matching", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Nagrani_Seeing_Voices_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "872": {"title": "learning monocular 3d human pose estimation from multi-view images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rhodin_Learning_Monocular_3D_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "873": {"title": "separating style and content for generalized style transfer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Separating_Style_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "874": {"title": "texturegan: controlling deep image synthesis with texture patches", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xian_TextureGAN_Controlling_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "875": {"title": "connecting pixels to privacy and utility: automatic redaction of private information in images", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Orekondy_Connecting_Pixels_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "876": {"title": "mapnet: an allocentric spatial memory for mapping environments", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Henriques_MapNet_An_Allocentric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "877": {"title": "accurate and diverse sampling of sequences based on a \u201cbest of many\u201d sample objective", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bhattacharyya_Accurate_and_Diverse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "878": {"title": "virtualhome: simulating household activities via programs", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Puig_VirtualHome_Simulating_Household_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "879": {"title": "generate to adapt: aligning domains using generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sankaranarayanan_Generate_to_Adapt_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "880": {"title": "multi-agent diverse generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ghosh_Multi-Agent_Diverse_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "881": {"title": "a pid controller approach for stochastic optimization of deep networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/An_A_PID_Controller_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "882": {"title": "\u201clearning-compression\u201d algorithms for neural net pruning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Carreira-Perpinan_Learning-Compression_Algorithms_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "883": {"title": "large-scale distance metric learning with uncertainty", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qian_Large-Scale_Distance_Metric_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "884": {"title": "guide me: interacting with deep networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Rupprecht_Guide_Me_Interacting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "885": {"title": "art of singular vectors and universal adversarial perturbations", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Khrulkov_Art_of_Singular_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "886": {"title": "deflecting adversarial attacks with pixel deflection", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Prakash_Deflecting_Adversarial_Attacks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "887": {"title": "moviegraphs: towards understanding human-centric situations from videos", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Vicol_MovieGraphs_Towards_Understanding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "888": {"title": "semstyle: learning to generate stylised image captions using unaligned text", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mathews_SemStyle_Learning_to_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "889": {"title": "benchmarking 6dof outdoor visual localization in changing conditions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sattler_Benchmarking_6DOF_Outdoor_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "890": {"title": "ivqa: inverse visual question answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_IVQA_Inverse_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "891": {"title": "unsupervised person image synthesis in arbitrary poses", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Pumarola_Unsupervised_Person_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "892": {"title": "learning descriptor networks for 3d shape synthesis and analysis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xie_Learning_Descriptor_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "893": {"title": "neural kinematic networks for unsupervised motion retargetting", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Villegas_Neural_Kinematic_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "894": {"title": "group consistent similarity learning via deep crf for person re-identification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Group_Consistent_Similarity_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "895": {"title": "learning compositional visual concepts with mutual consistency", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gong_Learning_Compositional_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "896": {"title": "nestednet: learning nested sparse structures in deep neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_NestedNet_Learning_Nested_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "897": {"title": "context embedding networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kim_Context_Embedding_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "898": {"title": "iterative learning with open-set noisy labels", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Iterative_Learning_With_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "899": {"title": "learning transferable architectures for scalable image recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zoph_Learning_Transferable_Architectures_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "900": {"title": "sbnet: sparse blocks network for fast inference", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ren_SBNet_Sparse_Blocks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "901": {"title": "language-based image editing with recurrent attentive models", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Language-Based_Image_Editing_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "902": {"title": "net2vec: quantifying and explaining how concepts are encoded by filters in deep neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fong_Net2Vec_Quantifying_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "903": {"title": "end-to-end dense video captioning with masked transformer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_End-to-End_Dense_Video_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "904": {"title": "a neural multi-sequence alignment technique (neumatch)", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dogan_A_Neural_Multi-Sequence_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "905": {"title": "path aggregation network for instance segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Path_Aggregation_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "906": {"title": "the inaturalist species classification and detection dataset", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Van_Horn_The_INaturalist_Species_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "907": {"title": "multimodal explanations: justifying decisions and pointing to the evidence", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Park_Multimodal_Explanations_Justifying_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "908": {"title": "stargan: unified generative adversarial networks for multi-domain image-to-image translation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Choi_StarGAN_Unified_Generative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "909": {"title": "high-resolution image synthesis and semantic manipulation with conditional gans", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_High-Resolution_Image_Synthesis_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "910": {"title": "semi-parametric image synthesis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Semi-Parametric_Image_Synthesis_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "911": {"title": "blockdrop: dynamic inference paths in residual networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_BlockDrop_Dynamic_Inference_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "912": {"title": "interpretable convolutional neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Interpretable_Convolutional_Neural_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "913": {"title": "deep cross-media knowledge transfer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Huang_Deep_Cross-Media_Knowledge_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "914": {"title": "interleaved structured sparse convolutional neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xie_Interleaved_Structured_Sparse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "915": {"title": "a variational u-net for conditional appearance and shape generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Esser_A_Variational_U-Net_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "916": {"title": "detach and adapt: learning cross-domain disentangled deep representation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Detach_and_Adapt_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "917": {"title": "learning deep structured active contours end-to-end", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Marcos_Learning_Deep_Structured_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "918": {"title": "deep learning under privileged information using heteroscedastic dropout", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lambert_Deep_Learning_Under_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "919": {"title": "smooth neighbors on teacher graphs for semi-supervised learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_Smooth_Neighbors_on_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "920": {"title": "interpret neural networks by identifying critical data routing paths", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Interpret_Neural_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "921": {"title": "deep spatio-temporal random fields for efficient video segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chandra_Deep_Spatio-Temporal_Random_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "922": {"title": "customized image narrative generation via interactive visual question generation and answering", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Shin_Customized_Image_Narrative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "923": {"title": "pwc-net: cnns for optical flow using pyramid, warping, and cost volume", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_PWC-Net_CNNs_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "924": {"title": "revisiting deep intrinsic image decompositions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Fan_Revisiting_Deep_Intrinsic_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "925": {"title": "multi-cell detection and classification using a generative convolutional model", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yellin_Multi-Cell_Detection_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "926": {"title": "learning spatial-aware regressions for visual tracking", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_Learning_Spatial-Aware_Regressions_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "927": {"title": "high performance visual tracking with siamese region proposal network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_High_Performance_Visual_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "928": {"title": "liteflownet: a lightweight convolutional neural network for optical flow estimation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hui_LiteFlowNet_A_Lightweight_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "929": {"title": "vital: visual tracking via adversarial learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Song_VITAL_VIsual_Tracking_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "930": {"title": "super slomo: high quality estimation of multiple intermediate frames for video interpolation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jiang_Super_SloMo_High_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "931": {"title": "real-world repetition estimation by div, grad and curl", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Runia_Real-World_Repetition_Estimation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "932": {"title": "recurrent pixel embedding for instance grouping", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Kong_Recurrent_Pixel_Embedding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "933": {"title": "deep unsupervised saliency detection: a multiple noisy labeling perspective", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Deep_Unsupervised_Saliency_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "934": {"title": "learning intrinsic image decomposition from watching the world", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Learning_Intrinsic_Image_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "935": {"title": "tienet: text-image embedding network for common thorax disease classification and reporting in chest x-rays", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_TieNet_Text-Image_Embedding_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "936": {"title": "generating synthetic x-ray images of a person from the surface geometry", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Teixeira_Generating_Synthetic_X-Ray_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "937": {"title": "gibson env: real-world perception for embodied agents", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Xia_Gibson_Env_Real-World_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "938": {"title": "reinforcement cutting-agent learning for video object segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Han_Reinforcement_Cutting-Agent_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "939": {"title": "feature space transfer for data augmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Feature_Space_Transfer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "940": {"title": "analytic expressions for probabilistic moments of pl-dnn with gaussian input", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bibi_Analytic_Expressions_for_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "941": {"title": "detail-preserving pooling in deep networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Saeedan_Detail-Preserving_Pooling_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "942": {"title": "rethinking feature distribution for loss functions in image classification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wan_Rethinking_Feature_Distribution_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "943": {"title": "shift: a zero flop, zero parameter alternative to spatial convolutions", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Shift_A_Zero_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "944": {"title": "sketch-a-classifier: sketch-based photo classifier generation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Sketch-a-Classifier_Sketch-Based_Photo_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "945": {"title": "light field intrinsics with a deep encoder-decoder network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Alperovich_Light_Field_Intrinsics_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "946": {"title": "learning generative convnets via multi-grid modeling and sampling", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Gao_Learning_Generative_ConvNets_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "947": {"title": "manifold learning in quotient spaces", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mehr_Manifold_Learning_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "948": {"title": "learning intelligent dialogs for bounding box annotation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Konyushkova_Learning_Intelligent_Dialogs_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "949": {"title": "boosting adversarial attacks with momentum", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dong_Boosting_Adversarial_Attacks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "950": {"title": "nisp: pruning networks using neuron importance score propagation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_NISP_Pruning_Networks_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "951": {"title": "pointgrid: a deep network for 3d shape understanding", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Le_PointGrid_A_Deep_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "952": {"title": "tell me where to look: guided attention inference network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_Tell_Me_Where_CVPR_2018_paper.html", "abstract": "Weakly supervised learning with only coarse labels can obtain visual explanations of deep neural net\nwork such as attention maps by back-propagating gradients. These attention maps are then available a\ns priors for tasks such as object localization and semantic segmentation. In one common framework we\n address three shortcomings of previous approaches in modeling such attention maps: We (1) first tim\ne make attention maps an explicit and natural component of the end-to-end training, (2) provide self\n-guidance directly on these maps by exploring supervision form the network itself to improve them, a\nnd (3) seamlessly bridge the gap between using weak and extra supervision if available. Despite its \nsimplicity, experiments on the semantic segmentation task demonstrate the effectiveness of our metho\nds. We clearly surpass the state-of-the-art on Pascal VOC 2012 val. and test set. Besides, the propo\nsed framework provides a way not only explaining the focus of the learner but also feeding back with\n direct guidance towards specific tasks. Under mild assumptions our method can also be understood as\n a plug-in to existing weakly supervised learners to improve their generalization performance.", "cite_num": 21, "conf": "cvpr", "time": "2018"}, "953": {"title": "3d semantic segmentation with submanifold sparse convolutional networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Graham_3D_Semantic_Segmentation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "954": {"title": "tom-net: learning transparent object matting from a single image", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_TOM-Net_Learning_Transparent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "955": {"title": "translating and segmenting multimodal medical volumes with cycle- and shape-consistency generative adversarial network", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Translating_and_Segmenting_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "956": {"title": "an unsupervised learning model for deformable medical image registration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Balakrishnan_An_Unsupervised_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "957": {"title": "deep lesion graphs in the wild: relationship learning and organization of significant radiology image findings in a diverse large-scale lesion database", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Yan_Deep_Lesion_Graphs_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "958": {"title": "learning distributions of shape trajectories from longitudinal datasets: a hierarchical model on a manifold of diffeomorphisms", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Bone_Learning_Distributions_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "959": {"title": "cnn driven sparse multi-level b-spline image registration", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Jiang_CNN_Driven_Sparse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "960": {"title": "anatomical priors in convolutional networks for unsupervised biomedical segmentation", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Dalca_Anatomical_Priors_in_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "961": {"title": "3d registration of curves and surfaces using local differential information", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Raposo_3D_Registration_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "962": {"title": "weakly supervised learning of single-cell feature embeddings", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Caicedo_Weakly_Supervised_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "963": {"title": "guided proofreading of automatic segmentations for connectomics", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Haehn_Guided_Proofreading_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "964": {"title": "wide compression: tensor ring nets", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Wide_Compression_Tensor_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "965": {"title": "improvements to context based self-supervised learning", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Mundhenk_Improvements_to_Context_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "966": {"title": "learning structure and strength of cnn filters for small sample size training", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Keshari_Learning_Structure_and_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "967": {"title": "boosting self-supervised learning via knowledge transfer", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Noroozi_Boosting_Self-Supervised_Learning_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "968": {"title": "the power of ensembles for active learning in image classification", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Beluch_The_Power_of_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "969": {"title": "learning compact recurrent neural networks with block-term tensor decomposition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ye_Learning_Compact_Recurrent_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "970": {"title": "spatially-adaptive filter units for deep neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Tabernik_Spatially-Adaptive_Filter_Units_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "971": {"title": "so-net: self-organizing network for point cloud analysis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Li_SO-Net_Self-Organizing_Network_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "972": {"title": "sgan: an alternative training of generative adversarial networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chavdarova_SGAN_An_Alternative_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "973": {"title": "sketchygan: towards diverse and realistic sketch to image synthesis", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_SketchyGAN_Towards_Diverse_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "974": {"title": "explicit loss-error-aware quantization for low-bit deep neural networks", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Explicit_Loss-Error-Aware_Quantization_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "975": {"title": "towards universal representation for unseen action recognition", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Zhu_Towards_Universal_Representation_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "976": {"title": "deep image prior", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Ulyanov_Deep_Image_Prior_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "977": {"title": "st-gan: spatial transformer generative adversarial networks for image compositing", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}, "978": {"title": "cartoongan: generative adversarial networks for photo cartoonization", "url": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.html", "abstract": "", "cite_num": -1, "conf": "cvpr", "time": "2018"}}