{"0": {"title": "attention transfer from web images for video recognition.", "url": "https://doi.org/10.1145/3123266.3123432", "abstract": "Training deep learning based video classifiers for action recognition requires a large amount of lab\neled videos. The labeling process is labor-intensive and time-consuming. On the other hand, large am\nount of weakly-labeled images are uploaded to the Internet by users everyday. To harness the rich an\nd highly diverse set of Web images, a scalable approach is to crawl these images to train deep learn\ning based classifier, such as Convolutional Neural Networks (CNN). However, due to the domain shift \nproblem, the performance of Web images trained deep classifiers tend to degrade when directly deploy\ned to videos. One way to address this problem is to fine-tune the trained models on videos, but suff\nicient amount of annotated videos are still required. In this work, we propose a novel approach to t\nransfer knowledge from image domain to video domain. The proposed method can adapt to the target dom\nain (i.e. video data) with limited amount of training data. Our method maps the video frames into a \nlow-dimensional feature space using the class-discriminative spatial attention map for CNNs. We desi\ngn a novel Siamese EnergyNet structure to learn energy functions on the attention maps by jointly op\ntimizing two loss functions, such that the attention map corresponding to a ground truth concept wou\nld have higher energy. We conduct extensive experiments on two challenging video recognition dataset\ns (i.e. TVHI and UCF101), and demonstrate the efficacy of our proposed method.", "cite_num": 7, "conf": "mm", "time": "2017"}, "1": {"title": "sketchparse: towards rich descriptions for poorly drawn sketches using multi-task hierarchical deep networks.", "url": "https://doi.org/10.1145/3123266.3123270", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "2": {"title": "place-centric visual urban perception with deep multi-instance regression.", "url": "https://doi.org/10.1145/3123266.3123271", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "3": {"title": "future-supervised retrieval of unseen queries for live video.", "url": "https://doi.org/10.1145/3123266.3123437", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "4": {"title": "learning to compose with professional photographs on the web.", "url": "https://doi.org/10.1145/3123266.3123274", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "5": {"title": "structcap: structured semantic embedding for image captioning.", "url": "https://doi.org/10.1145/3123266.3123275", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "6": {"title": "is foveated rendering perceivable in virtual reality?: exploring the efficiency and consistency of quality assessment methods.", "url": "https://doi.org/10.1145/3123266.3123434", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "7": {"title": "facecollage: a rapidly deployable system for real-time head reconstruction for on-the-go 3d telepresence.", "url": "https://doi.org/10.1145/3123266.3123281", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "8": {"title": "livejack: integrating cdns and edge clouds for live content broadcasting.", "url": "https://doi.org/10.1145/3123266.3123283", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "9": {"title": "face aging with contextual generative adversarial nets.", "url": "https://doi.org/10.1145/3123266.3123431", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "10": {"title": "fashion world map: understanding cities through streetwear fashion.", "url": "https://doi.org/10.1145/3123266.3123268", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "11": {"title": "automatic adjustment of stereoscopic content for long-range projections in outdoor areas.", "url": "https://doi.org/10.1145/3123266.3123269", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "12": {"title": "multiview and multimodal pervasive indoor localization.", "url": "https://doi.org/10.1145/3123266.3123436", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "13": {"title": "searching personal photos on the phone with instant visual query suggestion and joint text-image hashing.", "url": "https://doi.org/10.1145/3123266.3123446", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "14": {"title": "a unified personalized video recommendation via dynamic recurrent neural networks.", "url": "https://doi.org/10.1145/3123266.3123433", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "15": {"title": "enhancing and augmenting human perception with artificial intelligence technologies.", "url": "https://doi.org/10.1145/3123266.3130870", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "16": {"title": "h-time: haptic-enabled tele-immersive musculoskeletal examination.", "url": "https://doi.org/10.1145/3123266.3123395", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "17": {"title": "catching the temporal regions-of-interest for video captioning.", "url": "https://doi.org/10.1145/3123266.3123327", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "18": {"title": "adversarial cross-modal retrieval.", "url": "https://doi.org/10.1145/3123266.3123326", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "19": {"title": "deep low-rank sparse collective factorization for cross-domain recommendation.", "url": "https://doi.org/10.1145/3123266.3123361", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "20": {"title": "unconstrained fashion landmark detection via hierarchical recurrent transformer networks.", "url": "https://doi.org/10.1145/3123266.3123276", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "21": {"title": "deep attribute-preserving metric learning for natural language object retrieval.", "url": "https://doi.org/10.1145/3123266.3123439", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "22": {"title": "understanding fashion trends from street photos via neighbor-constrained embedding learning.", "url": "https://doi.org/10.1145/3123266.3123441", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "23": {"title": "skeleton-aided articulated motion generation.", "url": "https://doi.org/10.1145/3123266.3123277", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "24": {"title": "deep progressive hashing for image retrieval.", "url": "https://doi.org/10.1145/3123266.3123280", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "25": {"title": "the role of visual attention in sentiment prediction.", "url": "https://doi.org/10.1145/3123266.3123445", "abstract": "Automated assessment of visual sentiment has many applications, such as monitoring social media and \nfacilitating online advertising. In current research on automated visual sentiment assessment, image\ns are mainly input and processed as a whole. However, human attention is biased, and a focal region \nwith high acuity can disproportionately influence visual sentiment. To investigate how attention inf\nluences visual sentiment, we conducted experiments that reveal critical insights into human percepti\non. We discover that negative sentiments are elicited by the focal region without a notable influenc\ne of contextual information, whereas positive sentiments are influenced by both focal and contextual\n information. Building on these insights, we create new deep convolutional neural networks for senti\nment prediction that have additional channels devoted to encoding focal information. On two benchmar\nk datasets, the proposed models demonstrate superior performance compared with the state-of-the-art \nmethods. Extensive visualizations and statistical analyses indicate that the focal channels are more\n effective on images with focal objects, especially for images that also elicit negative sentiments.\n", "cite_num": 3, "conf": "mm", "time": "2017"}, "26": {"title": "robust visual object tracking with top-down reasoning.", "url": "https://doi.org/10.1145/3123266.3123449", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "27": {"title": "pedestrian path forecasting in crowd: a deep spatio-temporal perspective.", "url": "https://doi.org/10.1145/3123266.3123287", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "28": {"title": "stylized adversarial autoencoder for image generation.", "url": "https://doi.org/10.1145/3123266.3123450", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "29": {"title": "regle: spatially regularized graph learning for visual tracking.", "url": "https://doi.org/10.1145/3123266.3123288", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "30": {"title": "deep unsupervised convolutional domain adaptation.", "url": "https://doi.org/10.1145/3123266.3123292", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "31": {"title": "improving event extraction via multimodal integration.", "url": "https://doi.org/10.1145/3123266.3123294", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "32": {"title": "a dual-network progressive approach to weakly supervised object detection.", "url": "https://doi.org/10.1145/3123266.3123455", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "33": {"title": "multimodal learning for web information extraction.", "url": "https://doi.org/10.1145/3123266.3123296", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "34": {"title": "fast deep matting for portrait animation on mobile phone.", "url": "https://doi.org/10.1145/3123266.3123286", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "35": {"title": "an http/2-based adaptive streaming framework for 360\u00b0 virtual reality videos.", "url": "https://doi.org/10.1145/3123266.3123453", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "36": {"title": "360probdash: improving qoe of 360 video streaming using tile-based http adaptive streaming.", "url": "https://doi.org/10.1145/3123266.3123291", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "37": {"title": "sharerender: bypassing gpu virtualization to enable fine-grained resource sharing for cloud gaming.", "url": "https://doi.org/10.1145/3123266.3123306", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "38": {"title": "temporal binary coding for large-scale video search.", "url": "https://doi.org/10.1145/3123266.3123273", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "39": {"title": "one-shot fine-grained instance retrieval.", "url": "https://doi.org/10.1145/3123266.3123278", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "40": {"title": "modeling the intransitive pairwise image preference from multiple angles.", "url": "https://doi.org/10.1145/3123266.3123285", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "41": {"title": "pd-survey: supporting audience-centric research through surveys on pervasive display networks.", "url": "https://doi.org/10.1145/3123266.3123293", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "42": {"title": "learning visual emotion distributions via multi-modal features fusion.", "url": "https://doi.org/10.1145/3123266.3130858", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "43": {"title": "exploiting high-level semantics for no-reference image quality assessment of realistic blur images.", "url": "https://doi.org/10.1145/3123266.3123322", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "44": {"title": "a paralinguistic approach to speaker diarisation: using age, gender, voice likability and personality traits.", "url": "https://doi.org/10.1145/3123266.3123338", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "45": {"title": "wheel: accelerating cnns with distributed gpus via hybrid parallelism and alternate strategy.", "url": "https://doi.org/10.1145/3123266.3123435", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "46": {"title": "a delicious recipe analysis framework for exploring multi-modal recipes with various attributes.", "url": "https://doi.org/10.1145/3123266.3123272", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "47": {"title": "multi-modal knowledge representation learning via webly-supervised relationships mining.", "url": "https://doi.org/10.1145/3123266.3123443", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "48": {"title": "glad: global-local-alignment descriptor for pedestrian retrieval.", "url": "https://doi.org/10.1145/3123266.3123279", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "49": {"title": "magic-wall: visualizing room decoration.", "url": "https://doi.org/10.1145/3123266.3123398", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "50": {"title": "multi-scale cascade network for salient object detection.", "url": "https://doi.org/10.1145/3123266.3123290", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "51": {"title": "sketch recognition with deep visual-sequential fusion model.", "url": "https://doi.org/10.1145/3123266.3123321", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "52": {"title": "privacy protection in online multimedia.", "url": "https://doi.org/10.1145/3123266.3133335", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "53": {"title": "what your facebook profile picture reveals about your personality.", "url": "https://doi.org/10.1145/3123266.3123331", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "54": {"title": "capturing spatial and temporal patterns for distinguishing between posed and spontaneous expressions.", "url": "https://doi.org/10.1145/3123266.3123350", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "55": {"title": "an image-based deep spectrum feature representation for the recognition of emotional speech.", "url": "https://doi.org/10.1145/3123266.3123371", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "56": {"title": "automatic generation of lyrics parodies.", "url": "https://doi.org/10.1145/3123266.3123410", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "57": {"title": "on server provisioning for cloud gaming.", "url": "https://doi.org/10.1145/3123266.3123310", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "58": {"title": "fastshrinkage: perceptually-aware retargeting toward mobile platforms.", "url": "https://doi.org/10.1145/3123266.3123377", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "59": {"title": "real-time monocular dense mapping for augmented reality.", "url": "https://doi.org/10.1145/3123266.3123348", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "60": {"title": "automatic music video generation based on simultaneous soundtrack recommendation and video editing.", "url": "https://doi.org/10.1145/3123266.3123399", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "61": {"title": "region-based image retrieval revisited.", "url": "https://doi.org/10.1145/3123266.3123312", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "62": {"title": "learning multimodal attention lstm networks for video captioning.", "url": "https://doi.org/10.1145/3123266.3123448", "abstract": "Automatic generation of video caption is a challenging task as video is an information-intensive med\nia with complex variations. Most existing methods, either based on language templates or sequence le\narning, have treated video as a flat data sequence while ignoring intrinsic multimodality nature. Ob\nserving that different modalities (e.g., frame, motion, and audio streams), as well as the elements \nwithin each modality, contribute differently to the sentence generation, we present a novel deep fra\nmework to boost video captioning by learning Multimodal Attention Long-Short Term Memory networks (M\nA-LSTM). Our proposed MA-LSTM fully exploits both multimodal streams and temporal attention to selec\ntively focus on specific elements during the sentence generation. Moreover, we design a novel child-\nsum fusion unit in the MA-LSTM to effectively combine different encoded modalities to the initial de\ncoding states. Different from existing approaches that employ the same LSTM structure for different \nmodalities, we train modality-specific LSTM to capture the intrinsic representations of individual m\nodalities. The experiments on two benchmark datasets (MSVD and MSR-VTT) show that our MA-LSTM signif\nicantly outperforms the state-of-the-art methods with 52.3 BLEU@4 and 70.4 CIDER-D metrics on MSVD d\nataset, respectively.", "cite_num": 17, "conf": "mm", "time": "2017"}, "63": {"title": "profilio: psychometric profiling to boost social media advertising.", "url": "https://doi.org/10.1145/3123266.3129311", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "64": {"title": "pl@ntnet - my business.", "url": "https://doi.org/10.1145/3123266.3129312", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "65": {"title": "drag a star 3.0: an audience participatory interactive art.", "url": "https://doi.org/10.1145/3123266.3129323", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "66": {"title": "probably/possibly?: an immersive interactive visual/sonic quantum composition and synthesizer.", "url": "https://doi.org/10.1145/3123266.3129324", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "67": {"title": "touch me here: a virtual touch cinema.", "url": "https://doi.org/10.1145/3123266.3129325", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "68": {"title": "filters.", "url": "https://doi.org/10.1145/3123266.3129326", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "69": {"title": "split consideration for foreground and background painting using artificial neural networks.", "url": "https://doi.org/10.1145/3123266.3129327", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "70": {"title": "spatial magnetic field visualization: interactive kinetic art installation driven by the invisible forces of magnetic fields.", "url": "https://doi.org/10.1145/3123266.3129328", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "71": {"title": "\u00e0 quatre mains.", "url": "https://doi.org/10.1145/3123266.3129329", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "72": {"title": "las barricadas misteriosas.", "url": "https://doi.org/10.1145/3123266.3129330", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "73": {"title": "presently untitled: data mapping of 2016 u.s. presidential election twitter activity, phase iii.", "url": "https://doi.org/10.1145/3123266.3129332", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "74": {"title": "query-adaptive video summarization via quality-aware relevance estimation.", "url": "https://doi.org/10.1145/3123266.3123297", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "75": {"title": "predicting human intentions from motion cues only: a 2d+3d fusion approach.", "url": "https://doi.org/10.1145/3123266.3123298", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "76": {"title": "rgb-d scene recognition with object-to-object relation.", "url": "https://doi.org/10.1145/3123266.3123300", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "77": {"title": "data generation for improving person re-identification.", "url": "https://doi.org/10.1145/3123266.3123302", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "78": {"title": "salient object detection with chained multi-scale fully convolutional network.", "url": "https://doi.org/10.1145/3123266.3123318", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "79": {"title": "fine-grained discriminative localization via saliency-guided faster r-cnn.", "url": "https://doi.org/10.1145/3123266.3123319", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "80": {"title": "learning to recognise unseen classes by a few similes.", "url": "https://doi.org/10.1145/3123266.3123323", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "81": {"title": "deep cross-modality alignment for multi-shot person re-identification.", "url": "https://doi.org/10.1145/3123266.3123324", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "82": {"title": "improved multimodal representation learning with skip connections.", "url": "https://doi.org/10.1145/3123266.3123332", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "83": {"title": "modeling image virality with pairwise spatial transformer networks.", "url": "https://doi.org/10.1145/3123266.3123333", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "84": {"title": "metric-based generative adversarial network.", "url": "https://doi.org/10.1145/3123266.3123334", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "85": {"title": "more than an answer: neural pivot network for visual qestion answering.", "url": "https://doi.org/10.1145/3123266.3123335", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "86": {"title": "aristo: an augmented reality platform for immersion and interactivity.", "url": "https://doi.org/10.1145/3123266.3123308", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "87": {"title": "sports vr content generation from regular camera feeds.", "url": "https://doi.org/10.1145/3123266.3123315", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "88": {"title": "optile: toward optimal tiling in 360-degree video streaming.", "url": "https://doi.org/10.1145/3123266.3123339", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "89": {"title": "too many pixels to perceive: subpixel shutoff for display energy reduction on oled smartphones.", "url": "https://doi.org/10.1145/3123266.3123344", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "90": {"title": "exploring consistent preferences: discrete hashing with pair-exemplar for scalable landmark search.", "url": "https://doi.org/10.1145/3123266.3123301", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "91": {"title": "fast and accurate pedestrian detection using dual-stage group cost-sensitive realboost with vector form filters.", "url": "https://doi.org/10.1145/3123266.3123303", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "92": {"title": "online cross-modal scene retrieval by binary representation and semantic graph.", "url": "https://doi.org/10.1145/3123266.3123311", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "93": {"title": "neurostylist: neural compatibility modeling for clothing matching.", "url": "https://doi.org/10.1145/3123266.3123314", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "94": {"title": "it's all around you: exploring 360\u00b0 video viewing experiences on mobile devices.", "url": "https://doi.org/10.1145/3123266.3123347", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "95": {"title": "exploring domain knowledge for affective video content analyses.", "url": "https://doi.org/10.1145/3123266.3123352", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "96": {"title": "occlusion-aware video temporal consistency.", "url": "https://doi.org/10.1145/3123266.3123363", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "97": {"title": "protest activity detection and perceived violence estimation from social media images.", "url": "https://doi.org/10.1145/3123266.3123282", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "98": {"title": "multimodal fusion with recurrent neural networks for rumor detection on microblogs.", "url": "https://doi.org/10.1145/3123266.3123454", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "99": {"title": "building multi-modal interfaces for smartphones.", "url": "https://doi.org/10.1145/3123266.3130874", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "100": {"title": "acm sigmm award for outstanding technical contributions to multimedia computing, communications and applications.", "url": "https://doi.org/10.1145/3123266.3139462", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "101": {"title": "acm sigmm rising star award 2017.", "url": "https://doi.org/10.1145/3123266.3139463", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "102": {"title": "sigmm award for outstanding ph.d. thesis in multimedia computing, communications and applications 2017.", "url": "https://doi.org/10.1145/3123266.3139464", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "103": {"title": "using dash assisting network elements for optimizing video streaming quality.", "url": "https://doi.org/10.1145/3123266.3123965", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "104": {"title": "who composes the music?: musicality evaluation for algorithmic composition via electroencephalography.", "url": "https://doi.org/10.1145/3123266.3123967", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "105": {"title": "cross-media relevance computation for multimedia retrieval.", "url": "https://doi.org/10.1145/3123266.3123963", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "106": {"title": "towards global optimization in display advertising by integrating multimedia metrics with real-time bidding.", "url": "https://doi.org/10.1145/3123266.3123966", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "107": {"title": "indefinite kernel logistic regression.", "url": "https://doi.org/10.1145/3123266.3123295", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "108": {"title": "positive and unlabeled learning for anomaly detection with multi-features.", "url": "https://doi.org/10.1145/3123266.3123304", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "109": {"title": "hierarchical recurrent neural network for video summarization.", "url": "https://doi.org/10.1145/3123266.3123328", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "110": {"title": "learning a target sample re-generator for cross-database micro-expression recognition.", "url": "https://doi.org/10.1145/3123266.3123367", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "111": {"title": "from multimedia logs to personal chronicles.", "url": "https://doi.org/10.1145/3123266.3123375", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "112": {"title": "from hard to soft: towards more human-like emotion recognition by modelling the perception uncertainty.", "url": "https://doi.org/10.1145/3123266.3123383", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "113": {"title": "two birds one stone: on both cold-start and long-tail recommendation.", "url": "https://doi.org/10.1145/3123266.3123316", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "114": {"title": "multi-networks joint learning for large-scale cross-modal retrieval.", "url": "https://doi.org/10.1145/3123266.3123317", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "115": {"title": "photo2trip: exploiting visual contents in geo-tagged photos for personalized tour recommendation.", "url": "https://doi.org/10.1145/3123266.3123336", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "116": {"title": "rethinking http adaptive streaming with the mobile user perception.", "url": "https://doi.org/10.1145/3123266.3123357", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "117": {"title": "request: seamless dynamic adaptive streaming over http for multi-homed smartphone under resource constraints.", "url": "https://doi.org/10.1145/3123266.3123368", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "118": {"title": "optimal set of 360-degree videos for viewport-adaptive streaming.", "url": "https://doi.org/10.1145/3123266.3123372", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "119": {"title": "deep active learning through cognitive information parcels.", "url": "https://doi.org/10.1145/3123266.3123337", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "120": {"title": "3densinet: a robust neural network architecture towards 3d volumetric object prediction from 2d image.", "url": "https://doi.org/10.1145/3123266.3123340", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "121": {"title": "towards micro-video understanding by joint sequential-sparse modeling.", "url": "https://doi.org/10.1145/3123266.3123341", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "122": {"title": "leaf: latent extended attribute features discovery for visual classification.", "url": "https://doi.org/10.1145/3123266.3123342", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "123": {"title": "single shot temporal action detection.", "url": "https://doi.org/10.1145/3123266.3123343", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "124": {"title": "finding the secret of cnn parameter layout under strict size constraint.", "url": "https://doi.org/10.1145/3123266.3123346", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "125": {"title": "deep temporal models using identity skip-connections for speech emotion recognition.", "url": "https://doi.org/10.1145/3123266.3123353", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "126": {"title": "video description with spatial-temporal attention.", "url": "https://doi.org/10.1145/3123266.3123354", "abstract": "Temporal attention has been widely used in video description to adaptively focus on important frames\n. However, most existing methods based on temporal attention suffer from the problems of recognition\n error and detail missing, because only coarse frame-level global features are employed. Inspired by\n recent successful work in image description using spatial attention, we propose a spatial-temporal \nattention (STAT) method to address such problems. In particular, first, we take advantage of object-\nlevel local features to address the problem of detail missing. Second, the STAT method further selec\nts relevant local features by spatial attention and then attend to important frames by temporal atte\nntion to recognize related semantics. The proposed two-stage attention mechanism can recognize the s\nalient objects more precisely with high recall and automatically focus on the most relevant spatial-\ntemporal segments given the sentence context. Extensive experiments on two well-known benchmarks sug\ngest that STAT method outperforms the state-of-the-art methods on MSVD with BLEU4 score 0.511, and a\nchieves superior BLEU4 score 0.374 on MSR-VTT-10K. Compared to the method without local features, th\ne relative improvements derived from our STAT method are 10.1% and 0.8% respectively on two benchmar\nks. Compared to the method using only temporal attention, the relative improvements derived from our\n STAT method are 18.3% and 9.0% respectively on two benchmarks.", "cite_num": 5, "conf": "mm", "time": "2017"}, "127": {"title": "pedestrian detection via bi-directional multi-scale analysis.", "url": "https://doi.org/10.1145/3123266.3123356", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "128": {"title": "fine-grained recognition via attribute-guided attentive feature aggregation.", "url": "https://doi.org/10.1145/3123266.3123358", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "129": {"title": "normface: l2 hypersphere embedding for face verification.", "url": "https://doi.org/10.1145/3123266.3123359", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "130": {"title": "video question answering via hierarchical dual-level attention network learning.", "url": "https://doi.org/10.1145/3123266.3123364", "abstract": "Video question answering is a challenging task in visual information retrieval, which provides the a\nccurate answer from the referenced video contents according to the given question. However, the exis\nting visual question answering approaches mainly tackle the problem of static image question answeri\nng, which may be ineffectively applied for video question answering directly, due to the insufficien\ncy of modeling the video temporal dynamics. In this paper, we study the problem of video question an\nswering from the viewpoint of hierarchical dual-level attention network learning. We obtain the obje\nct appearance and movement information in the video based on both frame-level and segment-level feat\nure representation methods. We then develop the hierarchical duallevel attention networks to learn t\nhe question-aware video representations with word-level and question-level attention mechanisms. We \nnext devise the question-level fusion attention mechanism for our proposed networks to learn the que\nstionaware joint video representation for video question answering. We construct two large-scale vid\neo question answering datasets. The extensive experiments validate the effectiveness of our method.", "cite_num": 11, "conf": "mm", "time": "2017"}, "131": {"title": "region-based activity recognition using conditional gan.", "url": "https://doi.org/10.1145/3123266.3123365", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "132": {"title": "deepq: advancing healthcare through artificial intelligence and virtual reality.", "url": "https://doi.org/10.1145/3123266.3130875", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "133": {"title": "detecting temporal proposal for action localization with tree-structured search policy.", "url": "https://doi.org/10.1145/3123266.3123362", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "134": {"title": "learning fashion compatibility with bidirectional lstms.", "url": "https://doi.org/10.1145/3123266.3123394", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "135": {"title": "3d cnns on distance matrices for human action recognition.", "url": "https://doi.org/10.1145/3123266.3123299", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "136": {"title": "sync-draw: automatic video generation using deep recurrent attentive architectures.", "url": "https://doi.org/10.1145/3123266.3123309", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "137": {"title": "16k cinematic vr streaming.", "url": "https://doi.org/10.1145/3123266.3123307", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "138": {"title": "where are the sweet spots?: a systematic approach to reproducible dash player comparisons.", "url": "https://doi.org/10.1145/3123266.3123426", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "139": {"title": "towards forward-looking online bitrate adaptation for dash.", "url": "https://doi.org/10.1145/3123266.3123284", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "140": {"title": "quetra: a queuing theory approach to dash rate adaptation.", "url": "https://doi.org/10.1145/3123266.3123390", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "141": {"title": "vocktail: a virtual cocktail for pairing digital taste, smell, and color sensations.", "url": "https://doi.org/10.1145/3123266.3123440", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "142": {"title": "affect recognition in ads with application to computational advertising.", "url": "https://doi.org/10.1145/3123266.3123444", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "143": {"title": "image quality assessment for dibr synthesized views using elastic metric.", "url": "https://doi.org/10.1145/3123266.3123329", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "144": {"title": "elasticplay: interactive video summarization with dynamic time budgets.", "url": "https://doi.org/10.1145/3123266.3123393", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "145": {"title": "panel: cross-media intelligence.", "url": "https://doi.org/10.1145/3123266.3133336", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "146": {"title": "from part to whole: who is behind the painting?", "url": "https://doi.org/10.1145/3123266.3123325", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "147": {"title": "deepart: learning joint representations of visual arts.", "url": "https://doi.org/10.1145/3123266.3123405", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "148": {"title": "enhancing micro-video understanding by harnessing external sounds.", "url": "https://doi.org/10.1145/3123266.3123313", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "149": {"title": "tensorlayer: a versatile library for efficient deep learning development.", "url": "https://doi.org/10.1145/3123266.3129391", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "150": {"title": "nubomedia: the first open source webrtc paas.", "url": "https://doi.org/10.1145/3123266.3129392", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "151": {"title": "bmxnet: an open-source binary neural network implementation based on mxnet.", "url": "https://doi.org/10.1145/3123266.3129393", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "152": {"title": "webdnn: fastest dnn execution framework on web browser.", "url": "https://doi.org/10.1145/3123266.3129394", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "153": {"title": "chainercv: a library for deep learning in computer vision.", "url": "https://doi.org/10.1145/3123266.3129395", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "154": {"title": "unrealcv: virtual worlds for computer vision.", "url": "https://doi.org/10.1145/3123266.3129396", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "155": {"title": "a system for spatiotemporal anomaly localization in surveillance videos.", "url": "https://doi.org/10.1145/3123266.3127912", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "156": {"title": "a tag recommendation system for popularity boosting.", "url": "https://doi.org/10.1145/3123266.3127913", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "157": {"title": "deepcadx: automated prostate cancer detection and diagnosis in mp-mri based on multimodal convolutional neural networks.", "url": "https://doi.org/10.1145/3123266.3127914", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "158": {"title": "matplanner: plan your days in conferences by resolving conflicting events.", "url": "https://doi.org/10.1145/3123266.3127915", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "159": {"title": "natural experiences in museums through virtual reality and voice commands.", "url": "https://doi.org/10.1145/3123266.3127916", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "160": {"title": "facecloud: heterogeneous cloud visualization of multiplex networks for multimedia archive exploration.", "url": "https://doi.org/10.1145/3123266.3127917", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "161": {"title": "real-time dense monocular slam for augmented reality.", "url": "https://doi.org/10.1145/3123266.3127918", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "162": {"title": "enhancing music events using physiological sensor data.", "url": "https://doi.org/10.1145/3123266.3127919", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "163": {"title": "teleconsultant: communication and analysis of wearable videos in emergency medical environments.", "url": "https://doi.org/10.1145/3123266.3127920", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "164": {"title": "midot-key: a smart key instantly generated on your item.", "url": "https://doi.org/10.1145/3123266.3127921", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "165": {"title": "time traveler: a real-time face aging system.", "url": "https://doi.org/10.1145/3123266.3127922", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "166": {"title": "outdoor object recognition for smart audio guides.", "url": "https://doi.org/10.1145/3123266.3127923", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "167": {"title": "ibm high-five: highlights from intelligent video engine.", "url": "https://doi.org/10.1145/3123266.3127924", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "168": {"title": "shadow puppetry with robotic arms.", "url": "https://doi.org/10.1145/3123266.3127925", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "169": {"title": "smart mirror: intelligent makeup recommendation and synthesis.", "url": "https://doi.org/10.1145/3123266.3127926", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "170": {"title": "real-time deep video spatial resolution upconversion system (struct++ demo).", "url": "https://doi.org/10.1145/3123266.3127927", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "171": {"title": "rsvp: a real-time surveillance video parsing system with single frame supervision.", "url": "https://doi.org/10.1145/3123266.3127928", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "172": {"title": "nexgentv: providing real-time insight during political debates in a second screen application.", "url": "https://doi.org/10.1145/3123266.3127929", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "173": {"title": "a hybrid p2p/multi-server quality-adaptive live-streaming solution enhancing end-user's qoe.", "url": "https://doi.org/10.1145/3123266.3127936", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "174": {"title": "diversified and summarized video search system.", "url": "https://doi.org/10.1145/3123266.3127937", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "175": {"title": "t2u: a deep cross-platform video recommendation system with a novel interface.", "url": "https://doi.org/10.1145/3123266.3127938", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "176": {"title": "sketch-based image retrieval using generative adversarial networks.", "url": "https://doi.org/10.1145/3123266.3127939", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "177": {"title": "pic2dish: a customized cooking assistant system.", "url": "https://doi.org/10.1145/3123266.3126490", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "178": {"title": "visual sentiment analysis for review images with item-oriented and user-oriented cnn.", "url": "https://doi.org/10.1145/3123266.3123374", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "179": {"title": "mutually guided image filtering.", "url": "https://doi.org/10.1145/3123266.3123378", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "180": {"title": "learning semantic feature map for visual content recognition.", "url": "https://doi.org/10.1145/3123266.3123379", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "181": {"title": "video visual relation detection.", "url": "https://doi.org/10.1145/3123266.3123380", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "182": {"title": "deep location-specific tracking.", "url": "https://doi.org/10.1145/3123266.3123381", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "183": {"title": "a multi-task framework for weather recognition.", "url": "https://doi.org/10.1145/3123266.3123382", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "184": {"title": "discriminative training of complex-valued deep recurrent neural network for singing voice separation.", "url": "https://doi.org/10.1145/3123266.3123386", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "185": {"title": "adaptive low-rank multi-label active learning for image classification.", "url": "https://doi.org/10.1145/3123266.3123388", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "186": {"title": "adaptively attending to visual attributes and linguistic knowledge for captioning.", "url": "https://doi.org/10.1145/3123266.3123391", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "187": {"title": "efficient binary coding for subspace-based query-by-image video retrieval.", "url": "https://doi.org/10.1145/3123266.3123392", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "188": {"title": "fractal: fec-based rate control for rtp.", "url": "https://doi.org/10.1145/3123266.3123373", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "189": {"title": "when cloud meets uncertain crowd: an auction approach for crowdsourced livecast transcoding.", "url": "https://doi.org/10.1145/3123266.3123384", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "190": {"title": "multicamera summarization of rehabilitation sessions in home environment.", "url": "https://doi.org/10.1145/3123266.3123387", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "191": {"title": "visualization of stone trajectories in live curling broadcasts using online machine learning.", "url": "https://doi.org/10.1145/3123266.3123351", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "192": {"title": "deep binary reconstruction for cross-modal hashing.", "url": "https://doi.org/10.1145/3123266.3123355", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "193": {"title": "semi-dense depth interpolation using deep convolutional neural networks.", "url": "https://doi.org/10.1145/3123266.3123360", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "194": {"title": "venues in social media: examining ambiance perception through scene semantics.", "url": "https://doi.org/10.1145/3123266.3123402", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "195": {"title": "moving as a leader: detecting emergent leadership in small groups using body pose.", "url": "https://doi.org/10.1145/3123266.3123404", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "196": {"title": "#visualhashtags: visual summarization of social media events using mid-level visual elements.", "url": "https://doi.org/10.1145/3123266.3123407", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "197": {"title": "multi-scale context based attention for dynamic music emotion prediction.", "url": "https://doi.org/10.1145/3123266.3123408", "abstract": "Dynamic music emotion prediction is to recognize the continuous emotion information in music, which \nis necessary for music retrieval and recommendation. In this paper, we adopt the dimensional valence\n-arousal (V-A) emotion model to represent the dynamic emotion in music. In our opinion, music and V-\nA emotion label do not have the one-to-one correspondence in the time domain, while the expression o\nf music emotion at one moment is the accumulation of previous music content for a period of time, so\n we propose Long Short-Term Memory (LSTM) based sequence-to-one mapping for dynamic music emotion pr\nediction. Based on this sequence-to-one music emotion mapping, it is proved that different time scal\nes' preceding content has an influence on the LSTM model's performance, so we further propose the Mu\nlti-scale Context based Attention (MCA) for dynamic music emotion prediction. We evaluate our propos\ned method on the database of Emotion in Music task at MediaEval 2015, and the results show that our \nproposed method outperforms most of the models using the same features and achieves a competitive pe\nrformance with the state-of-the-art methods.", "cite_num": 1, "conf": "mm", "time": "2017"}, "198": {"title": "a simplified topological representation of text for local and global context.", "url": "https://doi.org/10.1145/3123266.3123330", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "199": {"title": "experimental analysis of bandwidth allocation in automated video surveillance systems.", "url": "https://doi.org/10.1145/3123266.3123376", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "200": {"title": "multimedia semantic integrity assessment using joint embedding of images and text.", "url": "https://doi.org/10.1145/3123266.3123385", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "201": {"title": "real-time false-contours removal for inverse tone mapped hdr content.", "url": "https://doi.org/10.1145/3123266.3123400", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "202": {"title": "deep matching and validation network: an end-to-end solution to constrained image splicing localization and detection.", "url": "https://doi.org/10.1145/3123266.3123411", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "203": {"title": "learning object-centric transformation for video prediction.", "url": "https://doi.org/10.1145/3123266.3123349", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "204": {"title": "two-stream attentive cnns for image retrieval.", "url": "https://doi.org/10.1145/3123266.3123396", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "205": {"title": "deep asymmetric pairwise hashing.", "url": "https://doi.org/10.1145/3123266.3123345", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "206": {"title": "integrated face analytics networks through cross-dataset hybrid training.", "url": "https://doi.org/10.1145/3123266.3123438", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "207": {"title": "exploring outliers in crowdsourced ranking for qoe.", "url": "https://doi.org/10.1145/3123266.3123267", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "208": {"title": "fluency-guided cross-lingual image captioning.", "url": "https://doi.org/10.1145/3123266.3123366", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "209": {"title": "mr.mapp: mixed reality for managing phantom pain.", "url": "https://doi.org/10.1145/3123266.3123419", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "210": {"title": "anti-camera led lighting.", "url": "https://doi.org/10.1145/3123266.3123416", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "211": {"title": "incremental accelerated kernel discriminant analysis.", "url": "https://doi.org/10.1145/3123266.3123401", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "212": {"title": "pseudo label based unsupervised deep discriminative hashing for image retrieval.", "url": "https://doi.org/10.1145/3123266.3123403", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "213": {"title": "multi-modal localization and enhancement of multiple sound sources from a micro aerial vehicle.", "url": "https://doi.org/10.1145/3123266.3123412", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "214": {"title": "selective deep convolutional features for image retrieval.", "url": "https://doi.org/10.1145/3123266.3123417", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "215": {"title": "statistical inference of gaussian-laplace distribution for person verification.", "url": "https://doi.org/10.1145/3123266.3123421", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "216": {"title": "beyond human-level license plate super-resolution with progressive vehicle search and domain priori gan.", "url": "https://doi.org/10.1145/3123266.3123422", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "217": {"title": "learning to generate and edit hairstyles.", "url": "https://doi.org/10.1145/3123266.3123423", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "218": {"title": "adaptively weighted multi-task deep network for person attribute classification.", "url": "https://doi.org/10.1145/3123266.3123424", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "219": {"title": "video question answering via gradually refined attention over appearance and motion.", "url": "https://doi.org/10.1145/3123266.3123427", "abstract": "Recently image question answering (ImageQA) has gained lots of attention in the research community. \nHowever, as its natural extension, video question answering (VideoQA) is less explored. Although bot\nh tasks look similar, VideoQA is more challenging mainly because of the complexity and diversity of \nvideos. As such, simply extending the ImageQA methods to videos is insufficient and suboptimal. Part\nicularly, working with the video needs to model its inherent temporal structure and analyze the dive\nrse information it contains. In this paper, we consider exploiting the appearance and motion informa\ntion resided in the video with a novel attention mechanism. More specifically, we propose an end-to-\nend model which gradually refines its attention over the appearance and motion features of the video\n using the question as guidance. The question is processed word by word until the model generates th\ne final optimized attention. The weighted representation of the video, as well as other contextual i\nnformation, are used to generate the answer. Extensive experiments show the advantages of our model \ncompared to other baseline models. We also demonstrate the effectiveness of our model by analyzing t\nhe refined attention weights during the question answering procedure.", "cite_num": 23, "conf": "mm", "time": "2017"}, "220": {"title": "cross-domain image retrieval with attention modeling.", "url": "https://doi.org/10.1145/3123266.3123429", "abstract": "With the proliferation of e-commerce websites and the ubiquitousness of smart phones, cross-domain i\nmage retrieval using images taken by smart phones as queries to search products on e-commerce websit\nes is emerging as a popular application. One challenge of this task is to locate the attention of bo\nth the query and database images. In particular, database images, e.g. of fashion products, on e-com\nmerce websites are typically displayed with other accessories, and the images taken by users contain\n noisy background and large variations in orientation and lighting. Consequently, their attention is\n difficult to locate. In this paper, we exploit the rich tag information available on the e-commerce\n websites to locate the attention of database images. For query images, we use each candidate image \nin the database as the context to locate the query attention. Novel deep convolutional neural networ\nk architectures, namely TagYNet and CtxYNet, are proposed to learn the attention weights and then ex\ntract effective representations of the images. Experimental results on public datasets confirm that \nour approaches have significant improvement over the existing methods in terms of the retrieval accu\nracy and efficiency.", "cite_num": 7, "conf": "mm", "time": "2017"}, "221": {"title": "modeling the resource requirements of convolutional neural networks on mobile devices.", "url": "https://doi.org/10.1145/3123266.3123389", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "222": {"title": "adaptive audio classification for smartphone in noisy car environment.", "url": "https://doi.org/10.1145/3123266.3123397", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "223": {"title": "a novel system for visual navigation of educational videos using multimodal cues.", "url": "https://doi.org/10.1145/3123266.3123406", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "224": {"title": "adaptive 360-degree video streaming using scalable video coding.", "url": "https://doi.org/10.1145/3123266.3123414", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "225": {"title": "cross-media retrieval by learning rich semantic embeddings of multimedia.", "url": "https://doi.org/10.1145/3123266.3123369", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "226": {"title": "deep supervised quantization by self-organizing map.", "url": "https://doi.org/10.1145/3123266.3123415", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "227": {"title": "laplacian-steered neural style transfer.", "url": "https://doi.org/10.1145/3123266.3123425", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "228": {"title": "pqk-means: billion-scale clustering for product-quantized codes.", "url": "https://doi.org/10.1145/3123266.3123430", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "229": {"title": "outlining objects for interactive segmentation on touch devices.", "url": "https://doi.org/10.1145/3123266.3123409", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "230": {"title": "temporally selective attention model for social and affective state recognition in multimedia content.", "url": "https://doi.org/10.1145/3123266.3123413", "abstract": "The sheer amount of human-centric multimedia content has led to increased research on human behavior\n understanding. Most existing methods model behavioral sequences without considering the temporal sa\nliency. This work is motivated by the psychological observation that temporally selective attention \nenables the human perceptual system to process the most relevant information. In this paper, we intr\noduce a new approach, named Temporally Selective Attention Model (TSAM), designed to selectively att\nend to salient parts of human-centric video sequences. Our TSAM models learn to recognize affective \nand social states using a new loss function called speaker-distribution loss. Extensive experiments \nshow that our model achieves the state-of-the-art performance on rapport detection and multimodal se\nntiment analysis. We also show that our speaker-distribution loss function can generalize to other c\nomputational models, improving the prediction performance of deep averaging network and Long Short T\nerm Memory (LSTM).", "cite_num": 7, "conf": "mm", "time": "2017"}, "231": {"title": "quality-of-experience of adaptive video streaming: exploring the space of adaptations.", "url": "https://doi.org/10.1145/3123266.3123418", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "232": {"title": "bringing gaming; vr; and ar to life with deep learning.", "url": "https://doi.org/10.1145/3123266.3130873", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "233": {"title": "semi-relaxation supervised hashing for cross-modal retrieval.", "url": "https://doi.org/10.1145/3123266.3123320", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "234": {"title": "cross-modal recipe retrieval with rich food attributes.", "url": "https://doi.org/10.1145/3123266.3123428", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "235": {"title": "exploring the use of time-dependent cross-network information for personalized recommendations.", "url": "https://doi.org/10.1145/3123266.3123447", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "236": {"title": "to create what you tell: generating videos from captions.", "url": "https://doi.org/10.1145/3123266.3127905", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "237": {"title": "harnessing a.i. for augmenting creativity: application to movie trailer creation.", "url": "https://doi.org/10.1145/3123266.3127906", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "238": {"title": "brain2image: converting brain signals into images.", "url": "https://doi.org/10.1145/3123266.3127907", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "239": {"title": "do individuals smile more in diverse social company?: studying smiles and diversity via social media photos.", "url": "https://doi.org/10.1145/3123266.3127908", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "240": {"title": "how personality affects our likes: towards a better understanding of actionable images.", "url": "https://doi.org/10.1145/3123266.3127909", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "241": {"title": "video captioning with guidance of multimodal latent topics.", "url": "https://doi.org/10.1145/3123266.3123420", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "242": {"title": "learning non-local image diffusion for image denoising.", "url": "https://doi.org/10.1145/3123266.3123370", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "243": {"title": "weighted sparse representation regularized graph learning for rgb-t object tracking.", "url": "https://doi.org/10.1145/3123266.3123289", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "244": {"title": "social media prediction based on residual learning and random forest.", "url": "https://doi.org/10.1145/3123266.3127894", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "245": {"title": "richer semantic visual and language representation for video captioning.", "url": "https://doi.org/10.1145/3123266.3127895", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "246": {"title": "multirate multimodal video captioning.", "url": "https://doi.org/10.1145/3123266.3127904", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "247": {"title": "multi-feature fusion for predicting social media popularity.", "url": "https://doi.org/10.1145/3123266.3127897", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "248": {"title": "manet: a modal attention network for describing videos.", "url": "https://doi.org/10.1145/3123266.3127898", "abstract": "Exploiting multimodal features has become a standard approach towards many video applications, inclu\nding the video captioning task. One problem with the existing work is that it models the relevance o\nf each type of features evenly, which neutralizes the impact of each individual modality to the word\n to be generated. In this paper, we propose a novel Modal Attention Network (MANet) to account for t\nhis issue. Our MANet extends the standard encoder-decoder network by adapting the attention mechanis\nm to video modalities. As a result, MANet emphasizes the impact of each modality with respect to the\n word to be generated. Experimental results show that our MANet effectively utilizes multimodal feat\nures to generate better video descriptions. Especially, our MANet system was ranked among the top th\nree systems at the 2nd Video to Language Challenge in both automatic metrics and human evaluations.", "cite_num": 0, "conf": "mm", "time": "2017"}, "249": {"title": "towards smp challenge: stacking of diverse models for social image popularity prediction.", "url": "https://doi.org/10.1145/3123266.3127899", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "250": {"title": "combining multiple features for image popularity prediction in social media.", "url": "https://doi.org/10.1145/3123266.3127900", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "251": {"title": "knowing yourself: improving video caption via in-depth recap.", "url": "https://doi.org/10.1145/3123266.3127901", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "252": {"title": "a hybrid model combining convolutional neural network with xgboost for predicting social media popularity.", "url": "https://doi.org/10.1145/3123266.3127902", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "253": {"title": "popularity meter: an influence- and aesthetics-aware social media popularity predictor.", "url": "https://doi.org/10.1145/3123266.3127903", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "254": {"title": "hashtag-centric immersive search on social media.", "url": "https://doi.org/10.1145/3123266.3123442", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "255": {"title": "spatio-temporal autoencoder for video anomaly detection.", "url": "https://doi.org/10.1145/3123266.3123451", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "256": {"title": "deep siamese network with multi-level similarity perception for person re-identification.", "url": "https://doi.org/10.1145/3123266.3123452", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "257": {"title": "human-like visual learning and reasoning.", "url": "https://doi.org/10.1145/3123266.3130144", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "258": {"title": "social multimedia sentiment analysis.", "url": "https://doi.org/10.1145/3123266.3130143", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "259": {"title": "deep learning for intelligent video analysis.", "url": "https://doi.org/10.1145/3123266.3130141", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "260": {"title": "medical multimedia information systems (mmis).", "url": "https://doi.org/10.1145/3123266.3130142", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "261": {"title": "first international acm thematic workshops 2017.", "url": "https://doi.org/10.1145/3123266.3132060", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "262": {"title": "mmhealth 2017: workshop on multimedia for personal health and health care.", "url": "https://doi.org/10.1145/3123266.3132051", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "263": {"title": "summary for avec 2017: real-life depression and affect challenge and workshop.", "url": "https://doi.org/10.1145/3123266.3132049", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "264": {"title": "sawacmmm'17: the 1st workshop on multi media applications within the south african context.", "url": "https://doi.org/10.1145/3123266.3132052", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "265": {"title": "lta 2017: the second workshop on lifelogging tools and applications.", "url": "https://doi.org/10.1145/3123266.3132050", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "266": {"title": "altmm 2017 - 2nd international workshop on multimedia alternate realities.", "url": "https://doi.org/10.1145/3123266.3132055", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "267": {"title": "rfiw: large-scale kinship recognition challenge.", "url": "https://doi.org/10.1145/3123266.3132059", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "268": {"title": "musa2: first acm workshop on multimodal understanding of social, affective and subjective attributes.", "url": "https://doi.org/10.1145/3123266.3132057", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "269": {"title": "vscc'2017: visual analysis for smart and connected communities.", "url": "https://doi.org/10.1145/3123266.3132053", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "270": {"title": "lsvc2017: large-scale video classification challenge.", "url": "https://doi.org/10.1145/3123266.3138874", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "271": {"title": "multiedtech 2017: 1st international workshop on multimedia-based educational and knowledge technologies for personalized and social online training.", "url": "https://doi.org/10.1145/3123266.3132056", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}, "272": {"title": "muver'17: first international workshop on multimedia verification.", "url": "https://doi.org/10.1145/3123266.3132058", "abstract": "", "cite_num": -1, "conf": "mm", "time": "2017"}}