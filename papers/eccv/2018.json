{"0": {"title": "convolutional networks with adaptive inference graphs.", "url": "https://doi.org/10.1007/978-3-030-01246-5_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "1": {"title": "progressive neural architecture search.", "url": "https://doi.org/10.1007/978-3-030-01246-5_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "2": {"title": "diverse image-to-image translation via disentangled representations.", "url": "https://doi.org/10.1007/978-3-030-01246-5_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "3": {"title": "lifting layers: analysis and applications.", "url": "https://doi.org/10.1007/978-3-030-01246-5_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "4": {"title": "learning with biased complementary labels.", "url": "https://doi.org/10.1007/978-3-030-01246-5_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "5": {"title": "semi-convolutional operators for instance segmentation.", "url": "https://doi.org/10.1007/978-3-030-01246-5_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "6": {"title": "skeleton-based action recognition with spatial reasoning and temporal stack learning.", "url": "https://doi.org/10.1007/978-3-030-01246-5_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "7": {"title": "fictitious gan: training gans with historical models.", "url": "https://doi.org/10.1007/978-3-030-01246-5_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "8": {"title": "bi-box regression for pedestrian detection and occlusion estimation.", "url": "https://doi.org/10.1007/978-3-030-01246-5_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "9": {"title": "c-wsl: count-guided weakly supervised localization.", "url": "https://doi.org/10.1007/978-3-030-01246-5_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "10": {"title": "attributes as operators: factorizing unseen attribute-object compositions.", "url": "https://doi.org/10.1007/978-3-030-01246-5_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "11": {"title": "product quantization network for fast image retrieval.", "url": "https://doi.org/10.1007/978-3-030-01246-5_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "12": {"title": "cross-modal hamming hashing.", "url": "https://doi.org/10.1007/978-3-030-01246-5_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "13": {"title": "deep video quality assessor: from spatio-temporal visual sensitivity to a convolutional neural aggregation network.", "url": "https://doi.org/10.1007/978-3-030-01246-5_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "14": {"title": "semi-dense 3d reconstruction with a stereo event camera.", "url": "https://doi.org/10.1007/978-3-030-01246-5_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "15": {"title": "self-calibrating isometric non-rigid structure-from-motion.", "url": "https://doi.org/10.1007/978-3-030-01246-5_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "16": {"title": "semi-supervised deep learning with memory.", "url": "https://doi.org/10.1007/978-3-030-01246-5_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "17": {"title": "deep fundamental matrix estimation.", "url": "https://doi.org/10.1007/978-3-030-01246-5_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "18": {"title": "trackingnet: a large-scale dataset and benchmark for object tracking in the wild.", "url": "https://doi.org/10.1007/978-3-030-01246-5_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "19": {"title": "starmap for category-agnostic keypoint and viewpoint estimation.", "url": "https://doi.org/10.1007/978-3-030-01246-5_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "20": {"title": "factorizable net: an efficient subgraph-based framework for scene graph generation.", "url": "https://doi.org/10.1007/978-3-030-01246-5_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "21": {"title": "multi-fiber networks for video recognition.", "url": "https://doi.org/10.1007/978-3-030-01246-5_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "22": {"title": "tackling 3d tof artifacts through learning and the flat dataset.", "url": "https://doi.org/10.1007/978-3-030-01246-5_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "23": {"title": "zero-shot object detection.", "url": "https://doi.org/10.1007/978-3-030-01246-5_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "24": {"title": "a modulation module for multi-task learning with applications in image retrieval.", "url": "https://doi.org/10.1007/978-3-030-01246-5_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "25": {"title": "fast and accurate intrinsic symmetry detection.", "url": "https://doi.org/10.1007/978-3-030-01246-5_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "26": {"title": "objects that sound.", "url": "https://doi.org/10.1007/978-3-030-01246-5_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "27": {"title": "deblurring natural image using super-gaussian fields.", "url": "https://doi.org/10.1007/978-3-030-01246-5_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "28": {"title": "question-guided hybrid convolution for visual question answering.", "url": "https://doi.org/10.1007/978-3-030-01246-5_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "29": {"title": "geometric constrained joint lane segmentation and lane boundary detection.", "url": "https://doi.org/10.1007/978-3-030-01246-5_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "30": {"title": "unpaired image captioning by language pivoting.", "url": "https://doi.org/10.1007/978-3-030-01246-5_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "31": {"title": "efficient uncertainty estimation for semantic segmentation in videos.", "url": "https://doi.org/10.1007/978-3-030-01246-5_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "32": {"title": "person search by multi-scale matching.", "url": "https://doi.org/10.1007/978-3-030-01246-5_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "33": {"title": "a hybrid model for identity obfuscation by face replacement.", "url": "https://doi.org/10.1007/978-3-030-01246-5_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "34": {"title": "the sound of pixels.", "url": "https://doi.org/10.1007/978-3-030-01246-5_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "35": {"title": "adaptive affinity fields for semantic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01246-5_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "36": {"title": "reenactgan: learning to reenact faces via boundary transfer.", "url": "https://doi.org/10.1007/978-3-030-01246-5_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "37": {"title": "learning to anonymize faces for privacy preserving action detection.", "url": "https://doi.org/10.1007/978-3-030-01246-5_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "38": {"title": "joint person segmentation and identification in synchronized first- and third-person videos.", "url": "https://doi.org/10.1007/978-3-030-01246-5_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "39": {"title": "neural graph matching networks for fewshot 3d action recognition.", "url": "https://doi.org/10.1007/978-3-030-01246-5_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "40": {"title": "graph r-cnn for scene graph generation.", "url": "https://doi.org/10.1007/978-3-030-01246-5_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "41": {"title": "deep cross-modal projection learning for image-text matching.", "url": "https://doi.org/10.1007/978-3-030-01246-5_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "42": {"title": "shapestacks: learning vision-based physical intuition for generalised object stacking.", "url": "https://doi.org/10.1007/978-3-030-01246-5_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "43": {"title": "inner space preserving generative pose machine.", "url": "https://doi.org/10.1007/978-3-030-01246-5_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "44": {"title": "attention-based ensemble for deep metric learning.", "url": "https://doi.org/10.1007/978-3-030-01246-5_45", "abstract": "Deep metric learning aims to learn an embedding function, modeled as deep neural network. This embed\nding function usually puts semantically similar images close while dissimilar images far from each o\nther in the learned embedding space. Recently, ensemble has been applied to deep metric learning to \nyield state-of-the-art results. As one important aspect of ensemble, the learners should be diverse \nin their feature embeddings. To this end, we propose an attention-based ensemble, which uses multipl\ne attention masks, so that each learner can attend to different parts of the object. We also propose\n a divergence loss, which encourages diversity among the learners. The proposed method is applied to\n the standard benchmarks of deep metric learning and experimental results show that it outperforms t\nhe state-of-the-art methods by a significant margin on image retrieval tasks.", "cite_num": 14, "conf": "eccv", "time": "2018"}, "45": {"title": "learning compression from limited unlabeled data.", "url": "https://doi.org/10.1007/978-3-030-01246-5_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "46": {"title": "discriminative region proposal adversarial networks for high-quality image-to-image translation.", "url": "https://doi.org/10.1007/978-3-030-01246-5_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "47": {"title": "unsupervised video object segmentation using motion saliency-guided spatio-temporal propagation.", "url": "https://doi.org/10.1007/978-3-030-01246-5_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "48": {"title": "temporal relational reasoning in videos.", "url": "https://doi.org/10.1007/978-3-030-01246-5_49", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "49": {"title": "contextual-based image inpainting: infer, match, and translate.", "url": "https://doi.org/10.1007/978-3-030-01216-8_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "50": {"title": "textsnake: a flexible representation for detecting text of arbitrary shapes.", "url": "https://doi.org/10.1007/978-3-030-01216-8_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "51": {"title": "graph adaptive knowledge transfer for unsupervised domain adaptation.", "url": "https://doi.org/10.1007/978-3-030-01216-8_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "52": {"title": "robust image stitching with multiple registrations.", "url": "https://doi.org/10.1007/978-3-030-01216-8_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "53": {"title": "ctap: complementary temporal action proposal generation.", "url": "https://doi.org/10.1007/978-3-030-01216-8_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "54": {"title": "effective use of synthetic data for urban scene semantic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01216-8_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "55": {"title": "open-world stereo video matching with deep rnn.", "url": "https://doi.org/10.1007/978-3-030-01216-8_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "56": {"title": "deep high dynamic range imaging with large foreground motions.", "url": "https://doi.org/10.1007/978-3-030-01216-8_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "57": {"title": "linear span network for object skeleton detection.", "url": "https://doi.org/10.1007/978-3-030-01216-8_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "58": {"title": "saas: speed as a supervisor for semi-supervised learning.", "url": "https://doi.org/10.1007/978-3-030-01216-8_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "59": {"title": "attention-gan for object transfiguration in wild images.", "url": "https://doi.org/10.1007/978-3-030-01216-8_11", "abstract": "This paper studies the object transfiguration problem in wild images. The generative network in clas\nsical GANs for object transfiguration often undertakes a dual responsibility: to detect the objects \nof interests and to convert the object from source domain to target domain. In contrast, we decompos\ne the generative network into two separat networks, each of which is only dedicated to one particula\nr sub-task. The attention network predicts spatial attention maps of images, and the transformation \nnetwork focuses on translating objects. Attention maps produced by attention network are encouraged \nto be sparse, so that major attention can be paid to objects of interests. No matter before or after\n object transfiguration, attention maps should remain constant. In addition, learning attention netw\nork can receive more instructions, given the available segmentation annotations of images. Experimen\ntal results demonstrate the necessity of investigating attention in object transfiguration, and that\n the proposed algorithm can learn accurate attention to improve quality of generated images.", "cite_num": 6, "conf": "eccv", "time": "2018"}, "60": {"title": "exploring the limits of weakly supervised pretraining.", "url": "https://doi.org/10.1007/978-3-030-01216-8_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "61": {"title": "egocentric activity prediction via event modulated attention.", "url": "https://doi.org/10.1007/978-3-030-01216-8_13", "abstract": "Predicting future activities from an egocentric viewpoint is of particular interest in assisted livi\nng. However, state-of-the-art egocentric activity understanding techniques are mostly NOT capable of\n predictive tasks, as their synchronous processing architecture performs poorly in either modeling e\nvent dependency or pruning temporal redundant features. This work explicitly addresses these issues \nby proposing an asynchronous gaze-event driven attentive activity prediction network. This network i\ns built on a gaze-event extraction module inspired by the fact that gaze moving in/out of a certain \nobject most probably indicates the occurrence/ending of a certain activity. The extracted gaze event\ns are input to: (1) an asynchronous module which reasons about the temporal dependency between event\ns and (2) a synchronous module which softly attends to informative temporal durations for more compa\nct and discriminative feature extraction. Both modules are seamlessly integrated for collaborative p\nrediction. Extensive experimental results on egocentric activity prediction as well as recognition w\nell demonstrate the effectiveness of the proposed method.", "cite_num": 3, "conf": "eccv", "time": "2018"}, "62": {"title": "how good is my gan?", "url": "https://doi.org/10.1007/978-3-030-01216-8_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "63": {"title": "3d-coded: 3d correspondences by deep deformation.", "url": "https://doi.org/10.1007/978-3-030-01216-8_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "64": {"title": "audio-visual event localization in unconstrained videos.", "url": "https://doi.org/10.1007/978-3-030-01216-8_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "65": {"title": "grounding visual explanations.", "url": "https://doi.org/10.1007/978-3-030-01216-8_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "66": {"title": "adversarial open-world person re-identification.", "url": "https://doi.org/10.1007/978-3-030-01216-8_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "67": {"title": "generative domain-migration hashing for sketch-to-image retrieval.", "url": "https://doi.org/10.1007/978-3-030-01216-8_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "68": {"title": "tbn: convolutional neural network with ternary inputs and binary weights.", "url": "https://doi.org/10.1007/978-3-030-01216-8_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "69": {"title": "end-to-end view synthesis for light field imaging with pseudo 4dcnn.", "url": "https://doi.org/10.1007/978-3-030-01216-8_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "70": {"title": "deepphys: video-based physiological measurement using convolutional attention networks.", "url": "https://doi.org/10.1007/978-3-030-01216-8_22", "abstract": "Non-contact video-based physiological measurement has many applications in health care and human-com\nputer interaction. Practical applications require measurements to be accurate even in the presence o\nf large head rotations. We propose the first end-to-end system for video-based measurement of heart \nand breathing rate using a deep convolutional network. The system features a new motion representati\non based on a skin reflection model and a new attention mechanism using appearance information to gu\nide motion estimation, both of which enable robust measurement under heterogeneous lighting and majo\nr motions. Our approach significantly outperforms all current state-of-the-art methods on both RGB a\nnd infrared video datasets. Furthermore, it allows spatial-temporal distributions of physiological s\nignals to be visualized via the attention mechanism.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "71": {"title": "deep video generation, prediction and completion of human action sequences.", "url": "https://doi.org/10.1007/978-3-030-01216-8_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "72": {"title": "semantic match consistency for long-term visual localization.", "url": "https://doi.org/10.1007/978-3-030-01216-8_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "73": {"title": "deep generative models for weakly-supervised multi-label classification.", "url": "https://doi.org/10.1007/978-3-030-01216-8_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "74": {"title": "efficient 6-dof tracking of handheld objects from an egocentric viewpoint.", "url": "https://doi.org/10.1007/978-3-030-01216-8_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "75": {"title": "foresthash: semantic hashing with shallow random forests and tiny convolutional networks.", "url": "https://doi.org/10.1007/978-3-030-01216-8_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "76": {"title": "local orthogonal-group testing.", "url": "https://doi.org/10.1007/978-3-030-01216-8_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "77": {"title": "rolling shutter pose and ego-motion estimation using shape-from-template.", "url": "https://doi.org/10.1007/978-3-030-01216-8_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "78": {"title": "unveiling the power of deep tracking.", "url": "https://doi.org/10.1007/978-3-030-01216-8_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "79": {"title": "recurrent fusion network for image captioning.", "url": "https://doi.org/10.1007/978-3-030-01216-8_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "80": {"title": "good line cutting: towards accurate pose tracking of line-assisted vo/vslam.", "url": "https://doi.org/10.1007/978-3-030-01216-8_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "81": {"title": "composition loss for counting, density map estimation and localization in dense crowds.", "url": "https://doi.org/10.1007/978-3-030-01216-8_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "82": {"title": "where are the blobs: counting by localization with point supervision.", "url": "https://doi.org/10.1007/978-3-030-01216-8_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "83": {"title": "textual explanations for self-driving vehicles.", "url": "https://doi.org/10.1007/978-3-030-01216-8_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "84": {"title": "contemplating visual emotions: understanding and overcoming dataset bias.", "url": "https://doi.org/10.1007/978-3-030-01216-8_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "85": {"title": "deep recursive hdri: inverse tone mapping using generative adversarial networks.", "url": "https://doi.org/10.1007/978-3-030-01216-8_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "86": {"title": "deepkspd: learning kernel-matrix-based spd representation for fine-grained image recognition.", "url": "https://doi.org/10.1007/978-3-030-01216-8_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "87": {"title": "pairwise relational networks for face recognition.", "url": "https://doi.org/10.1007/978-3-030-01216-8_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "88": {"title": "stereo vision-based semantic 3d object and ego-motion tracking for autonomous driving.", "url": "https://doi.org/10.1007/978-3-030-01216-8_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "89": {"title": "a+d net: training a shadow detector with adversarial shadow attenuation.", "url": "https://doi.org/10.1007/978-3-030-01216-8_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "90": {"title": "fast and accurate camera covariance computation for large 3d reconstruction.", "url": "https://doi.org/10.1007/978-3-030-01216-8_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "91": {"title": "eco: efficient convolutional network for online video understanding.", "url": "https://doi.org/10.1007/978-3-030-01216-8_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "92": {"title": "multi-scale structure-aware network for human pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01216-8_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "93": {"title": "diverse and coherent paragraph generation from images.", "url": "https://doi.org/10.1007/978-3-030-01216-8_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "94": {"title": "from face recognition to models of identity: a bayesian approach to learning about unknown identities from unsupervised data.", "url": "https://doi.org/10.1007/978-3-030-01216-8_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "95": {"title": "light structure from pin motion: simple and accurate point light calibration for physics-based modeling.", "url": "https://doi.org/10.1007/978-3-030-01219-9_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "96": {"title": "programmable triangulation light curtains.", "url": "https://doi.org/10.1007/978-3-030-01219-9_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "97": {"title": "learning to separate object sounds by watching unlabeled video.", "url": "https://doi.org/10.1007/978-3-030-01219-9_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "98": {"title": "coded two-bucket cameras for computer vision.", "url": "https://doi.org/10.1007/978-3-030-01219-9_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "99": {"title": "materials for masses: svbrdf acquisition with a single mobile phone image.", "url": "https://doi.org/10.1007/978-3-030-01219-9_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "100": {"title": "video object segmentation with joint re-identification and attention-aware mask propagation.", "url": "https://doi.org/10.1007/978-3-030-01219-9_6", "abstract": "The problem of video object segmentation can become extremely challenging when multiple instances co\n-exist. While each instance may exhibit large scale and pose variations, the problem is compounded w\nhen instances occlude each other causing failures in tracking. In this study, we formulate a deep re\ncurrent network that is capable of segmenting and tracking objects in video simultaneously by their \ntemporal continuity, yet able to re-identify them when they re-appear after a prolonged occlusion. W\ne combine temporal propagation and re-identification functionalities into a single framework that ca\nn be trained end-to-end. In particular, we present a re-identification module with template expansio\nn to retrieve missing objects despite their large appearance changes. In addition, we contribute an \nattention-based recurrent mask propagation approach that is robust to distractors not belonging to t\nhe target segment. Our approach achieves a new state-of-the-art \\(\\mathcal {G}\\)-mean of 68.2 on the\n challenging DAVIS 2017 benchmark (test-dev set), outperforming the winning solution. Project Page: \nhttp://mmlab.ie.cuhk.edu.hk/projects/DyeNet/.", "cite_num": 16, "conf": "eccv", "time": "2018"}, "101": {"title": "spatio-temporal transformer network for video restoration.", "url": "https://doi.org/10.1007/978-3-030-01219-9_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "102": {"title": "dense pose transfer.", "url": "https://doi.org/10.1007/978-3-030-01219-9_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "103": {"title": "memory aware synapses: learning what (not) to forget.", "url": "https://doi.org/10.1007/978-3-030-01219-9_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "104": {"title": "multi-view to novel view: synthesizing novel views with self-learned confidence.", "url": "https://doi.org/10.1007/978-3-030-01219-9_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "105": {"title": "multimodal unsupervised image-to-image translation.", "url": "https://doi.org/10.1007/978-3-030-01219-9_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "106": {"title": "deeply learned compositional models for human pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01219-9_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "107": {"title": "unsupervised video object segmentation with motion-based bilateral networks.", "url": "https://doi.org/10.1007/978-3-030-01219-9_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "108": {"title": "monocular depth estimation with affinity, vertical pooling, and label enhancement.", "url": "https://doi.org/10.1007/978-3-030-01219-9_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "109": {"title": "ml-locnet: improving object localization with multi-view learning network.", "url": "https://doi.org/10.1007/978-3-030-01219-9_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "110": {"title": "diagnosing error in temporal action detectors.", "url": "https://doi.org/10.1007/978-3-030-01219-9_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "111": {"title": "improved structure from motion using fiducial marker matching.", "url": "https://doi.org/10.1007/978-3-030-01219-9_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "112": {"title": "unsupervised domain adaptation for semantic segmentation via class-balanced self-training.", "url": "https://doi.org/10.1007/978-3-030-01219-9_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "113": {"title": "towards human-level license plate recognition.", "url": "https://doi.org/10.1007/978-3-030-01219-9_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "114": {"title": "zoom-net: mining deep feature interactions for visual relationship recognition.", "url": "https://doi.org/10.1007/978-3-030-01219-9_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "115": {"title": "quantized densely connected u-nets for efficient landmark localization.", "url": "https://doi.org/10.1007/978-3-030-01219-9_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "116": {"title": "grassmann pooling as compact homogeneous bilinear pooling for fine-grained visual classification.", "url": "https://doi.org/10.1007/978-3-030-01219-9_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "117": {"title": "cgintrinsics: better intrinsic image decomposition through physically-based rendering.", "url": "https://doi.org/10.1007/978-3-030-01219-9_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "118": {"title": "simultaneous edge alignment and learning.", "url": "https://doi.org/10.1007/978-3-030-01219-9_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "119": {"title": "icnet for real-time semantic segmentation on high-resolution images.", "url": "https://doi.org/10.1007/978-3-030-01219-9_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "120": {"title": "part-activated deep reinforcement learning for action prediction.", "url": "https://doi.org/10.1007/978-3-030-01219-9_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "121": {"title": "lifelong learning via progressive distillation and retrospection.", "url": "https://doi.org/10.1007/978-3-030-01219-9_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "122": {"title": "a closed-form solution to photorealistic image stylization.", "url": "https://doi.org/10.1007/978-3-030-01219-9_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "123": {"title": "visual tracking via spatially aligned correlation filters network.", "url": "https://doi.org/10.1007/978-3-030-01219-9_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "124": {"title": "online dictionary learning for approximate archetypal analysis.", "url": "https://doi.org/10.1007/978-3-030-01219-9_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "125": {"title": "compositing-aware image search.", "url": "https://doi.org/10.1007/978-3-030-01219-9_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "126": {"title": "improving sequential determinantal point processes for supervised video summarization.", "url": "https://doi.org/10.1007/978-3-030-01219-9_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "127": {"title": "online detection of action start in untrimmed, streaming videos.", "url": "https://doi.org/10.1007/978-3-030-01219-9_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "128": {"title": "temporal modular networks for retrieving complex compositional activities in videos.", "url": "https://doi.org/10.1007/978-3-030-01219-9_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "129": {"title": "meta-tracker: fast and robust online adaptation for visual object trackers.", "url": "https://doi.org/10.1007/978-3-030-01219-9_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "130": {"title": "collaborative deep reinforcement learning for multi-object tracking.", "url": "https://doi.org/10.1007/978-3-030-01219-9_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "131": {"title": "multi-scale context intertwining for semantic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01219-9_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "132": {"title": "second-order democratic aggregation.", "url": "https://doi.org/10.1007/978-3-030-01219-9_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "133": {"title": "occlusion-aware r-cnn: detecting pedestrians in a crowd.", "url": "https://doi.org/10.1007/978-3-030-01219-9_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "134": {"title": "seeing deeply and bidirectionally: a deep learning approach for single image reflection removal.", "url": "https://doi.org/10.1007/978-3-030-01219-9_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "135": {"title": "long-term tracking in the wild: a benchmark.", "url": "https://doi.org/10.1007/978-3-030-01219-9_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "136": {"title": "affinity derivation and graph merge for instance segmentation.", "url": "https://doi.org/10.1007/978-3-030-01219-9_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "137": {"title": "generating 3d faces using convolutional mesh autoencoders.", "url": "https://doi.org/10.1007/978-3-030-01219-9_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "138": {"title": "hierarchical relational networks for group activity recognition and retrieval.", "url": "https://doi.org/10.1007/978-3-030-01219-9_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "139": {"title": "neural procedural reconstruction for residential buildings.", "url": "https://doi.org/10.1007/978-3-030-01219-9_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "140": {"title": "simultaneous 3d reconstruction for water surface and underwater scene.", "url": "https://doi.org/10.1007/978-3-030-01219-9_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "141": {"title": "women also snowboard: overcoming bias in captioning models.", "url": "https://doi.org/10.1007/978-3-030-01219-9_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "142": {"title": "joint camera spectral sensitivity selection and hyperspectral image recovery.", "url": "https://doi.org/10.1007/978-3-030-01219-9_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "143": {"title": "disentangling factors of variation with cycle-consistent variational auto-encoders.", "url": "https://doi.org/10.1007/978-3-030-01219-9_49", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "144": {"title": "object-centered image stitching.", "url": "https://doi.org/10.1007/978-3-030-01219-9_50", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "145": {"title": "bsn: boundary sensitive network for temporal action proposal generation.", "url": "https://doi.org/10.1007/978-3-030-01225-0_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "146": {"title": "progressive structure from motion.", "url": "https://doi.org/10.1007/978-3-030-01225-0_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "147": {"title": "monocular depth estimation using whole strip masking and reliability-based refinement.", "url": "https://doi.org/10.1007/978-3-030-01225-0_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "148": {"title": "local spectral graph convolution for point set feature learning.", "url": "https://doi.org/10.1007/978-3-030-01225-0_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "149": {"title": "piggyback: adapting a single network to multiple tasks by learning to mask weights.", "url": "https://doi.org/10.1007/978-3-030-01225-0_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "150": {"title": "real-time mdnet.", "url": "https://doi.org/10.1007/978-3-030-01225-0_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "151": {"title": "real-time hair rendering using sequential adversarial networks.", "url": "https://doi.org/10.1007/978-3-030-01225-0_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "152": {"title": "model-free consensus maximization for non-rigid shapes.", "url": "https://doi.org/10.1007/978-3-030-01225-0_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "153": {"title": "relaxation-free deep hashing via policy gradient.", "url": "https://doi.org/10.1007/978-3-030-01225-0_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "154": {"title": "question type guided attention in visual question answering.", "url": "https://doi.org/10.1007/978-3-030-01225-0_10", "abstract": "Visual Question Answering (VQA) requires integration of feature maps with drastically different stru\nctures. Image descriptors have structures at multiple spatial scales, while lexical inputs inherentl\ny follow a temporal sequence and naturally cluster into semantically different question types. A lot\n of previous works use complex models to extract feature representations but neglect to use high-lev\nel information summary such as question types in learning. In this work, we propose Question Type-gu\nided Attention (QTA). It utilizes the information of question type to dynamically balance between bo\nttom-up and top-down visual features, respectively extracted from ResNet and Faster R-CNN networks. \nWe experiment with multiple VQA architectures with extensive input ablation studies over the TDIUC d\nataset and show that QTA systematically improves the performance by more than 5% across multiple que\nstion type categories such as \u201cActivity Recognition\u201d, \u201cUtility\u201d and \u201cCounting\u201d on TDIUC dataset comp\nared to the state-of-art. By adding QTA on the state-of-art model MCB, we achieve 3% improvement in \noverall accuracy. Finally, we propose a multi-task extension to predict question types which general\nizes QTA to applications that lack question type, with a minimal performance loss.", "cite_num": 5, "conf": "eccv", "time": "2018"}, "155": {"title": "estimating depth from rgb and sparse sensing.", "url": "https://doi.org/10.1007/978-3-030-01225-0_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "156": {"title": "specular-to-diffuse translation for multi-view reconstruction.", "url": "https://doi.org/10.1007/978-3-030-01225-0_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "157": {"title": "stacked cross attention for image-text matching.", "url": "https://doi.org/10.1007/978-3-030-01225-0_13", "abstract": "In this paper, we study the problem of image-text matching. Inferring the latent semantic alignment \nbetween objects or other salient stuffs (e.g. snow, sky, lawn) and the corresponding words in senten\nces allows to capture fine-grained interplay between vision and language, and makes image-text match\ning more interpretable. Prior works either simply aggregate the similarity of all possible pairs of \nregions and words without attending differentially to more and less important words or regions, or u\nse a multi-step attentional process to capture limited number of semantic alignments which is less i\nnterpretable. In this paper, we present Stacked Cross Attention to discover the full latent alignmen\nts using both image regions and words in sentence as context and infer the image-text similarity. Ou\nr approach achieves the state-of-the-art results on the MS-COCO and Flickr30K datasets. On Flickr30K\n, our approach outperforms the current best methods by 22.1% in text retrieval from image query, and\n 18.2% in image retrieval with text query (based on Recall@1). On MS-COCO, our approach improves sen\ntence retrieval by 17.8% and image retrieval by 16.6% (based on Recall@1 using the 5K test set).", "cite_num": 9, "conf": "eccv", "time": "2018"}, "158": {"title": "deep texture and structure aware filtering network for image smoothing.", "url": "https://doi.org/10.1007/978-3-030-01225-0_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "159": {"title": "vso: visual semantic odometry.", "url": "https://doi.org/10.1007/978-3-030-01225-0_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "160": {"title": "mplp++: fast, parallel dual block-coordinate ascent for dense graphical models.", "url": "https://doi.org/10.1007/978-3-030-01225-0_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "161": {"title": "single image highlight removal with a sparse and low-rank reflection model.", "url": "https://doi.org/10.1007/978-3-030-01225-0_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "162": {"title": "spatio-temporal channel correlation networks for action classification.", "url": "https://doi.org/10.1007/978-3-030-01225-0_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "163": {"title": "a zero-shot framework for sketch based image retrieval.", "url": "https://doi.org/10.1007/978-3-030-01225-0_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "164": {"title": "lambda twist: an accurate fast robust perspective three point (p3p) solver.", "url": "https://doi.org/10.1007/978-3-030-01225-0_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "165": {"title": "linear rgb-d slam for planar environments.", "url": "https://doi.org/10.1007/978-3-030-01225-0_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "166": {"title": "attentive semantic alignment with offset-aware correlation kernels.", "url": "https://doi.org/10.1007/978-3-030-01225-0_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "167": {"title": "mancs: a multi-task attentional network with curriculum sampling for person re-identification.", "url": "https://doi.org/10.1007/978-3-030-01225-0_23", "abstract": "We propose a novel deep network called Mancs that solves the person re-identification problem from t\nhe following aspects: fully utilizing the attention mechanism for the person misalignment problem an\nd properly sampling for the ranking loss to obtain more stable person representation. Technically, w\ne contribute a novel fully attentional block which is deeply supervised and can be plugged into any \nCNN, and a novel curriculum sampling method which is effective for training ranking losses. The lear\nning tasks are integrated into a unified framework and jointly optimized. Experiments have been carr\nied out on Market1501, CUHK03 and DukeMTMC. All the results show that Mancs can significantly outper\nform the previous state-of-the-arts. In addition, the effectiveness of the newly proposed ideas has \nbeen confirmed by extensive ablation studies.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "168": {"title": "deep discriminative model for video classification.", "url": "https://doi.org/10.1007/978-3-030-01225-0_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "169": {"title": "task-aware image downscaling.", "url": "https://doi.org/10.1007/978-3-030-01225-0_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "170": {"title": "self-calibration of cameras with euclidean image plane in case of two views and known relative rotation angle.", "url": "https://doi.org/10.1007/978-3-030-01225-0_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "171": {"title": "learning to detect and track visible and occluded body joints in a virtual world.", "url": "https://doi.org/10.1007/978-3-030-01225-0_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "172": {"title": "deepjdot: deep joint distribution optimal transport for unsupervised domain adaptation.", "url": "https://doi.org/10.1007/978-3-030-01225-0_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "173": {"title": "two at once: enhancing learning and generalization capacities via ibn-net.", "url": "https://doi.org/10.1007/978-3-030-01225-0_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "174": {"title": "beyond part models: person retrieval with refined part pooling (and a strong convolutional baseline).", "url": "https://doi.org/10.1007/978-3-030-01225-0_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "175": {"title": "refocusgan: scene refocusing using a single image.", "url": "https://doi.org/10.1007/978-3-030-01225-0_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "176": {"title": "zero-shot keyword spotting for visual speech recognition in-the-wild.", "url": "https://doi.org/10.1007/978-3-030-01225-0_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "177": {"title": "real-to-virtual domain unification for end-to-end autonomous driving.", "url": "https://doi.org/10.1007/978-3-030-01225-0_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "178": {"title": "the mutex watershed: efficient, parameter-free image partitioning.", "url": "https://doi.org/10.1007/978-3-030-01225-0_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "179": {"title": "w-talc: weakly-supervised temporal activity localization and classification.", "url": "https://doi.org/10.1007/978-3-030-01225-0_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "180": {"title": "value-aware quantization for training and inference of neural networks.", "url": "https://doi.org/10.1007/978-3-030-01225-0_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "181": {"title": "fully-convolutional point networks for large-scale point clouds.", "url": "https://doi.org/10.1007/978-3-030-01225-0_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "182": {"title": "multiple-gaze geometry: inferring novel 3d locations from gazes observed in monocular video.", "url": "https://doi.org/10.1007/978-3-030-01225-0_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "183": {"title": "learning-based video motion magnification.", "url": "https://doi.org/10.1007/978-3-030-01225-0_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "184": {"title": "massively parallel video networks.", "url": "https://doi.org/10.1007/978-3-030-01225-0_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "185": {"title": "deepwrinkles: accurate and realistic clothing modeling.", "url": "https://doi.org/10.1007/978-3-030-01225-0_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "186": {"title": "learning discriminative video representations using adversarial perturbations.", "url": "https://doi.org/10.1007/978-3-030-01225-0_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "187": {"title": "end-to-end joint semantic segmentation of actors and actions in video.", "url": "https://doi.org/10.1007/978-3-030-01225-0_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "188": {"title": "scaling egocentric vision: the dataset.", "url": "https://doi.org/10.1007/978-3-030-01225-0_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "189": {"title": "unsupervised person re-identification by deep learning tracklet association.", "url": "https://doi.org/10.1007/978-3-030-01225-0_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "190": {"title": "predicting gaze in egocentric video by learning task-dependent attention transition.", "url": "https://doi.org/10.1007/978-3-030-01225-0_46", "abstract": "We present a new computational model for gaze prediction in egocentric videos by exploring patterns \nin temporal shift of gaze fixations (attention transition) that are dependent on egocentric manipula\ntion tasks. Our assumption is that the high-level context of how a task is completed in a certain wa\ny has a strong influence on attention transition and should be modeled for gaze prediction in natura\nl dynamic scenes. Specifically, we propose a hybrid model based on deep neural networks which integr\nates task-dependent attention transition with bottom-up saliency prediction. In particular, the task\n-dependent attention transition is learned with a recurrent neural network to exploit the temporal c\nontext of gaze fixations, e.g. looking at a cup after moving gaze away from a grasped bottle. Experi\nments on public egocentric activity datasets show that our model significantly outperforms state-of-\nthe-art gaze prediction methods and is able to learn meaningful transition of human attention.", "cite_num": 9, "conf": "eccv", "time": "2018"}, "191": {"title": "instance-level human parsing via part grouping network.", "url": "https://doi.org/10.1007/978-3-030-01225-0_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "192": {"title": "adversarial geometry-aware human motion prediction.", "url": "https://doi.org/10.1007/978-3-030-01225-0_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "193": {"title": "snap angle prediction for 360 \u2218 panoramas.", "url": "https://doi.org/10.1007/978-3-030-01228-1_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "194": {"title": "unsupervised holistic image generation from key local patches.", "url": "https://doi.org/10.1007/978-3-030-01228-1_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "195": {"title": "df-net: unsupervised joint learning of depth and flow using cross-task consistency.", "url": "https://doi.org/10.1007/978-3-030-01228-1_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "196": {"title": "neural stereoscopic image style transfer.", "url": "https://doi.org/10.1007/978-3-030-01228-1_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "197": {"title": "transductive centroid projection for semi-supervised large-scale recognition.", "url": "https://doi.org/10.1007/978-3-030-01228-1_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "198": {"title": "generalized loss-sensitive adversarial learning with manifold margins.", "url": "https://doi.org/10.1007/978-3-030-01228-1_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "199": {"title": "into the twilight zone: depth estimation using joint structure-stereo optimization.", "url": "https://doi.org/10.1007/978-3-030-01228-1_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "200": {"title": "recycle-gan: unsupervised video retargeting.", "url": "https://doi.org/10.1007/978-3-030-01228-1_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "201": {"title": "fine-grained video categorization with redundancy reduction attention.", "url": "https://doi.org/10.1007/978-3-030-01228-1_9", "abstract": "For fine-grained categorization tasks, videos could serve as a better source than static images as v\nideos have a higher chance of containing discriminative patterns. Nevertheless, a video sequence cou\nld also contain a lot of redundant and irrelevant frames. How to locate critical information of inte\nrest is a challenging task. In this paper, we propose a new network structure, known as Redundancy R\neduction Attention (RRA), which learns to focus on multiple discriminative patterns by suppressing r\nedundant feature channels. Specifically, it firstly summarizes the video by weight-summing all featu\nre vectors in the feature maps of selected frames with a spatio-temporal soft attention, and then pr\nedicts which channels to suppress or to enhance according to this summary with a learned non-linear \ntransform. Suppression is achieved by modulating the feature maps and threshing out weak activations\n. The updated feature maps are then used in the next iteration. Finally, the video is classified bas\ned on multiple summaries. The proposed method achieves outstanding performances in multiple video cl\nassification datasets. Furthermore, we have collected two large-scale video datasets, YouTube-Birds \nand YouTube-Cars, for future researches on fine-grained video categorization. The datasets are avail\nable at http://www.cs.umd.edu/~chenzhu/fgvc.", "cite_num": 5, "conf": "eccv", "time": "2018"}, "202": {"title": "open set domain adaptation by backpropagation.", "url": "https://doi.org/10.1007/978-3-030-01228-1_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "203": {"title": "deep feature pyramid reconfiguration for object detection.", "url": "https://doi.org/10.1007/978-3-030-01228-1_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "204": {"title": "goal-oriented visual question generation via intermediate rewards.", "url": "https://doi.org/10.1007/978-3-030-01228-1_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "205": {"title": "deepgum: learning deep robust regression with a gaussian-uniform mixture model.", "url": "https://doi.org/10.1007/978-3-030-01228-1_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "206": {"title": "estimating the success of unsupervised image to image translation.", "url": "https://doi.org/10.1007/978-3-030-01228-1_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "207": {"title": "parallel feature pyramid network for object detection.", "url": "https://doi.org/10.1007/978-3-030-01228-1_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "208": {"title": "joint map and symmetry synchronization.", "url": "https://doi.org/10.1007/978-3-030-01228-1_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "209": {"title": "mt-vae: learning motion transformations to generate multimodal human dynamics.", "url": "https://doi.org/10.1007/978-3-030-01228-1_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "210": {"title": "rethinking the form of latent states in image captioning.", "url": "https://doi.org/10.1007/978-3-030-01228-1_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "211": {"title": "transductive semi-supervised deep learning using min-max features.", "url": "https://doi.org/10.1007/978-3-030-01228-1_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "212": {"title": "san: learning relationship between convolutional features for multi-scale object detection.", "url": "https://doi.org/10.1007/978-3-030-01228-1_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "213": {"title": "hashing with binary matrix pursuit.", "url": "https://doi.org/10.1007/978-3-030-01228-1_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "214": {"title": "maskconnect: connectivity learning by gradient descent.", "url": "https://doi.org/10.1007/978-3-030-01228-1_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "215": {"title": "online multi-object tracking with dual matching attention networks.", "url": "https://doi.org/10.1007/978-3-030-01228-1_23", "abstract": "In this paper, we propose an online Multi-Object Tracking (MOT) approach which integrates the merits\n of single object tracking and data association methods in a unified framework to handle noisy detec\ntions and frequent interactions between targets. Specifically, for applying single object tracking i\nn MOT, we introduce a cost-sensitive tracking loss based on the state-of-the-art visual tracker, whi\nch encourages the model to focus on hard negative distractors during online learning. For data assoc\niation, we propose Dual Matching Attention Networks (DMAN) with both spatial and temporal attention \nmechanisms. The spatial attention module generates dual attention maps which enable the network to f\nocus on the matching patterns of the input image pair, while the temporal attention module adaptivel\ny allocates different levels of attention to different samples in the tracklet to suppress noisy obs\nervations. Experimental results on the MOT benchmark datasets show that the proposed algorithm perfo\nrms favorably against both online and offline trackers in terms of identity-preserving metrics.", "cite_num": 18, "conf": "eccv", "time": "2018"}, "216": {"title": "connecting gaze, scene, and attention: generalized attention estimation via joint modeling of gaze and scene saliency.", "url": "https://doi.org/10.1007/978-3-030-01228-1_24", "abstract": "This paper addresses the challenging problem of estimating the general visual attention of people in\n images. Our proposed method is designed to work across multiple naturalistic social scenarios and p\nrovides a full picture of the subject\u2019s attention and gaze. In contrast, earlier works on gaze and a\nttention estimation have focused on constrained problems in more specific contexts. In particular, o\nur model explicitly represents the gaze direction and handles out-of-frame gaze targets. We leverage\n three different datasets using a multi-task learning approach. We evaluate our method on widely use\nd benchmarks for single-tasks such as gaze angle estimation and attention-within-an-image, as well a\ns on the new challenging task of generalized visual attention prediction. In addition, we have creat\ned extended annotations for the MMDB and GazeFollow datasets which are used in our experiments, whic\nh we will publicly release.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "217": {"title": "videos as space-time region graphs.", "url": "https://doi.org/10.1007/978-3-030-01228-1_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "218": {"title": "unified perceptual parsing for scene understanding.", "url": "https://doi.org/10.1007/978-3-030-01228-1_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "219": {"title": "synthetically supervised feature learning for scene text recognition.", "url": "https://doi.org/10.1007/978-3-030-01228-1_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "220": {"title": "probabilistic video generation using holistic attribute control.", "url": "https://doi.org/10.1007/978-3-030-01228-1_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "221": {"title": "learning rigidity in dynamic scenes with a moving camera for 3d motion field estimation.", "url": "https://doi.org/10.1007/978-3-030-01228-1_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "222": {"title": "unsupervised cnn-based co-saliency detection with graphical optimization.", "url": "https://doi.org/10.1007/978-3-030-01228-1_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "223": {"title": "mutual learning to adapt for joint human parsing and pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01228-1_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "224": {"title": "dcan: dual channel-wise alignment networks for unsupervised scene adaptation.", "url": "https://doi.org/10.1007/978-3-030-01228-1_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "225": {"title": "view-graph selection framework for sfm.", "url": "https://doi.org/10.1007/978-3-030-01228-1_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "226": {"title": "selfie video stabilization.", "url": "https://doi.org/10.1007/978-3-030-01228-1_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "227": {"title": "cubenet: equivariance to 3d rotation and translation.", "url": "https://doi.org/10.1007/978-3-030-01228-1_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "228": {"title": "youtube-vos: sequence-to-sequence video object segmentation.", "url": "https://doi.org/10.1007/978-3-030-01228-1_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "229": {"title": "ppf-foldnet: unsupervised learning of rotation invariant 3d local descriptors.", "url": "https://doi.org/10.1007/978-3-030-01228-1_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "230": {"title": "in the eye of beholder: joint learning of gaze and actions in first person video.", "url": "https://doi.org/10.1007/978-3-030-01228-1_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "231": {"title": "double jpeg detection in mixed jpeg quality factors using deep convolutional neural network.", "url": "https://doi.org/10.1007/978-3-030-01228-1_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "232": {"title": "wasserstein divergence for gans.", "url": "https://doi.org/10.1007/978-3-030-01228-1_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "233": {"title": "semi-supervised fusedgan for conditional image generation.", "url": "https://doi.org/10.1007/978-3-030-01228-1_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "234": {"title": "pose partition networks for multi-person pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01228-1_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "235": {"title": "understanding degeneracies and ambiguities in attribute transfer.", "url": "https://doi.org/10.1007/978-3-030-01228-1_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "236": {"title": "reinforced temporal attention and split-rate transfer for depth-based person re-identification.", "url": "https://doi.org/10.1007/978-3-030-01228-1_44", "abstract": "We address the problem of person re-identification from commodity depth sensors. One challenge for d\nepth-based recognition is data scarcity. Our first contribution addresses this problem by introducin\ng split-rate RGB-to-Depth transfer, which leverages large RGB datasets more effectively than popular\n fine-tuning approaches. Our transfer scheme is based on the observation that the model parameters a\nt the bottom layers of a deep convolutional neural network can be directly shared between RGB and de\npth data while the remaining layers need to be fine-tuned rapidly. Our second contribution enhances \nre-identification for video by implementing temporal attention as a Bernoulli-Sigmoid unit acting up\non frame-level features. Since this unit is stochastic, the temporal attention parameters are traine\nd using reinforcement learning. Extensive experiments validate the accuracy of our method in person \nre-identification from depth sequences. Finally, in a scenario where subjects wear unseen clothes, w\ne show large performance gains compared to a state-of-the-art model which relies on RGB data.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "237": {"title": "scale aggregation network for accurate and efficient crowd counting.", "url": "https://doi.org/10.1007/978-3-030-01228-1_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "238": {"title": "deep shape matching.", "url": "https://doi.org/10.1007/978-3-030-01228-1_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "239": {"title": "eigendecomposition-free training of deep networks with zero eigenvalue-based losses.", "url": "https://doi.org/10.1007/978-3-030-01228-1_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "240": {"title": "visual reasoning with multi-hop feature modulation.", "url": "https://doi.org/10.1007/978-3-030-01228-1_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "241": {"title": "learning visual question answering by bootstrapping hard attention.", "url": "https://doi.org/10.1007/978-3-030-01231-1_1", "abstract": "Attention mechanisms in biological perception are thought to select subsets of perceptual informatio\nn for more sophisticated processing which would be prohibitive to perform on all sensory inputs. In \ncomputer vision, however, there has been relatively little exploration of hard attention, where some\n information is selectively ignored, in spite of the success of soft attention, where information is\n re-weighted and aggregated, but never filtered out. Here, we introduce a new approach for hard atte\nntion and find it achieves very competitive performance on a recently-released visual question answe\nring datasets, equalling and in some cases surpassing similar soft attention architectures while ent\nirely ignoring some features. Even though the hard attention mechanism is thought to be non-differen\ntiable, we found that the feature magnitudes correlate with semantic relevance, and provide a useful\n signal for our mechanism\u2019s attentional selection criterion. Because hard attention selects importan\nt features of the input information, it can also be more efficient than analogous soft attention mec\nhanisms. This is especially important for recent approaches that use non-local pairwise operations, \nwhereby computational and memory costs are quadratic in the size of the set of features.", "cite_num": 9, "conf": "eccv", "time": "2018"}, "242": {"title": "multi-modal cycle-consistent generalized zero-shot learning.", "url": "https://doi.org/10.1007/978-3-030-01231-1_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "243": {"title": "key-word-aware network for referring expression image segmentation.", "url": "https://doi.org/10.1007/978-3-030-01231-1_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "244": {"title": "a segmentation-aware deep fusion network for compressed sensing mri.", "url": "https://doi.org/10.1007/978-3-030-01231-1_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "245": {"title": "correcting the triplet selection bias for triplet loss.", "url": "https://doi.org/10.1007/978-3-030-01231-1_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "246": {"title": "crossnet: an end-to-end reference-based super resolution network using cross-scale warping.", "url": "https://doi.org/10.1007/978-3-030-01231-1_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "247": {"title": "single image water hazard detection using fcn with reflection attention units.", "url": "https://doi.org/10.1007/978-3-030-01231-1_7", "abstract": "Water bodies, such as puddles and flooded areas, on and off road pose significant risks to autonomou\ns cars. Detecting water from moving camera is a challenging task as water surface is highly refracti\nve, and its appearance varies with viewing angle, surrounding scene, weather conditions. In this pap\ner, we present a water puddle detection method based on a Fully Convolutional Network (FCN) with our\n newly proposed Reflection Attention Units (RAUs). An RAU is a deep network unit designed to embody \nthe physics of reflection on water surface from sky and nearby scene. To verify the performance of o\nur proposed method, we collect 11455 color stereo images with polarizers, and 985 of left images are\n annotated and divided into 2 datasets: On Road (ONR) dataset and Off Road (OFR) dataset. We show th\nat FCN-8s with RAUs improves significantly precision and recall metrics as compared to FCN-8s, DeepL\nab V2 and Gaussian Mixture Model (GMM). We also show that focal loss function can improve the perfor\nmance of FCN-8s network due to the extreme imbalance of water versus ground classification problem.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "248": {"title": "bidirectional feature pyramid network with recurrent attention residual modules for shadow detection.", "url": "https://doi.org/10.1007/978-3-030-01231-1_8", "abstract": "This paper presents a network to detect shadows by exploring and combining global context in deep la\nyers and local context in shallow layers of a deep convolutional neural network (CNN). There are two\n technical contributions in our network design. First, we formulate the recurrent attention residual\n (RAR) module to combine the contexts in two adjacent CNN layers and learn an attention map to selec\nt a residual and then refine the context features. Second, we develop a bidirectional feature pyrami\nd network (BFPN) to aggregate shadow contexts spanned across different CNN layers by deploying two s\neries of RAR modules in the network to iteratively combine and refine context features: one series t\no refine context features from deep to shallow layers, and another series from shallow to deep layer\ns. Hence, we can better suppress false detections and enhance shadow details at the same time. We ev\naluate our network on two common shadow detection benchmark datasets: SBU and UCF. Experimental resu\nlts show that our network outperforms the best existing method with 34.88% reduction on SBU and 34.5\n7% reduction on UCF for the balance error rate.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "249": {"title": "fast light field reconstruction with deep coarse-to-fine modeling of spatial-angular clues.", "url": "https://doi.org/10.1007/978-3-030-01231-1_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "250": {"title": "image reassembly combining deep learning and shortest path problem.", "url": "https://doi.org/10.1007/978-3-030-01231-1_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "251": {"title": "busternet: detecting copy-move image forgery with source/target localization.", "url": "https://doi.org/10.1007/978-3-030-01231-1_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "252": {"title": "to learn image super-resolution, use a gan to learn how to do image degradation first.", "url": "https://doi.org/10.1007/978-3-030-01231-1_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "253": {"title": "floornet: a unified framework for floorplan reconstruction from 3d scans.", "url": "https://doi.org/10.1007/978-3-030-01231-1_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "254": {"title": "transferring gans: generating images from limited data.", "url": "https://doi.org/10.1007/978-3-030-01231-1_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "255": {"title": "saliency preservation in low-resolution grayscale images.", "url": "https://doi.org/10.1007/978-3-030-01231-1_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "256": {"title": "proxy clouds for live rgb-d stream processing and consolidation.", "url": "https://doi.org/10.1007/978-3-030-01231-1_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "257": {"title": "deep metric learning with hierarchical triplet loss.", "url": "https://doi.org/10.1007/978-3-030-01231-1_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "258": {"title": "joint learning of intrinsic images and semantic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01231-1_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "259": {"title": "recurrent tubelet proposal and recognition networks for action detection.", "url": "https://doi.org/10.1007/978-3-030-01231-1_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "260": {"title": "beyond local reasoning for stereo confidence estimation with deep learning.", "url": "https://doi.org/10.1007/978-3-030-01231-1_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "261": {"title": "self-supervised knowledge distillation using singular value decomposition.", "url": "https://doi.org/10.1007/978-3-030-01231-1_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "262": {"title": "parn: pyramidal affine regression networks for dense semantic correspondence.", "url": "https://doi.org/10.1007/978-3-030-01231-1_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "263": {"title": "start, follow, read: end-to-end full-page handwriting recognition.", "url": "https://doi.org/10.1007/978-3-030-01231-1_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "264": {"title": "pm-gans: discriminative representation learning for action recognition using partial-modalities.", "url": "https://doi.org/10.1007/978-3-030-01231-1_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "265": {"title": "wilddash - creating hazard-aware benchmarks.", "url": "https://doi.org/10.1007/978-3-030-01231-1_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "266": {"title": "generative adversarial network with spatial attention for face attribute editing.", "url": "https://doi.org/10.1007/978-3-030-01231-1_26", "abstract": "Face attribute editing aims at editing the face image with the given attribute. Most existing works \nemploy Generative Adversarial Network (GAN) to operate face attribute editing. However, these method\ns inevitably change the attribute-irrelevant regions, as shown in Fig. 1. Therefore, we introduce th\ne spatial attention mechanism into GAN framework (referred to as SaGAN), to only alter the attribute\n-specific region and keep the rest unchanged. Our approach SaGAN consists of a generator and a discr\niminator. The generator contains an attribute manipulation network (AMN) to edit the face image, and\n a spatial attention network (SAN) to localize the attribute-specific region which restricts the alt\nernation of AMN within this region. The discriminator endeavors to distinguish the generated images \nfrom the real ones, and classify the face attribute. Experiments demonstrate that our approach can a\nchieve promising visual results, and keep those attribute-irrelevant regions unchanged. Besides, our\n approach can benefit the face recognition by data augmentation.", "cite_num": 14, "conf": "eccv", "time": "2018"}, "267": {"title": "realtime time synchronized event-based stereo.", "url": "https://doi.org/10.1007/978-3-030-01231-1_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "268": {"title": "omnidepth: dense depth estimation for indoors spherical panoramas.", "url": "https://doi.org/10.1007/978-3-030-01231-1_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "269": {"title": "simple baselines for human pose estimation and tracking.", "url": "https://doi.org/10.1007/978-3-030-01231-1_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "270": {"title": "affine correspondences between central cameras for rapid relative pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01231-1_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "271": {"title": "convnets and imagenet beyond accuracy: understanding mistakes and uncovering biases.", "url": "https://doi.org/10.1007/978-3-030-01231-1_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "272": {"title": "resound: towards action recognition without representation bias.", "url": "https://doi.org/10.1007/978-3-030-01231-1_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "273": {"title": "integral human pose regression.", "url": "https://doi.org/10.1007/978-3-030-01231-1_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "274": {"title": "quadtree convolutional neural networks.", "url": "https://doi.org/10.1007/978-3-030-01231-1_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "275": {"title": "learning to predict crisp boundaries.", "url": "https://doi.org/10.1007/978-3-030-01231-1_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "276": {"title": "image manipulation with perceptual discriminators.", "url": "https://doi.org/10.1007/978-3-030-01231-1_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "277": {"title": "structural consistency and controllability for diverse colorization.", "url": "https://doi.org/10.1007/978-3-030-01231-1_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "278": {"title": "open set learning with counterfactual images.", "url": "https://doi.org/10.1007/978-3-030-01231-1_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "279": {"title": "audio-visual scene analysis with self-supervised multisensory features.", "url": "https://doi.org/10.1007/978-3-030-01231-1_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "280": {"title": "jointly discovering visual objects and spoken words from raw sensory input.", "url": "https://doi.org/10.1007/978-3-030-01231-1_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "281": {"title": "weakly-supervised 3d hand pose estimation from monocular rgb images.", "url": "https://doi.org/10.1007/978-3-030-01231-1_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "282": {"title": "deepim: deep iterative matching for 6d pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01231-1_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "283": {"title": "implicit 3d orientation learning for 6d object detection from rgb images.", "url": "https://doi.org/10.1007/978-3-030-01231-1_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "284": {"title": "cbam: convolutional block attention module.", "url": "https://doi.org/10.1007/978-3-030-01234-2_1", "abstract": "We propose Convolutional Block Attention Module (CBAM), a simple yet effective attention module for \nfeed-forward convolutional neural networks. Given an intermediate feature map, our module sequential\nly infers attention maps along two separate dimensions, channel and spatial, then the attention maps\n are multiplied to the input feature map for adaptive feature refinement. Because CBAM is a lightwei\nght and general module, it can be integrated into any CNN architectures seamlessly with negligible o\nverheads and is end-to-end trainable along with base CNNs. We validate our CBAM through extensive ex\nperiments on ImageNet-1K, MS COCO detection, and VOC 2007 detection datasets. Our experiments show c\nonsistent improvements in classification and detection performances with various models, demonstrati\nng the wide applicability of CBAM. The code and models will be publicly available.", "cite_num": 103, "conf": "eccv", "time": "2018"}, "285": {"title": "bodynet: volumetric inference of 3d human body shapes.", "url": "https://doi.org/10.1007/978-3-030-01234-2_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "286": {"title": "learning to segment via cut-and-paste.", "url": "https://doi.org/10.1007/978-3-030-01234-2_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "287": {"title": "explainable neural computation via stack neural module networks.", "url": "https://doi.org/10.1007/978-3-030-01234-2_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "288": {"title": "learning to blend photos.", "url": "https://doi.org/10.1007/978-3-030-01234-2_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "289": {"title": "switchable temporal propagation network.", "url": "https://doi.org/10.1007/978-3-030-01234-2_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "290": {"title": "multiresolution tree networks for 3d point cloud processing.", "url": "https://doi.org/10.1007/978-3-030-01234-2_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "291": {"title": "propagating lstm: 3d pose estimation based on joint interdependency.", "url": "https://doi.org/10.1007/978-3-030-01234-2_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "292": {"title": "deformable pose traversal convolution for 3d action and gesture recognition.", "url": "https://doi.org/10.1007/978-3-030-01234-2_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "293": {"title": "hybridnet: classification and reconstruction cooperation for semi-supervised learning.", "url": "https://doi.org/10.1007/978-3-030-01234-2_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "294": {"title": "robust anchor embedding for unsupervised video person re-identification in the wild.", "url": "https://doi.org/10.1007/978-3-030-01234-2_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "295": {"title": "holistic 3d scene parsing and reconstruction from a single rgb image.", "url": "https://doi.org/10.1007/978-3-030-01234-2_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "296": {"title": "escaping from collapsing modes in a constrained space.", "url": "https://doi.org/10.1007/978-3-030-01234-2_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "297": {"title": "leveraging motion priors in videos for improving human segmentation.", "url": "https://doi.org/10.1007/978-3-030-01234-2_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "298": {"title": "analyzing clothing layer deformation statistics of 3d human motions.", "url": "https://doi.org/10.1007/978-3-030-01234-2_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "299": {"title": "recurrent squeeze-and-excitation context aggregation net for single image deraining.", "url": "https://doi.org/10.1007/978-3-030-01234-2_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "300": {"title": "iterative crowd counting.", "url": "https://doi.org/10.1007/978-3-030-01234-2_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "301": {"title": "image super-resolution using very deep residual channel attention networks.", "url": "https://doi.org/10.1007/978-3-030-01234-2_18", "abstract": "Convolutional neural network (CNN) depth is of crucial importance for image super-resolution (SR). H\nowever, we observe that deeper networks for image SR are more difficult to train. The low-resolution\n inputs and features contain abundant low-frequency information, which is treated equally across cha\nnnels, hence hindering the representational ability of CNNs. To solve these problems, we propose the\n very deep residual channel attention networks (RCAN). Specifically, we propose a residual in residu\nal (RIR) structure to form very deep network, which consists of several residual groups with long sk\nip connections. Each residual group contains some residual blocks with short skip connections. Meanw\nhile, RIR allows abundant low-frequency information to be bypassed through multiple skip connections\n, making the main network focus on learning high-frequency information. Furthermore, we propose a ch\nannel attention mechanism to adaptively rescale channel-wise features by considering interdependenci\nes among channels. Extensive experiments show that our RCAN achieves better accuracy and visual impr\novements against state-of-the-art methods.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "302": {"title": "layer-structured 3d scene inference via view synthesis.", "url": "https://doi.org/10.1007/978-3-030-01234-2_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "303": {"title": "real-time 'actor-critic' tracking.", "url": "https://doi.org/10.1007/978-3-030-01234-2_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "304": {"title": "deep bilinear learning for rgb-d action recognition.", "url": "https://doi.org/10.1007/978-3-030-01234-2_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "305": {"title": "superpixel sampling networks.", "url": "https://doi.org/10.1007/978-3-030-01234-2_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "306": {"title": "towards robust neural networks via random self-ensemble.", "url": "https://doi.org/10.1007/978-3-030-01234-2_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "307": {"title": "ec-net: an edge-aware point set consolidation network.", "url": "https://doi.org/10.1007/978-3-030-01234-2_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "308": {"title": "3d recurrent neural networks with context fusion for point cloud semantic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01234-2_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "309": {"title": "learning to capture light fields through a coded aperture camera.", "url": "https://doi.org/10.1007/978-3-030-01234-2_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "310": {"title": "end-to-end learning of driving models with surround-view cameras and route planners.", "url": "https://doi.org/10.1007/978-3-030-01234-2_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "311": {"title": "coreset-based neural network compression.", "url": "https://doi.org/10.1007/978-3-030-01234-2_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "312": {"title": "a joint sequence fusion model for video question answering and retrieval.", "url": "https://doi.org/10.1007/978-3-030-01234-2_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "313": {"title": "saliency detection in 360 ^\\circ \u2218 videos.", "url": "https://doi.org/10.1007/978-3-030-01234-2_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "314": {"title": "localization recall precision (lrp): a new performance metric for object detection.", "url": "https://doi.org/10.1007/978-3-030-01234-2_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "315": {"title": "lip movements generation at a glance.", "url": "https://doi.org/10.1007/978-3-030-01234-2_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "316": {"title": "small-scale pedestrian detection based on topological line localization and temporal feature aggregation.", "url": "https://doi.org/10.1007/978-3-030-01234-2_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "317": {"title": "vqa-e: explaining, elaborating, and enhancing your answers for visual questions.", "url": "https://doi.org/10.1007/978-3-030-01234-2_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "318": {"title": "penalizing top performers: conservative loss for semantic segmentation adaptation.", "url": "https://doi.org/10.1007/978-3-030-01234-2_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "319": {"title": "cirl: controllable imitative reinforcement learning for vision-based self-driving.", "url": "https://doi.org/10.1007/978-3-030-01234-2_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "320": {"title": "statistically-motivated second-order pooling.", "url": "https://doi.org/10.1007/978-3-030-01234-2_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "321": {"title": "perturbation robust representations of topological persistence diagrams.", "url": "https://doi.org/10.1007/978-3-030-01234-2_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "322": {"title": "segstereo: exploiting semantic information for disparity estimation.", "url": "https://doi.org/10.1007/978-3-030-01234-2_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "323": {"title": "uncertainty estimates and multi-hypotheses networks for optical flow.", "url": "https://doi.org/10.1007/978-3-030-01234-2_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "324": {"title": "normalized blind deconvolution.", "url": "https://doi.org/10.1007/978-3-030-01234-2_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "325": {"title": "improving generalization via scalable neighborhood component analysis.", "url": "https://doi.org/10.1007/978-3-030-01234-2_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "326": {"title": "proximal dehaze-net: a prior learning-based deep network for single image dehazing.", "url": "https://doi.org/10.1007/978-3-030-01234-2_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "327": {"title": "sdc-net: video prediction using spatially-displaced convolution.", "url": "https://doi.org/10.1007/978-3-030-01234-2_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "328": {"title": "person search via a mask-guided two-stream cnn model.", "url": "https://doi.org/10.1007/978-3-030-01234-2_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "329": {"title": "compound memory networks for few-shot video classification.", "url": "https://doi.org/10.1007/978-3-030-01234-2_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "330": {"title": "t ^2 2 net: synthetic-to-realistic translation for solving single-image depth estimation tasks.", "url": "https://doi.org/10.1007/978-3-030-01234-2_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "331": {"title": "amc: automl for model compression and acceleration on mobile devices.", "url": "https://doi.org/10.1007/978-3-030-01234-2_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "332": {"title": "encoder-decoder with atrous separable convolution for semantic image segmentation.", "url": "https://doi.org/10.1007/978-3-030-01234-2_49", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "333": {"title": "learning 3d keypoint descriptors for non-rigid shape matching.", "url": "https://doi.org/10.1007/978-3-030-01237-3_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "334": {"title": "a trilateral weighted sparse coding scheme for real-world image denoising.", "url": "https://doi.org/10.1007/978-3-030-01237-3_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "335": {"title": "nneval: neural network based evaluation metric for image captioning.", "url": "https://doi.org/10.1007/978-3-030-01237-3_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "336": {"title": "videomatch: matching based video object segmentation.", "url": "https://doi.org/10.1007/978-3-030-01237-3_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "337": {"title": "context refinement for object detection.", "url": "https://doi.org/10.1007/978-3-030-01237-3_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "338": {"title": "spidercnn: deep learning on point sets with parameterized convolutional filters.", "url": "https://doi.org/10.1007/978-3-030-01237-3_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "339": {"title": "modality distillation with multiple stream networks for action recognition.", "url": "https://doi.org/10.1007/978-3-030-01237-3_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "340": {"title": "interpretable basis decomposition for visual explanation.", "url": "https://doi.org/10.1007/978-3-030-01237-3_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "341": {"title": "partial adversarial domain adaptation.", "url": "https://doi.org/10.1007/978-3-030-01237-3_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "342": {"title": "how local is the local diversity? reinforcing sequential determinantal point processes with dynamic ground sets for supervised video summarization.", "url": "https://doi.org/10.1007/978-3-030-01237-3_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "343": {"title": "toward scale-invariance and position-sensitive region proposal networks.", "url": "https://doi.org/10.1007/978-3-030-01237-3_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "344": {"title": "a systematic dnn weight pruning framework using alternating direction method of multipliers.", "url": "https://doi.org/10.1007/978-3-030-01237-3_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "345": {"title": "multi-object tracking with neural gating using bilinear lstm.", "url": "https://doi.org/10.1007/978-3-030-01237-3_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "346": {"title": "clustering convolutional kernels to compress deep neural networks.", "url": "https://doi.org/10.1007/978-3-030-01237-3_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "347": {"title": "fine-grained visual categorization using meta-learning optimization with sample selection of auxiliary data.", "url": "https://doi.org/10.1007/978-3-030-01237-3_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "348": {"title": "verisimilar image synthesis for accurate detection and recognition of texts in scenes.", "url": "https://doi.org/10.1007/978-3-030-01237-3_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "349": {"title": "quantization mimic: towards very tiny cnn for object detection.", "url": "https://doi.org/10.1007/978-3-030-01237-3_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "350": {"title": "learning to solve nonlinear least squares for monocular stereo.", "url": "https://doi.org/10.1007/978-3-030-01237-3_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "351": {"title": "extreme network compression via filter group approximation.", "url": "https://doi.org/10.1007/978-3-030-01237-3_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "352": {"title": "articulatedfusion: real-time reconstruction of motion, geometry and segmentation using a single depth camera.", "url": "https://doi.org/10.1007/978-3-030-01237-3_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "353": {"title": "mrf optimization with separable convex prior on partially ordered labels.", "url": "https://doi.org/10.1007/978-3-030-01237-3_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "354": {"title": "attend and rectify: a gated attention mechanism for fine-grained recovery.", "url": "https://doi.org/10.1007/978-3-030-01237-3_22", "abstract": "We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained rec\nognition. It learns to attend to lower-level feature activations without requiring part annotations \nand uses these activations to update and rectify the output likelihood distribution. In contrast to \nother approaches, the proposed mechanism is modular, architecture-independent and efficient both in \nterms of parameters and computation required. Experiments show that networks augmented with our appr\noach systematically improve their classification accuracy and become more robust to clutter. As a re\nsult, Wide Residual Networks augmented with our proposal surpasses the state of the art classificati\non accuracies in CIFAR-10, the Adience gender recognition task, Stanford dogs, and UEC Food-100.", "cite_num": 3, "conf": "eccv", "time": "2018"}, "355": {"title": "lq-nets: learned quantization for highly accurate and compact deep neural networks.", "url": "https://doi.org/10.1007/978-3-030-01237-3_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "356": {"title": "retrospective encoders for video summarization.", "url": "https://doi.org/10.1007/978-3-030-01237-3_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "357": {"title": "constraint-aware deep neural network compression.", "url": "https://doi.org/10.1007/978-3-030-01237-3_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "358": {"title": "video compression through image interpolation.", "url": "https://doi.org/10.1007/978-3-030-01237-3_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "359": {"title": "few-shot human motion prediction via meta-learning.", "url": "https://doi.org/10.1007/978-3-030-01237-3_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "360": {"title": "straight to the facts: learning knowledge base retrieval for factual visual question answering.", "url": "https://doi.org/10.1007/978-3-030-01237-3_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "361": {"title": "joint and progressive learning from high-dimensional data for multi-label classification.", "url": "https://doi.org/10.1007/978-3-030-01237-3_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "362": {"title": "video object detection with an aligned spatial-temporal memory.", "url": "https://doi.org/10.1007/978-3-030-01237-3_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "363": {"title": "coded illumination and imaging for fluorescence based classification.", "url": "https://doi.org/10.1007/978-3-030-01237-3_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "364": {"title": "multi-scale residual network for image super-resolution.", "url": "https://doi.org/10.1007/978-3-030-01237-3_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "365": {"title": "a dataset for lane instance segmentation in urban environments.", "url": "https://doi.org/10.1007/978-3-030-01237-3_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "366": {"title": "out-of-distribution detection using an ensemble of self supervised leave-out classifiers.", "url": "https://doi.org/10.1007/978-3-030-01237-3_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "367": {"title": "structure-from-motion-aware patchmatch for adaptive optical flow estimation.", "url": "https://doi.org/10.1007/978-3-030-01237-3_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "368": {"title": "universal sketch perceptual grouping.", "url": "https://doi.org/10.1007/978-3-030-01237-3_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "369": {"title": "imagine this! scripts to compositions to videos.", "url": "https://doi.org/10.1007/978-3-030-01237-3_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "370": {"title": "urban zoning using higher-order markov random fields on multi-view imagery data.", "url": "https://doi.org/10.1007/978-3-030-01237-3_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "371": {"title": "quaternion convolutional neural networks.", "url": "https://doi.org/10.1007/978-3-030-01237-3_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "372": {"title": "stereo relative pose from line and point feature triplets.", "url": "https://doi.org/10.1007/978-3-030-01237-3_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "373": {"title": "3d scene flow from 4d light field gradients.", "url": "https://doi.org/10.1007/978-3-030-01237-3_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "374": {"title": "direct sparse odometry with rolling shutter.", "url": "https://doi.org/10.1007/978-3-030-01237-3_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "375": {"title": "a style-aware content loss for real-time hd style transfer.", "url": "https://doi.org/10.1007/978-3-030-01237-3_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "376": {"title": "scale-awareness of light field camera based visual odometry.", "url": "https://doi.org/10.1007/978-3-030-01237-3_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "377": {"title": "burst image deblurring using permutation invariant convolutional neural networks.", "url": "https://doi.org/10.1007/978-3-030-01237-3_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "378": {"title": "planematch: patch coplanarity prediction for robust rgb-d reconstruction.", "url": "https://doi.org/10.1007/978-3-030-01237-3_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "379": {"title": "mvsnet: depth inference for unstructured multi-view stereo.", "url": "https://doi.org/10.1007/978-3-030-01237-3_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "380": {"title": "activestereonet: end-to-end self-supervised learning for active stereo systems.", "url": "https://doi.org/10.1007/978-3-030-01237-3_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "381": {"title": "gal: geometric adversarial loss for single-view 3d-object reconstruction.", "url": "https://doi.org/10.1007/978-3-030-01237-3_49", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "382": {"title": "deep virtual stereo odometry: leveraging deep depth prediction for monocular direct sparse odometry.", "url": "https://doi.org/10.1007/978-3-030-01237-3_50", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "383": {"title": "ps-fcn: a flexible learning framework for photometric stereo.", "url": "https://doi.org/10.1007/978-3-030-01240-3_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "384": {"title": "ask, acquire, and attack: data-free uap generation using class impressions.", "url": "https://doi.org/10.1007/978-3-030-01240-3_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "385": {"title": "rendering portraitures from monocular camera and beyond.", "url": "https://doi.org/10.1007/978-3-030-01240-3_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "386": {"title": "learning to zoom: a saliency-based sampling layer for neural networks.", "url": "https://doi.org/10.1007/978-3-030-01240-3_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "387": {"title": "a scalable exemplar-based subspace clustering algorithm for class-imbalanced data.", "url": "https://doi.org/10.1007/978-3-030-01240-3_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "388": {"title": "rcaa: relational context-aware agents for person search.", "url": "https://doi.org/10.1007/978-3-030-01240-3_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "389": {"title": "distractor-aware siamese networks for visual object tracking.", "url": "https://doi.org/10.1007/978-3-030-01240-3_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "390": {"title": "face recognition with contrastive convolution.", "url": "https://doi.org/10.1007/978-3-030-01240-3_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "391": {"title": "adding attentiveness to the neurons in recurrent neural networks.", "url": "https://doi.org/10.1007/978-3-030-01240-3_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "392": {"title": "learning dynamic memory networks for object tracking.", "url": "https://doi.org/10.1007/978-3-030-01240-3_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "393": {"title": "geodesc: learning local descriptors by integrating geometry constraints.", "url": "https://doi.org/10.1007/978-3-030-01240-3_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "394": {"title": "unsupervised image-to-image translation with stacked cycle-consistent adversarial networks.", "url": "https://doi.org/10.1007/978-3-030-01240-3_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "395": {"title": "find and focus: retrieve and localize video events with natural language queries.", "url": "https://doi.org/10.1007/978-3-030-01240-3_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "396": {"title": "face super-resolution guided by facial component heatmaps.", "url": "https://doi.org/10.1007/978-3-030-01240-3_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "397": {"title": "reverse attention for salient object detection.", "url": "https://doi.org/10.1007/978-3-030-01240-3_15", "abstract": "Benefit from the quick development of deep learning techniques, salient object detection has achieve\nd remarkable progresses recently. However, there still exists following two major challenges that hi\nnder its application in embedded devices, low resolution output and heavy model weight. To this end,\n this paper presents an accurate yet compact deep network for efficient salient object detection. Mo\nre specifically, given a coarse saliency prediction in the deepest layer, we first employ residual l\nearning to learn side-output residual features for saliency refinement, which can be achieved with v\nery limited convolutional parameters while keep accuracy. Secondly, we further propose reverse atten\ntion to guide such side-output residual learning in a top-down manner. By erasing the current predic\nted salient regions from side-output features, the network can eventually explore the missing object\n parts and details which results in high resolution and accuracy. Experiments on six benchmark datas\nets demonstrate that the proposed approach compares favorably against state-of-the-art methods, and \nwith advantages in terms of simplicity, efficiency (45 FPS) and model size (81 MB).", "cite_num": 12, "conf": "eccv", "time": "2018"}, "398": {"title": "action search: spotting actions in videos and its application to temporal action localization.", "url": "https://doi.org/10.1007/978-3-030-01240-3_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "399": {"title": "psanet: point-wise spatial attention network for scene parsing.", "url": "https://doi.org/10.1007/978-3-030-01240-3_17", "abstract": "We notice information flow in convolutional neural networks is restricted inside local neighborhood \nregions due to the physical design of convolutional filters, which limits the overall understanding \nof complex scenes. In this paper, we propose the point-wise spatial attention network (PSANet) to re\nlax the local neighborhood constraint. Each position on the feature map is connected to all the othe\nr ones through a self-adaptively learned attention mask. Moreover, information propagation in bi-dir\nection for scene parsing is enabled. Information at other positions can be collected to help the pre\ndiction of the current position and vice versa, information at the current position can be distribut\ned to assist the prediction of other ones. Our proposed approach achieves top performance on various\n competitive scene parsing datasets, including ADE20K, PASCAL VOC 2012 and Cityscapes, demonstrating\n its effectiveness and generality.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "400": {"title": "repeatability is not enough: learning affine regions via discriminability.", "url": "https://doi.org/10.1007/978-3-030-01240-3_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "401": {"title": "compressing the input for cnns with the first-order scattering transform.", "url": "https://doi.org/10.1007/978-3-030-01240-3_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "402": {"title": "faces as lighting probes via unsupervised deep highlight extraction.", "url": "https://doi.org/10.1007/978-3-030-01240-3_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "403": {"title": "detnet: design backbone for object detection.", "url": "https://doi.org/10.1007/978-3-030-01240-3_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "404": {"title": "structured siamese network for real-time visual tracking.", "url": "https://doi.org/10.1007/978-3-030-01240-3_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "405": {"title": "associating inter-image salient instances for weakly supervised semantic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01240-3_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "406": {"title": "hybridfusion: real-time performance capture using a single depth sensor and sparse imus.", "url": "https://doi.org/10.1007/978-3-030-01240-3_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "407": {"title": "learning human-object interactions by graph parsing neural networks.", "url": "https://doi.org/10.1007/978-3-030-01240-3_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "408": {"title": "macro-micro adversarial network for human parsing.", "url": "https://doi.org/10.1007/978-3-030-01240-3_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "409": {"title": "stereo computation for a single mixture image.", "url": "https://doi.org/10.1007/978-3-030-01240-3_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "410": {"title": "dividing and aggregating network for multi-view action recognition.", "url": "https://doi.org/10.1007/978-3-030-01240-3_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "411": {"title": "selective zero-shot classification with augmented attributes.", "url": "https://doi.org/10.1007/978-3-030-01240-3_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "412": {"title": "modeling varying camera-imu time offset in optimization-based visual-inertial odometry.", "url": "https://doi.org/10.1007/978-3-030-01240-3_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "413": {"title": "an adversarial approach to hard triplet generation.", "url": "https://doi.org/10.1007/978-3-030-01240-3_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "414": {"title": "spherenet: learning spherical representations for detection and classification in omnidirectional images.", "url": "https://doi.org/10.1007/978-3-030-01240-3_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "415": {"title": "deep directional statistics: pose estimation with uncertainty quantification.", "url": "https://doi.org/10.1007/978-3-030-01240-3_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "416": {"title": "joint representation and truncated inference learning for correlation filter based tracking.", "url": "https://doi.org/10.1007/978-3-030-01240-3_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "417": {"title": "consensus-driven propagation in massive unlabeled data for face recognition.", "url": "https://doi.org/10.1007/978-3-030-01240-3_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "418": {"title": "predicting future instance segmentation by forecasting convolutional features.", "url": "https://doi.org/10.1007/978-3-030-01240-3_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "419": {"title": "flow-grounded spatial-temporal video prediction from still images.", "url": "https://doi.org/10.1007/978-3-030-01240-3_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "420": {"title": "learning to reconstruct high-quality 3d shapes with cascaded fully convolutional networks.", "url": "https://doi.org/10.1007/978-3-030-01240-3_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "421": {"title": "a dataset of flash and ambient illumination pairs from the crowd.", "url": "https://doi.org/10.1007/978-3-030-01240-3_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "422": {"title": "pose-normalized image generation for person re-identification.", "url": "https://doi.org/10.1007/978-3-030-01240-3_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "423": {"title": "learning 3d human pose from structure and motion.", "url": "https://doi.org/10.1007/978-3-030-01240-3_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "424": {"title": "deep reinforcement learning with iterative shift for visual tracking.", "url": "https://doi.org/10.1007/978-3-030-01240-3_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "425": {"title": "psdf fusion: probabilistic signed distance function for on-the-fly 3d data fusion and scene reconstruction.", "url": "https://doi.org/10.1007/978-3-030-01240-3_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "426": {"title": "auggan: cross domain adaptation with gan-based data augmentation.", "url": "https://doi.org/10.1007/978-3-030-01240-3_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "427": {"title": "graininess-aware deep feature learning for pedestrian detection.", "url": "https://doi.org/10.1007/978-3-030-01240-3_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "428": {"title": "seeing tree structure from vibration.", "url": "https://doi.org/10.1007/978-3-030-01240-3_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "429": {"title": "the devil of face recognition is in the noise.", "url": "https://doi.org/10.1007/978-3-030-01240-3_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "430": {"title": "shape reconstruction using volume sweeping and learned photoconsistency.", "url": "https://doi.org/10.1007/978-3-030-01240-3_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "431": {"title": "pyramidbox: a context-assisted single shot face detector.", "url": "https://doi.org/10.1007/978-3-030-01240-3_49", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "432": {"title": "bayesian semantic instance segmentation in open set world.", "url": "https://doi.org/10.1007/978-3-030-01249-6_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "433": {"title": "bop: benchmark for 6d object pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01249-6_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "434": {"title": "3d vehicle trajectory reconstruction in monocular video data using environment structure constraints.", "url": "https://doi.org/10.1007/978-3-030-01249-6_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "435": {"title": "pairwise body-part attention for recognizing human-object interactions.", "url": "https://doi.org/10.1007/978-3-030-01249-6_4", "abstract": "In human-object interactions (HOI) recognition, conventional methods consider the human body as a wh\nole and pay a uniform attention to the entire body region. They ignore the fact that normally, human\n interacts with an object by using some parts of the body. In this paper, we argue that different bo\ndy parts should be paid with different attention in HOI recognition, and the correlations between di\nfferent body parts should be further considered. This is because our body parts always work collabor\natively. We propose a new pairwise body-part attention model which can learn to focus on crucial par\nts, and their correlations for HOI recognition. A novel attention based feature selection method and\n a feature representation scheme that can capture pairwise correlations between body parts are intro\nduced in the model. Our proposed approach achieved 4% improvement over the state-of-the-art results \nin HOI recognition on the HICO dataset. We will make our model and source codes publicly available.", "cite_num": 3, "conf": "eccv", "time": "2018"}, "436": {"title": "exploiting temporal information for 3d human pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01249-6_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "437": {"title": "recovering 3d planes from a single image via convolutional neural networks.", "url": "https://doi.org/10.1007/978-3-030-01249-6_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "438": {"title": "stagnet: an attentive semantic rnn for group activity recognition.", "url": "https://doi.org/10.1007/978-3-030-01249-6_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "439": {"title": "learning class prototypes via structure alignment for zero-shot recognition.", "url": "https://doi.org/10.1007/978-3-030-01249-6_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "440": {"title": "curriculumnet: weakly supervised learning from large-scale web images.", "url": "https://doi.org/10.1007/978-3-030-01249-6_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "441": {"title": "ddrnet: depth map denoising and refinement for consumer depth cameras using cascaded cnns.", "url": "https://doi.org/10.1007/978-3-030-01249-6_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "442": {"title": "elegant: exchanging latent encodings with gan for transferring multiple face attributes.", "url": "https://doi.org/10.1007/978-3-030-01249-6_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "443": {"title": "dynamic filtering with large sampling field for convnets.", "url": "https://doi.org/10.1007/978-3-030-01249-6_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "444": {"title": "pose guided human video generation.", "url": "https://doi.org/10.1007/978-3-030-01249-6_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "445": {"title": "characterizing adversarial examples based on spatial consistency information for semantic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01249-6_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "446": {"title": "joint task-recursive learning for semantic segmentation and depth estimation.", "url": "https://doi.org/10.1007/978-3-030-01249-6_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "447": {"title": "fast, accurate, and lightweight super-resolution with cascading residual network.", "url": "https://doi.org/10.1007/978-3-030-01249-6_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "448": {"title": "exfuse: enhancing feature fusion for semantic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01249-6_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "449": {"title": "netadapt: platform-aware neural network adaptation for mobile applications.", "url": "https://doi.org/10.1007/978-3-030-01249-6_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "450": {"title": "action anticipation with rbf kernelized feature mapping rnn.", "url": "https://doi.org/10.1007/978-3-030-01249-6_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "451": {"title": "a-contrario horizon-first vanishing point detection using second-order grouping laws.", "url": "https://doi.org/10.1007/978-3-030-01249-6_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "452": {"title": "rt-gene: real-time eye gaze estimation in natural environments.", "url": "https://doi.org/10.1007/978-3-030-01249-6_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "453": {"title": "unsupervised class-specific deblurring.", "url": "https://doi.org/10.1007/978-3-030-01249-6_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "454": {"title": "the unmanned aerial vehicle benchmark: object detection and tracking.", "url": "https://doi.org/10.1007/978-3-030-01249-6_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "455": {"title": "motion feature network: fixed motion filter for action recognition.", "url": "https://doi.org/10.1007/978-3-030-01249-6_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "456": {"title": "efficient sliding window computation for nn-based template matching.", "url": "https://doi.org/10.1007/978-3-030-01249-6_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "457": {"title": "advio: an authentic dataset for visual-inertial odometry.", "url": "https://doi.org/10.1007/978-3-030-01249-6_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "458": {"title": "extending layered models to 3d motion.", "url": "https://doi.org/10.1007/978-3-030-01249-6_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "459": {"title": "3dmv: joint 3d-multi-view prediction for 3d semantic scene segmentation.", "url": "https://doi.org/10.1007/978-3-030-01249-6_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "460": {"title": "fisheyerecnet: a multi-context collaborative deep network for fisheye image rectification.", "url": "https://doi.org/10.1007/978-3-030-01249-6_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "461": {"title": "lapran: a scalable laplacian pyramid reconstructive adversarial network for flexible compressive sensing reconstruction.", "url": "https://doi.org/10.1007/978-3-030-01249-6_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "462": {"title": "3d face reconstruction from light field images: a model-free approach.", "url": "https://doi.org/10.1007/978-3-030-01249-6_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "463": {"title": "\"factual\" or \"emotional\": stylized image captioning with adaptive learning and attention.", "url": "https://doi.org/10.1007/978-3-030-01249-6_32", "abstract": "Generating stylized captions for an image is an emerging topic in image captioning. Given an image a\ns input, it requires the system to generate a caption that has a specific style (e.g., humorous, rom\nantic, positive, and negative) while describing the image content semantically accurately. In this p\naper, we propose a novel stylized image captioning model that effectively takes both requirements in\nto consideration. To this end, we first devise a new variant of LSTM, named style-factual LSTM, as t\nhe building block of our model. It uses two groups of matrices to capture the factual and stylized k\nnowledge, respectively, and automatically learns the word-level weights of the two groups based on p\nrevious context. In addition, when we train the model to capture stylized elements, we propose an ad\naptive learning approach based on a reference factual model, it provides factual knowledge to the mo\ndel as the model learns from stylized caption labels, and can adaptively compute how much informatio\nn to supply at each time step. We evaluate our model on two stylized image captioning datasets, whic\nh contain humorous/romantic captions and positive/negative captions, respectively. Experiments shows\n that our proposed model outperforms the state-of-the-art approaches, without using extra ground tru\nth supervision.", "cite_num": 1, "conf": "eccv", "time": "2018"}, "464": {"title": "cplanet: enhancing image geolocalization by combinatorial partitioning of maps.", "url": "https://doi.org/10.1007/978-3-030-01249-6_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "465": {"title": "espnet: efficient spatial pyramid of dilated convolutions for semantic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01249-6_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "466": {"title": "mvtec d2s: densely segmented supermarket dataset.", "url": "https://doi.org/10.1007/978-3-030-01249-6_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "467": {"title": "u-pc: unsupervised planogram compliance.", "url": "https://doi.org/10.1007/978-3-030-01249-6_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "468": {"title": "recovering accurate 3d human pose in the wild using imus and a moving camera.", "url": "https://doi.org/10.1007/978-3-030-01249-6_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "469": {"title": "deep bilevel learning.", "url": "https://doi.org/10.1007/978-3-030-01249-6_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "470": {"title": "joint optimization for compressive video sensing and reconstruction under hardware constraints.", "url": "https://doi.org/10.1007/978-3-030-01249-6_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "471": {"title": "deforming autoencoders: unsupervised disentangling of shape and appearance.", "url": "https://doi.org/10.1007/978-3-030-01249-6_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "472": {"title": "explaingan: model explanation via decision boundary crossing transformations.", "url": "https://doi.org/10.1007/978-3-030-01249-6_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "473": {"title": "does haze removal help cnn-based image classification?", "url": "https://doi.org/10.1007/978-3-030-01249-6_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "474": {"title": "supervising the new with the old: learning sfm from sfm.", "url": "https://doi.org/10.1007/978-3-030-01249-6_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "475": {"title": "a dataset and architecture for visual reasoning with a working memory.", "url": "https://doi.org/10.1007/978-3-030-01249-6_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "476": {"title": "constrained optimization based low-rank approximation of deep neural networks.", "url": "https://doi.org/10.1007/978-3-030-01249-6_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "477": {"title": "unsupervised geometry-aware representation for 3d human pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01249-6_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "478": {"title": "dual-agent deep reinforcement learning for deformable face tracking.", "url": "https://doi.org/10.1007/978-3-030-01249-6_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "479": {"title": "deep autoencoder for combined human pose estimation and body model upscaling.", "url": "https://doi.org/10.1007/978-3-030-01249-6_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "480": {"title": "occlusion-aware hand pose estimation using hierarchical mixture density network.", "url": "https://doi.org/10.1007/978-3-030-01249-6_49", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "481": {"title": "ganimation: anatomically-aware facial animation from a single image.", "url": "https://doi.org/10.1007/978-3-030-01249-6_50", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "482": {"title": "deep boosting for image denoising.", "url": "https://doi.org/10.1007/978-3-030-01252-6_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "483": {"title": "self-supervised relative depth learning for urban scene understanding.", "url": "https://doi.org/10.1007/978-3-030-01252-6_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "484": {"title": "k-convexity shape priors for segmentation.", "url": "https://doi.org/10.1007/978-3-030-01252-6_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "485": {"title": "pixel2mesh: generating 3d mesh models from single rgb images.", "url": "https://doi.org/10.1007/978-3-030-01252-6_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "486": {"title": "boosted attention: leveraging human attention for image captioning.", "url": "https://doi.org/10.1007/978-3-030-01252-6_5", "abstract": "Visual attention has shown usefulness in image captioning, with the goal of enabling a caption model\n to selectively focus on regions of interest. Existing models typically rely on top-down language in\nformation and learn attention implicitly by optimizing the captioning objectives. While somewhat eff\nective, the learned top-down attention can fail to focus on correct regions of interest without dire\nct supervision of attention. Inspired by the human visual system which is driven by not only the tas\nk-specific top-down signals but also the visual stimuli, we in this work propose to use both types o\nf attention for image captioning. In particular, we highlight the complementary nature of the two ty\npes of attention and develop a model (Boosted Attention) to integrate them for image captioning. We \nvalidate the proposed approach with state-of-the-art performance across various evaluation metrics.", "cite_num": 5, "conf": "eccv", "time": "2018"}, "487": {"title": "image inpainting for irregular holes using partial convolutions.", "url": "https://doi.org/10.1007/978-3-030-01252-6_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "488": {"title": "fighting fake news: image splice detection via learned self-consistency.", "url": "https://doi.org/10.1007/978-3-030-01252-6_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "489": {"title": "hand pose estimation via latent 2.5d heatmap regression.", "url": "https://doi.org/10.1007/978-3-030-01252-6_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "490": {"title": "depth-aware cnn for rgb-d segmentation.", "url": "https://doi.org/10.1007/978-3-030-01252-6_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "491": {"title": "car-net: clairvoyant attentive recurrent network.", "url": "https://doi.org/10.1007/978-3-030-01252-6_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "492": {"title": "evaluating capability of deep neural networks for image classification via information plane.", "url": "https://doi.org/10.1007/978-3-030-01252-6_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "493": {"title": "super-identity convolutional neural network for face hallucination.", "url": "https://doi.org/10.1007/978-3-030-01252-6_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "494": {"title": "what do i annotate next? an empirical study of active learning for action localization.", "url": "https://doi.org/10.1007/978-3-030-01252-6_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "495": {"title": "semi-supervised adversarial learning to generate photorealistic face images of new identities from 3d morphable model.", "url": "https://doi.org/10.1007/978-3-030-01252-6_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "496": {"title": "hairnet: single-view hair reconstruction using convolutional neural networks.", "url": "https://doi.org/10.1007/978-3-030-01252-6_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "497": {"title": "neural network encapsulation.", "url": "https://doi.org/10.1007/978-3-030-01252-6_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "498": {"title": "learning deep representations with probabilistic knowledge transfer.", "url": "https://doi.org/10.1007/978-3-030-01252-6_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "499": {"title": "integrating egocentric videos in top-view surveillance videos: joint identification and temporal alignment.", "url": "https://doi.org/10.1007/978-3-030-01252-6_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "500": {"title": "visual-inertial object detection and mapping.", "url": "https://doi.org/10.1007/978-3-030-01252-6_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "501": {"title": "actor-centric relation network.", "url": "https://doi.org/10.1007/978-3-030-01252-6_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "502": {"title": "liquid pouring monitoring via rich sensory inputs.", "url": "https://doi.org/10.1007/978-3-030-01252-6_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "503": {"title": "weakly supervised region proposal network and object detection.", "url": "https://doi.org/10.1007/978-3-030-01252-6_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "504": {"title": "zero-annotation object detection with web knowledge transfer.", "url": "https://doi.org/10.1007/978-3-030-01252-6_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "505": {"title": "receptive field block net for accurate and fast object detection.", "url": "https://doi.org/10.1007/978-3-030-01252-6_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "506": {"title": "deep adversarial attention alignment for unsupervised domain adaptation: the benefit of target expectation maximization.", "url": "https://doi.org/10.1007/978-3-030-01252-6_25", "abstract": "In this paper, we make two contributions to unsupervised domain adaptation (UDA) using the convoluti\nonal neural network (CNN). First, our approach transfers knowledge in all the convolutional layers t\nhrough attention alignment. Most previous methods align high-level representations, e.g., activation\ns of the fully connected (FC) layers. In these methods, however, the convolutional layers which unde\nrpin critical low-level domain knowledge cannot be updated directly towards reducing domain discrepa\nncy. Specifically, we assume that the discriminative regions in an image are relatively invariant to\n image style changes. Based on this assumption, we propose an attention alignment scheme on all the \ntarget convolutional layers to uncover the knowledge shared by the source domain. Second, we estimat\ne the posterior label distribution of the unlabeled data for target network training. Previous metho\nds, which iteratively update the pseudo labels by the target network and refine the target network b\ny the updated pseudo labels, are vulnerable to label estimation errors. Instead, our approach uses c\nategory distribution to calculate the cross-entropy loss for training, thereby ameliorating the erro\nr accumulation of the estimated labels. The two contributions allow our approach to outperform the s\ntate-of-the-art methods by +2.6% on the Office-31 dataset.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "507": {"title": "multiposenet: fast multi-person pose estimation using pose residual network.", "url": "https://doi.org/10.1007/978-3-030-01252-6_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "508": {"title": "ts ^2 2 c: tight box mining with surrounding segmentation context for weakly supervised object detection.", "url": "https://doi.org/10.1007/978-3-030-01252-6_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "509": {"title": "hierarchy of alternating specialists for scene recognition.", "url": "https://doi.org/10.1007/978-3-030-01252-6_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "510": {"title": "move forward and tell: a progressive generator of video descriptions.", "url": "https://doi.org/10.1007/978-3-030-01252-6_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "511": {"title": "learning monocular depth by distilling cross-domain stereo networks.", "url": "https://doi.org/10.1007/978-3-030-01252-6_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "512": {"title": "video object segmentation by learning location-sensitive embeddings.", "url": "https://doi.org/10.1007/978-3-030-01252-6_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "513": {"title": "dpp-net: device-aware progressive search for pareto-optimal neural architectures.", "url": "https://doi.org/10.1007/978-3-030-01252-6_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "514": {"title": "riemannian walk for incremental learning: understanding forgetting and intransigence.", "url": "https://doi.org/10.1007/978-3-030-01252-6_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "515": {"title": "dependency-aware attention control for unconstrained face recognition with image sets.", "url": "https://doi.org/10.1007/978-3-030-01252-6_34", "abstract": "This paper targets the problem of image set-based face verification and identification. Unlike tradi\ntional single media (an image or video) setting, we encounter a set of heterogeneous contents contai\nning orderless images and videos. The importance of each image is usually considered either equal or\n based on their independent quality assessment. How to model the relationship of orderless images wi\nthin a set remains a challenge. We address this problem by formulating it as a Markov Decision Proce\nss (MDP) in the latent space. Specifically, we first present a dependency-aware attention control (D\nAC) network, which resorts to actor-critic reinforcement learning for sequential attention decision \nof each image embedding to fully exploit the rich correlation cues among the unordered images. Moreo\nver, we introduce its sample-efficient variant with off-policy experience replay to speed up the lea\nrning process. The pose-guided representation scheme can further boost the performance at the extrem\nes of the pose variation.", "cite_num": 4, "conf": "eccv", "time": "2018"}, "516": {"title": "volumetric performance capture from minimal camera viewpoints.", "url": "https://doi.org/10.1007/978-3-030-01252-6_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "517": {"title": "a framework for evaluating 6-dof object trackers.", "url": "https://doi.org/10.1007/978-3-030-01252-6_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "518": {"title": "variable ring light imaging: capturing transient subsurface scattering with an ordinary camera.", "url": "https://doi.org/10.1007/978-3-030-01252-6_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "519": {"title": "large scale urban scene modeling from mvs meshes.", "url": "https://doi.org/10.1007/978-3-030-01252-6_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "520": {"title": "dynamic multimodal instance segmentation guided by natural language queries.", "url": "https://doi.org/10.1007/978-3-030-01252-6_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "521": {"title": "learning shape priors for single-view 3d completion and reconstruction.", "url": "https://doi.org/10.1007/978-3-030-01252-6_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "522": {"title": "agil: learning attention from human for visuomotor tasks.", "url": "https://doi.org/10.1007/978-3-030-01252-6_41", "abstract": "When intelligent agents learn visuomotor behaviors from human demonstrations, they may benefit from \nknowing where the human is allocating visual attention, which can be inferred from their gaze. A wea\nlth of information regarding intelligent decision making is conveyed by human gaze allocation; hence\n, exploiting such information has the potential to improve the agents\u2019 performance. With this motiva\ntion, we propose the AGIL (Attention Guided Imitation Learning) framework. We collect high-quality h\numan action and gaze data while playing Atari games in a carefully controlled experimental setting. \nUsing these data, we first train a deep neural network that can predict human gaze positions and vis\nual attention with high accuracy (the gaze network) and then train another network to predict human \nactions (the policy network). Incorporating the learned attention model from the gaze network into t\nhe policy network significantly improves the action prediction accuracy and task performance.", "cite_num": 7, "conf": "eccv", "time": "2018"}, "523": {"title": "deep imbalanced attribute classification using visual attention aggregation.", "url": "https://doi.org/10.1007/978-3-030-01252-6_42", "abstract": "For many computer vision applications, such as image description and human identification, recognizi\nng the visual attributes of humans is an essential yet challenging problem. Its challenges originate\n from its multi-label nature, the large underlying class imbalance and the lack of spatial annotatio\nns. Existing methods follow either a computer vision approach while failing to account for class imb\nalance, or explore machine learning solutions, which disregard the spatial and semantic relations th\nat exist in the images. With that in mind, we propose an effective method that extracts and aggregat\nes visual attention masks at different scales. We introduce a loss function to handle class imbalanc\ne both at class and at an instance level and further demonstrate that penalizing attention masks wit\nh high prediction variance accounts for the weak supervision of the attention mechanism. By identify\ning and addressing these challenges, we achieve state-of-the-art results with a simple attention mec\nhanism in both PETA and WIDER-Attribute datasets without additional context or side information.", "cite_num": 9, "conf": "eccv", "time": "2018"}, "524": {"title": "sub-gan: an unsupervised generative model via subspaces.", "url": "https://doi.org/10.1007/978-3-030-01252-6_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "525": {"title": "pyramid dilated deeper convlstm for video salient object detection.", "url": "https://doi.org/10.1007/978-3-030-01252-6_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "526": {"title": "where will they go? predicting fine-grained adversarial multi-agent motion using conditional variational autoencoders.", "url": "https://doi.org/10.1007/978-3-030-01252-6_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "527": {"title": "learning data terms for non-blind deblurring.", "url": "https://doi.org/10.1007/978-3-030-01252-6_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "528": {"title": "zero-shot deep domain adaptation.", "url": "https://doi.org/10.1007/978-3-030-01252-6_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "529": {"title": "comparator networks.", "url": "https://doi.org/10.1007/978-3-030-01252-6_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "530": {"title": "deep regionlets for object detection.", "url": "https://doi.org/10.1007/978-3-030-01252-6_49", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "531": {"title": "physical primitive decomposition.", "url": "https://doi.org/10.1007/978-3-030-01258-8_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "532": {"title": "deep attention neural tensor network for visual question answering.", "url": "https://doi.org/10.1007/978-3-030-01258-8_2", "abstract": "Visual question answering (VQA) has drawn great attention in cross-modal learning problems, which en\nables a machine to answer a natural language question given a reference image. Significant progress \nhas been made by learning rich embedding features from images and questions by bilinear models, whil\ne neglects the key role from answers. In this paper, we propose a novel deep attention neural tensor\n network (DA-NTN) for visual question answering, which can discover the joint correlations over imag\nes, questions and answers with tensor-based representations. First, we model one of the pairwise int\neraction (e.g., image and question) by bilinear features, which is further encoded with the third di\nmension (e.g., answer) to be a triplet by bilinear tensor product. Second, we decompose the correlat\nion of different triplets by different answer and question types, and further propose a slice-wise a\nttention module on tensor to select the most discriminative reasoning process for inference. Third, \nwe optimize the proposed DA-NTN by learning a label regression with KL-divergence losses. Such a des\nign enables scalable training and fast convergence over a large number of answer set. We integrate t\nhe proposed DA-NTN structure into the state-of-the-art VQA models (e.g., MLB and MUTAN). Extensive e\nxperiments demonstrate the superior accuracy than the original MLB and MUTAN models, with 1.98%, 1.7\n0% relative increases on VQA-2.0 dataset, respectively.", "cite_num": 7, "conf": "eccv", "time": "2018"}, "533": {"title": "shuffle-then-assemble: learning object-agnostic visual relationship features.", "url": "https://doi.org/10.1007/978-3-030-01258-8_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "534": {"title": "combining 3d model contour energy and keypoints for object tracking.", "url": "https://doi.org/10.1007/978-3-030-01258-8_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "535": {"title": "pairwise confusion for fine-grained visual classification.", "url": "https://doi.org/10.1007/978-3-030-01258-8_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "536": {"title": "interpretable intuitive physics model.", "url": "https://doi.org/10.1007/978-3-030-01258-8_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "537": {"title": "deep multi-task learning to recognise subtle facial expressions of mental states.", "url": "https://doi.org/10.1007/978-3-030-01258-8_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "538": {"title": "srda: generating instance segmentation annotation via scanning, reasoning and domain adaptation.", "url": "https://doi.org/10.1007/978-3-030-01258-8_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "539": {"title": "unsupervised domain adaptation for 3d keypoint estimation via view consistency.", "url": "https://doi.org/10.1007/978-3-030-01258-8_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "540": {"title": "practical black-box attacks on deep neural networks using efficient query mechanisms.", "url": "https://doi.org/10.1007/978-3-030-01258-8_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "541": {"title": "dyan: a dynamical atoms-based network for video prediction.", "url": "https://doi.org/10.1007/978-3-030-01258-8_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "542": {"title": "sparsely aggregated convolutional networks.", "url": "https://doi.org/10.1007/978-3-030-01258-8_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "543": {"title": "revisiting the inverted indices for billion-scale approximate nearest neighbors.", "url": "https://doi.org/10.1007/978-3-030-01258-8_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "544": {"title": "diverse feature visualizations reveal invariances in early layers of deep neural networks.", "url": "https://doi.org/10.1007/978-3-030-01258-8_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "545": {"title": "end-to-end incremental learning.", "url": "https://doi.org/10.1007/978-3-030-01258-8_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "546": {"title": "conditional image-text embedding networks.", "url": "https://doi.org/10.1007/978-3-030-01258-8_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "547": {"title": "sampling algebraic varieties for robust camera autocalibration.", "url": "https://doi.org/10.1007/978-3-030-01258-8_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "548": {"title": "attribute-guided face generation using conditional cyclegan.", "url": "https://doi.org/10.1007/978-3-030-01258-8_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "549": {"title": "deep structure inference network for facial action unit recognition.", "url": "https://doi.org/10.1007/978-3-030-01258-8_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "550": {"title": "learning priors for semantic 3d reconstruction.", "url": "https://doi.org/10.1007/978-3-030-01258-8_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "551": {"title": "object detection in video with spatiotemporal sampling networks.", "url": "https://doi.org/10.1007/978-3-030-01258-8_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "552": {"title": "video summarization using fully convolutional sequence networks.", "url": "https://doi.org/10.1007/978-3-030-01258-8_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "553": {"title": "modeling visual context is key to augmenting object detection datasets.", "url": "https://doi.org/10.1007/978-3-030-01258-8_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "554": {"title": "learning region features for object detection.", "url": "https://doi.org/10.1007/978-3-030-01258-8_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "555": {"title": "end-to-end deep structured models for drawing crosswalks.", "url": "https://doi.org/10.1007/978-3-030-01258-8_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "556": {"title": "sidekick policy learning for active visual exploration.", "url": "https://doi.org/10.1007/978-3-030-01258-8_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "557": {"title": "coloring with words: guiding image colorization through text-based palette generation.", "url": "https://doi.org/10.1007/978-3-030-01258-8_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "558": {"title": "efficient global point cloud registration by matching rotation invariant features through translation search.", "url": "https://doi.org/10.1007/978-3-030-01258-8_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "559": {"title": "facial dynamics interpreter network: what are the important relations between local dynamics for facial trait estimation?", "url": "https://doi.org/10.1007/978-3-030-01258-8_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "560": {"title": "visual question generation for class acquisition of unknown objects.", "url": "https://doi.org/10.1007/978-3-030-01258-8_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "561": {"title": "efficient dense point cloud object reconstruction using deformation vector fields.", "url": "https://doi.org/10.1007/978-3-030-01258-8_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "562": {"title": "improving dnn robustness to adversarial attacks using jacobian regularization.", "url": "https://doi.org/10.1007/978-3-030-01258-8_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "563": {"title": "concept mask: large-scale segmentation from semantic concepts.", "url": "https://doi.org/10.1007/978-3-030-01258-8_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "564": {"title": "descending, lifting or smoothing: secrets of robust cost optimization.", "url": "https://doi.org/10.1007/978-3-030-01258-8_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "565": {"title": "geolocation estimation of photos using a hierarchical model and scene classification.", "url": "https://doi.org/10.1007/978-3-030-01258-8_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "566": {"title": "license plate detection and recognition in unconstrained scenarios.", "url": "https://doi.org/10.1007/978-3-030-01258-8_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "567": {"title": "self-produced guidance for weakly-supervised object localization.", "url": "https://doi.org/10.1007/978-3-030-01258-8_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "568": {"title": "occlusions, motion and depth boundaries with a generic network for disparity, optical flow or scene flow estimation.", "url": "https://doi.org/10.1007/978-3-030-01258-8_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "569": {"title": "is robustness the cost of accuracy? - a comprehensive study on the robustness of 18 deep image classification models.", "url": "https://doi.org/10.1007/978-3-030-01258-8_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "570": {"title": "improving shape deformation in unsupervised image-to-image translation.", "url": "https://doi.org/10.1007/978-3-030-01258-8_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "571": {"title": "swapnet: image based garment transfer.", "url": "https://doi.org/10.1007/978-3-030-01258-8_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "572": {"title": "deterministic consensus maximization with biconvex programming.", "url": "https://doi.org/10.1007/978-3-030-01258-8_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "573": {"title": "robust fitting in computer vision: easy or hard?", "url": "https://doi.org/10.1007/978-3-030-01258-8_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "574": {"title": "highly-economized multi-view binary compression for scalable image clustering.", "url": "https://doi.org/10.1007/978-3-030-01258-8_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "575": {"title": "efficient semantic scene completion network with spatial group convolution.", "url": "https://doi.org/10.1007/978-3-030-01258-8_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "576": {"title": "asynchronous, photometric feature tracking using events and frames.", "url": "https://doi.org/10.1007/978-3-030-01258-8_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "577": {"title": "group normalization.", "url": "https://doi.org/10.1007/978-3-030-01261-8_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "578": {"title": "deep expander networks: efficient deep networks from graph theory.", "url": "https://doi.org/10.1007/978-3-030-01261-8_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "579": {"title": "towards realistic predictors.", "url": "https://doi.org/10.1007/978-3-030-01261-8_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "580": {"title": "learning so(3) equivariant representations with spherical cnns.", "url": "https://doi.org/10.1007/978-3-030-01261-8_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "581": {"title": "learnable pins: cross-modal embeddings for person identity.", "url": "https://doi.org/10.1007/978-3-030-01261-8_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "582": {"title": "separating reflection and transmission images in the wild.", "url": "https://doi.org/10.1007/978-3-030-01261-8_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "583": {"title": "object level visual reasoning in videos.", "url": "https://doi.org/10.1007/978-3-030-01261-8_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "584": {"title": "maximum margin metric learning over discriminative nullspace for person re-identification.", "url": "https://doi.org/10.1007/978-3-030-01261-8_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "585": {"title": "incremental multi-graph matching via diversity and randomness based graph clustering.", "url": "https://doi.org/10.1007/978-3-030-01261-8_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "586": {"title": "visual text correction.", "url": "https://doi.org/10.1007/978-3-030-01261-8_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "587": {"title": "generalizing a person retrieval model hetero- and homogeneously.", "url": "https://doi.org/10.1007/978-3-030-01261-8_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "588": {"title": "domain adaptation through synthesis for unsupervised person re-identification.", "url": "https://doi.org/10.1007/978-3-030-01261-8_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "589": {"title": "sod-mtgan: small object detection via multi-task generative adversarial network.", "url": "https://doi.org/10.1007/978-3-030-01261-8_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "590": {"title": "facial expression recognition with inconsistently annotated datasets.", "url": "https://doi.org/10.1007/978-3-030-01261-8_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "591": {"title": "stroke controllable fast style transfer with adaptive receptive fields.", "url": "https://doi.org/10.1007/978-3-030-01261-8_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "592": {"title": "towards end-to-end license plate detection and recognition: a large dataset and baseline.", "url": "https://doi.org/10.1007/978-3-030-01261-8_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "593": {"title": "learning warped guidance for blind face restoration.", "url": "https://doi.org/10.1007/978-3-030-01261-8_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "594": {"title": "face de-spoofing: anti-spoofing via noise modeling.", "url": "https://doi.org/10.1007/978-3-030-01261-8_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "595": {"title": "unsupervised hard example mining from videos for improved object detection.", "url": "https://doi.org/10.1007/978-3-030-01261-8_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "596": {"title": "bisenet: bilateral segmentation network for real-time semantic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01261-8_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "597": {"title": "pose proposal networks.", "url": "https://doi.org/10.1007/978-3-030-01261-8_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "598": {"title": "less is more: picking informative frames for video captioning.", "url": "https://doi.org/10.1007/978-3-030-01261-8_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "599": {"title": "cross-modal and hierarchical modeling of video and text.", "url": "https://doi.org/10.1007/978-3-030-01261-8_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "600": {"title": "tracking emerges by colorizing videos.", "url": "https://doi.org/10.1007/978-3-030-01261-8_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "601": {"title": "skipnet: learning dynamic routing in convolutional networks.", "url": "https://doi.org/10.1007/978-3-030-01261-8_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "602": {"title": "person search in videos with one portrait through visual and temporal links.", "url": "https://doi.org/10.1007/978-3-030-01261-8_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "603": {"title": "decouple learning for parameterized image operators.", "url": "https://doi.org/10.1007/978-3-030-01261-8_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "604": {"title": "triplet loss in siamese network for object tracking.", "url": "https://doi.org/10.1007/978-3-030-01261-8_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "605": {"title": "point-to-point regression pointnet for 3d hand pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01261-8_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "606": {"title": "dock: detecting objects by transferring common-sense knowledge.", "url": "https://doi.org/10.1007/978-3-030-01261-8_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "607": {"title": "multi-scale spatially-asymmetric recalibration for image classification.", "url": "https://doi.org/10.1007/978-3-030-01261-8_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "608": {"title": "choose your neuron: incorporating domain knowledge through neuron-importance.", "url": "https://doi.org/10.1007/978-3-030-01261-8_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "609": {"title": "fully motion-aware network for video object detection.", "url": "https://doi.org/10.1007/978-3-030-01261-8_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "610": {"title": "generative semantic manipulation with mask-contrasting gan.", "url": "https://doi.org/10.1007/978-3-030-01261-8_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "611": {"title": "interpolating convolutional neural networks using batch normalization.", "url": "https://doi.org/10.1007/978-3-030-01261-8_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "612": {"title": "toward characteristic-preserving image-based virtual try-on network.", "url": "https://doi.org/10.1007/978-3-030-01261-8_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "613": {"title": "deep cross-modality adaptation via semantics preserving adversarial learning for sketch-based 3d shape retrieval.", "url": "https://doi.org/10.1007/978-3-030-01261-8_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "614": {"title": "ridi: robust imu double integration.", "url": "https://doi.org/10.1007/978-3-030-01261-8_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "615": {"title": "training binary weight networks via semi-binary decomposition.", "url": "https://doi.org/10.1007/978-3-030-01261-8_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "616": {"title": "focus, segment and erase: an efficient network for multi-label brain tumor segmentation.", "url": "https://doi.org/10.1007/978-3-030-01261-8_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "617": {"title": "x2face: a network for controlling face generation using images, audio, and pose codes.", "url": "https://doi.org/10.1007/978-3-030-01261-8_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "618": {"title": "model adaptation with synthetic and real data for semantic dense foggy scene understanding.", "url": "https://doi.org/10.1007/978-3-030-01261-8_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "619": {"title": "deep adaptive attention for joint facial action unit detection and face alignment.", "url": "https://doi.org/10.1007/978-3-030-01261-8_43", "abstract": "Facial action unit (AU) detection and face alignment are two highly correlated tasks since facial la\nndmarks can provide precise AU locations to facilitate the extraction of meaningful local features f\nor AU detection. Most existing AU detection works often treat face alignment as a preprocessing and \nhandle the two tasks independently. In this paper, we propose a novel end-to-end deep learning frame\nwork for joint AU detection and face alignment, which has not been explored before. In particular, m\nulti-scale shared features are learned firstly, and high-level features of face alignment are fed in\nto AU detection. Moreover, to extract precise local features, we propose an adaptive attention learn\ning module to refine the attention map of each AU adaptively. Finally, the assembled local features \nare integrated with face alignment features and global features for AU detection. Experiments on BP4\nD and DISFA benchmarks demonstrate that our framework significantly outperforms the state-of-the-art\n methods for AU detection.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "620": {"title": "deep pictorial gaze estimation.", "url": "https://doi.org/10.1007/978-3-030-01261-8_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "621": {"title": "learning to fuse proposals from multiple scanline optimizations in semi-global matching.", "url": "https://doi.org/10.1007/978-3-030-01261-8_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "622": {"title": "incremental non-rigid structure-from-motion with unknown focal length.", "url": "https://doi.org/10.1007/978-3-030-01261-8_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "623": {"title": "r2p2: a reparameterized pushforward policy for diverse, precise generative path forecasting.", "url": "https://doi.org/10.1007/978-3-030-01261-8_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "624": {"title": "eliminating the blind spot: adapting 3d object detection and monocular depth estimation to 360 ^\\circ \u2218 panoramic imagery.", "url": "https://doi.org/10.1007/978-3-030-01261-8_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "625": {"title": "cross-modal ranking with soft consistency and noisy labels for robust rgb-t tracking.", "url": "https://doi.org/10.1007/978-3-030-01261-8_49", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "626": {"title": "shift-net: image inpainting via deep feature rearrangement.", "url": "https://doi.org/10.1007/978-3-030-01264-9_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "627": {"title": "interactive boundary prediction for object selection.", "url": "https://doi.org/10.1007/978-3-030-01264-9_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "628": {"title": "x-ray computed tomography through scatter.", "url": "https://doi.org/10.1007/978-3-030-01264-9_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "629": {"title": "video re-localization.", "url": "https://doi.org/10.1007/978-3-030-01264-9_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "630": {"title": "mask textspotter: an end-to-end trainable neural network for spotting text with arbitrary shapes.", "url": "https://doi.org/10.1007/978-3-030-01264-9_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "631": {"title": "dft-based transformation invariant pooling layer for visual classification.", "url": "https://doi.org/10.1007/978-3-030-01264-9_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "632": {"title": "appearance-based gaze estimation via evaluation-guided asymmetric regression.", "url": "https://doi.org/10.1007/978-3-030-01264-9_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "633": {"title": "shufflenet v2: practical guidelines for efficient cnn architecture design.", "url": "https://doi.org/10.1007/978-3-030-01264-9_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "634": {"title": "deep clustering for unsupervised learning of visual features.", "url": "https://doi.org/10.1007/978-3-030-01264-9_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "635": {"title": "modular generative adversarial networks.", "url": "https://doi.org/10.1007/978-3-030-01264-9_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "636": {"title": "graph distillation for action detection with privileged modalities.", "url": "https://doi.org/10.1007/978-3-030-01264-9_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "637": {"title": "weakly-supervised video summarization using variational encoder-decoder and web prior.", "url": "https://doi.org/10.1007/978-3-030-01264-9_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "638": {"title": "single image intrinsic decomposition without a single intrinsic image.", "url": "https://doi.org/10.1007/978-3-030-01264-9_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "639": {"title": "learning to dodge a bullet: concyclic view morphing via deep learning.", "url": "https://doi.org/10.1007/978-3-030-01264-9_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "640": {"title": "compositional learning for human object interaction.", "url": "https://doi.org/10.1007/978-3-030-01264-9_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "641": {"title": "viewpoint estimation - insights and model.", "url": "https://doi.org/10.1007/978-3-030-01264-9_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "642": {"title": "personlab: person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model.", "url": "https://doi.org/10.1007/978-3-030-01264-9_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "643": {"title": "task-driven webpage saliency.", "url": "https://doi.org/10.1007/978-3-030-01264-9_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "644": {"title": "deep image demosaicking using a cascade of convolutional residual denoising networks.", "url": "https://doi.org/10.1007/978-3-030-01264-9_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "645": {"title": "a new large scale dynamic texture dataset with application to convnet understanding.", "url": "https://doi.org/10.1007/978-3-030-01264-9_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "646": {"title": "deep feature factorization for concept discovery.", "url": "https://doi.org/10.1007/978-3-030-01264-9_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "647": {"title": "deep regression tracking with shrinkage loss.", "url": "https://doi.org/10.1007/978-3-030-01264-9_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "648": {"title": "dist-gan: an improved gan using distance constraints.", "url": "https://doi.org/10.1007/978-3-030-01264-9_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "649": {"title": "pivot correlational neural network for multimodal video categorization.", "url": "https://doi.org/10.1007/978-3-030-01264-9_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "650": {"title": "part-aligned bilinear representations for person re-identification.", "url": "https://doi.org/10.1007/978-3-030-01264-9_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "651": {"title": "learning to navigate for fine-grained classification.", "url": "https://doi.org/10.1007/978-3-030-01264-9_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "652": {"title": "nam: non-adversarial unsupervised domain mapping.", "url": "https://doi.org/10.1007/978-3-030-01264-9_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "653": {"title": "transferable adversarial perturbations.", "url": "https://doi.org/10.1007/978-3-030-01264-9_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "654": {"title": "semantically aware urban 3d reconstruction with plane-based regularization.", "url": "https://doi.org/10.1007/978-3-030-01264-9_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "655": {"title": "joint 3d tracking of a deformable object in interaction with a hand.", "url": "https://doi.org/10.1007/978-3-030-01264-9_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "656": {"title": "hbe: hand branch ensemble network for real-time 3d hand pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01264-9_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "657": {"title": "sequential clique optimization for video object segmentation.", "url": "https://doi.org/10.1007/978-3-030-01264-9_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "658": {"title": "joint 3d face reconstruction and dense alignment with position map regression network.", "url": "https://doi.org/10.1007/978-3-030-01264-9_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "659": {"title": "efficient relative attribute learning using graph neural networks.", "url": "https://doi.org/10.1007/978-3-030-01264-9_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "660": {"title": "deep kalman filtering network for video compression artifact reduction.", "url": "https://doi.org/10.1007/978-3-030-01264-9_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "661": {"title": "a deeply-initialized coarse-to-fine ensemble of regression trees for face alignment.", "url": "https://doi.org/10.1007/978-3-030-01264-9_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "662": {"title": "deepvs: a deep learning based video saliency prediction approach.", "url": "https://doi.org/10.1007/978-3-030-01264-9_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "663": {"title": "learning efficient single-stage pedestrian detectors by asymptotic localization fitting.", "url": "https://doi.org/10.1007/978-3-030-01264-9_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "664": {"title": "scenes-objects-actions: a multi-task, multi-label video dataset.", "url": "https://doi.org/10.1007/978-3-030-01264-9_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "665": {"title": "accelerating dynamic programs via nested benders decomposition with application to multi-person pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01264-9_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "666": {"title": "human motion analysis with deep metric learning.", "url": "https://doi.org/10.1007/978-3-030-01264-9_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "667": {"title": "exploring visual relationship for image captioning.", "url": "https://doi.org/10.1007/978-3-030-01264-9_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "668": {"title": "single shot scene text retrieval.", "url": "https://doi.org/10.1007/978-3-030-01264-9_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "669": {"title": "folded recurrent neural networks for future video prediction.", "url": "https://doi.org/10.1007/978-3-030-01264-9_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "670": {"title": "cornernet: detecting objects as paired keypoints.", "url": "https://doi.org/10.1007/978-3-030-01264-9_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "671": {"title": "relocnet: continuous metric learning relocalisation using neural nets.", "url": "https://doi.org/10.1007/978-3-030-01264-9_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "672": {"title": "the contextual loss for image transformation with non-aligned data.", "url": "https://doi.org/10.1007/978-3-030-01264-9_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "673": {"title": "acquisition of localization confidence for accurate object detection.", "url": "https://doi.org/10.1007/978-3-030-01264-9_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "674": {"title": "deep model-based 6d pose refinement in rgb.", "url": "https://doi.org/10.1007/978-3-030-01264-9_49", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "675": {"title": "cnn-ps: cnn-based photometric stereo for general non-convex surfaces.", "url": "https://doi.org/10.1007/978-3-030-01267-0_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "676": {"title": "dynamic conditional networks for few-shot learning.", "url": "https://doi.org/10.1007/978-3-030-01267-0_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "677": {"title": "deep factorised inverse-sketching.", "url": "https://doi.org/10.1007/978-3-030-01267-0_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "678": {"title": "look deeper into depth: monocular depth estimation with semantic booster and attention-driven loss.", "url": "https://doi.org/10.1007/978-3-030-01267-0_4", "abstract": "Monocular depth estimation benefits greatly from learning based techniques. By studying the training\n data, we observe that the per-pixel depth values in existing datasets typically exhibit a long-tail\ned distribution. However, most previous approaches treat all the regions in the training data equall\ny regardless of the imbalanced depth distribution, which restricts the model performance particularl\ny on distant depth regions. In this paper, we investigate the long tail property and delve deeper in\nto the distant depth regions (i.e. the tail part) to propose an attention-driven loss for the networ\nk supervision. In addition, to better leverage the semantic information for monocular depth estimati\non, we propose a synergy network to automatically learn the information sharing strategies between t\nhe two tasks. With the proposed attention-driven loss and synergy network, the depth estimation and \nsemantic labeling tasks can be mutually improved. Experiments on the challenging indoor dataset show\n that the proposed approach achieves state-of-the-art performance on both monocular depth estimation\n and semantic labeling tasks.", "cite_num": -1, "conf": "eccv", "time": "2018"}, "679": {"title": "summarizing first-person videos from third persons' points of views.", "url": "https://doi.org/10.1007/978-3-030-01267-0_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "680": {"title": "learning single-view 3d reconstruction with limited pose supervision.", "url": "https://doi.org/10.1007/978-3-030-01267-0_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "681": {"title": "weakly- and semi-supervised panoptic segmentation.", "url": "https://doi.org/10.1007/978-3-030-01267-0_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "682": {"title": "making deep heatmaps robust to partial occlusions for 3d object pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01267-0_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "683": {"title": "deep co-training for semi-supervised image recognition.", "url": "https://doi.org/10.1007/978-3-030-01267-0_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "684": {"title": "visual coreference resolution in visual dialog using neural module networks.", "url": "https://doi.org/10.1007/978-3-030-01267-0_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "685": {"title": "learning blind video temporal consistency.", "url": "https://doi.org/10.1007/978-3-030-01267-0_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "686": {"title": "salient objects in clutter: bringing salient object detection to the foreground.", "url": "https://doi.org/10.1007/978-3-030-01267-0_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "687": {"title": "gray-box adversarial training.", "url": "https://doi.org/10.1007/978-3-030-01267-0_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "688": {"title": "visual question answering as a meta learning task.", "url": "https://doi.org/10.1007/978-3-030-01267-0_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "689": {"title": "on offline evaluation of vision-based driving models.", "url": "https://doi.org/10.1007/978-3-030-01267-0_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "690": {"title": "visual psychophysics for making face recognition algorithms more explainable.", "url": "https://doi.org/10.1007/978-3-030-01267-0_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "691": {"title": "conditional prior networks for optical flow.", "url": "https://doi.org/10.1007/978-3-030-01267-0_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "692": {"title": "robust optical flow in rainy scenes.", "url": "https://doi.org/10.1007/978-3-030-01267-0_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "693": {"title": "rethinking spatiotemporal feature learning: speed-accuracy trade-offs in video classification.", "url": "https://doi.org/10.1007/978-3-030-01267-0_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "694": {"title": "variational wasserstein clustering.", "url": "https://doi.org/10.1007/978-3-030-01267-0_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "695": {"title": "show, tell and discriminate: image captioning by self-retrieval with partially labeled data.", "url": "https://doi.org/10.1007/978-3-030-01267-0_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "696": {"title": "contour knowledge transfer for salient object detection.", "url": "https://doi.org/10.1007/978-3-030-01267-0_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "697": {"title": "learning category-specific mesh reconstruction from image collections.", "url": "https://doi.org/10.1007/978-3-030-01267-0_23", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "698": {"title": "learning to forecast and refine residual motion for image-to-video generation.", "url": "https://doi.org/10.1007/978-3-030-01267-0_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "699": {"title": "teaching machines to understand baseball games: large-scale baseball video database for multiple video understanding tasks.", "url": "https://doi.org/10.1007/978-3-030-01267-0_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "700": {"title": "sketchyscene: richly-annotated scene sketches.", "url": "https://doi.org/10.1007/978-3-030-01267-0_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "701": {"title": "learn-to-score: efficient 3d scene exploration by predicting view utility.", "url": "https://doi.org/10.1007/978-3-030-01267-0_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "702": {"title": "revisiting rcnn: on awakening the classification power of faster rcnn.", "url": "https://doi.org/10.1007/978-3-030-01267-0_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "703": {"title": "semi-supervised generative adversarial hashing for image retrieval.", "url": "https://doi.org/10.1007/978-3-030-01267-0_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "704": {"title": "person re-identification with deep similarity-guided graph neural network.", "url": "https://doi.org/10.1007/978-3-030-01267-0_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "705": {"title": "learning and matching multi-view descriptors for registration of point clouds.", "url": "https://doi.org/10.1007/978-3-030-01267-0_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "706": {"title": "revisiting autofocus for smartphone cameras.", "url": "https://doi.org/10.1007/978-3-030-01267-0_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "707": {"title": "deep burst denoising.", "url": "https://doi.org/10.1007/978-3-030-01267-0_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "708": {"title": "isnn: impact sound neural network for audio-visual object classification.", "url": "https://doi.org/10.1007/978-3-030-01267-0_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "709": {"title": "stereonet: guided hierarchical refinement for real-time edge-aware depth prediction.", "url": "https://doi.org/10.1007/978-3-030-01267-0_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "710": {"title": "attention-aware deep adversarial hashing for cross-modal retrieval.", "url": "https://doi.org/10.1007/978-3-030-01267-0_36", "abstract": "Due to the rapid growth of multi-modal data, hashing methods for cross-modal retrieval have received\n considerable attention. However, finding content similarities between different modalities of data \nis still challenging due to an existing heterogeneity gap. To further address this problem, we propo\nse an adversarial hashing network with an attention mechanism to enhance the measurement of content \nsimilarities by selectively focusing on the informative parts of multi-modal data. The proposed new \ndeep adversarial network consists of three building blocks: (1) the feature learning module to obtai\nn the feature representations; (2) the attention module to generate an attention mask, which is used\n to divide the feature representations into the attended and unattended feature representations; and\n (3) the hashing module to learn hash functions that preserve the similarities between different mod\nalities. In our framework, the attention and hashing modules are trained in an adversarial way: the \nattention module attempts to make the hashing module unable to preserve the similarities of multi-mo\ndal data w.r.t. the unattended feature representations, while the hashing module aims to preserve th\ne similarities of multi-modal data w.r.t. the attended and unattended feature representations. Exten\nsive evaluations on several benchmark datasets demonstrate that the proposed method brings substanti\nal improvements over other state-of-the-art cross-modal hashing methods.", "cite_num": 8, "conf": "eccv", "time": "2018"}, "711": {"title": "3dfeat-net: weakly supervised local 3d features for point cloud registration.", "url": "https://doi.org/10.1007/978-3-030-01267-0_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "712": {"title": "deep domain generalization via conditional invariant adversarial networks.", "url": "https://doi.org/10.1007/978-3-030-01267-0_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "713": {"title": "using lip to gloss over faces in single-stage face detection networks.", "url": "https://doi.org/10.1007/978-3-030-01267-0_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "714": {"title": "hidden: hiding data with deep networks.", "url": "https://doi.org/10.1007/978-3-030-01267-0_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "715": {"title": "multimodal dual attention memory for video story question answering.", "url": "https://doi.org/10.1007/978-3-030-01267-0_41", "abstract": "We propose a video story question-answering (QA) architecture, Multimodal Dual Attention Memory (MDA\nM). The key idea is to use a dual attention mechanism with late fusion. MDAM uses self-attention to \nlearn the latent concepts in scene frames and captions. Given a question, MDAM uses the second atten\ntion over these latent concepts. Multimodal fusion is performed after the dual attention processes (\nlate fusion). Using this processing pipeline, MDAM learns to infer a high-level vision-language join\nt representation from an abstraction of the full video content. We evaluate MDAM on PororoQA and Mov\nieQA datasets which have large-scale QA annotations on cartoon videos and movies, respectively. For \nboth datasets, MDAM achieves new state-of-the-art results with significant margins compared to the r\nunner-up models. We confirm the best performance of the dual attention mechanism combined with late \nfusion by ablation studies. We also perform qualitative analysis by visualizing the inference mechan\nisms of MDAM.", "cite_num": 6, "conf": "eccv", "time": "2018"}, "716": {"title": "deep variational metric learning.", "url": "https://doi.org/10.1007/978-3-030-01267-0_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "717": {"title": "hgmr: hierarchical gaussian mixtures for adaptive 3d registration.", "url": "https://doi.org/10.1007/978-3-030-01267-0_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "718": {"title": "bi-real net: enhancing the performance of 1-bit cnns with improved representational capability and advanced training algorithm.", "url": "https://doi.org/10.1007/978-3-030-01267-0_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "719": {"title": "orthogonal deep features decomposition for age-invariant face recognition.", "url": "https://doi.org/10.1007/978-3-030-01267-0_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "720": {"title": "broadcasting convolutional network for visual relational reasoning.", "url": "https://doi.org/10.1007/978-3-030-01267-0_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "721": {"title": "improving spatiotemporal self-supervision by deep reinforcement learning.", "url": "https://doi.org/10.1007/978-3-030-01267-0_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "722": {"title": "learning to look around objects for top-view representations of outdoor scenes.", "url": "https://doi.org/10.1007/978-3-030-01267-0_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "723": {"title": "hierarchical metric learning and matching for 2d and 3d geometric correspondences.", "url": "https://doi.org/10.1007/978-3-030-01267-0_49", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "724": {"title": "deep component analysis via alternating direction neural networks.", "url": "https://doi.org/10.1007/978-3-030-01267-0_50", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "725": {"title": "advise: symbolism and external knowledge for decoding advertisements.", "url": "https://doi.org/10.1007/978-3-030-01267-0_51", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "726": {"title": "gridface: face rectification via learning local homography transformations.", "url": "https://doi.org/10.1007/978-3-030-01270-0_1", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "727": {"title": "polarimetric three-view geometry.", "url": "https://doi.org/10.1007/978-3-030-01270-0_2", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "728": {"title": "look before you leap: bridging model-free and model-based reinforcement learning for planned-ahead vision-and-language navigation.", "url": "https://doi.org/10.1007/978-3-030-01270-0_3", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "729": {"title": "improving deep visual representation for person re-identification by global and local image-language association.", "url": "https://doi.org/10.1007/978-3-030-01270-0_4", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "730": {"title": "learning 3d shapes as multi-layered height-maps using 2d convolutional networks.", "url": "https://doi.org/10.1007/978-3-030-01270-0_5", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "731": {"title": "a geometric perspective on structured light coding.", "url": "https://doi.org/10.1007/978-3-030-01270-0_6", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "732": {"title": "depth estimation via affinity learned with convolutional spatial propagation network.", "url": "https://doi.org/10.1007/978-3-030-01270-0_7", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "733": {"title": "shapecodes: self-supervised feature learning by lifting views to viewgrids.", "url": "https://doi.org/10.1007/978-3-030-01270-0_8", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "734": {"title": "super-resolution and sparse view ct reconstruction.", "url": "https://doi.org/10.1007/978-3-030-01270-0_9", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "735": {"title": "autoloc: weakly-supervised temporal action localization in untrimmed videos.", "url": "https://doi.org/10.1007/978-3-030-01270-0_10", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "736": {"title": "exploiting vector fields for geometric rectification of distorted document images.", "url": "https://doi.org/10.1007/978-3-030-01270-0_11", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "737": {"title": "hard-aware point-to-set deep metric for person re-identification.", "url": "https://doi.org/10.1007/978-3-030-01270-0_12", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "738": {"title": "image generation from sketch constraint using contextual gan.", "url": "https://doi.org/10.1007/978-3-030-01270-0_13", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "739": {"title": "multi-class model fitting by energy minimization and mode-seeking.", "url": "https://doi.org/10.1007/978-3-030-01270-0_14", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "740": {"title": "handmap: robust hand pose estimation via intermediate dense guidance map supervision.", "url": "https://doi.org/10.1007/978-3-030-01270-0_15", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "741": {"title": "a unified framework for multi-view multi-class object pose estimation.", "url": "https://doi.org/10.1007/978-3-030-01270-0_16", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "742": {"title": "dynamic task prioritization for multitask learning.", "url": "https://doi.org/10.1007/978-3-030-01270-0_17", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "743": {"title": "joint blind motion deblurring and depth estimation of light field.", "url": "https://doi.org/10.1007/978-3-030-01270-0_18", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "744": {"title": "data-driven sparse structure selection for deep neural networks.", "url": "https://doi.org/10.1007/978-3-030-01270-0_19", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "745": {"title": "on the solvability of viewing graphs.", "url": "https://doi.org/10.1007/978-3-030-01270-0_20", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "746": {"title": "deep volumetric video from very sparse multi-view performance capture.", "url": "https://doi.org/10.1007/978-3-030-01270-0_21", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "747": {"title": "accurate scene text detection through border semantics awareness and bootstrapping.", "url": "https://doi.org/10.1007/978-3-030-01270-0_22", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "748": {"title": "interaction-aware spatio-temporal pyramid attention networks for action classification.", "url": "https://doi.org/10.1007/978-3-030-01270-0_23", "abstract": "Local features at neighboring spatial positions in feature maps have high correlation since their re\nceptive fields are often overlapped. Self-attention usually uses the weighted sum (or other function\ns) with internal elements of each local feature to obtain its weight score, which ignores interactio\nns among local features. To address this, we propose an effective interaction-aware self-attention m\nodel inspired by PCA to learn attention maps. Furthermore, since different layers in a deep network \ncapture feature maps of different scales, we use these feature maps to construct a spatial pyramid a\nnd then utilize multi-scale information to obtain more accurate attention scores, which are used to \nweight the local features in all spatial positions of feature maps to calculate attention maps. More\nover, our spatial pyramid attention is unrestricted to the number of its input feature maps so it is\n easily extended to a spatio-temporal version. Finally, our model is embedded in general CNNs to for\nm end-to-end attention networks for action classification. Experimental results show that our method\n achieves the state-of-the-art results on the UCF101, HMDB51 and untrimmed Charades.", "cite_num": 2, "conf": "eccv", "time": "2018"}, "749": {"title": "learning type-aware embeddings for fashion compatibility.", "url": "https://doi.org/10.1007/978-3-030-01270-0_24", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "750": {"title": "diverse conditional image generation by stochastic regression with latent drop-out codes.", "url": "https://doi.org/10.1007/978-3-030-01270-0_25", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "751": {"title": "reconstruction-based pairwise depth dataset for depth image enhancement using cnn.", "url": "https://doi.org/10.1007/978-3-030-01270-0_26", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "752": {"title": "srfeat: single image super-resolution with feature discrimination.", "url": "https://doi.org/10.1007/978-3-030-01270-0_27", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "753": {"title": "recognition in terra incognita.", "url": "https://doi.org/10.1007/978-3-030-01270-0_28", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "754": {"title": "a minimal closed-form solution for multi-perspective pose estimation using points and lines.", "url": "https://doi.org/10.1007/978-3-030-01270-0_29", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "755": {"title": "lsq++: lower running time and higher recall in multi-codebook quantization.", "url": "https://doi.org/10.1007/978-3-030-01270-0_30", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "756": {"title": "on regularized losses for weakly-supervised cnn segmentation.", "url": "https://doi.org/10.1007/978-3-030-01270-0_31", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "757": {"title": "dense semantic and topological correspondence of 3d faces without landmarks.", "url": "https://doi.org/10.1007/978-3-030-01270-0_32", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "758": {"title": "using object information for spotting text.", "url": "https://doi.org/10.1007/978-3-030-01270-0_33", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "759": {"title": "remote photoplethysmography correspondence feature for 3d mask face presentation attack detection.", "url": "https://doi.org/10.1007/978-3-030-01270-0_34", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "760": {"title": "hierarchical bilinear pooling for fine-grained visual recognition.", "url": "https://doi.org/10.1007/978-3-030-01270-0_35", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "761": {"title": "domain transfer through deep activation matching.", "url": "https://doi.org/10.1007/978-3-030-01270-0_36", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "762": {"title": "towards privacy-preserving visual recognition via adversarial training: a pilot study.", "url": "https://doi.org/10.1007/978-3-030-01270-0_37", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "763": {"title": "adaptively transforming graph matching.", "url": "https://doi.org/10.1007/978-3-030-01270-0_38", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "764": {"title": "deep continuous fusion for multi-sensor 3d object detection.", "url": "https://doi.org/10.1007/978-3-030-01270-0_39", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "765": {"title": "multimodal image alignment through a multiscale chain of neural networks with application to remote sensing.", "url": "https://doi.org/10.1007/978-3-030-01270-0_40", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "766": {"title": "understanding perceptual and conceptual fluency at a large scale.", "url": "https://doi.org/10.1007/978-3-030-01270-0_41", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "767": {"title": "unsupervised learning of multi-frame optical flow with occlusions.", "url": "https://doi.org/10.1007/978-3-030-01270-0_42", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "768": {"title": "distortion-aware convolutional filters for dense prediction in panoramic images.", "url": "https://doi.org/10.1007/978-3-030-01270-0_43", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "769": {"title": "deep randomized ensembles for metric learning.", "url": "https://doi.org/10.1007/978-3-030-01270-0_44", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "770": {"title": "3d ego-pose estimation via imitation learning.", "url": "https://doi.org/10.1007/978-3-030-01270-0_45", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "771": {"title": "contextvp: fully context-aware video prediction.", "url": "https://doi.org/10.1007/978-3-030-01270-0_46", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "772": {"title": "saliency benchmarking made easy: separating models, maps and metrics.", "url": "https://doi.org/10.1007/978-3-030-01270-0_47", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "773": {"title": "museum exhibit identification challenge for the supervised domain adaptation and beyond.", "url": "https://doi.org/10.1007/978-3-030-01270-0_48", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}, "774": {"title": "multi-attention multi-class constraint for fine-grained image recognition.", "url": "https://doi.org/10.1007/978-3-030-01270-0_49", "abstract": "Attention-based learning for fine-grained image recognition remains a challenging task, where most o\nf the existing methods treat each object part in isolation, while neglecting the correlations among \nthem. In addition, the multi-stage or multi-scale mechanisms involved make the existing methods less\n efficient and hard to be trained end-to-end. In this paper, we propose a novel attention-based conv\nolutional neural network (CNN) which regulates multiple object parts among different input images. O\nur method first learns multiple attention region features of each input image through the one-squeez\ne multi-excitation (OSME) module, and then apply the multi-attention multi-class constraint (MAMC) i\nn a metric learning framework. For each anchor feature, the MAMC functions by pulling same-attention\n same-class features closer, while pushing different-attention or different-class features away. Our\n method can be easily trained end-to-end, and is highly efficient which requires only one training s\ntage. Moreover, we introduce Dogs-in-the-Wild, a comprehensive dog species dataset that surpasses si\nmilar existing datasets by category coverage, data volume and annotation quality. Extensive experime\nnts are conducted to show the substantial improvements of our method on four benchmark datasets.", "cite_num": 7, "conf": "eccv", "time": "2018"}, "775": {"title": "deeptam: deep tracking and mapping.", "url": "https://doi.org/10.1007/978-3-030-01270-0_50", "abstract": "", "cite_num": -1, "conf": "eccv", "time": "2018"}}