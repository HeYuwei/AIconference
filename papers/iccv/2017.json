{"191": {"title": "fashion forward: forecasting visual style in fashion", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Al-Halah_Fashion_Forward_Forecasting_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "235": {"title": "centered weight normalization in accelerating training of deep neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Huang_Centered_Weight_Normalization_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "475": {"title": "adaptive rnn tree for large-scale human action recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Adaptive_RNN_Tree_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "156": {"title": "temporal generative adversarial nets with singular value clipping", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Saito_Temporal_Generative_Adversarial_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "496": {"title": "faster than real-time facial alignment: a 3d spatial transformer network approach in unconstrained poses", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bhagavatula_Faster_Than_Real-Time_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "469": {"title": "deepsetnet: predicting sets with deep neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Rezatofighi_DeepSetNet_Predicting_Sets_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "412": {"title": "stereo dso: large-scale direct sparse visual odometry with stereo cameras", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Stereo_DSO_Large-Scale_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "606": {"title": "unrestricted facial geometry reconstruction using image-to-image translation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sela_Unrestricted_Facial_Geometry_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "284": {"title": "shape inpainting using 3d generative adversarial network and recurrent convolutional networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Shape_Inpainting_Using_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "410": {"title": "photographic image synthesis with cascaded refinement networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Photographic_Image_Synthesis_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "145": {"title": "transitive invariance for self-supervised visual representation learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Transitive_Invariance_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "197": {"title": "fast multi-image matching via density-based clustering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tron_Fast_Multi-Image_Matching_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "453": {"title": "joint learning of object and action detectors", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kalogeiton_Joint_Learning_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "526": {"title": "svdnet for pedestrian retrieval", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sun_SVDNet_for_Pedestrian_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "245": {"title": "reflectance capture using univariate sampling of brdfs", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hui_Reflectance_Capture_Using_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "419": {"title": "online video deblurring via dynamic temporal blending network", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kim_Online_Video_Deblurring_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "538": {"title": "parameter-free lens distortion calibration of central cameras", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bergamasco_Parameter-Free_Lens_Distortion_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "256": {"title": "unsupervised creation of parameterized avatars", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wolf_Unsupervised_Creation_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "110": {"title": "learning to fuse 2d and 3d image cues for monocular body pose estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tekin_Learning_to_Fuse_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "218": {"title": "zero-order reverse filtering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tao_Zero-Order_Reverse_Filtering_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "568": {"title": "bringing background into the foreground: making all classes equal in weakly-supervised video semantic segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Saleh_Bringing_Background_Into_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "35": {"title": "beyond face rotation: global and local perception gan for photorealistic and identity preserving frontal view synthesis", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Huang_Beyond_Face_Rotation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "616": {"title": "quasiconvex plane sweep for triangulation with outliers", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Quasiconvex_Plane_Sweep_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "59": {"title": "performance guaranteed network acceleration via high-order residual quantization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Performance_Guaranteed_Network_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "241": {"title": "deepcoder: semi-parametric variational autoencoders for automatic facial action coding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tran_DeepCoder_Semi-Parametric_Variational_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "116": {"title": "a novel space-time representation on the positive semidefinite cone for facial expression recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kacem_A_Novel_Space-Time_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "619": {"title": "anticipating daily intention using on-wrist motion triggered sensing", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wu_Anticipating_Daily_Intention_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "136": {"title": "a spatiotemporal oriented energy network for dynamic texture recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hadji_A_Spatiotemporal_Oriented_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "441": {"title": "referring expression generation and comprehension via attributes", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Referring_Expression_Generation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "204": {"title": "probflow: joint optical flow and uncertainty estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wannenwetsch_ProbFlow_Joint_Optical_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "350": {"title": "submodular trajectory optimization for aerial 3d scanning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Roberts_Submodular_Trajectory_Optimization_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "135": {"title": "towards a unified compositional model for visual pattern modeling", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tang_Towards_a_Unified_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "479": {"title": "multi-label image recognition by recurrently discovering attentional regions", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Multi-Label_Image_Recognition_ICCV_2017_paper.html", "abstract": "This paper proposes a novel deep architecture to address multi-label image recognition, a fundamenta\nl and practical task towards general visual understanding. Current solutions for this task usually r\nely on an extra step of extracting hypothesis regions (i.e., region proposals), resulting in redunda\nnt computation and sub-optimal performance. In this work, we achieve the interpretable and contextua\nlized multi-label image classification by developing a recurrent memorized-attention module. This mo\ndule consists of two alternately performed components: i) a spatial transformer layer to locate atte\nntional regions from the convolutional feature maps in a region-proposal-free way and ii) an LSTM (L\nong-Short Term Memory) sub-network to sequentially predict semantic labeling scores on the located r\negions while capturing the global dependencies of these regions. The LSTM also output the parameters\n for computing the spatial transformer. On large-scale benchmarks of multi-label image classificatio\nn (e.g., MS-COCO and PASCAL VOC 07), our approach demonstrates superior performances over other exis\nting state-of-the-arts in both accuracy and efficiency.", "cite_num": 46}, "474": {"title": "learning multi-attention convolutional neural network for fine-grained image recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zheng_Learning_Multi-Attention_Convolutional_ICCV_2017_paper.html", "abstract": "Recognizing fine-grained categories (e.g., bird species) highly relies on discriminative part locali\nzation and part-based fine-grained feature learning. Existing approaches predominantly solve these c\nhallenges independently, while neglecting the fact that part localization (e.g., head of a bird) and\n fine-grained feature learning (e.g., head shape) are mutually correlated. In this paper, we propose\n a novel part learning approach by a multi-attention convolutional neural network (MA-CNN), where pa\nrt generation and feature learning can reinforce each other. MA-CNN consists of convolution, channel\n grouping and part classification sub-networks. The channel grouping network takes as input feature \nchannels from convolutional layers, and generates multiple parts by clustering, weighting and poolin\ng from spatially-correlated channels. The part classification network further classifies an image by\n each individual part, through which more discriminative fine-grained features can be learned. Two l\nosses are proposed to guide the multi-task learning of channel grouping and part classification, whi\nch encourages MA-CNN to generate more discriminative parts from feature channels and learn better fi\nne-grained features from parts in a mutual reinforced way. MA-CNN does not need bounding box/part an\nnotation and can be trained end-to-end. We incorporate the learned parts from MA-CNN with part-CNN f\nor recognition, and show the best performances on three challenging published fine-grained datasets,\n e.g., CUB-Birds, FGVC-Aircraft and Stanford-Cars.", "cite_num": 108}, "385": {"title": "look, listen and learn", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Arandjelovic_Look_Listen_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "361": {"title": "deep facial action unit recognition from partially labeled data", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wu_Deep_Facial_Action_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "494": {"title": "bam! the behance artistic media dataset for recognition beyond photography", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wilber_BAM_The_Behance_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "147": {"title": "monocular dense 3d reconstruction of a complex dynamic scene from two perspective frames", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kumar_Monocular_Dense_3D_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "189": {"title": "s3fd: single shot scale-invariant face detector", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_S3FD_Single_Shot_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "231": {"title": "going unconstrained with rolling shutter deblurring", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/R._Going_Unconstrained_With_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "346": {"title": "mofa: model-based deep convolutional face autoencoder for unsupervised monocular reconstruction", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tewari_MoFA_Model-Based_Deep_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "249": {"title": "learning to disambiguate by asking discriminative questions", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Learning_to_Disambiguate_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "413": {"title": "blind image deblurring with outlier handling", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dong_Blind_Image_Deblurring_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "169": {"title": "learning action recognition model from depth and skeleton videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Rahmani_Learning_Action_Recognition_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "583": {"title": "bounding boxes, segmentations and object coordinates: how important is recognition for 3d scene flow estimation in autonomous driving scenarios?", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Behl_Bounding_Boxes_Segmentations_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "313": {"title": "convergence analysis of map based blur kernel estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Cho_Convergence_Analysis_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "193": {"title": "spatiotemporal modeling for crowd counting in videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xiong_Spatiotemporal_Modeling_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "166": {"title": "generalized orderless pooling performs implicit salient matching", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Simon_Generalized_Orderless_Pooling_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "113": {"title": "amtnet: action-micro-tube regression by end-to-end trainable deep architecture", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Saha_AMTnet_Action-Micro-Tube_Regression_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "258": {"title": "a coarse-fine network for keypoint localization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Huang_A_Coarse-Fine_Network_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "4": {"title": "deep growing learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Deep_Growing_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "263": {"title": "show, adapt and tell: adversarial training of cross-domain image captioner", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Show_Adapt_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "244": {"title": "curriculum dropout", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Morerio_Curriculum_Dropout_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "36": {"title": "depth estimation using structured light flow -- analysis of projected pattern flow on an object's surface", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Furukawa_Depth_Estimation_Using_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "283": {"title": "crest: convolutional residual learning for visual tracking", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Song_CREST_Convolutional_Residual_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "576": {"title": "rolling shutter correction in manhattan world", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Purkait_Rolling_Shutter_Correction_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "288": {"title": "a self-balanced min-cut algorithm for image clustering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_A_Self-Balanced_Min-Cut_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "201": {"title": "towards a visual privacy advisor: understanding and predicting privacy risks in images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Orekondy_Towards_a_Visual_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "102": {"title": "multi-view dynamic shape refinement using local temporal integration", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Leroy_Multi-View_Dynamic_Shape_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "339": {"title": "deep free-form deformation network for object-mask registration", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Deep_Free-Form_Deformation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "124": {"title": "recognition of action units in the wild with deep nets and a new global-local loss", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Benitez-Quiroz_Recognition_of_Action_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "527": {"title": "dsod: learning deeply supervised object detectors from scratch", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shen_DSOD_Learning_Deeply_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "569": {"title": "revisiting im2gps in the deep learning era", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Vo_Revisiting_IM2GPS_in_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "456": {"title": "factorized bilinear models for image recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Factorized_Bilinear_Models_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "454": {"title": "recurrent 3d-2d dual learning for large-pose facial landmark detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xiao_Recurrent_3D-2D_Dual_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "586": {"title": "probabilistic structure from motion with objects (psfmo)", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gay_Probabilistic_Structure_From_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "103": {"title": "class rectification hard mining for imbalanced deep learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dong_Class_Rectification_Hard_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "537": {"title": "ensemble diffusion for retrieval", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bai_Ensemble_Diffusion_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "585": {"title": "amat: medial axis transform for natural images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tsogkas_AMAT_Medial_Axis_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "386": {"title": "compressive quantization for fast object instance search in videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yu_Compressive_Quantization_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "476": {"title": "video scene parsing with predictive feature learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Jin_Video_Scene_Parsing_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "357": {"title": "action tubelet detector for spatio-temporal action localization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kalogeiton_Action_Tubelet_Detector_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "93": {"title": "tube convolutional neural network (t-cnn) for action detection in videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hou_Tube_Convolutional_Neural_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "56": {"title": "structure-measure: a new way to evaluate foreground maps", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Fan_Structure-Measure_A_New_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "369": {"title": "rmpe: regional multi-person pose estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Fang_RMPE_Regional_Multi-Person_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "356": {"title": "drone-based object counting by spatially regularized regional proposal network", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hsieh_Drone-Based_Object_Counting_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "109": {"title": "self-organized text detection with minimal post-processing via border learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wu_Self-Organized_Text_Detection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "71": {"title": "mutan: multimodal tucker fusion for visual question answering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ben-younes_MUTAN_Multimodal_Tucker_ICCV_2017_paper.html", "abstract": "Bilinear models provide an appealing framework for mixing and merging information in Visual Question\n Answering (VQA) tasks. They help to learn high level associations between question meaning and visu\nal concepts in the image, but they suffer from huge dimensionality issues. We introduce MUTAN, a mul\ntimodal tensor-based Tucker decomposition to efficiently parametrize bilinear interactions between v\nisual and textual representations. Additionally to the Tucker framework, we design a low-rank matrix\n-based decomposition to explicitly constrain the interaction rank. With MUTAN, we control the comple\nxity of the merging scheme while keeping nice interpretable fusion relations. We show how our MUTAN \nmodel generalizes some of the latest VQA architectures, providing state-of-the-art results.", "cite_num": 69}, "378": {"title": "representation learning by learning to count", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Noroozi_Representation_Learning_by_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "584": {"title": "learning from noisy labels with distillation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Learning_From_Noisy_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "531": {"title": "interpretable transformations with encoder-decoder networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Worrall_Interpretable_Transformations_With_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "181": {"title": "a multilayer-based framework for online background subtraction with freely moving cameras", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_A_Multilayer-Based_Framework_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "409": {"title": "trespassing the boundaries: labeling temporal bounds for object interactions in egocentric video", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Moltisanti_Trespassing_the_Boundaries_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "160": {"title": "deeply-learned part-aligned representations for person re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhao_Deeply-Learned_Part-Aligned_Representations_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "524": {"title": "3d surface detail enhancement from a single normal map", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xie_3D_Surface_Detail_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "127": {"title": "adaptive feeding: achieving fast and accurate detections by adaptively combining object detectors", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhou_Adaptive_Feeding_Achieving_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "225": {"title": "deepfuse: a deep unsupervised approach for exposure fusion with extreme exposure image pairs", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Prabhakar_DeepFuse_A_Deep_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "480": {"title": "multi-stage multi-recursive-input fully convolutional networks for neuronal boundary detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shen_Multi-Stage_Multi-Recursive-Input_Fully_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "406": {"title": "dynamics enhanced multi-camera motion segmentation from unsynchronized videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Dynamics_Enhanced_Multi-Camera_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "596": {"title": "towards large-pose face frontalization in the wild", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yin_Towards_Large-Pose_Face_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "379": {"title": "optimal transformation estimation with semantic cues", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Paudel_Optimal_Transformation_Estimation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "219": {"title": "3d graph neural networks for rgbd semantic segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Qi_3D_Graph_Neural_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "270": {"title": "supervision by fusion: towards unsupervised learning of deep salient object detector", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Supervision_by_Fusion_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "618": {"title": "stepwise metric promotion for unsupervised video person re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Stepwise_Metric_Promotion_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "351": {"title": "attribute-enhanced face recognition with neural tensor fusion networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hu_Attribute-Enhanced_Face_Recognition_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "121": {"title": "open vocabulary scene parsing", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhao_Open_Vocabulary_Scene_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "310": {"title": "visual forecasting by imitating dynamics in natural sequences", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zeng_Visual_Forecasting_by_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "590": {"title": "self-supervised learning of pose embeddings from spatiotemporal relations in videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sumer_Self-Supervised_Learning_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "230": {"title": "from rgb to spectrum for natural scenes via manifold-based mapping", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Jia_From_RGB_to_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "269": {"title": "makeup-go: blind reversion of portrait edit", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Makeup-Go_Blind_Reversion_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "262": {"title": "r-c3d: region convolutional 3d network for temporal activity detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xu_R-C3D_Region_Convolutional_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "542": {"title": "one network to solve them all -- solving linear inverse problems using deep projection models", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chang_One_Network_to_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "150": {"title": "corner-based geometric calibration of multi-focus plenoptic cameras", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Nousias_Corner-Based_Geometric_Calibration_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "158": {"title": "efficient algorithms for moral lineage tracing", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Rempfler_Efficient_Algorithms_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "336": {"title": "towards more accurate iris recognition using deeply learned spatially corresponding features", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhao_Towards_More_Accurate_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "79": {"title": "video reflection removal through spatio-temporal optimization ", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Nandoriya_Video_Reflection_Removal_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "566": {"title": "cad priors for accurate and flexible instance reconstruction", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Birdal_CAD_Priors_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "381": {"title": "sampling matters in deep embedding learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wu_Sampling_Matters_in_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "316": {"title": "surface normals in the wild", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Surface_Normals_in_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "575": {"title": "higher-order integration of hierarchical convolutional activations for fine-grained visual categorization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Cai_Higher-Order_Integration_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "512": {"title": "dense non-rigid structure-from-motion and shading with unknown albedos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gallardo_Dense_Non-Rigid_Structure-From-Motion_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "78": {"title": "predictor combination at test time", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kim_Predictor_Combination_at_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "291": {"title": "encoder based lifelong learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Rannen_Encoder_Based_Lifelong_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "508": {"title": "what actions are needed for understanding human actions in videos?", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sigurdsson_What_Actions_Are_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "420": {"title": "learning dynamic siamese network for visual object tracking", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Guo_Learning_Dynamic_Siamese_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "404": {"title": "chained multi-stream networks exploiting pose, motion, and appearance for action classification and detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zolfaghari_Chained_Multi-Stream_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "267": {"title": "spatio-temporal person retrieval via natural language queries", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yamaguchi_Spatio-Temporal_Person_Retrieval_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "9": {"title": "deformable convolutional networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dai_Deformable_Convolutional_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "530": {"title": "deep determinantal point process for large-scale multi-label classification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xie_Deep_Determinantal_Point_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "85": {"title": "multi-channel weighted nuclear norm minimization for real color image denoising", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xu_Multi-Channel_Weighted_Nuclear_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "397": {"title": "efficient online local metric adaptation via negative samples for person re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhou_Efficient_Online_Local_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "520": {"title": "learning view-invariant features for person identification in temporally synchronized videos taken by wearable cameras", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zheng_Learning_View-Invariant_Features_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "450": {"title": "towards end-to-end text spotting with convolutional recurrent neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Towards_End-To-End_Text_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "88": {"title": "learning blind motion deblurring", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wieschollek_Learning_Blind_Motion_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "481": {"title": "unsupervised learning from video to detect foreground objects in single images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Croitoru_Unsupervised_Learning_From_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "31": {"title": "shadow detection with conditional generative adversarial networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Nguyen_Shadow_Detection_With_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "29": {"title": "jointly recognizing object fluents and tasks in egocentric videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Jointly_Recognizing_Object_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "146": {"title": "non-markovian globally consistent multi-object tracking", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Maksai_Non-Markovian_Globally_Consistent_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "94": {"title": "weakly- and self-supervised learning for content-aware deep image retargeting", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Cho_Weakly-_and_Self-Supervised_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "556": {"title": "anchored regression networks applied to age estimation and super resolution", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Agustsson_Anchored_Regression_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "176": {"title": "online multi-object tracking using cnn-based single object tracker with spatial-temporal attention mechanism", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chu_Online_Multi-Object_Tracking_ICCV_2017_paper.html", "abstract": "In this paper, we propose a CNN-based framework for online MOT. This framework utilizes the merits o\nf single object trackers in adapting appearance models and searching for target in the next frame. S\nimply applying single object tracker for MOT will encounter the problem in computational efficiency \nand drifted results caused by occlusion. Our framework achieves computational efficiency by sharing \nfeatures and using ROI-Pooling to obtain individual features for each target. Some online learned ta\nrget-specific CNN layers are used for adapting the appearance model for each target. In the framewor\nk, we introduce spatial-temporal attention mechanism (STAM) to handle the drift caused by occlusion \nand interaction among targets. The visibility map of the target is learned and used for inferring th\ne spatial attention map. The spatial attention map is then applied to weight the features. Besides, \nthe occlusion status can be estimated from the visibility map, which controls the online updating pr\nocess via weighted loss on training samples with different occlusion statuses in different frames. I\nt can be considered as temporal attention mechanism. The proposed algorithm achieves 34.3% and 46.0%\n in MOTA on challenging MOT15 and MOT16 benchmark dataset respectively.", "cite_num": -1}, "175": {"title": "wetext: scene text detection under weak supervision", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tian_WeText_Scene_Text_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "326": {"title": "playing for benchmarks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Richter_Playing_for_Benchmarks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "148": {"title": "marioqa: answering questions by watching gameplay videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mun_MarioQA_Answering_Questions_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "104": {"title": "group re-identification via unsupervised transfer of sparse features encoding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lisanti_Group_Re-Identification_via_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "373": {"title": "bodyfusion: real-time capture of human motion and surface geometry using a single depth camera", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yu_BodyFusion_Real-Time_Capture_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "282": {"title": "\"maximizing rigidity\" revisited: a convex programming approach for generic 3d shape reconstruction from multiple perspective views", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ji_Maximizing_Rigidity_Revisited_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "321": {"title": "unified deep supervised domain adaptation and generalization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Motiian_Unified_Deep_Supervised_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "114": {"title": "intrinsic3d: high-quality 3d reconstruction by joint appearance and geometry optimization with spatially-varying lighting", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Maier_Intrinsic3D_High-Quality_3D_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "58": {"title": "unsupervised action discovery and localization in videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Soomro_Unsupervised_Action_Discovery_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "243": {"title": "deep functional maps: structured prediction for dense shape correspondence", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Litany_Deep_Functional_Maps_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "442": {"title": "estimating defocus blur via rank of local patches", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xu_Estimating_Defocus_Blur_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "341": {"title": "end-to-end learning of geometry and context for deep stereo regression", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kendall_End-To-End_Learning_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "239": {"title": "pannet: a deep network architecture for pan-sharpening", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yang_PanNet_A_Deep_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "408": {"title": "video deblurring via semantic segmentation and pixel-wise non-linear kernel", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ren_Video_Deblurring_via_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "403": {"title": " semi supervised semantic segmentation using generative adversarial network", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Souly__Semi_Supervised_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "593": {"title": "interpretable learning for self-driving cars by visualizing causal attention", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kim_Interpretable_Learning_for_ICCV_2017_paper.html", "abstract": "Deep neural perception and control networks are likely to be a key component of self-driving vehicle\ns. These models need to be explainable - they should provide easy-tointerpret rationales for their b\nehavior - so that passengers, insurance companies, law enforcement, developers etc., can understand \nwhat triggered a particular behavior. Here we explore the use of visual explanations. These explanat\nions take the form of real-time highlighted regions of an image that causally influence the network\u2019\ns output (steering control). Our approach is two-stage. In the first stage, we use a visual attentio\nn model to train a convolution network endto- end from images to steering angle. The attention model\n highlights image regions that potentially influence the network\u2019s output. Some of these are true in\nfluences, but some are spurious. We then apply a causal filtering step to determine which input regi\nons actually influence the output. This produces more succinct visual explanations and more accurate\nly exposes the network\u2019s behavior. We demonstrate the effectiveness of our model on three datasets t\notaling 16 hours of driving. We first show that training with attention does not degrade the perform\nance of the end-to-end network. Then we show that the network causally cues on a variety of features\n that are used by humans while driving.", "cite_num": 32}, "347": {"title": "deep globally constrained mrfs for human pose estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Marras_Deep_Globally_Constrained_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "617": {"title": "long short-term memory kalman filters: recurrent neural estimators for pose regularization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Coskun_Long_Short-Term_Memory_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "32": {"title": "temporal superpixels based on proximity-weighted patch matching", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lee_Temporal_Superpixels_Based_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "53": {"title": "segflow: joint learning for video object segmentation and optical flow", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Cheng_SegFlow_Joint_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "388": {"title": "2d-driven 3d object detection in rgb-d images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lahoud_2D-Driven_3D_Object_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "279": {"title": "an analysis of visual question answering algorithms", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kafle_An_Analysis_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "234": {"title": "learning bag-of-features pooling for deep convolutional neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Passalis_Learning_Bag-Of-Features_Pooling_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "390": {"title": "following gaze in video", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Recasens_Following_Gaze_in_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "470": {"title": "robust pseudo random fields for light-field stereo matching", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Huang_Robust_Pseudo_Random_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "21": {"title": "learning to estimate 3d hand pose from single rgb images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zimmermann_Learning_to_Estimate_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "76": {"title": "inferring and executing programs for visual reasoning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Johnson_Inferring_and_Executing_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "458": {"title": "deep direct regression for multi-oriented scene text detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/He_Deep_Direct_Regression_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "325": {"title": "nonparametric variational auto-encoders for hierarchical representation learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Goyal_Nonparametric_Variational_Auto-Encoders_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "482": {"title": "multimodal gaussian process latent variable models with harmonization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Song_Multimodal_Gaussian_Process_ICCV_2017_paper.html", "abstract": "In this work, we address multimodal learning problem with Gaussian process latent variable models (G\nPLVMs) and their application to cross-modal retrieval. Existing GPLVM based studies generally impose\n individual priors over the model parameters and ignore the intrinsic relations among these paramete\nrs. Considering the strong complementarity between modalities, we propose a novel joint prior over t\nhe parameters for multimodal GPLVMs to propagate multimodal information in both kernel hyperparamete\nr spaces and latent space. The joint prior is formulated as a harmonization constraint on the model \nparameters, which enforces the agreement among the modality-specific GP kernels and the similarity i\nn the latent space. We incorporate the harmonization mechanism into the learning process of multimod\nal GPLVMs. The proposed methods are evaluated on three widely used multimodal datasets for cross-mod\nal retrieval. Experimental results show that the harmonization mechanism is beneficial to the GPLVM \nalgorithms for learning non-linear correlation among heterogeneous modalities.", "cite_num": 2}, "355": {"title": "recurrent scale approximation for object detection in cnn", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Recurrent_Scale_Approximation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "51": {"title": "globally-optimal inlier set maximisation for simultaneous camera pose and feature correspondence", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Campbell_Globally-Optimal_Inlier_Set_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "264": {"title": "learning to super-resolve blurry face and text images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xu_Learning_to_Super-Resolve_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "42": {"title": "face sketch matching via coupled deep transform learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Nagpal_Face_Sketch_Matching_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "396": {"title": "detailed surface geometry and albedo recovery from rgb-d video under natural illumination", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zuo_Detailed_Surface_Geometry_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "105": {"title": "annarbor: approximate nearest neighbors using arborescence coding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Babenko_AnnArbor_Approximate_Nearest_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "311": {"title": "joint prediction of activity labels and starting times in untrimmed videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mahmud_Joint_Prediction_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "315": {"title": "scenenet rgb-d: can 5m synthetic images beat generic imagenet pre-training on indoor segmentation?", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/McCormac_SceneNet_RGB-D_Can_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "12": {"title": "extreme clicking for efficient object annotation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Papadopoulos_Extreme_Clicking_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "168": {"title": "look, perceive and segment: finding the salient objects in images via two-stream fixation-semantic cnns", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Look_Perceive_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "354": {"title": "efficient global illumination for morphable models", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Schneider_Efficient_Global_Illumination_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "548": {"title": "learning cooperative visual dialog agents with deep reinforcement learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Das_Learning_Cooperative_Visual_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "25": {"title": "convolutional dictionary learning via local processing", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Papyan_Convolutional_Dictionary_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "185": {"title": "complex event detection by identifying reliable shots from untrimmed videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Fan_Complex_Event_Detection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "570": {"title": "distributed very large scale bundle adjustment by global camera consensus", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Distributed_Very_Large_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "452": {"title": "joint adaptive sparsity and low-rankness on the fly: an online tensor reconstruction scheme for video denoising", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wen_Joint_Adaptive_Sparsity_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "613": {"title": "a multimodal deep regression bayesian network for affective video content analyses", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gan_A_Multimodal_Deep_ICCV_2017_paper.html", "abstract": "The inherent dependencies between visual elements and aural elements are crucial for affective video\n content analyses, yet have not been successfully exploited. Therefore, we propose a multimodal deep\n regression Bayesian network (MMDRBN) to capture the dependencies between visual elements and aural \nelements for affective video content analyses. The regression Bayesian network (RBN) is a directed g\nraphical model consisting of one latent layer and one visible layer. Due to the explaining away effe\nct in Bayesian networks (BN), RBN is able to capture both the dependencies among the latent variable\ns given the observation and the dependencies among visible variables. We propose a fast learning alg\norithm to learn the RBN. For the MMDRB-N, first, we learn several RBNs layer-wisely from visual moda\nlity and audio modality respectively. Then we stack these RBNs and obtain two deep networks. After t\nhat, a joint representation is extracted from the top layers of the two deep networks, and thus capt\nures the high order dependencies between visual modality and audio modality. In order to predict the\n valence or arousal score of video contents, we initialize a feed-forward inference network from the\n MMDRBN whose inference is intractable by minimizing the KullbackCLeibler (KL)divergence between the\n two networks. The back propagation algorithm is adopted for finetuning the inference network. Exper\nimental results on the LIRIS-ACCEDE database demonstrate that the proposed MMDRBN successfully captu\nres the dependencies between visual and audio elements, and thus achieves better performance compare\nd with state-of-the-art work.", "cite_num": 3}, "144": {"title": "learning the latent \"look\": unsupervised discovery of a style-coherent embedding from fashion images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hsiao_Learning_the_Latent_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "172": {"title": "learning gaze transitions from depth to improve video saliency estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Leifman_Learning_Gaze_Transitions_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "228": {"title": "neural epi-volume networks for shape from light field", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Heber_Neural_EPI-Volume_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "10": {"title": "safetynet: detecting and rejecting adversarial examples robustly", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lu_SafetyNet_Detecting_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "111": {"title": "vpgnet: vanishing point guided network for lane and road marking detection and recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lee_VPGNet_Vanishing_Point_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "6": {"title": "multi-modal factorized bilinear pooling with co-attention learning for visual question answering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yu_Multi-Modal_Factorized_Bilinear_ICCV_2017_paper.html", "abstract": "Visual question answering (VQA) is challenging because it requires a simultaneous understanding of b\noth the visual content of images and the textual content of questions. The approaches used to repres\nent the images and questions in a fine-grained manner and questions and to fuse these multi-modal fe\natures play key roles in performance. Bilinear pooling based models have been shown to outperform tr\naditional linear models for VQA, but their high-dimensional representations and high computational c\nomplexity may seriously limit their applicability in practice. For multi-modal feature fusion, here \nwe develop a Multi-modal Factorized Bilinear (MFB) pooling approach to efficiently and effectively c\nombine multi-modal features, which results in superior performance for VQA compared with other bilin\near pooling approaches. For fine-grained image and question representation, we develop a co-attentio\nn mechanism using an end-to-end deep network architecture to jointly learn both the image and questi\non attentions. Combining the proposed MFB approach with co-attention learning in a new network archi\ntecture provides a unified model for VQA. Our experimental results demonstrate that the single MFB w\nith co-attention model achieves new state-of-the-art performance on the real-world VQA dataset. Code\n available at this https URL.", "cite_num": 61}, "17": {"title": "recurrent color constancy", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Qian_Recurrent_Color_Constancy_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "61": {"title": "flip-invariant motion representation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kobayashi_Flip-Invariant_Motion_Representation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "187": {"title": "curriculum domain adaptation for semantic segmentation of urban scenes", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Curriculum_Domain_Adaptation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "22": {"title": "octree generating networks: efficient convolutional architectures for high-resolution 3d outputs", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tatarchenko_Octree_Generating_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "196": {"title": "video fill in the blank using lr/rl lstms with spatial-temporal attentions", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mazaheri_Video_Fill_in_ICCV_2017_paper.html", "abstract": "Given a video and a description sentence with one missing word (we call it the \"source sentence\"), V\nideo-Fill-In-the-Blank (VFIB) problem is to find the missing word automatically. The contextual info\nrmation of the sentence, as well as visual cues from the video, are important to infer the missing w\nord accurately. Since the source sentence is broken into two fragments: the sentence's left fragment\n (before the blank) and the sentence's right fragment (after the blank), traditional Recurrent Neura\nl Networks cannot encode this structure accurately because of many possible variations of the missin\ng word in terms of the location and type of the word in the source sentence. For example, a missing \nword can be the first word or be in the middle of the sentence and it can be a verb or an adjective.\n In this paper, we propose a framework to tackle the textual encoding: Two separate LSTMs (the LR an\nd RL LSTMs) are employed to encode the left and right sentence fragments and a novel structure is in\ntroduced to combine each fragment with an \"external memory\" corresponding the opposite fragments. Fo\nr the visual encoding, end-to-end spatial and temporal attention models are employed to select discr\niminative visual representations to find the missing word. In the experiments, we demonstrate the su\nperior performance of the proposed method on challenging VFIB problem. Furthermore, we introduce an \nextended and more generalized version of VFIB, which is not limited to a single blank. Our experimen\nts indicate the generalization capability of our method in dealing with such more realistic scenario\ns.", "cite_num": -1}, "393": {"title": "joint discovery of object states and manipulation actions", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Alayrac_Joint_Discovery_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "82": {"title": "progressive large scale-invariant image matching in scale space", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhou_Progressive_Large_Scale-Invariant_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "92": {"title": "dslr-quality photos on mobile devices with deep convolutional networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ignatov_DSLR-Quality_Photos_on_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "473": {"title": "high order tensor formulation for convolutional sparse coding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bibi_High_Order_Tensor_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "179": {"title": "learning to synthesize a 4d rgbd light field from a single image", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Srinivasan_Learning_to_Synthesize_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "309": {"title": "automatic spatially-aware fashion concept discovery", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Han_Automatic_Spatially-Aware_Fashion_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "614": {"title": "unsupervised domain adaptation for face recognition in unlabeled videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sohn_Unsupervised_Domain_Adaptation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "209": {"title": "catadioptric hyperspectral light field imaging", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xue_Catadioptric_HyperSpectral_Light_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "290": {"title": "recurrent multimodal interaction for referring image segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Recurrent_Multimodal_Interaction_ICCV_2017_paper.html", "abstract": "In this paper we are interested in the problem of image segmentation given natural language descript\nions, i.e. referring expressions. Existing works tackle this problem by first modeling images and se\nntences independently and then segment images by combining these two types of representations. We ar\ngue that learning word-to-image interaction is more native in the sense of jointly modeling two moda\nlities for the image segmentation task, and we propose convolutional multimodal LSTM to encode the s\nequential interactions between individual words, visual information, and spatial information. We sho\nw that our proposed model outperforms the baseline model on benchmark datasets. In addition, we anal\nyze the intermediate output of the proposed multimodal LSTM approach and empirically explain how thi\ns approach enforces a more effective word-to-image interaction.", "cite_num": 10}, "543": {"title": "single image action recognition using semantic body part actions", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhao_Single_Image_Action_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "167": {"title": "scene categorization with spectral features", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Khan_Scene_Categorization_With_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "319": {"title": "attribute recognition by joint recurrent learning of context and correlation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Attribute_Recognition_by_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "605": {"title": "vegfru: a domain-specific dataset for fine-grained visual categorization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hou_VegFru_A_Domain-Specific_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "44": {"title": "semantic jitter: dense supervision for visual comparisons via synthetic images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yu_Semantic_Jitter_Dense_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "173": {"title": "modeling urban scenes from pointclouds", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Nguatem_Modeling_Urban_Scenes_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "15": {"title": "space-time localization and mapping", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lee_Space-Time_Localization_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "170": {"title": "blob reconstruction using unilateral second order gaussian kernels with application to high-iso long-exposure image denoising", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Blob_Reconstruction_Using_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "492": {"title": "cross-modal deep variational hashing", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liong_Cross-Modal_Deep_Variational_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "398": {"title": "privacy-preserving visual learning using doubly permuted homomorphic encryption", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yonetani_Privacy-Preserving_Visual_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "18": {"title": "sublabel-accurate discretization of nonconvex free-discontinuity problems", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mollenhoff_Sublabel-Accurate_Discretization_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "134": {"title": "wordsup: exploiting word annotations for character based text detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hu_WordSup_Exploiting_Word_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "539": {"title": "learning policies for adaptive tracking with deep feature cascades", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Huang_Learning_Policies_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "382": {"title": "areas of attention for image captioning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Pedersoli_Areas_of_Attention_ICCV_2017_paper.html", "abstract": "We propose \"Areas of Attention\", a novel attention-based model for automatic image captioning. Our a\npproach models the dependencies between image regions, caption words, and the state of an RNN langua\nge model, using three pairwise interactions. In contrast to previous attention-based approaches that\n associate image regions only to the RNN state, our method allows a direct association between capti\non words and image regions. During training these associations are inferred from image-level caption\ns, akin to weakly-supervised object detector training. These associations help to improve captioning\n by localizing the corresponding regions during testing. We also propose and compare different ways \nof generating attention areas: CNN activation grids, object proposals, and spatial transformers nets\n applied in a convolutional fashion. Spatial transformers give the best results. They allow for imag\ne specific attention areas, and can be trained jointly with the rest of the network. Our attention m\nechanism and spatial transformer attention areas together yield state-of-the-art results on the MSCO\nCO dataset.o meaningful latent semantic structure in the generated captions.", "cite_num": 39}, "579": {"title": "deep binaries: encoding semantic-rich cues for efficient textual-visual cross retrieval", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shen_Deep_Binaries_Encoding_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "118": {"title": "learning background-aware correlation filters for visual tracking", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Galoogahi_Learning_Background-Aware_Correlation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "178": {"title": "summarization and classification of wearable camera streams by learning the distributions over deep features of out-of-sample image sequences", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Perina_Summarization_and_Classification_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "194": {"title": "scalenet: guiding object proposal generation in supermarkets and beyond", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Qiao_ScaleNet_Guiding_Object_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "348": {"title": "mirrorflow: exploiting symmetries in joint optical flow and occlusion estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hur_MirrorFlow_Exploiting_Symmetries_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "592": {"title": "semantic video cnns through representation warping", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gadde_Semantic_Video_CNNs_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "30": {"title": "non-uniform blind deblurring by reblurring", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bahat_Non-Uniform_Blind_Deblurring_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "54": {"title": "low-rank tensor completion: a pseudo-bayesian learning approach", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Low-Rank_Tensor_Completion_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "424": {"title": "lattice long short-term memory for human action recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sun_Lattice_Long_Short-Term_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "461": {"title": "dense and low-rank gaussian crfs using deep embeddings", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chandra_Dense_and_Low-Rank_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "577": {"title": "learning high dynamic range from outdoor panoramas", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Learning_High_Dynamic_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "320": {"title": "detail-revealing deep video super-resolution", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tao_Detail-Revealing_Deep_Video_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "203": {"title": "image-based localization using lstms for structured feature correlation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Walch_Image-Based_Localization_Using_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "27": {"title": "deep cropping via attention box prediction and aesthetics assessment", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Deep_Cropping_via_ICCV_2017_paper.html", "abstract": "We model the photo cropping problem as a cascade of attention box regression and aesthetic quality c\nlassification, based on deep learning. A neural network is designed that has two branches for predic\nting attention bounding box and analyzing aesthetics, respectively. The predicted attention box is t\nreated as an initial crop window where a set of cropping candidates are generated around it, without\n missing important information. Then, aesthetics assessment is employed to select the final crop as \nthe one with the best aesthetic quality. With our network, cropping candidates share features within\n full-image convolutional feature maps, thus avoiding repeated feature computation and leading to hi\ngher computation efficiency. Via leveraging rich data for attention prediction and aesthetics assess\nment, the proposed method produces high-quality cropping results, even with the limited availability\n of training data for photo cropping. The experimental results demonstrate the competitive results a\nnd fast processing speed (5 fps with all steps).", "cite_num": 18}, "328": {"title": "truncating wide networks using binary tree architectures", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Truncating_Wide_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "151": {"title": "neural person search machines", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Neural_Person_Search_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "457": {"title": "active learning for human pose estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Active_Learning_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "423": {"title": "introspective neural networks for generative modeling", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lazarow_Introspective_Neural_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "389": {"title": "benchmarking single-image reflection removal algorithms", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wan_Benchmarking_Single-Image_Reflection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "460": {"title": "turn tap: temporal unit regression network for temporal action proposals", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gao_TURN_TAP_Temporal_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "223": {"title": "learning 3d object categories by looking around them", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Novotny_Learning_3D_Object_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "582": {"title": "learning efficient convolutional networks through network slimming", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Learning_Efficient_Convolutional_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "252": {"title": "illuminating pedestrians via simultaneous detection & segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Brazil_Illuminating_Pedestrians_via_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "493": {"title": "dual-glance model for deciphering social relationships ", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Dual-Glance_Model_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "588": {"title": "learning visual attention to identify people with autism spectrum disorder", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Jiang_Learning_Visual_Attention_ICCV_2017_paper.html", "abstract": "This paper presents a novel method for quantitative and objective diagnoses of Autism Spectrum Disor\nder (ASD) using eye tracking and deep neural networks. ASD is prevalent, with 1.5% of people in the \nUS. The lack of clinical resources for early diagnoses has been a long-lasting issue. This work diff\nerentiates itself with three unique features: first, the proposed approach is data-driven and free o\nf assumptions, important for new discoveries in understanding ASD as well as other neurodevelopmenta\nl disorders. Second, we concentrate our analyses on the differences in eye movement patterns between\n healthy people and those with ASD. An image selection method based on Fisher scores allows feature \nlearning with the most discriminative contents, leading to efficient and accurate diagnoses. Third, \nwe leverage the recent advances in deep neural networks for both prediction and visualization. Exper\nimental results show the superior performance of our method in terms of multiple evaluation metrics \nused in diagnostic tests.", "cite_num": 8}, "216": {"title": "a two stream siamese convolutional neural network for person re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chung_A_Two_Stream_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "16": {"title": "need for speed: a benchmark for higher frame rate object tracking", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Galoogahi_Need_for_Speed_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "115": {"title": "tall: temporal activity localization via language query", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gao_TALL_Temporal_Activity_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "564": {"title": "improved image captioning via policy gradient optimization of spider", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Improved_Image_Captioning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "415": {"title": "multi-view non-rigid refinement and normal selection for high quality 3d reconstruction", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Haque_Multi-View_Non-Rigid_Refinement_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "139": {"title": "local-to-global point cloud registration using a dictionary of viewpoint descriptors", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Avidar_Local-To-Global_Point_Cloud_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "340": {"title": "recurrent topic-transition gan for visual paragraph generation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liang_Recurrent_Topic-Transition_GAN_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "443": {"title": "approximate grassmannian intersections: subspace-valued subspace learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Murdock_Approximate_Grassmannian_Intersections_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "301": {"title": "roomnet: end-to-end room layout estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lee_RoomNet_End-To-End_Room_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "597": {"title": "directionally convolutional networks for 3d shape segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xu_Directionally_Convolutional_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "445": {"title": "colored point cloud registration revisited", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Park_Colored_Point_Cloud_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "554": {"title": "making minimal solvers for absolute pose estimation compact and robust", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Larsson_Making_Minimal_Solvers_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "490": {"title": "learning robust visual-semantic embeddings", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tsai_Learning_Robust_Visual-Semantic_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "43": {"title": "reconfiguring the imaging pipeline for computer vision", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Buckler_Reconfiguring_the_Imaging_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "472": {"title": "visual transformation aided contrastive learning for video-based kinship verification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dibeklioglu_Visual_Transformation_Aided_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "69": {"title": "pose guided rgbd feature learning for 3d object pose estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Balntas_Pose_Guided_RGBD_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "298": {"title": "robust video super-resolution with learned temporal dynamics", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Robust_Video_Super-Resolution_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "428": {"title": "robust object tracking based on temporal and spatial deep networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Teng_Robust_Object_Tracking_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "46": {"title": "arbitrary style transfer in real-time with adaptive instance normalization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Huang_Arbitrary_Style_Transfer_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "75": {"title": "unpaired image-to-image translation using cycle-consistent adversarial networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "399": {"title": "semantic line detection and its applications", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lee_Semantic_Line_Detection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "427": {"title": "coherent online video style transfer", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Coherent_Online_Video_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "0": {"title": "low compute and fully parallel computer vision with hashmatch", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Fanello_Low_Compute_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "240": {"title": "ppr-fcn: weakly supervised visual relation detection via parallel pairwise r-fcn", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_PPR-FCN_Weakly_Supervised_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "421": {"title": "embedding 3d geometric features for rigid object part segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Song_Embedding_3D_Geometric_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "143": {"title": "visual odometry for pixel processor arrays", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bose_Visual_Odometry_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "447": {"title": "situation recognition with graph neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Situation_Recognition_With_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "437": {"title": "view adaptive recurrent neural networks for high performance human action recognition from skeleton data", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_View_Adaptive_Recurrent_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "26": {"title": "adversarial inverse graphics networks: learning 2d-to-3d lifting and image-to-image translation from unpaired supervision", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tung_Adversarial_Inverse_Graphics_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "574": {"title": "an optimal transportation based univariate neuroimaging index", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mi_An_Optimal_Transportation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "62": {"title": "gplac: generalizing vision-based robotic skills using weakly labeled images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Singh_GPLAC_Generalizing_Vision-Based_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "329": {"title": "scene graph generation from objects, phrases and region captions", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Scene_Graph_Generation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "446": {"title": "visual semantic planning using deep successor representations", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Visual_Semantic_Planning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "276": {"title": "query-guided regression network with context policy for phrase grounding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Query-Guided_Regression_Network_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "314": {"title": "tracking the untrackable: learning to track multiple cues with long-term dependencies", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sadeghian_Tracking_the_Untrackable_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "213": {"title": "decoder network over lightweight reconstructed feature for fast semantic style transfer", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lu_Decoder_Network_Over_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "435": {"title": "wavelet-srnet: a wavelet-based cnn for multi-scale face super resolution", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Huang_Wavelet-SRNet_A_Wavelet-Based_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "265": {"title": "sparse exact pga on riemannian manifolds", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Banerjee_Sparse_Exact_PGA_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "363": {"title": "joint convolutional analysis and synthesis sparse representation for single image layer separation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gu_Joint_Convolutional_Analysis_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "33": {"title": "blur-invariant deep learning for blind-deblurring", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Nimisha_Blur-Invariant_Deep_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "483": {"title": "click here: human-localized keypoints as guidance for viewpoint estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Szeto_Click_Here_Human-Localized_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "324": {"title": "temporal tessellation: a unified approach for video analysis", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kaufman_Temporal_Tessellation_A_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "558": {"title": "orientation invariant feature embedding and spatial temporal regularization for vehicle re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Orientation_Invariant_Feature_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "247": {"title": "deep occlusion reasoning for multi-camera multi-target detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Baque_Deep_Occlusion_Reasoning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "180": {"title": "towards 3d human pose estimation in the wild: a weakly-supervised approach", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhou_Towards_3D_Human_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "183": {"title": "raster-to-vector: revisiting floorplan transformation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Raster-To-Vector_Revisiting_Floorplan_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "278": {"title": "primary video object segmentation via complementary cnns and neighborhood reversible flow", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Primary_Video_Object_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "372": {"title": "when unsupervised domain adaptation meets tensor representations", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lu_When_Unsupervised_Domain_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "343": {"title": "personalized cinemagraphs using semantic understanding and collaborative learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Oh_Personalized_Cinemagraphs_Using_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "108": {"title": "boosting image captioning with attributes", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yao_Boosting_Image_Captioning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "405": {"title": "temporal dynamic graph lstm for action-driven video object detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yuan_Temporal_Dynamic_Graph_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "211": {"title": "unsupervised representation learning by sorting sequences", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lee_Unsupervised_Representation_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "489": {"title": "two-phase learning for weakly supervised object localization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kim_Two-Phase_Learning_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "418": {"title": "learning discriminative ab-divergences for positive definite matrices", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Cherian_Learning_Discriminative_ab-Divergences_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "117": {"title": "learned multi-patch similarity", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hartmann_Learned_Multi-Patch_Similarity_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "212": {"title": "camera calibration by global constraints on the motion of silhouettes", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ben-Artzi_Camera_Calibration_by_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "275": {"title": "training deep networks to be spatially sensitive", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kolkin_Training_Deep_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "200": {"title": "high-quality correspondence and segmentation estimation for dual-lens smart-phone portraits", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shen_High-Quality_Correspondence_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "37": {"title": "generating high-quality crowd density maps using contextual pyramid cnns", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sindagi_Generating_High-Quality_Crowd_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "184": {"title": "fast image processing with fully-convolutional networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Fast_Image_Processing_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "384": {"title": "filter selection for hyperspectral estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Arad_Filter_Selection_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "222": {"title": "learning a recurrent residual fusion network for multimodal matching", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Learning_a_Recurrent_ICCV_2017_paper.html", "abstract": "A major challenge in matching between vision and language is that they typically have completely dif\nferent features and representations. In this work, we introduce a novel bridge between the modality-\nspecific representations by creating a co-embedding space based on a recurrent residual fusion (RRF)\n block. Specifically, RRF adapts the recurrent mechanism to residual learning, so that it can recurs\nively improve feature embeddings while retaining the shared parameters. Then, a fusion module is use\nd to integrate the intermediate recurrent outputs and generates a more powerful representation. In t\nhe matching network, RRF acts as a feature enhancement component to gather visual and textual repres\nentations into a more discriminative embedding space where it allows to narrow the crossmodal gap be\ntween vision and language. Moreover, we employ a bi-rank loss function to enforce separability of th\ne two modalities in the embedding space. In the experiments, we evaluate the proposed RRF-Net using \ntwo multi-modal datasets where it achieves state-of-the-art results.", "cite_num": 17}, "349": {"title": "autodial: automatic domain alignment layers", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Carlucci_AutoDIAL_Automatic_DomaIn_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "563": {"title": "rankiqa: learning from rankings for no-reference image quality assessment", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_RankIQA_Learning_From_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "1": {"title": "low-shot visual recognition by shrinking and hallucinating features", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hariharan_Low-Shot_Visual_Recognition_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "519": {"title": "compositional human pose regression", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sun_Compositional_Human_Pose_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "610": {"title": "the \"something something\" video database for learning and evaluating visual common sense", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Goyal_The_Something_Something_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "400": {"title": "understanding and mapping natural beauty", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Workman_Understanding_and_Mapping_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "380": {"title": "joint detection and recounting of abnormal events by learning deep generic knowledge", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hinami_Joint_Detection_and_ICCV_2017_paper.html", "abstract": "This paper addresses the problem of joint detection and recounting of abnormal events in videos. Rec\nounting of abnormal events, i.e., explaining why they are judged to be abnormal, is an unexplored bu\nt critical task in video surveillance, because it helps human observers quickly judge if they are fa\nlse alarms or not. To describe the events in the human-understandable form for event recounting, lea\nrning generic knowledge about visual concepts (e.g., object and action) is crucial. Although convolu\ntional neural networks (CNNs) have achieved promising results in learning such concepts, it remains \nan open question as to how to effectively use CNNs for abnormal event detection, mainly due to the e\nnvironment-dependent nature of the anomaly detection. In this paper, we tackle this problem by integ\nrating a generic CNN model and environment-dependent anomaly detectors. Our approach first learns CN\nN with multiple visual tasks to exploit semantic information that is useful for detecting and recoun\nting abnormal events. By appropriately plugging the model into anomaly detectors, we can detect and \nrecount abnormal events while taking advantage of the discriminative power of CNNs. Our approach out\nperforms the state-of-the-art on Avenue and UCSD Ped2 benchmarks for abnormal event detection and al\nso produces promising results of abnormal event recounting.", "cite_num": 11}, "487": {"title": "a joint intrinsic-extrinsic prior model for retinex", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Cai_A_Joint_Intrinsic-Extrinsic_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "96": {"title": "hierarchical multimodal lstm for dense visual-semantic embedding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Niu_Hierarchical_Multimodal_LSTM_ICCV_2017_paper.html", "abstract": "We address the problem of dense visual-semantic embedding that maps not only full sentences and whol\ne images but also phrases within sentences and salient regions within images into a multimodal embed\nding space. Such dense embeddings, when applied to the task of image captioning, enable us to produc\ne several region-oriented and detailed phrases rather than just an overview sentence to describe an \nimage. Specifically, we present a hierarchical structured recurrent neural network (RNN), namely Hie\nrarchical Multimodal LSTM (HM-LSTM). Compared with chain structured RNN, our proposed model exploits\n the hierarchical relations between sentences and phrases, and between whole images and image region\ns, to jointly establish their representations. Without the need of any supervised labels, our propos\ned model automatically learns the fine-grained correspondences between phrases and image regions tow\nards the dense embedding. Extensive experiments on several datasets validate the efficacy of our met\nhod, which compares favorably with the state-of-the-art methods.", "cite_num": 36}, "260": {"title": "how far are we from solving the 2d & 3d face alignment problem? (and a dataset of 230,000 3d facial landmarks)", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bulat_How_Far_Are_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "133": {"title": "the mapillary vistas dataset for semantic understanding of street scenes", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Neuhold_The_Mapillary_Vistas_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "464": {"title": "offline handwritten signature modeling and verification based on archetypal analysis", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zois_Offline_Handwritten_Signature_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "387": {"title": "video frame interpolation via adaptive separable convolution", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Niklaus_Video_Frame_Interpolation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "161": {"title": "semantically informed multiview surface refinement", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Blaha_Semantically_Informed_Multiview_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "514": {"title": "deep spatial-semantic attention for fine-grained sketch-based image retrieval", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Song_Deep_Spatial-Semantic_Attention_ICCV_2017_paper.html", "abstract": "Human sketches are unique in being able to capture both the spatial topology of a visual object, as \nwell as its subtle appearance details. Fine-grained sketch-based image retrieval (FG-SBIR) important\nly leverages on such fine-grained characteristics of sketches to conduct instance-level retrieval of\n photos. Nevertheless, human sketches are often highly abstract and iconic, resulting in severe misa\nlignments with candidate photos which in turn make subtle visual detail matching difficult. Existing\n FG-SBIR approaches focus only on coarse holistic matching via deep cross-domain representation lear\nning, yet ignore explicitly accounting for fine-grained details and their spatial context. In this p\naper, a novel deep FG-SBIR model is proposed which differs significantly from the existing models in\n that: (1) It is spatially aware, achieved by introducing an attention module that is sensitive to t\nhe spatial position of visual details: (2) It combines coarse and fine semantic information via a sh\nortcut connection fusion block: and (3) It models feature correlation and is robust to misalignments\n between the extracted features across the two domains by introducing a novel higher-order learnable\n energy function (HOLEF) based loss. Extensive experiments show that the proposed deep spatial-seman\ntic attention model significantly outperforms the state-of-the-art.", "cite_num": 36}, "14": {"title": "supplementary meta-learning: towards a dynamic model for deep neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Supplementary_Meta-Learning_Towards_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "49": {"title": "learning feature pyramids for human pose estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yang_Learning_Feature_Pyramids_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "97": {"title": "real-time hand tracking under occlusion from an egocentric rgb-d sensor", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mueller_Real-Time_Hand_Tracking_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "226": {"title": "hard-aware deeply cascaded embedding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yuan_Hard-Aware_Deeply_Cascaded_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "65": {"title": "predicting visual exemplars of unseen classes for zero-shot learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Changpinyo_Predicting_Visual_Exemplars_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "52": {"title": "learning for active 3d mapping", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zimmermann_Learning_for_Active_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "68": {"title": "beyond standard benchmarks: parameterizing performance evaluation in visual object tracking", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zajc_Beyond_Standard_Benchmarks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "553": {"title": "deeper, broader and artier domain generalization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Deeper_Broader_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "370": {"title": "interleaved group convolutions", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Interleaved_Group_Convolutions_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "266": {"title": "learning spatio-temporal representation with pseudo-3d residual networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Qiu_Learning_Spatio-Temporal_Representation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "106": {"title": "gans for biological image synthesis", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Osokin_GANs_for_Biological_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "38": {"title": "on-demand learning for deep image restoration", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gao_On-Demand_Learning_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "608": {"title": "cross-view asymmetric metric learning for unsupervised person re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yu_Cross-View_Asymmetric_Metric_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "130": {"title": "escape from cells: deep kd-networks for the recognition of 3d point cloud models", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Klokov_Escape_From_Cells_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "274": {"title": "learning to reason: end-to-end module networks for visual question answering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hu_Learning_to_Reason_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "536": {"title": "rdfnet: rgb-d multi-level residual feature fusion for indoor semantic segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Park_RDFNet_RGB-D_Multi-Level_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "522": {"title": "sgn: sequential grouping networks for instance segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_SGN_Sequential_Grouping_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "364": {"title": "side information in robust principal component analysis: algorithms and applications", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xue_Side_Information_in_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "317": {"title": "a stagewise refinement model for detecting salient objects in images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_A_Stagewise_Refinement_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "511": {"title": "pathtrack: fast trajectory annotation with path supervision", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Manen_PathTrack_Fast_Trajectory_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "495": {"title": "learning to push the limits of efficient fft-based image deconvolution", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kruse_Learning_to_Push_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "23": {"title": "deep adaptive image clustering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chang_Deep_Adaptive_Image_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "533": {"title": "predicting deeper into the future of semantic segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Luc_Predicting_Deeper_Into_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "242": {"title": "dense-captioning events in videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Krishna_Dense-Captioning_Events_in_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "123": {"title": "structured attentions for visual question answering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Structured_Attentions_for_ICCV_2017_paper.html", "abstract": "Visual attention, which assigns weights to image regions according to their relevance to a question,\n is considered as an indispensable part by most Visual Question Answering models. Although the quest\nions may involve complex relations among multiple regions, few attention models can effectively enco\nde such cross-region relations. In this paper, we demonstrate the importance of encoding such relati\nons by showing the limited effective receptive field of ResNet on two datasets, and propose to model\n the visual attention as a multivariate distribution over a grid-structured Conditional Random Field\n on image regions. We demonstrate how to convert the iterative inference algorithms, Mean Field and \nLoopy Belief Propagation, as recurrent layers of an end-to-end neural network. We empirically evalua\nted our model on 3 datasets, in which it surpasses the best baseline model of the newly released CLE\nVR dataset by 9.5%, and the best published model on the VQA dataset by 1.25%. Source code is availab\nle at https: //github.com/zhuchen03/vqa-sva.", "cite_num": 21}, "327": {"title": "hide-and-seek: forcing a network to be meticulous for weakly-supervised object and action localization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Singh_Hide-And-Seek_Forcing_a_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "205": {"title": "sort: second-order response transform for visual recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_SORT_Second-Order_Response_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "529": {"title": "detecting faces using inside cascaded contextual cnn", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Detecting_Faces_Using_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "138": {"title": "an empirical study of language cnn for image captioning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gu_An_Empirical_Study_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "120": {"title": "adversarial posenet: a structure-aware convolutional network for human pose estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Adversarial_PoseNet_A_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "112": {"title": "learning proximal operators: using denoising networks for regularizing inverse imaging problems", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Meinhardt_Learning_Proximal_Operators_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "296": {"title": "saliency pattern detection by ranking structured trees", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Saliency_Pattern_Detection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "591": {"title": "cut, paste and learn: surprisingly easy synthesis for instance detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dwibedi_Cut_Paste_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "312": {"title": "weakly supervised manifold learning for dense semantic object correspondence", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gaur_Weakly_Supervised_Manifold_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "45": {"title": "weakly supervised object localization using things and stuff transfer", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shi_Weakly_Supervised_Object_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "60": {"title": "deep scene image classification with the mfafvnet", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Deep_Scene_Image_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "233": {"title": "temporal context network for activity localization in videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dai_Temporal_Context_Network_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "488": {"title": "3d-prnn: generating shape primitives with recurrent neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zou_3D-PRNN_Generating_Shape_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "515": {"title": "transferring objects: joint inference of container and human pose", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Transferring_Objects_Joint_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "371": {"title": "cdts: collaborative detection, tracking, and segmentation for online multiple object segmentation in videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Koh_CDTS_Collaborative_Detection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "432": {"title": "see the glass half full: reasoning about liquid containers, their volume and content", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mottaghi_See_the_Glass_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "220": {"title": "tornado: a spatio-temporal convolutional regression network for video action proposal", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_TORNADO_A_Spatio-Temporal_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "407": {"title": "non-rigid object tracking via deformable patches using shape-preserved kcf and level sets", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sun_Non-Rigid_Object_Tracking_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "199": {"title": "ensemble deep learning for skeleton-based action recognition using temporal sliding lstm networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lee_Ensemble_Deep_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "155": {"title": "pose-driven deep convolutional model for person re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Su_Pose-Driven_Deep_Convolutional_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "11": {"title": "deep dual learning for semantic image segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Luo_Deep_Dual_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "532": {"title": "a unified model for near and remote sensing", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Workman_A_Unified_Model_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "91": {"title": "guided perturbations: self-corrective behavior in convolutional neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sankaranarayanan_Guided_Perturbations_Self-Corrective_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "417": {"title": "temporal shape super-resolution by intra-frame motion encoding using high-fps structured light", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shiba_Temporal_Shape_Super-Resolution_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "392": {"title": "learned watershed: end-to-end learning of seeded segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wolf_Learned_Watershed_End-To-End_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "162": {"title": "subic: a supervised, structured binary code for image search", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Jain_SUBIC_A_Supervised_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "581": {"title": "focal track: depth and accommodation with oscillating lens deformation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Guo_Focal_Track_Depth_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "358": {"title": "universal adversarial perturbations against semantic image segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Metzen_Universal_Adversarial_Perturbations_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "99": {"title": "encouraging lstms to anticipate actions very early", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Aliakbarian_Encouraging_LSTMs_to_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "438": {"title": "ssd-6d: making rgb-based 3d detection and 6d pose estimation great again", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kehl_SSD-6D_Making_RGB-Based_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "192": {"title": "point set registration with global-local correspondence and transformation estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Point_Set_Registration_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "426": {"title": "dualgan: unsupervised dual learning for image-to-image translation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yi_DualGAN_Unsupervised_Dual_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "57": {"title": "adversarial examples for semantic segmentation and object detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xie_Adversarial_Examples_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "451": {"title": "human pose estimation using global and local normalization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sun_Human_Pose_Estimation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "440": {"title": "attributes2classname: a discriminative model for attribute-based unsupervised zero-shot learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Demirel_Attributes2Classname_A_Discriminative_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "254": {"title": "active decision boundary annotation with deep generative models", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Huijser_Active_Decision_Boundary_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "248": {"title": "unmasking the abnormal events in video", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ionescu_Unmasking_the_Abnormal_ICCV_2017_paper.html", "abstract": "We propose a novel framework for abnormal event detection in video that requires no training sequenc\nes. Our framework is based on unmasking, a technique previously used for authorship verification in \ntext documents, which we adapt to our task. We iteratively train a binary classifier to distinguish \nbetween two consecutive video sequences while removing at each step the most discriminant features. \nHigher training accuracy rates of the intermediately obtained classifiers represent abnormal events.\n To the best of our knowledge, this is the first work to apply unmasking for a computer vision task.\n We compare our method with several state-of-the-art supervised and unsupervised methods on four ben\nchmark data sets. The empirical results indicate that our abnormal event detection framework can ach\nieve state-of-the-art results, while running in real-time at 20 frames per second.", "cite_num": 14}, "498": {"title": "genetic cnn", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xie_Genetic_CNN_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "268": {"title": "learning discriminative data fitting functions for blind image deblurring", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Pan_Learning_Discriminative_Data_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "491": {"title": "flame: fast lightweight mesh estimation using variational smoothing on delaunay graphs", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Greene_FLaME_Fast_Lightweight_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "293": {"title": "delving into salient object subitizing and detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/He_Delving_Into_Salient_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "509": {"title": "polynomial solvers for saturated ideals", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Larsson_Polynomial_Solvers_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "48": {"title": "associative domain adaptation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Haeusser_Associative_Domain_Adaptation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "257": {"title": "learning hand articulations by hallucinating heat distribution", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Choi_Learning_Hand_Articulations_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "572": {"title": "torontocity: seeing the world with a million eyes", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_TorontoCity_Seeing_the_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "391": {"title": "amulet: aggregating multi-level convolutional features for salient object detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Amulet_Aggregating_Multi-Level_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "374": {"title": "incremental learning of object detectors without catastrophic forgetting", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shmelkov_Incremental_Learning_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "615": {"title": "adversarial examples detection in deep networks with convolutional filter statistics", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Adversarial_Examples_Detection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "224": {"title": "jointly attentive spatial-temporal pooling networks for video-based person re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Xu_Jointly_Attentive_Spatial-Temporal_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "13": {"title": "generative adversarial networks conditioned by brain signals", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Palazzo_Generative_Adversarial_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "215": {"title": "consensus convolutional sparse coding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Choudhury_Consensus_Convolutional_Sparse_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "600": {"title": "range loss for deep face recognition with long-tailed training data", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Range_Loss_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "277": {"title": "toward perceptually-consistent stereo: a scanline study", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Toward_Perceptually-Consistent_Stereo_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "335": {"title": "least squares generative adversarial networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mao_Least_Squares_Generative_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "152": {"title": "personalized image aesthetics", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ren_Personalized_Image_Aesthetics_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "502": {"title": "bb8: a scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Rad_BB8_A_Scalable_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "359": {"title": "semantic image synthesis via adversarial learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dong_Semantic_Image_Synthesis_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "578": {"title": "monocular free-head 3d gaze tracking with deep learning and geometry constraints", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Monocular_Free-Head_3D_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "500": {"title": "reconstruction-based disentanglement for pose-invariant face recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Peng_Reconstruction-Based_Disentanglement_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "83": {"title": "spatial memory for context reasoning in object detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Spatial_Memory_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "2": {"title": "online real-time multiple spatiotemporal action localisation and prediction", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Singh_Online_Real-Time_Multiple_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "571": {"title": "segmentation-aware convolutional networks using local attention masks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Harley_Segmentation-Aware_Convolutional_Networks_ICCV_2017_paper.html", "abstract": "We introduce an approach to integrate segmentation information within a convolutional neural network\n (CNN). This counter-acts the tendency of CNNs to smooth information across regions and increases th\neir spatial precision. To obtain segmentation information, we set up a CNN to provide an embedding s\npace where region co-membership can be estimated based on Euclidean distance. We use these embedding\ns to compute a local attention mask relative to every neuron position. We incorporate such masks in \nCNNs and replace the convolution operation with a \"segmentation-aware\" variant that allows a neuron \nto selectively attend to inputs coming from its own region. We call the resulting network a segmenta\ntion-aware CNN because it adapts its filters at each image point according to local segmentation cue\ns. We demonstrate the merit of our method on two widely different dense prediction tasks, that invol\nve classification (semantic segmentation) and regression (optical flow). Our results show that in se\nmantic segmentation we can match the performance of DenseCRFs while being faster and simpler, and in\n optical flow we obtain clearly sharper responses than networks that do not use local attention mask\ns. In both cases, segmentation-aware convolution yields systematic improvements over strong baseline\ns. Source code for this work is available online at this http URL.", "cite_num": 19}, "39": {"title": "dual motion gan for future-flow embedded video prediction", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liang_Dual_Motion_GAN_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "455": {"title": "subunets: end-to-end hand shape and continuous sign language recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Camgoz_SubUNets_End-To-End_Hand_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "607": {"title": "learning visual n-grams from web data", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Learning_Visual_N-Grams_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "294": {"title": "unsupervised object segmentation in video by efficient selection of highly probable positive features", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Haller_Unsupervised_Object_Segmentation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "40": {"title": "shape: a novel graph theoretic algorithm for making consensus-based decisions in person re-identification systems", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Barman_SHaPE_A_Novel_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "459": {"title": "sbgar: semantics based group activity recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_SBGAR_Semantics_Based_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "604": {"title": "aod-net: all-in-one dehazing network", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_AOD-Net_All-In-One_Dehazing_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "84": {"title": "a lightweight approach for on-the-fly reflectance estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kim_A_Lightweight_Approach_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "594": {"title": "focal loss for dense object detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lin_Focal_Loss_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "599": {"title": "focusing attention: towards accurate text recognition in natural images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Cheng_Focusing_Attention_Towards_ICCV_2017_paper.html", "abstract": "Scene text recognition has been a hot research topic in computer vision due to its various applicati\nons. The state of the art is the attention-based encoder-decoder framework that learns the mapping b\netween input images and output sequences in a purely data-driven way. However, we observe that exist\ning attention-based methods perform poorly on complicated and/or low-quality images. One major reaso\nn is that existing methods cannot get accurate alignments between feature areas and targets for such\n images. We call this phenomenon \u201cattention drift\u201d. To tackle this problem, in this paper we propose\n the FAN (the abbreviation of Focusing Attention Network) method that employs a focusing attention m\nechanism to automatically draw back the drifted attention. FAN consists of two major components: an \nattention network (AN) that is responsible for recognizing character targets as in the existing meth\nods, and a focusing network (FN) that is responsible for adjusting attention by evaluating whether A\nN pays attention properly on the target areas in the images. Furthermore, different from the existin\ng methods, we adopt a ResNet-based network to enrich deep representations of scene text images. Exte\nnsive experiments on various benchmarks, including the IIIT5k, SVT and ICDAR datasets, show that the\n FAN method substantially outperforms the existing methods.", "cite_num": 29}, "8": {"title": "deep textspotter: an end-to-end trainable scene text localization and recognition framework", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Busta_Deep_TextSpotter_An_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "523": {"title": "should we encode rain streaks in video as deterministic or stochastic?", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wei_Should_We_Encode_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "449": {"title": "rgb-infrared cross-modality person re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wu_RGB-Infrared_Cross-Modality_Person_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "165": {"title": "stackgan: text to photo-realistic image synthesis with stacked generative adversarial networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_StackGAN_Text_to_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "255": {"title": "learning dense facial correspondences in unconstrained images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yu_Learning_Dense_Facial_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "122": {"title": "surfacenet: an end-to-end 3d neural network for multiview stereopsis", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ji_SurfaceNet_An_End-To-End_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "297": {"title": "foveanet: perspective-aware urban scene parsing", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_FoveaNet_Perspective-Aware_Urban_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "323": {"title": "hydraplus-net: attentive deep features for pedestrian analysis", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_HydraPlus-Net_Attentive_Deep_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "119": {"title": "detect to track and track to detect", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Feichtenhofer_Detect_to_Track_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "518": {"title": "super-trajectory for video segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Super-Trajectory_for_Video_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "547": {"title": "learning long-term dependencies for action recognition with a biologically-inspired deep network", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shi_Learning_Long-Term_Dependencies_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "250": {"title": "semi-global weighted least squares in image filtering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Semi-Global_Weighted_Least_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "73": {"title": "large pose 3d face reconstruction from a single image via direct volumetric cnn regression", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Jackson_Large_Pose_3D_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "499": {"title": "learning uncertain convolutional features for accurate saliency detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Learning_Uncertain_Convolutional_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "300": {"title": "common action discovery and localization in unconstrained videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yang_Common_Action_Discovery_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "609": {"title": "joint bi-layer optimization for single-image rain streak removal", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Joint_Bi-Layer_Optimization_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "232": {"title": "towards diverse and natural image descriptions via a conditional gan", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dai_Towards_Diverse_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "304": {"title": "from point clouds to mesh using regression", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ladicky_From_Point_Clouds_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "64": {"title": "soft proposal networks for weakly supervised object localization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Soft_Proposal_Networks_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "281": {"title": "infant footprint recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Infant_Footprint_Recognition_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "559": {"title": "recursive spatial transformer (rest) for alignment-free face recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wu_Recursive_Spatial_Transformer_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "360": {"title": "attention-based multimodal fusion for video description", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hori_Attention-Based_Multimodal_Fusion_ICCV_2017_paper.html", "abstract": "Current methods for video description are based on encoder-decoder sentence generation using recurre\nnt neural networks (RNNs). Recent work has demonstrated the advantages of integrating temporal atten\ntion mechanisms into these models, in which the decoder network predicts each word in the descriptio\nn by selectively giving more weight to encoded features from specific time frames. Such methods typi\ncally use two different types of features: image features (from an object classification model), and\n motion features (from an action recognition model), combined by naive concatenation in the model in\nput. Because different feature modalities may carry task-relevant information at different times, fu\nsing them by naive concatenation may limit the model's ability to dynamically determine the relevanc\ne of each type of feature to different parts of the description. In this paper, we incorporate audio\n features in addition to the image and motion features. To fuse these three modalities, we introduce\n a multimodal attention model that can selectively utilize features from different modalities for ea\nch word in the output description. Combining our new multimodal attention model with standard tempor\nal attention outperforms state-of-the-art methods on two standard datasets: YouTube2Text and MSR-VTT\n.", "cite_num": 46}, "20": {"title": "image super-resolution using dense skip connections", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tong_Image_Super-Resolution_Using_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "159": {"title": "binarized convolutional landmark localizers for human pose estimation and face alignment with limited resources", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bulat_Binarized_Convolutional_Landmark_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "3": {"title": "unlabeled samples generated by gan improve the person re-identification baseline in vitro", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zheng_Unlabeled_Samples_Generated_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "375": {"title": "denet: scalable real-time object detection with directed sparse sampling", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tychsen-Smith_DeNet_Scalable_Real-Time_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "67": {"title": "dualnet: learn complementary features for image recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hou_DualNet_Learn_Complementary_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "322": {"title": "am i a baller? basketball performance assessment from first-person videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bertasius_Am_I_a_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "377": {"title": "simultaneous detection and removal of high altitude clouds from an image", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sandhan_Simultaneous_Detection_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "603": {"title": "low-dimensionality calibration through local anisotropic scaling for robust hand model personalization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Remelli_Low-Dimensionality_Calibration_Through_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "251": {"title": "linear differential constraints for photo-polarimetric height estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tozza_Linear_Differential_Constraints_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "549": {"title": "intrinsic 3d dynamic surface tracking based on dynamic ricci flow and teichmuller map", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yu_Intrinsic_3D_Dynamic_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "306": {"title": "understanding low- and high-level contributions to fixation prediction", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kummerer_Understanding_Low-_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "330": {"title": "unsupervised learning of object landmarks by factorized spatial embeddings", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Thewlis_Unsupervised_Learning_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "87": {"title": "dynamic label graph matching for unsupervised video re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ye_Dynamic_Label_Graph_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "295": {"title": "a microfacet-based reflectance model for photometric stereo with highly specular surfaces", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_A_Microfacet-Based_Reflectance_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "422": {"title": "a generic deep architecture for single image reflection removal and image smoothing", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Fan_A_Generic_Deep_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "227": {"title": "mask r-cnn", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/He_Mask_R-CNN_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "589": {"title": "scnet: learning semantic correspondence", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Han_SCNet_Learning_Semantic_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "50": {"title": "spatial-aware object embeddings for zero-shot localization and classification of actions", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mettes_Spatial-Aware_Object_Embeddings_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "237": {"title": "predicting human activities using stochastic grammar", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Qi_Predicting_Human_Activities_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "567": {"title": "first-person activity forecasting with online inverse reinforcement learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Rhinehart_First-Person_Activity_Forecasting_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "535": {"title": "material editing using a physically based rendering network", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Material_Editing_Using_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "334": {"title": "cascaded feature network for semantic segmentation of rgb-d images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lin_Cascaded_Feature_Network_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "63": {"title": "deep clustering via joint convolutional autoencoder embedding and relative entropy minimization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dizaji_Deep_Clustering_via_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "507": {"title": "learning deep neural networks for vehicle re-id with visual-spatio-temporal path proposals", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shen_Learning_Deep_Neural_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "141": {"title": "localizing moments in video with natural language", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hendricks_Localizing_Moments_in_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "305": {"title": "adversarial image perturbation for privacy protection -- a game theory perspective", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Oh_Adversarial_Image_Perturbation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "238": {"title": "channel pruning for accelerating very deep neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/He_Channel_Pruning_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "246": {"title": "grad-cam: visual explanations from deep networks via gradient-based localization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "198": {"title": "learning spread-out local feature descriptors", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Learning_Spread-Out_Local_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "208": {"title": "generative modeling of audible shapes for object perception", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Generative_Modeling_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "352": {"title": "pixel-level matching for video object segmentation using convolutional neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yoon_Pixel-Level_Matching_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "271": {"title": "scale recovery for monocular visual odometry using depth estimated with deep convolutional neural fields", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yin_Scale_Recovery_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "541": {"title": "deltille grids for geometric camera calibration", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ha_Deltille_Grids_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "195": {"title": "enhancenet: single image super-resolution through automated texture synthesis", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sajjadi_EnhanceNet_Single_Image_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "468": {"title": "end-to-end face detection and cast grouping in movies using erdos-renyi clustering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Jin_End-To-End_Face_Detection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "516": {"title": "no fuss distance metric learning using proxies", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Movshovitz-Attias_No_Fuss_Distance_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "444": {"title": "weakly-supervised learning of visual relations", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Peyre_Weakly-Supervised_Learning_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "513": {"title": "fine-grained recognition in the wild: a multi-task domain adaptation approach", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gebru_Fine-Grained_Recognition_in_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "551": {"title": "chained cascade network for object detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ouyang_Chained_Cascade_Network_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "337": {"title": "deep metric learning with angular loss", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Deep_Metric_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "28": {"title": "be your own prada: fashion synthesis with structural coherence", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Be_Your_Own_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "562": {"title": "single shot text detector with regional attention", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/He_Single_Shot_Text_ICCV_2017_paper.html", "abstract": "We present a novel single-shot text detector that directly outputs word-level bounding boxes in a na\ntural image. We propose an attention mechanism which roughly identifies text regions via an automati\ncally learned attentional map. This substantially suppresses background interference in the convolut\nional features, which is the key to producing accurate inference of words, particularly at extremely\n small sizes. This results in a single model that essentially works in a coarse-to-fine manner. It d\neparts from recent FCN- based text detectors which cascade multiple FCN models to achieve an accurat\ne prediction. Furthermore, we develop a hierarchical inception module which efficiently aggregates m\nulti-scale inception features. This enhances local details, and also encodes strong context informat\nion, allow- ing the detector to work reliably on multi-scale and multi- orientation text with single\n-scale images. Our text detector achieves an F-measure of 77% on the ICDAR 2015 bench- mark, advanci\nng the state-of-the-art results in [18, 28]. Demo is available at: this http URL", "cite_num": 49}, "345": {"title": "practical projective structure from motion (p2sfm)", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Magerand_Practical_Projective_Structure_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "401": {"title": "monocular 3d human pose estimation by predicting depth on joints", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Nie_Monocular_3D_Human_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "190": {"title": "learning discriminative latent attributes for zero-shot classification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Jiang_Learning_Discriminative_Latent_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "561": {"title": "rotational subgroup voting and pose clustering for robust 3d object recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Buch_Rotational_Subgroup_Voting_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "303": {"title": "a read-write memory network for movie story understanding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Na_A_Read-Write_Memory_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "425": {"title": "misalignment-robust joint filter for cross-modal image pairs", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shibata_Misalignment-Robust_Joint_Filter_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "506": {"title": "cvae-gan: fine-grained image generation through asymmetric training", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bao_CVAE-GAN_Fine-Grained_Image_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "259": {"title": "coordinating filters for faster deep neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wen_Coordinating_Filters_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "573": {"title": "infinite latent feature selection: a probabilistic latent graph-based ranking approach", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Roffo_Infinite_Latent_Feature_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "368": {"title": "weakly supervised learning of deep metrics for stereo reconstruction", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tulyakov_Weakly_Supervised_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "34": {"title": "deep generative adversarial compression artifact removal", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Galteri_Deep_Generative_Adversarial_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "302": {"title": "automatic content-aware projection for 360deg videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kim_Automatic_Content-Aware_Projection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "217": {"title": "object-level proposals", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ma_Object-Level_Proposals_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "5": {"title": "learning in an uncertain world: representing ambiguity through multiple hypotheses", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Rupprecht_Learning_in_an_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "171": {"title": "large-scale image retrieval with attentive deep local features", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Noh_Large-Scale_Image_Retrieval_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "505": {"title": "phrase localization and visual relationship detection with comprehensive image-language cues", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Plummer_Phrase_Localization_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "332": {"title": "higher-order minimum cost lifted multicuts for motion segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Keuper_Higher-Order_Minimum_Cost_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "140": {"title": "modelling the scene dependent imaging in cameras with a deep neural network", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Nam_Modelling_the_Scene_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "333": {"title": "rolling-shutter-aware differential sfm and image rectification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhuang_Rolling-Shutter-Aware_Differential_SfM_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "308": {"title": "bier - boosting independent embeddings robustly", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Opitz_BIER_-_Boosting_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "182": {"title": "learning-based cloth material recovery from video", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yang_Learning-Based_Cloth_Material_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "510": {"title": "no more discrimination: cross city adaptation of road scene segmenters", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chen_No_More_Discrimination_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "484": {"title": "tensor rpca by bayesian cp factorization with complex noise", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Luo_Tensor_RPCA_by_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "383": {"title": "a revisit of sparse coding based anomaly detection in stacked rnn framework", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Luo_A_Revisit_of_ICCV_2017_paper.html", "abstract": "Motivated by the capability of sparse coding based anomaly detection, we propose a Temporally-cohere\nnt Sparse Coding (TSC) where we enforce similar neighbouring frames be encoded with similar reconstr\nuction coefficients. Then we map the TSC with a special type of stacked Recurrent Neural Network (sR\nNN). By taking advantage of sRNN in learning all parameters simultaneously, the nontrivial hyper-par\nameter selection to TSC can be avoided, meanwhile with a shallow sRNN, the reconstruction coefficien\nts can be inferred within a forward pass, which reduces the computational cost for learning sparse c\noefficients. The contributions of this paper are two-fold: i) We propose a TSC, which can be mapped \nto a sRNN which facilitates the parameter optimization and accelerates the anomaly prediction. ii) W\ne build a very large dataset which is even larger than the summation of all existing dataset for ano\nmaly detection in terms of both the volume of data and the diversity of scenes. Extensive experiment\ns on both a toy dataset and real datasets demonstrate that our TSC based and sRNN based method consi\nstently outperform existing methods, which validates the effectiveness of our method.", "cite_num": 27}, "467": {"title": "region-based correspondence between 3d shapes via spatially smooth biclustering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Denitto_Region-Based_Correspondence_Between_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "206": {"title": "pose-invariant face alignment with a single cnn", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Jourabloo_Pose-Invariant_Face_Alignment_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "261": {"title": "constrained convolutional sparse coding for parametric based reconstruction of line drawings", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shaheen_Constrained_Convolutional_Sparse_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "411": {"title": "memnet: a persistent memory network for image restoration", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tai_MemNet_A_Persistent_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "521": {"title": "a generative model of people in clothing", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lassner_A_Generative_Model_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "517": {"title": "locally-transferred fisher vectors for texture classification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Song_Locally-Transferred_Fisher_Vectors_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "394": {"title": "temporal action detection with structured segment networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhao_Temporal_Action_Detection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "149": {"title": "identity-aware textual-visual matching with latent co-attention", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Identity-Aware_Textual-Visual_Matching_ICCV_2017_paper.html", "abstract": "Textual-visual matching aims at measuring similarities between sentence descriptions and images. Mos\nt existing methods tackle this problem without effectively utilizing identity-level annotations. In \nthis paper, we propose an identity-aware two-stage framework for the textual-visual matching problem\n. Our stage-1 CNN-LSTM network learns to embed cross-modal features with a novel Cross-Modal Cross-E\nntropy (CMCE) loss. The stage-1 network is able to efficiently screen easy incorrect matchings and a\nlso provide initial training point for the stage-2 training. The stage-2 CNN-LSTM network refines th\ne matching results with a latent co-attention mechanism. The spatial attention relates each word wit\nh corresponding image regions while the latent semantic attention aligns different sentence structur\nes to make the matching results more robust to sentence structure variations. Extensive experiments \non three datasets with identity-level annotations show that our framework outperforms state-of-the-a\nrt approaches by large margins.", "cite_num": 14}, "174": {"title": "learning discriminative aggregation network for video-based face recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Rao_Learning_Discriminative_Aggregation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "366": {"title": "sketching with style: visual search with sketches and aesthetic context", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Collomosse_Sketching_With_Style_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "164": {"title": "thinet: a filter level pruning method for deep neural network compression", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Luo_ThiNet_A_Filter_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "89": {"title": "multi-scale deep learning architectures for person re-identification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Qian_Multi-Scale_Deep_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "131": {"title": "volumetric flow estimation for incompressible fluids using the stationary stokes equations", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lasinger_Volumetric_Flow_Estimation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "77": {"title": "characterizing and improving stability in neural style transfer", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gupta_Characterizing_and_Improving_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "142": {"title": "paying attention to descriptions generated by image captioning models", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tavakoli_Paying_Attention_to_ICCV_2017_paper.html", "abstract": "To bridge the gap between humans and machines in image understanding and describing, we need further\n insight into how people describe a perceived scene. In this paper, we study the agreement between b\nottom-up saliency-based visual attention and object referrals in scene description constructs. We in\nvestigate the properties of human-written descriptions and machine-generated ones. We then propose a\n saliency-boosted image captioning model in order to investigate benefits from low-level cues in lan\nguage models. We learn that (1) humans mention more salient objects earlier than less salient ones i\nn their descriptions, (2) the better a captioning model performs, the better attention agreement it \nhas with human descriptions, (3) the proposed saliency-boosted model, compared to its baseline form,\n does not improve significantly on the MS COCO database, indicating explicit bottom-up boosting does\n not help when the task is well learnt and tuned on a data, (4) a better generalization is, however,\n observed for the saliency-boosted model on unseen data.", "cite_num": 0}, "153": {"title": "a lightweight single-camera polarization compass with covariance estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sturzl_A_Lightweight_Single-Camera_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "555": {"title": "smart mining for deep metric learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Harwood_Smart_Mining_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "557": {"title": "a discriminative view of mrf pre-processing algorithms", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_A_Discriminative_View_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "503": {"title": "aesthetic critiques generation for photos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chang_Aesthetic_Critiques_Generation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "287": {"title": "a two-streamed network for estimating fine-scaled depth maps from single rgb images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_A_Two-Streamed_Network_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "342": {"title": "online robust image alignment via subspace learning from gradient orientations", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zheng_Online_Robust_Image_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "72": {"title": "robust kronecker-decomposable component analysis for low-rank modeling", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bahri_Robust_Kronecker-Decomposable_Component_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "545": {"title": "domain-adaptive deep network compression", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Masana_Domain-Adaptive_Deep_Network_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "163": {"title": "attention-aware deep reinforcement learning for video face recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Rao_Attention-Aware_Deep_Reinforcement_ICCV_2017_paper.html", "abstract": "In this paper, we propose an attention-aware deep reinforcement learning (ADRL) method for video fac\ne recognition, which aims to discard the misleading and confounding frames and find the focuses of a\nttentions in face videos for person recognition. We formulate the process of finding the attentions \nof videos as a Markov decision process and train the attention model through a deep reinforcement le\narning framework without using extra labels. Unlike existing attention models, our method takes info\nrmation from both the image space and the feature space as the input to make better use of face info\nrmation that is discarded in the feature learning process. Besides, our approach is attention-aware,\n which seeks different attentions of videos for the recognition of different pairs of videos. Our ap\nproach achieves very competitive video face recognition performance on three widely used video face \ndatasets.", "cite_num": 32}, "477": {"title": "revisiting cross-channel information transfer for chromatic aberration correction", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sun_Revisiting_Cross-Channel_Information_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "546": {"title": "vqs: linking segmentations to questions and answers for supervised attention in vqa and question-focused semantic segmentation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gan_VQS_Linking_Segmentations_ICCV_2017_paper.html", "abstract": "Rich and dense human labeled datasets are among the main enabling factors for the recent advance on \nvision-language understanding. Many seemingly distant annotations (e.g., semantic segmentation and v\nisual question answering (VQA)) are inherently connected in that they reveal different levels and pe\nrspectives of human understandings about the same visual scenes --- and even the same set of images \n(e.g., of COCO). The popularity of COCO correlates those annotations and tasks. Explicitly linking t\nhem up may significantly benefit both individual tasks and the unified vision and language modeling.\n We present the preliminary work of linking the instance segmentations provided by COCO to the quest\nions and answers (QAs) in the VQA dataset, and name the collected links visual questions and segment\nation answers (VQS). They transfer human supervision between the previously separate tasks, offer mo\nre effective leverage to existing problems, and also open the door for new research problems and mod\nels. We study two applications of the VQS data in this paper: supervised attention for VQA and a nov\nel question-focused semantic segmentation task. For the former, we obtain state-of-the-art results o\nn the VQA real multiple-choice task by simply augmenting the multilayer perceptrons with some attent\nion features that are learned using the segmentation-QA links as explicit supervision. To put the la\ntter in perspective, we study two plausible methods and compare them to an oracle method assuming th\nat the instance segmentations are given at the test stage.", "cite_num": -1}, "434": {"title": "the pose knows: video forecasting by generating pose futures", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Walker_The_Pose_Knows_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "101": {"title": "ssh: single stage headless face detector", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Najibi_SSH_Single_Stage_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "229": {"title": "multi-task self-supervised visual learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Doersch_Multi-Task_Self-Supervised_Visual_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "285": {"title": "from square pieces to brick walls: the next challenge in solving jigsaw puzzles", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gur_From_Square_Pieces_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "236": {"title": "video frame synthesis using deep voxel flow", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Video_Frame_Synthesis_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "416": {"title": "scene parsing with global context embedding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Hung_Scene_Parsing_With_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "188": {"title": "weakly supervised summarization of web videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Panda_Weakly_Supervised_Summarization_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "478": {"title": "open set domain adaptation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Busto_Open_Set_Domain_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "98": {"title": "learning compact geometric features", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Khoury_Learning_Compact_Geometric_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "550": {"title": "deeproadmapper: extracting road topology from aerial images", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mattyus_DeepRoadMapper_Extracting_Road_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "90": {"title": "neural ctrl-f: segmentation-free query-by-string word spotting in handwritten manuscript collections", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wilkinson_Neural_Ctrl-F_Segmentation-Free_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "137": {"title": "refractive structure-from-motion through a flat refractive interface", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chadebecq_Refractive_Structure-From-Motion_Through_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "74": {"title": "composite focus measure for high quality depth maps", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sakurikar_Composite_Focus_Measure_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "24": {"title": "synergy between face alignment and tracking via discriminative global consensus optimization", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Khan_Synergy_Between_Face_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "598": {"title": "robust hand pose estimation during the interaction with an unknown object", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Choi_Robust_Hand_Pose_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "210": {"title": "speaking the same language: matching machine to human captions by adversarial training", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shetty_Speaking_the_Same_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "587": {"title": "exploiting spatial structure for localizing manipulated image regions", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bappy_Exploiting_Spatial_Structure_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "365": {"title": "reasoning about fine-grained attribute phrases using reference games", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Su_Reasoning_About_Fine-Grained_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "485": {"title": "parallel tracking and verifying: a framework for real-time and high accuracy visual tracking", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Fan_Parallel_Tracking_and_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "331": {"title": "exploiting multi-grain ranking constraints for precisely searching visually-similar vehicles", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yan_Exploiting_Multi-Grain_Ranking_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "81": {"title": "moving object detection in time-lapse or motion trigger image sequences using low-rank and invariant sparse decomposition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Shakeri_Moving_Object_Detection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "430": {"title": "learning from video and text via large-scale discriminative clustering", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Miech_Learning_From_Video_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "462": {"title": "couplenet: coupling global structure with local parts for object detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_CoupleNet_Coupling_Global_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "544": {"title": "mihash: online hashing with mutual information", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Cakir_MIHash_Online_Hashing_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "344": {"title": "interpretable explanations of black boxes by meaningful perturbation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Fong_Interpretable_Explanations_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "338": {"title": "what is around the camera?", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Georgoulis_What_Is_Around_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "126": {"title": "rpan: an end-to-end recurrent pose-attention network for action recognition in videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Du_RPAN_An_End-To-End_ICCV_2017_paper.html", "abstract": "Recent studies demonstrate the effectiveness of Recurrent Neural Networks (RNNs) for action recognit\nion in videos. However, previous works mainly utilize video-level category as supervision to train R\nNNs, which may prohibit RNNs to learn complex motion structures along time. In this paper, we propos\ne a recurrent pose-attention network (RPAN) to address this challenge, where we introduce a novel po\nse-attention mechanism to adaptively learn pose-related features at every time-step action predictio\nn of RNNs. More specifically, we make three main contributions in this paper. Firstly, unlike previo\nus works on pose-related action recognition, our RPAN is an end-toend recurrent network which can ex\nploit important spatialtemporal evolutions of human pose to assist action recognition in a unified f\nramework. Secondly, instead of learning individual human-joint features separately, our poseattentio\nn mechanism learns robust human-part features by sharing attention parameters partially on the seman\nticallyrelated human joints. These human-part features are then fed into the human-part pooling laye\nr to construct a highlydiscriminative pose-related representation for temporal action modeling. Thir\ndly, one important byproduct of our RPAN is pose estimation in videos, which can be used for coarse \npose annotation in action videos. We evaluate the proposed RPAN quantitatively and qualitatively on \ntwo popular benchmarks, i.e., Sub-JHMDB and PennAction. Experimental results show that RPAN outperfo\nrms the recent state-of-the-art methods on these challenging datasets.", "cite_num": -1}, "125": {"title": "image2song: song retrieval via bridging image content and lyric words", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Image2song_Song_Retrieval_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "253": {"title": "punda: probabilistic unsupervised domain adaptation for knowledge transfer across visual categories", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gholami_PUnDA_Probabilistic_Unsupervised_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "80": {"title": "high-resolution shape completion using deep neural networks for global structure and local geometry inference", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Han_High-Resolution_Shape_Completion_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "565": {"title": "unsupervised video understanding by reconciliation of posture similarities", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Milbich_Unsupervised_Video_Understanding_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "272": {"title": "real time eye gaze tracking with 3d deformable eye-face model", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Real_Time_Eye_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "353": {"title": "pixel recursive super resolution", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dahl_Pixel_Recursive_Super_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "448": {"title": "rotation equivariant vector field networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Marcos_Rotation_Equivariant_Vector_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "501": {"title": "fcn-rlstm: deep spatio-temporal neural networks for vehicle counting in city cameras", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_FCN-rLSTM_Deep_Spatio-Temporal_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "395": {"title": "learning video object segmentation with visual memory", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tokmakov_Learning_Video_Object_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "66": {"title": "what will happen next? forecasting player moves in sports videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Felsen_What_Will_Happen_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "318": {"title": "joint layout estimation and global multi-view registration for indoor reconstruction", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lee_Joint_Layout_Estimation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "466": {"title": "attentive semantic video generation using captions", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Marwah_Attentive_Semantic_Video_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "433": {"title": "visual relationship detection with internal and external linguistic knowledge distillation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yu_Visual_Relationship_Detection_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "128": {"title": "deepcontext: context-encoding neural pathways for 3d holistic scene understanding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_DeepContext_Context-Encoding_Neural_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "602": {"title": "quantitative evaluation of confidence measures in a machine learning world", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Poggi_Quantitative_Evaluation_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "273": {"title": "deepcd: learning deep complementary descriptors for patch representations", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Yang_DeepCD_Learning_Deep_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "486": {"title": "real-time monocular pose estimation of 3d objects using temporally consistent local color histograms", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tjaden_Real-Time_Monocular_Pose_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "157": {"title": "self-paced kernel estimation for robust blind image deblurring", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gong_Self-Paced_Kernel_Estimation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "100": {"title": "scale-adaptive convolutions for scene parsing", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Scale-Adaptive_Convolutions_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "214": {"title": "a simple yet effective baseline for 3d human pose estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Martinez_A_Simple_yet_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "362": {"title": "blitznet: a real-time deep network for scene understanding", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dvornik_BlitzNet_A_Real-Time_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "552": {"title": "recurrent models for situation recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mallya_Recurrent_Models_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "177": {"title": "temporal non-volume preserving approach to facial age-progression and age-invariant face recognition", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Duong_Temporal_Non-Volume_Preserving_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "95": {"title": "efficient low rank tensor ring completion", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Efficient_Low_Rank_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "431": {"title": "unrolled memory inner-products: an abstract gpu operator for efficient vision-related computations", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lin_Unrolled_Memory_Inner-Products_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "289": {"title": "realistic dynamic facial textures from a single image using gans", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Olszewski_Realistic_Dynamic_Facial_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "414": {"title": "fast face-swap using convolutional neural networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Korshunova_Fast_Face-Swap_Using_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "292": {"title": "revisiting unreasonable effectiveness of data in deep learning era", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Sun_Revisiting_Unreasonable_Effectiveness_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "528": {"title": "egocentric gesture recognition using recurrent 3d convolutional neural networks with spatiotemporal transformer modules", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Cao_Egocentric_Gesture_Recognition_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "620": {"title": "regional interactive image segmentation networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liew_Regional_Interactive_Image_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "207": {"title": "monocular video-based trailer coupler detection using multiplexer convolutional neural network", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Atoum_Monocular_Video-Based_Trailer_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "402": {"title": "a 3d morphable model of craniofacial shape and texture variation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Dai_A_3D_Morphable_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "221": {"title": "3dcnn-dqn-rnn: a deep reinforcement learning framework for semantic parsing of large-scale 3d point clouds", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_3DCNN-DQN-RNN_A_Deep_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "471": {"title": "surface registration via foliation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zheng_Surface_Registration_via_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "612": {"title": "mutual enhancement for detection of multiple logos in sports videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liao_Mutual_Enhancement_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "70": {"title": "practical and efficient multi-view matching", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Maset_Practical_and_Efficient_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "86": {"title": " online video object detection using association lstm", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Lu__Online_Video_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "465": {"title": "efficient global 2d-3d matching for camera localization in a large-scale 3d map", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Efficient_Global_2D-3D_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "504": {"title": "non-convex rank/sparsity regularization and local minima", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Olsson_Non-Convex_RankSparsity_Regularization_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "376": {"title": "transformed low-rank model for line pattern noise removal", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chang_Transformed_Low-Rank_Model_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "463": {"title": "taking the scenic route to 3d: optimising reconstruction from moving cameras", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Mendez_Taking_the_Scenic_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "7": {"title": "benchmarking and error diagnosis in multi-instance pose estimation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Ronchi_Benchmarking_and_Error_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "595": {"title": "increasing cnn robustness to occlusions by reducing filter support", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Osherov_Increasing_CNN_Robustness_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "186": {"title": "multi-label learning of part detectors for heavily occluded pedestrian detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhou_Multi-Label_Learning_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "525": {"title": "flow-guided feature aggregation for video object detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Flow-Guided_Feature_Aggregation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "601": {"title": "unsupervised adaptation for deep stereo", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tonioni_Unsupervised_Adaptation_for_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "534": {"title": "joint estimation of camera pose, depth, deblurring, and super-resolution from a blurred image sequence", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Park_Joint_Estimation_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "286": {"title": "hashnet: deep learning to hash by continuation", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Cao_HashNet_Deep_Learning_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "107": {"title": "unsupervised learning of stereo matching", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhou_Unsupervised_Learning_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "367": {"title": "using sparse elimination for solving minimal problems in computer vision", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Heikkila_Using_Sparse_Elimination_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "55": {"title": "turning corners into cameras: principles and methods", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bouman_Turning_Corners_Into_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "580": {"title": "tracking as online decision-making: learning a policy from streaming videos with reinforcement learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Supancic_Tracking_as_Online_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "307": {"title": "polyfit: polygonal surface reconstruction from point clouds", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Nan_PolyFit_Polygonal_Surface_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "202": {"title": "unsupervised learning of important objects from first-person videos", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bertasius_Unsupervised_Learning_of_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "154": {"title": "editable parametric dense foliage from 3d capture", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chaurasia_Editable_Parametric_Dense_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "47": {"title": "is second-order information helpful for large-scale visual recognition?", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Is_Second-Order_Information_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "497": {"title": "beyond planar symmetry: modeling human perception of reflection and rotation symmetries in the wild", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Funk_Beyond_Planar_Symmetry_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "439": {"title": "depth and image restoration from light field in a scattering medium", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Tian_Depth_and_Image_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "540": {"title": "leveraging weak semantic relevance for complex video event classification", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Li_Leveraging_Weak_Semantic_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "132": {"title": "scaling the scattering transform: deep hybrid networks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Oyallon_Scaling_the_Scattering_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "129": {"title": "towards context-aware interaction recognition for visual relationship detection", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhuang_Towards_Context-Aware_Interaction_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "41": {"title": "non-linear convolution filters for cnn-based learning", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zoumpourlis_Non-Linear_Convolution_Filters_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "560": {"title": "aligned image-word representations improve inductive transfer across vision-language tasks", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Gupta_Aligned_Image-Word_Representations_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "280": {"title": "rethinking reprojection: closing the loop for pose-aware shape reconstruction from a single image", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Rethinking_Reprojection_Closing_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "436": {"title": "a geometric framework for statistical analysis of trajectories with distinct temporal spans", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Chakraborty_A_Geometric_Framework_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "429": {"title": "chromatag: a colored marker and fast detection algorithm", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/DeGol_ChromaTag_A_Colored_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "19": {"title": "dctm: discrete-continuous transformation matching for semantic flow", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Kim_DCTM_Discrete-Continuous_Transformation_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "611": {"title": "ray space features for plenoptic structure-from-motion", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Ray_Space_Features_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}, "299": {"title": "soft-nms -- improving object detection with one line of code", "conf": "iccv", "time": "2017", "url": "http://openaccess.thecvf.com/content_iccv_2017/html/Bodla_Soft-NMS_--_Improving_ICCV_2017_paper.html", "abstract": "", "cite_num": -1}}