{"191": {"title": "deep voice 2: multi-speaker neural text-to-speech.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6889-deep-voice-2-multi-speaker-neural-text-to-speech", "abstract": "", "cite_num": -1}, "235": {"title": "translation synchronization via truncated least squares.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6744-translation-synchronization-via-truncated-least-squares", "abstract": "", "cite_num": -1}, "475": {"title": "revenue optimization with approximate bid predictions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6782-revenue-optimization-with-approximate-bid-predictions", "abstract": "", "cite_num": -1}, "156": {"title": "a general framework for robust interactive learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7283-a-general-framework-for-robust-interactive-learning", "abstract": "", "cite_num": -1}, "496": {"title": "efficient sublinear-regret algorithms for online sparse linear regression with limited observation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6998-efficient-sublinear-regret-algorithms-for-online-sparse-linear-regression-with-limited-observation", "abstract": "", "cite_num": -1}, "469": {"title": "temporal coherency based criteria for predicting video frames using deep multi-stage generative adversarial networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7014-temporal-coherency-based-criteria-for-predicting-video-frames-using-deep-multi-stage-generative-adversarial-networks", "abstract": "", "cite_num": -1}, "412": {"title": "vae learning via stein variational gradient descent.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7011-vae-learning-via-stein-variational-gradient-descent", "abstract": "", "cite_num": -1}, "606": {"title": "mean teachers are better role models: weight-averaged consistency targets improve semi-supervised deep learning results.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6719-mean-teachers-are-better-role-models-weight-averaged-consistency-targets-improve-semi-supervised-deep-learning-results", "abstract": "", "cite_num": -1}, "284": {"title": "on the model shrinkage effect of gamma process edge partition models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6643-on-the-model-shrinkage-effect-of-gamma-process-edge-partition-models", "abstract": "", "cite_num": -1}, "410": {"title": "sgd learns the conjugate kernel class of the network.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network", "abstract": "", "cite_num": -1}, "145": {"title": "self-supervised intrinsic image decomposition.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7175-self-supervised-intrinsic-image-decomposition", "abstract": "", "cite_num": -1}, "197": {"title": "nearest-neighbor sample compression: efficiency, consistency, infinite dimensions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6755-nearest-neighbor-sample-compression-efficiency-consistency-infinite-dimensions", "abstract": "", "cite_num": -1}, "453": {"title": "convergence analysis of two-layer neural networks with relu activation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6662-convergence-analysis-of-two-layer-neural-networks-with-relu-activation", "abstract": "", "cite_num": -1}, "526": {"title": "exploring generalization in deep learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7176-exploring-generalization-in-deep-learning", "abstract": "", "cite_num": -1}, "624": {"title": "neural networks for efficient bayesian decoding of natural images from retinal neurons.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7222-neural-networks-for-efficient-bayesian-decoding-of-natural-images-from-retinal-neurons", "abstract": "", "cite_num": -1}, "245": {"title": "efficient approximation algorithms for strings kernel based sequence classification.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7269-efficient-approximation-algorithms-for-strings-kernel-based-sequence-classification", "abstract": "", "cite_num": -1}, "419": {"title": "invariance and stability of deep convolutional representations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7201-invariance-and-stability-of-deep-convolutional-representations", "abstract": "", "cite_num": -1}, "538": {"title": "model-powered conditional independence test.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6888-model-powered-conditional-independence-test", "abstract": "", "cite_num": -1}, "665": {"title": "unsupervised learning of disentangled representations from video.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7028-unsupervised-learning-of-disentangled-representations-from-video", "abstract": "", "cite_num": -1}, "256": {"title": "modulating early visual processing by language.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7237-modulating-early-visual-processing-by-language", "abstract": "", "cite_num": -1}, "110": {"title": "monte-carlo tree search by best arm identification.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7075-monte-carlo-tree-search-by-best-arm-identification", "abstract": "", "cite_num": -1}, "218": {"title": "reducing reparameterization gradient variance.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6961-reducing-reparameterization-gradient-variance", "abstract": "", "cite_num": -1}, "568": {"title": "minimal exploration in structured stochastic bandits.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6773-minimal-exploration-in-structured-stochastic-bandits", "abstract": "", "cite_num": -1}, "35": {"title": "asynchronous coordinate descent under more realistic assumptions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7198-asynchronous-coordinate-descent-under-more-realistic-assumptions", "abstract": "", "cite_num": -1}, "616": {"title": "ex2: exploration with exemplar models for deep reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6851-ex2-exploration-with-exemplar-models-for-deep-reinforcement-learning", "abstract": "", "cite_num": -1}, "59": {"title": "streaming robust submodular maximization: a partitioned thresholding approach.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7042-streaming-robust-submodular-maximization-a-partitioned-thresholding-approach", "abstract": "", "cite_num": -1}, "241": {"title": "the expxorcist: nonparametric graphical models via conditional exponential densities.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7031-the-expxorcist-nonparametric-graphical-models-via-conditional-exponential-densities", "abstract": "", "cite_num": -1}, "668": {"title": "decoding with value networks for neural machine translation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6622-decoding-with-value-networks-for-neural-machine-translation", "abstract": "", "cite_num": -1}, "116": {"title": "learning to inpaint for image compression.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6724-learning-to-inpaint-for-image-compression", "abstract": "", "cite_num": -1}, "619": {"title": "k-medoids for k-means seeding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7104-k-medoids-for-k-means-seeding", "abstract": "", "cite_num": -1}, "136": {"title": "position-based multiple-play bandit problem with unknown position bias.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7085-position-based-multiple-play-bandit-problem-with-unknown-position-bias", "abstract": "", "cite_num": -1}, "441": {"title": "deanonymization in the bitcoin p2p network.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6735-deanonymization-in-the-bitcoin-p2p-network", "abstract": "", "cite_num": -1}, "629": {"title": "deep learning with topological signatures.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6761-deep-learning-with-topological-signatures", "abstract": "", "cite_num": -1}, "204": {"title": "falkon: an optimal large scale kernel method.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6978-falkon-an-optimal-large-scale-kernel-method", "abstract": "", "cite_num": -1}, "350": {"title": "a unified approach to interpreting model predictions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions", "abstract": "", "cite_num": -1}, "135": {"title": "a bayesian data augmentation approach for learning deep models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6872-a-bayesian-data-augmentation-approach-for-learning-deep-models", "abstract": "", "cite_num": -1}, "479": {"title": "learned in translation: contextualized word vectors.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors", "abstract": "", "cite_num": -1}, "474": {"title": "collaborative deep learning in fixed topology networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7172-collaborative-deep-learning-in-fixed-topology-networks", "abstract": "", "cite_num": -1}, "385": {"title": "predicting organic reaction outcomes with weisfeiler-lehman network.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6854-predicting-organic-reaction-outcomes-with-weisfeiler-lehman-network", "abstract": "", "cite_num": -1}, "361": {"title": "a-nice-mc: adversarial training for mcmc.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7099-a-nice-mc-adversarial-training-for-mcmc", "abstract": "", "cite_num": -1}, "655": {"title": "an empirical bayes approach to optimizing machine learning algorithms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6864-an-empirical-bayes-approach-to-optimizing-machine-learning-algorithms", "abstract": "", "cite_num": -1}, "494": {"title": "wasserstein learning of deep generative point process models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6917-wasserstein-learning-of-deep-generative-point-process-models", "abstract": "", "cite_num": -1}, "147": {"title": "gated recurrent convolution neural network for ocr.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6637-gated-recurrent-convolution-neural-network-for-ocr", "abstract": "", "cite_num": -1}, "189": {"title": "revisiting perceptron: efficient and label-optimal learning of halfspaces.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6706-revisiting-perceptron-efficient-and-label-optimal-learning-of-halfspaces", "abstract": "", "cite_num": -1}, "231": {"title": "towards generalization and simplicity in continuous control.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7233-towards-generalization-and-simplicity-in-continuous-control", "abstract": "", "cite_num": -1}, "346": {"title": "revisit fuzzy neural network: demystifying batch normalization and relu with generalized hamming network.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6788-revisit-fuzzy-neural-network-demystifying-batch-normalization-and-relu-with-generalized-hamming-network", "abstract": "", "cite_num": -1}, "249": {"title": "gradient episodic memory for continual learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7225-gradient-episodic-memory-for-continual-learning", "abstract": "", "cite_num": -1}, "413": {"title": "on clustering network-valued data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7282-on-clustering-network-valued-data", "abstract": "", "cite_num": -1}, "169": {"title": "improved dynamic regret for non-degenerate functions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6675-improved-dynamic-regret-for-non-degenerate-functions", "abstract": "", "cite_num": -1}, "583": {"title": "qmdp-net: deep learning for planning under partial observability.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7055-qmdp-net-deep-learning-for-planning-under-partial-observability", "abstract": "", "cite_num": -1}, "313": {"title": "aggressive sampling for multi-class to binary reduction with applications to text classification.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7004-aggressive-sampling-for-multi-class-to-binary-reduction-with-applications-to-text-classification", "abstract": "", "cite_num": -1}, "193": {"title": "adaptive clustering through semidefinite programming.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6776-adaptive-clustering-through-semidefinite-programming", "abstract": "", "cite_num": -1}, "166": {"title": "masked autoregressive flow for density estimation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6828-masked-autoregressive-flow-for-density-estimation", "abstract": "", "cite_num": -1}, "113": {"title": "adaptive bayesian sampling with monte carlo em.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6725-adaptive-bayesian-sampling-with-monte-carlo-em", "abstract": "", "cite_num": -1}, "258": {"title": "variational laws of visual attention for dynamic scenes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6972-variational-laws-of-visual-attention-for-dynamic-scenes", "abstract": "Computational models of visual attention are at the crossroad of disciplines like cognitive science,\n computational neuroscience, and computer vision. This paper proposes a model of attentional scanpat\nh that is based on the principle that there are foundational laws that drive the emergence of visual\n attention. We devise variational laws of the eye-movement that rely on a generalized view of the Le\nast Action Principle in physics. The potential energy captures details as well as peripheral visual \nfeatures, while the kinetic energy corresponds with the classic interpretation in analytic mechanics\n. In addition, the Lagrangian contains a brightness invariance term, which characterizes significant\nly the scanpath trajectories. We obtain differential equations of visual attention as the stationary\n point of the generalized action, and we propose an algorithm to estimate the model parameters. Fina\nlly, we report experimental results to validate the model in tasks of saliency detection.", "cite_num": 7}, "4": {"title": "scalable demand-aware recommendation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6835-scalable-demand-aware-recommendation", "abstract": "", "cite_num": -1}, "263": {"title": "neural expectation maximization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7246-neural-expectation-maximization", "abstract": "", "cite_num": -1}, "244": {"title": "fast amortized inference of neural activity from calcium imaging data with variational autoencoders.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6991-fast-amortized-inference-of-neural-activity-from-calcium-imaging-data-with-variational-autoencoders", "abstract": "", "cite_num": -1}, "36": {"title": "protein interface prediction using graph convolutional networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7231-protein-interface-prediction-using-graph-convolutional-networks", "abstract": "", "cite_num": -1}, "283": {"title": "experimental design for learning causal graphs with latent variables.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7277-experimental-design-for-learning-causal-graphs-with-latent-variables", "abstract": "", "cite_num": -1}, "576": {"title": "one-sided unsupervised domain mapping.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6677-one-sided-unsupervised-domain-mapping", "abstract": "", "cite_num": -1}, "288": {"title": "adaptive svrg methods under error bound conditions with unknown growth parameter.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6920-adaptive-svrg-methods-under-error-bound-conditions-with-unknown-growth-parameter", "abstract": "", "cite_num": -1}, "201": {"title": "stochastic approximation for canonical correlation analysis.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7063-stochastic-approximation-for-canonical-correlation-analysis", "abstract": "", "cite_num": -1}, "102": {"title": "learning from complementary labels.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7147-learning-from-complementary-labels", "abstract": "", "cite_num": -1}, "339": {"title": "multi-task learning for contextual bandits.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7070-multi-task-learning-for-contextual-bandits", "abstract": "", "cite_num": -1}, "124": {"title": "safetynets: verifiable execution of deep neural networks on an untrusted cloud.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7053-safetynets-verifiable-execution-of-deep-neural-networks-on-an-untrusted-cloud", "abstract": "", "cite_num": -1}, "527": {"title": "permutation-based causal inference algorithms with interventions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7164-permutation-based-causal-inference-algorithms-with-interventions", "abstract": "", "cite_num": -1}, "569": {"title": "learning koopman invariant subspaces for dynamic mode decomposition.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6713-learning-koopman-invariant-subspaces-for-dynamic-mode-decomposition", "abstract": "", "cite_num": -1}, "456": {"title": "regret minimization in mdps with options without prior knowledge.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6909-regret-minimization-in-mdps-with-options-without-prior-knowledge", "abstract": "", "cite_num": -1}, "454": {"title": "a screening rule for l1-regularized ising model estimation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6674-a-screening-rule-for-l1-regularized-ising-model-estimation", "abstract": "", "cite_num": -1}, "649": {"title": "task-based end-to-end model learning in stochastic optimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7132-task-based-end-to-end-model-learning-in-stochastic-optimization", "abstract": "", "cite_num": -1}, "586": {"title": "compatible reward inverse reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6800-compatible-reward-inverse-reinforcement-learning", "abstract": "", "cite_num": -1}, "103": {"title": "zap q-learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6818-zap-q-learning", "abstract": "", "cite_num": -1}, "537": {"title": "adaptive accelerated gradient converging method under h\\\"{o}lderian error bound condition.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6903-adaptive-accelerated-gradient-converging-method-under-holderian-error-bound-condition", "abstract": "", "cite_num": -1}, "585": {"title": "affinity clustering: hierarchical clustering at scale.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7262-affinity-clustering-hierarchical-clustering-at-scale", "abstract": "", "cite_num": -1}, "386": {"title": "unbounded cache model for online language modeling with open vocabulary.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7185-unbounded-cache-model-for-online-language-modeling-with-open-vocabulary", "abstract": "", "cite_num": -1}, "476": {"title": "learning neural representations of human cognition across many fmri studies.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7170-learning-neural-representations-of-human-cognition-across-many-fmri-studies", "abstract": "", "cite_num": -1}, "357": {"title": "a scale free algorithm for stochastic bandits with bounded kurtosis.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6756-a-scale-free-algorithm-for-stochastic-bandits-with-bounded-kurtosis", "abstract": "", "cite_num": -1}, "93": {"title": "effective parallelisation for machine learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7226-effective-parallelisation-for-machine-learning", "abstract": "", "cite_num": -1}, "56": {"title": "multi-objective non-parametric sequential prediction.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6929-multi-objective-non-parametric-sequential-prediction", "abstract": "", "cite_num": -1}, "369": {"title": "polynomial codes: an optimal design for high-dimensional coded matrix multiplication.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7027-polynomial-codes-an-optimal-design-for-high-dimensional-coded-matrix-multiplication", "abstract": "", "cite_num": -1}, "356": {"title": "a new theory for matrix completion.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6680-a-new-theory-for-matrix-completion", "abstract": "", "cite_num": -1}, "109": {"title": "value prediction network.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7192-value-prediction-network", "abstract": "", "cite_num": -1}, "71": {"title": "online control of the false discovery rate with decaying memory.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7148-online-control-of-the-false-discovery-rate-with-decaying-memory", "abstract": "", "cite_num": -1}, "378": {"title": "generalizing gans: a turing perspective.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7211-generalizing-gans-a-turing-perspective", "abstract": "", "cite_num": -1}, "584": {"title": "approximation algorithms for l0-low rank approximation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7242-approximation-algorithms-for-ell_0-low-rank-approximation", "abstract": "", "cite_num": -1}, "531": {"title": "pixelgan autoencoders.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6793-pixelgan-autoencoders", "abstract": "", "cite_num": -1}, "181": {"title": "variational inference for gaussian process models with linear complexity.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7103-variational-inference-for-gaussian-process-models-with-linear-complexity", "abstract": "", "cite_num": -1}, "409": {"title": "onacid: online analysis of calcium imaging data in real time.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6832-onacid-online-analysis-of-calcium-imaging-data-in-real-time", "abstract": "", "cite_num": -1}, "160": {"title": "state aware imitation learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6884-state-aware-imitation-learning", "abstract": "", "cite_num": -1}, "524": {"title": "gaussian quadrature for kernel features.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7191-gaussian-quadrature-for-kernel-features", "abstract": "", "cite_num": -1}, "127": {"title": "improved graph laplacian via geometric self-consistency.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7032-improved-graph-laplacian-via-geometric-self-consistency", "abstract": "", "cite_num": -1}, "225": {"title": "multi-armed bandits with metric movement costs.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7000-multi-armed-bandits-with-metric-movement-costs", "abstract": "", "cite_num": -1}, "480": {"title": "detrended partial cross correlation for brain connectivity analysis.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6690-detrended-partial-cross-correlation-for-brain-connectivity-analysis", "abstract": "", "cite_num": -1}, "406": {"title": "multi-agent actor-critic for mixed cooperative-competitive environments.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7217-multi-agent-actor-critic-for-mixed-cooperative-competitive-environments", "abstract": "", "cite_num": -1}, "596": {"title": "polynomial time algorithms for dual volume sampling.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7089-polynomial-time-algorithms-for-dual-volume-sampling", "abstract": "", "cite_num": -1}, "670": {"title": "stochastic submodular maximization: the case of coverage functions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7261-stochastic-submodular-maximization-the-case-of-coverage-functions", "abstract": "", "cite_num": -1}, "379": {"title": "learning disentangled representations with semi-supervised deep generative models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7174-learning-disentangled-representations-with-semi-supervised-deep-generative-models", "abstract": "", "cite_num": -1}, "219": {"title": "group additive structure identification for kernel nonparametric regression.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7076-group-additive-structure-identification-for-kernel-nonparametric-regression", "abstract": "", "cite_num": -1}, "270": {"title": "variational memory addressing in generative models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6981-variational-memory-addressing-in-generative-models", "abstract": "", "cite_num": -1}, "618": {"title": "real-time bidding with side information.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7101-real-time-bidding-with-side-information", "abstract": "", "cite_num": -1}, "351": {"title": "practical hash functions for similarity estimation and dimensionality reduction.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7239-practical-hash-functions-for-similarity-estimation-and-dimensionality-reduction", "abstract": "", "cite_num": -1}, "121": {"title": "svd-softmax: fast softmax approximation on large vocabulary neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7130-svd-softmax-fast-softmax-approximation-on-large-vocabulary-neural-networks", "abstract": "", "cite_num": -1}, "310": {"title": "adversarial surrogate losses for ordinal regression.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6659-adversarial-surrogate-losses-for-ordinal-regression", "abstract": "", "cite_num": -1}, "590": {"title": "inverse filtering for hidden markov models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7008-inverse-filtering-for-hidden-markov-models", "abstract": "", "cite_num": -1}, "230": {"title": "reconstructing perceived faces from brain activations with deep adversarial neural decoding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7012-reconstructing-perceived-faces-from-brain-activations-with-deep-adversarial-neural-decoding", "abstract": "", "cite_num": -1}, "663": {"title": "few-shot learning through an information retrieval lens.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6820-few-shot-learning-through-an-information-retrieval-lens", "abstract": "", "cite_num": -1}, "269": {"title": "the importance of communities for learning to influence.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7168-the-importance-of-communities-for-learning-to-influence", "abstract": "", "cite_num": -1}, "262": {"title": "z-forcing: training stochastic recurrent networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7248-z-forcing-training-stochastic-recurrent-networks", "abstract": "", "cite_num": -1}, "542": {"title": "recurrent ladder networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7182-recurrent-ladder-networks", "abstract": "", "cite_num": -1}, "150": {"title": "learning multiple tasks with multilinear relationship networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6757-learning-multiple-tasks-with-multilinear-relationship-networks", "abstract": "", "cite_num": -1}, "158": {"title": "subset selection and summarization in sequential data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6704-subset-selection-and-summarization-in-sequential-data", "abstract": "", "cite_num": -1}, "336": {"title": "thy friend is my friend: iterative collaborative filtering for sparse matrix estimation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7057-thy-friend-is-my-friend-iterative-collaborative-filtering-for-sparse-matrix-estimation", "abstract": "", "cite_num": -1}, "79": {"title": "practical data-dependent metric compression with provable guarantees.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6855-practical-data-dependent-metric-compression-with-provable-guarantees", "abstract": "", "cite_num": -1}, "566": {"title": "deep mean-shift priors for image restoration.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6678-deep-mean-shift-priors-for-image-restoration", "abstract": "", "cite_num": -1}, "381": {"title": "best response regression.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6748-best-response-regression", "abstract": "", "cite_num": -1}, "316": {"title": "multi-way interacting regression via factorization machines.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6853-multi-way-interacting-regression-via-factorization-machines", "abstract": "", "cite_num": -1}, "633": {"title": "submultiplicative glivenko-cantelli and uniform convergence of revenues.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6763-submultiplicative-glivenko-cantelli-and-uniform-convergence-of-revenues", "abstract": "", "cite_num": -1}, "625": {"title": "lookahead bayesian optimization with inequality constraints.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6785-lookahead-bayesian-optimization-with-inequality-constraints", "abstract": "", "cite_num": -1}, "575": {"title": "non-stationary spectral kernels.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7050-non-stationary-spectral-kernels", "abstract": "", "cite_num": -1}, "512": {"title": "terngrad: ternary gradients to reduce communication in distributed deep learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6749-terngrad-ternary-gradients-to-reduce-communication-in-distributed-deep-learning", "abstract": "", "cite_num": -1}, "78": {"title": "affine-invariant online optimization and the low-rank experts problem.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7060-affine-invariant-online-optimization-and-the-low-rank-experts-problem", "abstract": "", "cite_num": -1}, "291": {"title": "sparse convolutional coding for neuronal assembly detection.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6958-sparse-convolutional-coding-for-neuronal-assembly-detection", "abstract": "", "cite_num": -1}, "508": {"title": "parameter-free online learning via model selection.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7183-parameter-free-online-learning-via-model-selection", "abstract": "", "cite_num": -1}, "420": {"title": "preventing gradient explosions in gated recurrent units.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6647-preventing-gradient-explosions-in-gated-recurrent-units", "abstract": "", "cite_num": -1}, "404": {"title": "accelerated first-order methods for geodesically convex optimization on riemannian manifolds.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7072-accelerated-first-order-methods-for-geodesically-convex-optimization-on-riemannian-manifolds", "abstract": "", "cite_num": -1}, "656": {"title": "union of intersections (uoi) for interpretable data driven discovery and prediction.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6708-union-of-intersections-uoi-for-interpretable-data-driven-discovery-and-prediction", "abstract": "", "cite_num": -1}, "267": {"title": "from bayesian sparsity to gated recurrent nets.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7139-from-bayesian-sparsity-to-gated-recurrent-nets", "abstract": "", "cite_num": -1}, "9": {"title": "on tensor train rank minimization : statistical efficiency and scalable algorithm.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6982-on-tensor-train-rank-minimization-statistical-efficiency-and-scalable-algorithm", "abstract": "", "cite_num": -1}, "530": {"title": "the expressive power of neural networks: a view from the width.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7203-the-expressive-power-of-neural-networks-a-view-from-the-width", "abstract": "", "cite_num": -1}, "85": {"title": "elf: an extensive, lightweight and flexible research platform for real-time strategy games.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6859-elf-an-extensive-lightweight-and-flexible-research-platform-for-real-time-strategy-games", "abstract": "", "cite_num": -1}, "397": {"title": "learned d-amp: principled neural network based compressive image recovery.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6774-learned-d-amp-principled-neural-network-based-compressive-image-recovery", "abstract": "", "cite_num": -1}, "520": {"title": "f-gans in an information geometric nutshell.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6649-f-gans-in-an-information-geometric-nutshell", "abstract": "", "cite_num": -1}, "450": {"title": "nonbacktracking bounds on the influence in independent cascade models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6739-nonbacktracking-bounds-on-the-influence-in-independent-cascade-models", "abstract": "", "cite_num": -1}, "88": {"title": "geometric matrix completion with recurrent multi-graph neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6960-geometric-matrix-completion-with-recurrent-multi-graph-neural-networks", "abstract": "", "cite_num": -1}, "481": {"title": "active learning from peers.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7276-active-learning-from-peers", "abstract": "", "cite_num": -1}, "31": {"title": "hash embeddings for efficient word representations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7078-hash-embeddings-for-efficient-word-representations", "abstract": "", "cite_num": -1}, "29": {"title": "dilated recurrent neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6613-dilated-recurrent-neural-networks", "abstract": "", "cite_num": -1}, "146": {"title": "premise selection for theorem proving by deep graph embedding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6871-premise-selection-for-theorem-proving-by-deep-graph-embedding", "abstract": "", "cite_num": -1}, "94": {"title": "fast, sample-efficient algorithms for structured phase retrieval.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7077-fast-sample-efficient-algorithms-for-structured-phase-retrieval", "abstract": "", "cite_num": -1}, "556": {"title": "recursive sampling for the nystrom method.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6973-recursive-sampling-for-the-nystrom-method", "abstract": "", "cite_num": -1}, "176": {"title": "alice: towards understanding adversarial learning for joint distribution matching.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7133-alice-towards-understanding-adversarial-learning-for-joint-distribution-matching", "abstract": "", "cite_num": -1}, "175": {"title": "sparse approximate conic hulls.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6847-sparse-approximate-conic-hulls", "abstract": "", "cite_num": -1}, "326": {"title": "differentially private empirical risk minimization revisited: faster and more general.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6865-differentially-private-empirical-risk-minimization-revisited-faster-and-more-general", "abstract": "", "cite_num": -1}, "148": {"title": "dropoutnet: addressing cold start in recommender systems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7081-dropoutnet-addressing-cold-start-in-recommender-systems", "abstract": "", "cite_num": -1}, "104": {"title": "adaptive stimulus selection for optimizing neural population responses.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6738-adaptive-stimulus-selection-for-optimizing-neural-population-responses", "abstract": "", "cite_num": -1}, "373": {"title": "online learning with transductive regret.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7106-online-learning-with-transductive-regret", "abstract": "", "cite_num": -1}, "282": {"title": "nonlinear random matrix theory for deep learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6857-nonlinear-random-matrix-theory-for-deep-learning", "abstract": "", "cite_num": -1}, "321": {"title": "learning spherical convolution for fast features from 360\u00b0 imagery.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6656-learning-spherical-convolution-for-fast-features-from-360-imagery", "abstract": "", "cite_num": -1}, "114": {"title": "stochastic mirror descent in variationally coherent optimization problems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7279-stochastic-mirror-descent-in-variationally-coherent-optimization-problems", "abstract": "", "cite_num": -1}, "58": {"title": "learning chordal markov networks via branch and bound.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6781-learning-chordal-markov-networks-via-branch-and-bound", "abstract": "", "cite_num": -1}, "243": {"title": "matching on balanced nonlinear representations for treatment effects estimation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6694-matching-on-balanced-nonlinear-representations-for-treatment-effects-estimation", "abstract": "", "cite_num": -1}, "442": {"title": "triple generative adversarial nets.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6997-triple-generative-adversarial-nets", "abstract": "", "cite_num": -1}, "341": {"title": "successor features for transfer in reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6994-successor-features-for-transfer-in-reinforcement-learning", "abstract": "", "cite_num": -1}, "239": {"title": "optimistic posterior sampling for reinforcement learning: worst-case regret bounds.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6718-optimistic-posterior-sampling-for-reinforcement-learning-worst-case-regret-bounds", "abstract": "", "cite_num": -1}, "408": {"title": "model-based bayesian inference of neural activity and connectivity from all-optical interrogation of a neural circuit.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6940-model-based-bayesian-inference-of-neural-activity-and-connectivity-from-all-optical-interrogation-of-a-neural-circuit", "abstract": "", "cite_num": -1}, "653": {"title": "fast rates for bandit optimization with upper-confidence frank-wolfe.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6817-fast-rates-for-bandit-optimization-with-upper-confidence-frank-wolfe", "abstract": "", "cite_num": -1}, "642": {"title": "overcoming catastrophic forgetting by incremental moment matching.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7051-overcoming-catastrophic-forgetting-by-incremental-moment-matching", "abstract": "", "cite_num": -1}, "403": {"title": "pose guided person image generation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6644-pose-guided-person-image-generation", "abstract": "", "cite_num": -1}, "593": {"title": "variational inference via \\chi upper bound minimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6866-variational-inference-via-chi-upper-bound-minimization", "abstract": "", "cite_num": -1}, "347": {"title": "diffusion approximations for online principal component estimation and global convergence.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6667-diffusion-approximations-for-online-principal-component-estimation-and-global-convergence", "abstract": "", "cite_num": -1}, "617": {"title": "federated multi-task learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7029-federated-multi-task-learning", "abstract": "", "cite_num": -1}, "32": {"title": "decomposable submodular function minimization: discrete and continuous.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6880-decomposable-submodular-function-minimization-discrete-and-continuous", "abstract": "", "cite_num": -1}, "53": {"title": "what-if reasoning using counterfactual gaussian processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6767-what-if-reasoning-using-counterfactual-gaussian-processes", "abstract": "", "cite_num": -1}, "388": {"title": "a sharp error analysis for the fused lasso, with application to approximate changepoint screening.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7264-a-sharp-error-analysis-for-the-fused-lasso-with-application-to-approximate-changepoint-screening", "abstract": "", "cite_num": -1}, "279": {"title": "concentration of multilinear functions of the ising model with applications to network data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6607-concentration-of-multilinear-functions-of-the-ising-model-with-applications-to-network-data", "abstract": "", "cite_num": -1}, "234": {"title": "self-normalizing neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6698-self-normalizing-neural-networks", "abstract": "", "cite_num": -1}, "390": {"title": "joint distribution optimal transportation for domain adaptation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6963-joint-distribution-optimal-transportation-for-domain-adaptation", "abstract": "", "cite_num": -1}, "470": {"title": "mapping distinct timescales of functional interactions among brain networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6999-mapping-distinct-timescales-of-functional-interactions-among-brain-networks", "abstract": "", "cite_num": -1}, "21": {"title": "a simple model of recognition and recall memory.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6633-a-simple-model-of-recognition-and-recall-memory", "abstract": "", "cite_num": -1}, "76": {"title": "tractability in structured probability spaces.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6939-tractability-in-structured-probability-spaces", "abstract": "", "cite_num": -1}, "458": {"title": "linearly constrained gaussian processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6721-linearly-constrained-gaussian-processes", "abstract": "", "cite_num": -1}, "325": {"title": "qsgd: communication-efficient sgd via gradient quantization and encoding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6768-qsgd-communication-efficient-sgd-via-gradient-quantization-and-encoding", "abstract": "", "cite_num": -1}, "482": {"title": "label efficient learning of transferable representations acrosss domains and tasks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6621-label-efficient-learning-of-transferable-representations-acrosss-domains-and-tasks", "abstract": "", "cite_num": -1}, "355": {"title": "matching neural paths: transfer from recognition to correspondence search.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6720-matching-neural-paths-transfer-from-recognition-to-correspondence-search", "abstract": "", "cite_num": -1}, "622": {"title": "estimating accuracy from unlabeled data: a probabilistic logic approach.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7023-estimating-accuracy-from-unlabeled-data-a-probabilistic-logic-approach", "abstract": "", "cite_num": -1}, "51": {"title": "variable importance using decision trees.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6646-variable-importance-using-decision-trees", "abstract": "", "cite_num": -1}, "264": {"title": "structured bayesian pruning via log-normal multiplicative noise.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7254-structured-bayesian-pruning-via-log-normal-multiplicative-noise", "abstract": "", "cite_num": -1}, "42": {"title": "eeg-graph: a factor-graph-based model for capturing spatial, temporal, and observational relationships in electroencephalograms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7121-eeg-graph-a-factor-graph-based-model-for-capturing-spatial-temporal-and-observational-relationships-in-electroencephalograms", "abstract": "", "cite_num": -1}, "396": {"title": "generating steganographic images via adversarial training.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6791-generating-steganographic-images-via-adversarial-training", "abstract": "", "cite_num": -1}, "632": {"title": "bridging the gap between value and policy based reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6870-bridging-the-gap-between-value-and-policy-based-reinforcement-learning", "abstract": "", "cite_num": -1}, "105": {"title": "high-order attention models for visual question answering.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6957-high-order-attention-models-for-visual-question-answering", "abstract": "The quest for algorithms that enable cognitive abilities is an important part of machine learning. A\n common trait in many recently investigated cognitive-like tasks is that they take into account diff\nerent data modalities, such as visual and textual input. In this paper we propose a novel and genera\nlly applicable form of attention mechanism that learns high-order correlations between various data \nmodalities. We show that high-order correlations effectively direct the appropriate attention to the\n relevant elements in the different data modalities that are required to solve the joint task. We de\nmonstrate the effectiveness of our high-order attention mechanism on the task of visual question ans\nwering (VQA), where we achieve state-of-the-art performance on the standard VQA dataset.", "cite_num": 19}, "311": {"title": "associative embedding: end-to-end learning for joint detection and grouping.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6822-associative-embedding-end-to-end-learning-for-joint-detection-and-grouping", "abstract": "", "cite_num": -1}, "315": {"title": "gauging variational inference.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6881-gauging-variational-inference", "abstract": "", "cite_num": -1}, "12": {"title": "certified defenses for data poisoning attacks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6943-certified-defenses-for-data-poisoning-attacks", "abstract": "", "cite_num": -1}, "168": {"title": "regularized modal regression with applications in cognitive impairment prediction.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6743-regularized-modal-regression-with-applications-in-cognitive-impairment-prediction", "abstract": "", "cite_num": -1}, "354": {"title": "gp cake: effective brain connectivity with causal kernels.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6696-gp-cake-effective-brain-connectivity-with-causal-kernels", "abstract": "", "cite_num": -1}, "548": {"title": "generalization properties of learning with random features.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6914-generalization-properties-of-learning-with-random-features", "abstract": "", "cite_num": -1}, "25": {"title": "action centered contextual bandits.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7179-action-centered-contextual-bandits", "abstract": "", "cite_num": -1}, "185": {"title": "veegan: reducing mode collapse in gans using implicit variational learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6923-veegan-reducing-mode-collapse-in-gans-using-implicit-variational-learning", "abstract": "", "cite_num": -1}, "570": {"title": "predictive-state decoders: encoding the future into recurrent networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6717-predictive-state-decoders-encoding-the-future-into-recurrent-networks", "abstract": "", "cite_num": -1}, "452": {"title": "linear regression without correspondence.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6751-linear-regression-without-correspondence", "abstract": "", "cite_num": -1}, "613": {"title": "is input sparsity time possible for kernel low-rank approximation?", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7030-is-input-sparsity-time-possible-for-kernel-low-rank-approximation", "abstract": "", "cite_num": -1}, "144": {"title": "learning relus via gradient descent.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6796-learning-relus-via-gradient-descent", "abstract": "", "cite_num": -1}, "676": {"title": "learning multiple visual domains with residual adapters.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6654-learning-multiple-visual-domains-with-residual-adapters", "abstract": "", "cite_num": -1}, "172": {"title": "an empirical study on the properties of random bases for kernel methods.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6869-an-empirical-study-on-the-properties-of-random-bases-for-kernel-methods", "abstract": "", "cite_num": -1}, "228": {"title": "vain: attentional multi-agent predictive modeling.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6863-vain-attentional-multi-agent-predictive-modeling", "abstract": "Multi-agent predictive modeling is an essential step for understanding physical, social and team-pla\ny systems. Recently, Interaction Networks (INs) were proposed for the task of modeling multi-agent p\nhysical systems, INs scale with the number of interactions in the system (typically quadratic or hig\nher order in the number of agents). In this paper we introduce VAIN, a novel attentional architectur\ne for multi-agent predictive modeling that scales linearly with the number of agents. We show that V\nAIN is effective for multi-agent predictive modeling. Our method is evaluated on tasks from challeng\ning multi-agent prediction domains: chess and soccer, and outperforms competing multi-agent approach\nes.", "cite_num": 26}, "10": {"title": "information theoretic properties of markov random fields, and their algorithmic applications.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6840-information-theoretic-properties-of-markov-random-fields-and-their-algorithmic-applications", "abstract": "", "cite_num": -1}, "111": {"title": "inference in graphical models via semidefinite programming hierarchies.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6645-inference-in-graphical-models-via-semidefinite-programming-hierarchies", "abstract": "", "cite_num": -1}, "669": {"title": "inferring generative model structure with static analysis.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6628-inferring-generative-model-structure-with-static-analysis", "abstract": "", "cite_num": -1}, "673": {"title": "learning overcomplete hmms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6695-learning-overcomplete-hmms", "abstract": "", "cite_num": -1}, "6": {"title": "online learning of optimal bidding strategy in repeated multi-commodity auctions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7037-online-learning-of-optimal-bidding-strategy-in-repeated-multi-commodity-auctions", "abstract": "", "cite_num": -1}, "17": {"title": "continual learning with deep generative replay.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6892-continual-learning-with-deep-generative-replay", "abstract": "", "cite_num": -1}, "61": {"title": "deep dynamic poisson factorization model.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6764-deep-dynamic-poisson-factorization-model", "abstract": "", "cite_num": -1}, "187": {"title": "predrnn: recurrent neural networks for predictive learning using spatiotemporal lstms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6689-predrnn-recurrent-neural-networks-for-predictive-learning-using-spatiotemporal-lstms", "abstract": "", "cite_num": -1}, "22": {"title": "convolutional gaussian processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6877-convolutional-gaussian-processes", "abstract": "", "cite_num": -1}, "196": {"title": "policy gradient with value function approximation for collective multiagent planning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7019-policy-gradient-with-value-function-approximation-for-collective-multiagent-planning", "abstract": "", "cite_num": -1}, "393": {"title": "conic scan-and-cover algorithms for nonparametric topic modeling.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6977-conic-scan-and-cover-algorithms-for-nonparametric-topic-modeling", "abstract": "", "cite_num": -1}, "82": {"title": "good semi-supervised learning that requires a bad gan.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7229-good-semi-supervised-learning-that-requires-a-bad-gan", "abstract": "", "cite_num": -1}, "92": {"title": "from parity to preference-based notions of fairness in classification.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6627-from-parity-to-preference-based-notions-of-fairness-in-classification", "abstract": "", "cite_num": -1}, "473": {"title": "practical locally private heavy hitters.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6823-practical-locally-private-heavy-hitters", "abstract": "", "cite_num": -1}, "179": {"title": "near minimax optimal players for the finite-time 3-expert prediction problem.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6896-near-minimax-optimal-players-for-the-finite-time-3-expert-prediction-problem", "abstract": "", "cite_num": -1}, "309": {"title": "scalable log determinants for gaussian process kernel learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7212-scalable-log-determinants-for-gaussian-process-kernel-learning", "abstract": "", "cite_num": -1}, "614": {"title": "excess risk bounds for the bayes risk using variational inference in latent gaussian models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7100-excess-risk-bounds-for-the-bayes-risk-using-variational-inference-in-latent-gaussian-models", "abstract": "", "cite_num": -1}, "209": {"title": "collecting telemetry data privately.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6948-collecting-telemetry-data-privately", "abstract": "", "cite_num": -1}, "290": {"title": "subset selection under noise.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6947-subset-selection-under-noise", "abstract": "", "cite_num": -1}, "543": {"title": "beyond normality: learning sparse probabilistic graphical models in the non-gaussian setting.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6830-beyond-normality-learning-sparse-probabilistic-graphical-models-in-the-non-gaussian-setting", "abstract": "", "cite_num": -1}, "641": {"title": "learning populations of parameters.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7160-learning-populations-of-parameters", "abstract": "", "cite_num": -1}, "167": {"title": "learning with average top-k loss.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6653-learning-with-average-top-k-loss", "abstract": "", "cite_num": -1}, "319": {"title": "generative local metric learning for kernel regression.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6839-generative-local-metric-learning-for-kernel-regression", "abstract": "", "cite_num": -1}, "605": {"title": "regret analysis for continuous dueling bandit.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6747-regret-analysis-for-continuous-dueling-bandit", "abstract": "", "cite_num": -1}, "44": {"title": "simple and scalable predictive uncertainty estimation using deep ensembles.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7219-simple-and-scalable-predictive-uncertainty-estimation-using-deep-ensembles", "abstract": "", "cite_num": -1}, "173": {"title": "statistical cost sharing.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7202-statistical-cost-sharing", "abstract": "", "cite_num": -1}, "15": {"title": "multi-view matrix factorization for linear dynamical system estimation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7284-multi-view-matrix-factorization-for-linear-dynamical-system-estimation", "abstract": "", "cite_num": -1}, "170": {"title": "learning combinatorial optimization algorithms over graphs.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7214-learning-combinatorial-optimization-algorithms-over-graphs", "abstract": "", "cite_num": -1}, "492": {"title": "efficient online linear optimization with approximation algorithms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6665-efficient-online-linear-optimization-with-approximation-algorithms", "abstract": "", "cite_num": -1}, "398": {"title": "safe model-based reinforcement learning with stability guarantees.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6692-safe-model-based-reinforcement-learning-with-stability-guarantees", "abstract": "", "cite_num": -1}, "18": {"title": "fast black-box variational inference through stochastic trust-region optimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6834-fast-black-box-variational-inference-through-stochastic-trust-region-optimization", "abstract": "", "cite_num": -1}, "134": {"title": "clustering with noisy queries.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7161-clustering-with-noisy-queries", "abstract": "", "cite_num": -1}, "539": {"title": "breaking the nonsmooth barrier: a scalable parallel method for composite optimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6611-breaking-the-nonsmooth-barrier-a-scalable-parallel-method-for-composite-optimization", "abstract": "", "cite_num": -1}, "382": {"title": "gradients of generative models for improved discriminative analysis of tandem mass spectra.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7155-gradients-of-generative-models-for-improved-discriminative-analysis-of-tandem-mass-spectra", "abstract": "", "cite_num": -1}, "579": {"title": "prune: preserving proximity and global ranking for network embedding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7110-prune-preserving-proximity-and-global-ranking-for-network-embedding", "abstract": "", "cite_num": -1}, "118": {"title": "on structured prediction theory with calibrated convex surrogate losses.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6634-on-structured-prediction-theory-with-calibrated-convex-surrogate-losses", "abstract": "", "cite_num": -1}, "178": {"title": "attend and predict: understanding gene regulation by selective attention on chromatin.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7255-attend-and-predict-understanding-gene-regulation-by-selective-attention-on-chromatin", "abstract": "The past decade has seen a revolution in genomic technologies that enabled a flood of genome-wide pr\nofiling of chromatin marks. Recent literature tried to understand gene regulation by predicting gene\n expression from large-scale chromatin measurements. Two fundamental challenges exist for such learn\ning tasks: (1) genome-wide chromatin signals are spatially structured, high-dimensional and highly m\nodular; and (2) the core aim is to understand what are the relevant factors and how they work togeth\ner. Previous studies either failed to model complex dependencies among input signals or relied on se\nparate feature analysis to explain the decisions. This paper presents an attention-based deep learni\nng approach; AttentiveChrome, that uses a unified architecture to model and to interpret dependencie\ns among chromatin factors for controlling gene regulation. AttentiveChrome uses a hierarchy of multi\nple Long Short-Term Memory (LSTM) modules to encode the input signals and to model how various chrom\natin marks cooperate automatically. AttentiveChrome trains two levels of attention jointly with the \ntarget prediction, enabling it to attend differentially to relevant marks and to locate important po\nsitions per mark. We evaluate the model across 56 different cell types (tasks) in human. Not only is\n the proposed architecture more accurate, but its attention scores also provide a better interpretat\nion than state-of-the-art feature visualization methods such as saliency map.", "cite_num": 6}, "194": {"title": "lightgbm: a highly efficient gradient boosting decision tree.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree", "abstract": "", "cite_num": -1}, "348": {"title": "discovering potential correlations via hypercontractivity.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7044-discovering-potential-correlations-via-hypercontractivity", "abstract": "", "cite_num": -1}, "592": {"title": "adaptive active hypothesis testing under limited information.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6992-adaptive-active-hypothesis-testing-under-limited-information", "abstract": "", "cite_num": -1}, "30": {"title": "a regularized framework for sparse and structured neural attention.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6926-a-regularized-framework-for-sparse-and-structured-neural-attention", "abstract": "Modern neural networks are often augmented with an attention mechanism, which tells the network wher\ne to focus within the input. We propose in this paper a new framework for sparse and structured atte\nntion, building upon a smoothed max operator. We show that the gradient of this operator defines a m\napping from real values to probabilities, suitable as an attention mechanism. Our framework includes\n softmax and a slight generalization of the recently-proposed sparsemax as special cases. However, w\ne also show how our framework can incorporate modern structured penalties, resulting in more interpr\netable attention mechanisms, that focus on entire segments or groups of an input. We derive efficien\nt algorithms to compute the forward and backward passes of our attention mechanisms, enabling their \nuse in a neural network trained with backpropagation. To showcase their potential as a drop-in repla\ncement for existing ones, we evaluate our attention mechanisms on three large-scale tasks: textual e\nntailment, machine translation, and sentence summarization. Our attention mechanisms improve interpr\netability without sacrificing performance; notably, on textual entailment and summarization, we outp\nerform the standard attention mechanisms based on softmax and sparsemax.", "cite_num": 8}, "54": {"title": "non-monotone continuous dr-submodular maximization: structure and algorithms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6652-non-monotone-continuous-dr-submodular-maximization-structure-and-algorithms", "abstract": "", "cite_num": -1}, "424": {"title": "generalized linear model regression under distance-to-set penalties.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6737-generalized-linear-model-regression-under-distance-to-set-penalties", "abstract": "", "cite_num": -1}, "461": {"title": "communication-efficient distributed learning of discrete distributions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7218-communication-efficient-distributed-learning-of-discrete-distributions", "abstract": "", "cite_num": -1}, "577": {"title": "gradient methods for submodular maximization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7166-gradient-methods-for-submodular-maximization", "abstract": "", "cite_num": -1}, "651": {"title": "near optimal sketching of low-rank tensor regression.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6938-near-optimal-sketching-of-low-rank-tensor-regression", "abstract": "", "cite_num": -1}, "320": {"title": "deconvolutional paragraph representation learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7005-deconvolutional-paragraph-representation-learning", "abstract": "", "cite_num": -1}, "203": {"title": "asynchronous parallel coordinate minimization for map inference.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7156-asynchronous-parallel-coordinate-minimization-for-map-inference", "abstract": "", "cite_num": -1}, "27": {"title": "when cyclic coordinate descent outperforms randomized coordinate descent.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7275-when-cyclic-coordinate-descent-outperforms-randomized-coordinate-descent", "abstract": "", "cite_num": -1}, "328": {"title": "deep hyperspherical learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6984-deep-hyperspherical-learning", "abstract": "", "cite_num": -1}, "151": {"title": "principles of riemannian geometry in neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6873-principles-of-riemannian-geometry-in-neural-networks", "abstract": "", "cite_num": -1}, "457": {"title": "doubly stochastic variational inference for deep gaussian processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7045-doubly-stochastic-variational-inference-for-deep-gaussian-processes", "abstract": "", "cite_num": -1}, "423": {"title": "visual interaction networks: learning a physics simulator from video.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7040-visual-interaction-networks-learning-a-physics-simulator-from-video", "abstract": "", "cite_num": -1}, "389": {"title": "query complexity of clustering with side information.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7054-query-complexity-of-clustering-with-side-information", "abstract": "", "cite_num": -1}, "460": {"title": "houdini: fooling deep structured visual and speech recognition models with adversarial examples.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7273-houdini-fooling-deep-structured-visual-and-speech-recognition-models-with-adversarial-examples", "abstract": "", "cite_num": -1}, "223": {"title": "hierarchical implicit models and likelihood-free variational inference.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7136-hierarchical-implicit-models-and-likelihood-free-variational-inference", "abstract": "", "cite_num": -1}, "582": {"title": "hypothesis transfer learning via transformation functions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6660-hypothesis-transfer-learning-via-transformation-functions", "abstract": "", "cite_num": -1}, "252": {"title": "stein variational gradient descent as gradient flow.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6904-stein-variational-gradient-descent-as-gradient-flow", "abstract": "", "cite_num": -1}, "493": {"title": "robust conditional probabilities.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7215-robust-conditional-probabilities", "abstract": "", "cite_num": -1}, "588": {"title": "cold-start reinforcement learning with softmax policy gradient.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6874-cold-start-reinforcement-learning-with-softmax-policy-gradient", "abstract": "", "cite_num": -1}, "216": {"title": "shallow updates for deep reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6906-shallow-updates-for-deep-reinforcement-learning", "abstract": "", "cite_num": -1}, "16": {"title": "learning graph representations with embedding propagation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7097-learning-graph-representations-with-embedding-propagation", "abstract": "", "cite_num": -1}, "115": {"title": "deep subspace clustering networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6608-deep-subspace-clustering-networks", "abstract": "", "cite_num": -1}, "564": {"title": "when worlds collide: integrating different counterfactual assumptions in fairness.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7220-when-worlds-collide-integrating-different-counterfactual-assumptions-in-fairness", "abstract": "", "cite_num": -1}, "415": {"title": "collaborative pac learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6833-collaborative-pac-learning", "abstract": "", "cite_num": -1}, "139": {"title": "universal consistency and minimax rates for online mondrian forests.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6966-universal-consistency-and-minimax-rates-for-online-mondrian-forests", "abstract": "", "cite_num": -1}, "340": {"title": "train longer, generalize better: closing the generalization gap in large batch training of neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6770-train-longer-generalize-better-closing-the-generalization-gap-in-large-batch-training-of-neural-networks", "abstract": "", "cite_num": -1}, "443": {"title": "sparse embedded k-means clustering.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6924-sparse-embedded-k-means-clustering", "abstract": "", "cite_num": -1}, "301": {"title": "gibbsnet: iterative adversarial inference for deep graphical models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7094-gibbsnet-iterative-adversarial-inference-for-deep-graphical-models", "abstract": "", "cite_num": -1}, "597": {"title": "kernel functions based on triplet comparisons.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7257-kernel-functions-based-on-triplet-comparisons", "abstract": "", "cite_num": -1}, "445": {"title": "subspace clustering via tangent cones.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7251-subspace-clustering-via-tangent-cones", "abstract": "", "cite_num": -1}, "554": {"title": "structured embedding models for grouped data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6629-structured-embedding-models-for-grouped-data", "abstract": "", "cite_num": -1}, "490": {"title": "yass: yet another spike sorter.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6989-yass-yet-another-spike-sorter", "abstract": "", "cite_num": -1}, "43": {"title": "eigen-distortions of hierarchical representations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6944-eigen-distortions-of-hierarchical-representations", "abstract": "", "cite_num": -1}, "472": {"title": "cross-spectral factor analysis.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7260-cross-spectral-factor-analysis", "abstract": "", "cite_num": -1}, "69": {"title": "improved training of wasserstein gans.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans", "abstract": "", "cite_num": -1}, "298": {"title": "doubly accelerated stochastic variance reduced dual averaging method for regularized empirical risk minimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6663-doubly-accelerated-stochastic-variance-reduced-dual-averaging-method-for-regularized-empirical-risk-minimization", "abstract": "", "cite_num": -1}, "428": {"title": "collapsed variational bayes for markov jump processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6965-collapsed-variational-bayes-for-markov-jump-processes", "abstract": "", "cite_num": -1}, "46": {"title": "the scaling limit of high-dimensional online independent component analysis.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7241-the-scaling-limit-of-high-dimensional-online-independent-component-analysis", "abstract": "", "cite_num": -1}, "75": {"title": "identifying outlier arms in multi-armed bandit.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7105-identifying-outlier-arms-in-multi-armed-bandit", "abstract": "", "cite_num": -1}, "399": {"title": "style transfer from non-parallel text by cross-alignment.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7259-style-transfer-from-non-parallel-text-by-cross-alignment", "abstract": "", "cite_num": -1}, "427": {"title": "the unreasonable effectiveness of structured random orthogonal embeddings.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6626-the-unreasonable-effectiveness-of-structured-random-orthogonal-embeddings", "abstract": "", "cite_num": -1}, "0": {"title": "wider and deeper, cheaper and faster: tensorized lstms for sequence learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6606-wider-and-deeper-cheaper-and-faster-tensorized-lstms-for-sequence-learning", "abstract": "", "cite_num": -1}, "240": {"title": "deep sets.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6931-deep-sets", "abstract": "", "cite_num": -1}, "421": {"title": "end-to-end differentiable proving.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6969-end-to-end-differentiable-proving", "abstract": "", "cite_num": -1}, "143": {"title": "deep hyperalignment.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6758-deep-hyperalignment", "abstract": "", "cite_num": -1}, "447": {"title": "pass-glm: polynomial approximate sufficient statistics for scalable bayesian glm inference.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6952-pass-glm-polynomial-approximate-sufficient-statistics-for-scalable-bayesian-glm-inference", "abstract": "", "cite_num": -1}, "437": {"title": "on frank-wolfe and equilibrium computation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7236-on-frank-wolfe-and-equilibrium-computation", "abstract": "", "cite_num": -1}, "26": {"title": "a kl-lucb algorithm for large-scale crowdsourcing.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7171-a-kl-lucb-algorithm-for-large-scale-crowdsourcing", "abstract": "", "cite_num": -1}, "574": {"title": "the reversible residual network: backpropagation without storing activations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6816-the-reversible-residual-network-backpropagation-without-storing-activations", "abstract": "", "cite_num": -1}, "62": {"title": "parallel streaming wasserstein barycenters.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6858-parallel-streaming-wasserstein-barycenters", "abstract": "", "cite_num": -1}, "666": {"title": "bayesian optimization with gradients.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7111-bayesian-optimization-with-gradients", "abstract": "", "cite_num": -1}, "329": {"title": "greedy algorithms for cone constrained optimization with convergence guarantees.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6679-greedy-algorithms-for-cone-constrained-optimization-with-convergence-guarantees", "abstract": "", "cite_num": -1}, "446": {"title": "the numerics of gans.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6779-the-numerics-of-gans", "abstract": "", "cite_num": -1}, "276": {"title": "expectation propagation for t-exponential family using q-algebra.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6819-expectation-propagation-for-t-exponential-family-using-q-algebra", "abstract": "", "cite_num": -1}, "314": {"title": "fisher gan.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6845-fisher-gan", "abstract": "", "cite_num": -1}, "213": {"title": "probabilistic models for integration error in the assessment of functional cardiac models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6616-probabilistic-models-for-integration-error-in-the-assessment-of-functional-cardiac-models", "abstract": "", "cite_num": -1}, "643": {"title": "nonparametric online regression while learning the metric.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6669-nonparametric-online-regression-while-learning-the-metric", "abstract": "", "cite_num": -1}, "435": {"title": "a greedy approach for budgeted maximum inner product search.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7129-a-greedy-approach-for-budgeted-maximum-inner-product-search", "abstract": "", "cite_num": -1}, "265": {"title": "mean field residual networks: on the edge of chaos.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6879-mean-field-residual-networks-on-the-edge-of-chaos", "abstract": "", "cite_num": -1}, "363": {"title": "deep reinforcement learning from human preferences.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7017-deep-reinforcement-learning-from-human-preferences", "abstract": "", "cite_num": -1}, "33": {"title": "the power of absolute discounting: all-dimensional distribution estimation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7243-the-power-of-absolute-discounting-all-dimensional-distribution-estimation", "abstract": "", "cite_num": -1}, "483": {"title": "label distribution learning forests.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6685-label-distribution-learning-forests", "abstract": "", "cite_num": -1}, "324": {"title": "graph matching via multiplicative update algorithm.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6911-graph-matching-via-multiplicative-update-algorithm", "abstract": "", "cite_num": -1}, "558": {"title": "positive-unlabeled learning with non-negative risk estimator.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6765-positive-unlabeled-learning-with-non-negative-risk-estimator", "abstract": "", "cite_num": -1}, "247": {"title": "estimation of the covariance structure of heavy-tailed distributions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6878-estimation-of-the-covariance-structure-of-heavy-tailed-distributions", "abstract": "", "cite_num": -1}, "180": {"title": "flexpoint: an adaptive numerical format for efficient training of deep neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6771-flexpoint-an-adaptive-numerical-format-for-efficient-training-of-deep-neural-networks", "abstract": "", "cite_num": -1}, "183": {"title": "noise-tolerant interactive learning using pairwise comparisons.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6837-noise-tolerant-interactive-learning-using-pairwise-comparisons", "abstract": "", "cite_num": -1}, "278": {"title": "repeated inverse reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6778-repeated-inverse-reinforcement-learning", "abstract": "", "cite_num": -1}, "372": {"title": "distral: robust multitask reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7036-distral-robust-multitask-reinforcement-learning", "abstract": "", "cite_num": -1}, "343": {"title": "neural system identification for large populations separating \"what\" and \"where\".", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6942-neural-system-identification-for-large-populations-separating-what-and-where", "abstract": "", "cite_num": -1}, "108": {"title": "poincar\u00e9 embeddings for learning hierarchical representations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7213-poincare-embeddings-for-learning-hierarchical-representations", "abstract": "", "cite_num": -1}, "405": {"title": "efficient second-order online kernel learning with adaptive embedding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7194-efficient-second-order-online-kernel-learning-with-adaptive-embedding", "abstract": "", "cite_num": -1}, "211": {"title": "online learning with a hint.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7114-online-learning-with-a-hint", "abstract": "", "cite_num": -1}, "489": {"title": "a learning error analysis for structured prediction with approximate inference.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7193-a-learning-error-analysis-for-structured-prediction-with-approximate-inference", "abstract": "", "cite_num": -1}, "658": {"title": "learning identifiable gaussian bayesian networks in polynomial time and sample complexity.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7224-learning-identifiable-gaussian-bayesian-networks-in-polynomial-time-and-sample-complexity", "abstract": "", "cite_num": -1}, "418": {"title": "on blackbox backpropagation and jacobian sensing.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7230-on-blackbox-backpropagation-and-jacobian-sensing", "abstract": "", "cite_num": -1}, "117": {"title": "best of both worlds: transferring knowledge from discriminative learning to a generative visual dialog model.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6635-best-of-both-worlds-transferring-knowledge-from-discriminative-learning-to-a-generative-visual-dialog-model", "abstract": "", "cite_num": -1}, "674": {"title": "stochastic and adversarial online learning without hyperparameters.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7091-stochastic-and-adversarial-online-learning-without-hyperparameters", "abstract": "", "cite_num": -1}, "212": {"title": "solid harmonic wavelet scattering: predicting quantum molecular energy from invariant descriptors of 3d electronic densities.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7232-solid-harmonic-wavelet-scattering-predicting-quantum-molecular-energy-from-invariant-descriptors-of-3d-electronic-densities", "abstract": "", "cite_num": -1}, "275": {"title": "decoupling \"when to update\" from \"how to update\".", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6697-decoupling-when-to-update-from-how-to-update", "abstract": "", "cite_num": -1}, "200": {"title": "analyzing hidden representations in end-to-end automatic speech recognition systems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6838-analyzing-hidden-representations-in-end-to-end-automatic-speech-recognition-systems", "abstract": "", "cite_num": -1}, "648": {"title": "accelerated stochastic greedy coordinate descent by soft thresholding projection onto simplex.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7069-accelerated-stochastic-greedy-coordinate-descent-by-soft-thresholding-projection-onto-simplex", "abstract": "", "cite_num": -1}, "37": {"title": "log-normality and skewness of estimated state/action values in reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6777-log-normality-and-skewness-of-estimated-stateaction-values-in-reinforcement-learning", "abstract": "", "cite_num": -1}, "184": {"title": "unified representation of tractography and diffusion-weighted mri data using sparse multidimensional arrays.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7021-unified-representation-of-tractography-and-diffusion-weighted-mri-data-using-sparse-multidimensional-arrays", "abstract": "", "cite_num": -1}, "384": {"title": "infogail: interpretable imitation learning from visual demonstrations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations", "abstract": "", "cite_num": -1}, "634": {"title": "interpretable and globally optimal prediction for textual grounding using image concepts.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6787-interpretable-and-globally-optimal-prediction-for-textual-grounding-using-image-concepts", "abstract": "", "cite_num": -1}, "222": {"title": "fitting low-rank tensors in constant time.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6841-fitting-low-rank-tensors-in-constant-time", "abstract": "", "cite_num": -1}, "349": {"title": "model evidence from nonequilibrium simulations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6772-model-evidence-from-nonequilibrium-simulations", "abstract": "", "cite_num": -1}, "678": {"title": "rebar: low-variance, unbiased gradient estimates for discrete latent variable models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6856-rebar-low-variance-unbiased-gradient-estimates-for-discrete-latent-variable-models", "abstract": "", "cite_num": -1}, "563": {"title": "solving most systems of random quadratic equations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6783-solving-most-systems-of-random-quadratic-equations", "abstract": "", "cite_num": -1}, "1": {"title": "fully decentralized policies for multi-agent systems: an information theoretic approach.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6887-fully-decentralized-policies-for-multi-agent-systems-an-information-theoretic-approach", "abstract": "", "cite_num": -1}, "519": {"title": "sample and computationally efficient learning algorithms under s-concave distributions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7065-sample-and-computationally-efficient-learning-algorithms-under-s-concave-distributions", "abstract": "", "cite_num": -1}, "610": {"title": "streaming sparse gaussian process approximations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6922-streaming-sparse-gaussian-process-approximations", "abstract": "", "cite_num": -1}, "400": {"title": "linear time computation of moments in sum-product networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7265-linear-time-computation-of-moments-in-sum-product-networks", "abstract": "", "cite_num": -1}, "380": {"title": "finite sample analysis of the gtd policy evaluation algorithms in markov setting.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7134-finite-sample-analysis-of-the-gtd-policy-evaluation-algorithms-in-markov-setting", "abstract": "", "cite_num": -1}, "487": {"title": "estimating mutual information for discrete-continuous mixtures.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7180-estimating-mutual-information-for-discrete-continuous-mixtures", "abstract": "", "cite_num": -1}, "96": {"title": "expectation propagation with stochastic kinetic model in complex interaction systems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6798-expectation-propagation-with-stochastic-kinetic-model-in-complex-interaction-systems", "abstract": "", "cite_num": -1}, "260": {"title": "local aggregative games.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7118-local-aggregative-games", "abstract": "", "cite_num": -1}, "133": {"title": "multiscale semi-markov dynamics for intracortical brain-computer interfaces.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6688-multiscale-semi-markov-dynamics-for-intracortical-brain-computer-interfaces", "abstract": "", "cite_num": -1}, "464": {"title": "dpscreen: dynamic personalized screening.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6731-dpscreen-dynamic-personalized-screening", "abstract": "", "cite_num": -1}, "387": {"title": "toward robustness against label noise in training deep discriminative neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7143-toward-robustness-against-label-noise-in-training-deep-discriminative-neural-networks", "abstract": "", "cite_num": -1}, "161": {"title": "maxing and ranking with few assumptions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7281-maxing-and-ranking-with-few-assumptions", "abstract": "", "cite_num": -1}, "514": {"title": "unifying pac and regret: uniform pac bounds for episodic reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7154-unifying-pac-and-regret-uniform-pac-bounds-for-episodic-reinforcement-learning", "abstract": "", "cite_num": -1}, "14": {"title": "hierarchical clustering beyond the worst-case.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7200-hierarchical-clustering-beyond-the-worst-case", "abstract": "", "cite_num": -1}, "49": {"title": "contrastive learning for image captioning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6691-contrastive-learning-for-image-captioning", "abstract": "", "cite_num": -1}, "97": {"title": "unsupervised learning of disentangled and interpretable representations from sequential data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6784-unsupervised-learning-of-disentangled-and-interpretable-representations-from-sequential-data", "abstract": "", "cite_num": -1}, "226": {"title": "unsupervised sequence classification using sequential output statistics.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6946-unsupervised-sequence-classification-using-sequential-output-statistics", "abstract": "", "cite_num": -1}, "65": {"title": "scalable model selection for belief networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7047-scalable-model-selection-for-belief-networks", "abstract": "", "cite_num": -1}, "52": {"title": "probabilistic rule realization and selection.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6754-probabilistic-rule-realization-and-selection", "abstract": "", "cite_num": -1}, "68": {"title": "multiresolution kernel approximation for gaussian process regression.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6964-multiresolution-kernel-approximation-for-gaussian-process-regression", "abstract": "", "cite_num": -1}, "553": {"title": "multi-modal imitation learning from unstructured demonstrations using generative adversarial nets.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6723-multi-modal-imitation-learning-from-unstructured-demonstrations-using-generative-adversarial-nets", "abstract": "Imitation learning has traditionally been applied to learn a single task from demonstrations thereof\n. The requirement of structured and isolated demonstrations limits the scalability of imitation lear\nning approaches as they are difficult to apply to real-world scenarios, where robots have to be able\n to execute a multitude of tasks. In this paper, we propose a multi-modal imitation learning framewo\nrk that is able to segment and imitate skills from unlabelled and unstructured demonstrations by lea\nrning skill segmentation and imitation learning jointly. The extensive simulation results indicate t\nhat our method can efficiently separate the demonstrations into individual skills and learn to imita\nte them using a single multi-modal policy. The video of our experiments is available at this http UR\nL", "cite_num": 20}, "370": {"title": "near-optimal edge evaluation in explicit generalized binomial graphs.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7049-near-optimal-edge-evaluation-in-explicit-generalized-binomial-graphs", "abstract": "", "cite_num": -1}, "266": {"title": "inductive representation learning on large graphs.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6703-inductive-representation-learning-on-large-graphs", "abstract": "", "cite_num": -1}, "106": {"title": "deep multi-task gaussian processes for survival analysis with competing risks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6827-deep-multi-task-gaussian-processes-for-survival-analysis-with-competing-risks", "abstract": "", "cite_num": -1}, "647": {"title": "multi-output polynomial networks and factorization machines.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6927-multi-output-polynomial-networks-and-factorization-machines", "abstract": "", "cite_num": -1}, "38": {"title": "variance-based regularization with convex objectives.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6890-variance-based-regularization-with-convex-objectives", "abstract": "", "cite_num": -1}, "608": {"title": "robust and efficient transfer learning with hidden parameter markov decision processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7205-robust-and-efficient-transfer-learning-with-hidden-parameter-markov-decision-processes", "abstract": "", "cite_num": -1}, "130": {"title": "spectrally-normalized margin bounds for neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7204-spectrally-normalized-margin-bounds-for-neural-networks", "abstract": "", "cite_num": -1}, "631": {"title": "interactive submodular bandit.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6619-interactive-submodular-bandit", "abstract": "", "cite_num": -1}, "274": {"title": "formal guarantees on the robustness of a classifier against adversarial manipulation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6821-formal-guarantees-on-the-robustness-of-a-classifier-against-adversarial-manipulation", "abstract": "", "cite_num": -1}, "536": {"title": "higher-order total variation classes on grids: minimax theory and trend filtering methods.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7162-higher-order-total-variation-classes-on-grids-minimax-theory-and-trend-filtering-methods", "abstract": "", "cite_num": -1}, "628": {"title": "few-shot adversarial domain adaptation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7244-few-shot-adversarial-domain-adaptation", "abstract": "", "cite_num": -1}, "522": {"title": "boltzmann exploration done right.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7208-boltzmann-exploration-done-right", "abstract": "", "cite_num": -1}, "364": {"title": "conservative contextual linear bandits.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6980-conservative-contextual-linear-bandits", "abstract": "", "cite_num": -1}, "317": {"title": "predictive state recurrent neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7186-predictive-state-recurrent-neural-networks", "abstract": "", "cite_num": -1}, "511": {"title": "on separability of loss functions, and revisiting discriminative vs generative models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7280-on-separability-of-loss-functions-and-revisiting-discriminative-vs-generative-models", "abstract": "", "cite_num": -1}, "495": {"title": "rigorous dynamics and consistent estimation in arbitrarily conditioned linear systems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6848-rigorous-dynamics-and-consistent-estimation-in-arbitrarily-conditioned-linear-systems", "abstract": "", "cite_num": -1}, "677": {"title": "clustering stable instances of euclidean k-means.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7228-clustering-stable-instances-of-euclidean-k-means", "abstract": "", "cite_num": -1}, "23": {"title": "schnet: a continuous-filter convolutional neural network for modeling quantum interactions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6700-schnet-a-continuous-filter-convolutional-neural-network-for-modeling-quantum-interactions", "abstract": "", "cite_num": -1}, "533": {"title": "a framework for multi-a(rmed)/b(andit) testing with online fdr control.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7177-a-framework-for-multi-armedbandit-testing-with-online-fdr-control", "abstract": "", "cite_num": -1}, "242": {"title": "learning to model the tail.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7278-learning-to-model-the-tail", "abstract": "", "cite_num": -1}, "123": {"title": "time-dependent spatially varying graphical models, with application to brain fmri data analysis.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7165-time-dependent-spatially-varying-graphical-models-with-application-to-brain-fmri-data-analysis", "abstract": "", "cite_num": -1}, "327": {"title": "robust hypothesis test for nonlinear effect with gaussian processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6681-robust-hypothesis-test-for-nonlinear-effect-with-gaussian-processes", "abstract": "", "cite_num": -1}, "667": {"title": "using options and covariance testing for long horizon off-policy policy evaluation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6843-using-options-and-covariance-testing-for-long-horizon-off-policy-policy-evaluation", "abstract": "", "cite_num": -1}, "205": {"title": "simple strategies for recovering inner products from coarsely quantized random projections.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7043-simple-strategies-for-recovering-inner-products-from-coarsely-quantized-random-projections", "abstract": "", "cite_num": -1}, "529": {"title": "speeding up latent variable gaussian graphical model estimation via nonconvex optimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6789-speeding-up-latent-variable-gaussian-graphical-model-estimation-via-nonconvex-optimization", "abstract": "", "cite_num": -1}, "138": {"title": "#exploration: a study of count-based exploration for deep reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6868-exploration-a-study-of-count-based-exploration-for-deep-reinforcement-learning", "abstract": "", "cite_num": -1}, "120": {"title": "integration methods and optimization algorithms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6711-integration-methods-and-optimization-algorithms", "abstract": "", "cite_num": -1}, "112": {"title": "cortical microcircuits as gated-recurrent neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6631-cortical-microcircuits-as-gated-recurrent-neural-networks", "abstract": "", "cite_num": -1}, "296": {"title": "a multi-agent reinforcement learning model of common-pool resource appropriation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6955-a-multi-agent-reinforcement-learning-model-of-common-pool-resource-appropriation", "abstract": "", "cite_num": -1}, "591": {"title": "geometric descent method for convex composite minimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6666-geometric-descent-method-for-convex-composite-minimization", "abstract": "", "cite_num": -1}, "312": {"title": "language modeling with recurrent highway hypernetworks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6919-language-modeling-with-recurrent-highway-hypernetworks", "abstract": "", "cite_num": -1}, "45": {"title": "deep learning for precipitation nowcasting: a benchmark and a new model.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7145-deep-learning-for-precipitation-nowcasting-a-benchmark-and-a-new-model", "abstract": "", "cite_num": -1}, "60": {"title": "structured generative adversarial networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6979-structured-generative-adversarial-networks", "abstract": "", "cite_num": -1}, "233": {"title": "parametric simplex method for sparse learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6623-parametric-simplex-method-for-sparse-learning", "abstract": "", "cite_num": -1}, "636": {"title": "learning to compose domain-specific transformations for data augmentation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6916-learning-to-compose-domain-specific-transformations-for-data-augmentation", "abstract": "", "cite_num": -1}, "638": {"title": "nonlinear acceleration of stochastic algorithms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6987-nonlinear-acceleration-of-stochastic-algorithms", "abstract": "", "cite_num": -1}, "488": {"title": "unbiased estimates for linear regression via volume sampling.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6901-unbiased-estimates-for-linear-regression-via-volume-sampling", "abstract": "", "cite_num": -1}, "515": {"title": "one-shot imitation learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6709-one-shot-imitation-learning", "abstract": "", "cite_num": -1}, "371": {"title": "multi-view decision processes: the helper-ai problem.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7128-multi-view-decision-processes-the-helper-ai-problem", "abstract": "", "cite_num": -1}, "432": {"title": "on optimal generalizability in parametric learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6937-on-optimal-generalizability-in-parametric-learning", "abstract": "", "cite_num": -1}, "220": {"title": "on the optimization landscape of tensor decompositions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6956-on-the-optimization-landscape-of-tensor-decompositions", "abstract": "", "cite_num": -1}, "407": {"title": "convergence of gradient em on multi-component mixture of gaussians.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7271-convergence-of-gradient-em-on-multi-component-mixture-of-gaussians", "abstract": "", "cite_num": -1}, "199": {"title": "pointnet++: deep hierarchical feature learning on point sets in a metric space.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space", "abstract": "", "cite_num": -1}, "155": {"title": "accuracy first: selecting a differential privacy level for accuracy constrained erm.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6850-accuracy-first-selecting-a-differential-privacy-level-for-accuracy-constrained-erm", "abstract": "", "cite_num": -1}, "11": {"title": "coded distributed computing for inverse problems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6673-coded-distributed-computing-for-inverse-problems", "abstract": "", "cite_num": -1}, "532": {"title": "a graph-theoretic approach to multitasking.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6805-a-graph-theoretic-approach-to-multitasking", "abstract": "", "cite_num": -1}, "91": {"title": "approximation bounds for hierarchical clustering: average linkage, bisecting k-means, and local search.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6902-approximation-bounds-for-hierarchical-clustering-average-linkage-bisecting-k-means-and-local-search", "abstract": "", "cite_num": -1}, "417": {"title": "early stopping for kernel boosting algorithms: a general analysis with localized complexities.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7187-early-stopping-for-kernel-boosting-algorithms-a-general-analysis-with-localized-complexities", "abstract": "", "cite_num": -1}, "392": {"title": "adversarial ranking for language generation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6908-adversarial-ranking-for-language-generation", "abstract": "", "cite_num": -1}, "162": {"title": "bayesian inference of individualized treatment effects using multi-task gaussian processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6934-bayesian-inference-of-individualized-treatment-effects-using-multi-task-gaussian-processes", "abstract": "", "cite_num": -1}, "581": {"title": "attention is all you need.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7181-attention-is-all-you-need", "abstract": "The dominant sequence transduction models are based on complex recurrent orconvolutional neural netw\norks in an encoder and decoder configuration. The best performing such models also connect the encod\ner and decoder through an attentionm echanisms. We propose a novel, simple network architecture base\nd solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments \non two machine translation tasks show these models to be superiorin quality while being more paralle\nlizable and requiring significantly less timeto train. Our single model with 165 million parameters,\n achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble resul\nt by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-ar\nt with model by 0.7 BLEU, achieving a BLEU score of 41.1.", "cite_num": 2607}, "626": {"title": "what uncertainties do we need in bayesian deep learning for computer vision?", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7141-what-uncertainties-do-we-need-in-bayesian-deep-learning-for-computer-vision", "abstract": "", "cite_num": -1}, "358": {"title": "a simple neural network module for relational reasoning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7082-a-simple-neural-network-module-for-relational-reasoning", "abstract": "", "cite_num": -1}, "659": {"title": "adagan: boosting generative models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7126-adagan-boosting-generative-models", "abstract": "", "cite_num": -1}, "657": {"title": "variational walkback: learning a transition operator as a stochastic recurrent net.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7026-variational-walkback-learning-a-transition-operator-as-a-stochastic-recurrent-net", "abstract": "", "cite_num": -1}, "99": {"title": "neuralfdr: learning discovery thresholds from hypothesis features.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6752-neuralfdr-learning-discovery-thresholds-from-hypothesis-features", "abstract": "", "cite_num": -1}, "438": {"title": "training quantized nets: a deeper understanding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7163-training-quantized-nets-a-deeper-understanding", "abstract": "", "cite_num": -1}, "192": {"title": "learning with feature evolvable streams.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6740-learning-with-feature-evolvable-streams", "abstract": "", "cite_num": -1}, "426": {"title": "sharpness, restart and acceleration.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6712-sharpness-restart-and-acceleration", "abstract": "", "cite_num": -1}, "57": {"title": "limitations on variance-reduction and acceleration schemes for finite sums optimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6945-limitations-on-variance-reduction-and-acceleration-schemes-for-finite-sums-optimization", "abstract": "", "cite_num": -1}, "662": {"title": "towards accurate binary convolutional neural network.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6638-towards-accurate-binary-convolutional-neural-network", "abstract": "", "cite_num": -1}, "451": {"title": "training deep networks without learning rates through coin betting.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6811-training-deep-networks-without-learning-rates-through-coin-betting", "abstract": "", "cite_num": -1}, "440": {"title": "differentially private bayesian learning on distributed data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6915-differentially-private-bayesian-learning-on-distributed-data", "abstract": "", "cite_num": -1}, "627": {"title": "diving into the shallows: a computational perspective on large-scale shallow learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6968-diving-into-the-shallows-a-computational-perspective-on-large-scale-shallow-learning", "abstract": "", "cite_num": -1}, "254": {"title": "fair clustering through fairlets.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7088-fair-clustering-through-fairlets", "abstract": "", "cite_num": -1}, "248": {"title": "acceleration and averaging in stochastic descent dynamics.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7256-acceleration-and-averaging-in-stochastic-descent-dynamics", "abstract": "", "cite_num": -1}, "498": {"title": "uprooting and rerooting higher-order graphical models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6625-uprooting-and-rerooting-higher-order-graphical-models", "abstract": "", "cite_num": -1}, "268": {"title": "eigenvalue decay implies polynomial-time learnability for neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6814-eigenvalue-decay-implies-polynomial-time-learnability-for-neural-networks", "abstract": "", "cite_num": -1}, "491": {"title": "on the complexity of learning neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7135-on-the-complexity-of-learning-neural-networks", "abstract": "", "cite_num": -1}, "293": {"title": "random permutation online isotonic regression.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7006-random-permutation-online-isotonic-regression", "abstract": "", "cite_num": -1}, "509": {"title": "multimodal learning and reasoning for visual question answering.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6658-multimodal-learning-and-reasoning-for-visual-question-answering", "abstract": "Reasoning about entities and their relationships from multimodal data is a key goal of Artificial Ge\nneral Intelligence. The visual question answering (VQA) problem is an excellent way to test such rea\nsoning capabilities of an AI model and its multimodal representation learning. However, the current \nVQA models are over-simplified deep neural networks, comprised of a long short-term memory (LSTM) un\nit for question comprehension and a convolutional neural network (CNN) for learning single image rep\nresentation. We argue that the single visual representation contains a limited and general informati\non about the image contents and thus limits the model reasoning capabilities. In this work we introd\nuce a modular neural network model that learns a multimodal and multifaceted representation of the i\nmage and the question. The proposed model learns to use the multimodal representation to reason abou\nt the image entities and achieves a new state-of-the-art performance on both VQA benchmark datasets,\n VQA v1.0 and v2.0, by a wide margin.", "cite_num": 6}, "48": {"title": "reconstruct & crush network.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7041-reconstruct-crush-network", "abstract": "", "cite_num": -1}, "257": {"title": "teaching machines to describe images with natural language feedback.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7092-teaching-machines-to-describe-images-with-natural-language-feedback", "abstract": "", "cite_num": -1}, "572": {"title": "hindsight experience replay.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7090-hindsight-experience-replay", "abstract": "", "cite_num": -1}, "391": {"title": "aide: an algorithm for measuring the accuracy of probabilistic inference algorithms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6893-aide-an-algorithm-for-measuring-the-accuracy-of-probabilistic-inference-algorithms", "abstract": "", "cite_num": -1}, "374": {"title": "deliberation networks: sequence generation beyond one-pass decoding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6775-deliberation-networks-sequence-generation-beyond-one-pass-decoding", "abstract": "", "cite_num": -1}, "615": {"title": "dual discriminator generative adversarial nets.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6860-dual-discriminator-generative-adversarial-nets", "abstract": "", "cite_num": -1}, "224": {"title": "large-scale quadratically constrained quadratic program via low-discrepancy sequences.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6824-large-scale-quadratically-constrained-quadratic-program-via-low-discrepancy-sequences", "abstract": "", "cite_num": -1}, "13": {"title": "adaptive classification for prediction under a budget.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7058-adaptive-classification-for-prediction-under-a-budget", "abstract": "", "cite_num": -1}, "215": {"title": "compression-aware training of deep networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6687-compression-aware-training-of-deep-networks", "abstract": "", "cite_num": -1}, "660": {"title": "attentional pooling for action recognition.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6609-attentional-pooling-for-action-recognition", "abstract": "We introduce a simple yet surprisingly powerful model to incorporate attention in action recognition\n and human object interaction tasks. Our proposed attention module can be trained with or without ex\ntra supervision, and gives a sizable boost in accuracy while keeping the network size and computatio\nnal cost nearly the same. It leads to significant improvements over state of the art base architectu\nre on three standard action recognition benchmarks across still images and videos, and establishes n\new state of the art on MPII dataset with 12.5% relative improvement. We also perform an extensive an\nalysis of our attention module both empirically and analytically. In terms of the latter, we introdu\nce a novel derivation of bottom-up and top-down attention as low-rank approximations of bilinear poo\nling methods (typically used for fine-grained classification). From this perspective, our attention \nformulation suggests a novel characterization of action recognition as a fine-grained recognition pr\noblem.", "cite_num": 33}, "600": {"title": "bayesian compression for deep learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6921-bayesian-compression-for-deep-learning", "abstract": "", "cite_num": -1}, "277": {"title": "kernel feature selection via conditional covariance minimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7270-kernel-feature-selection-via-conditional-covariance-minimization", "abstract": "", "cite_num": -1}, "335": {"title": "controllable invariance through adversarial feature learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6661-controllable-invariance-through-adversarial-feature-learning", "abstract": "", "cite_num": -1}, "152": {"title": "emergence of language with multi-agent games: learning to communicate with sequences of symbols.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6810-emergence-of-language-with-multi-agent-games-learning-to-communicate-with-sequences-of-symbols", "abstract": "", "cite_num": -1}, "502": {"title": "concrete dropout.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6949-concrete-dropout", "abstract": "", "cite_num": -1}, "359": {"title": "phase transitions in the pooled data problem.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6641-phase-transitions-in-the-pooled-data-problem", "abstract": "", "cite_num": -1}, "578": {"title": "minimax estimation of bandable precision matrices.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7074-minimax-estimation-of-bandable-precision-matrices", "abstract": "", "cite_num": -1}, "500": {"title": "multi-information source optimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7016-multi-information-source-optimization", "abstract": "", "cite_num": -1}, "83": {"title": "can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7117-can-decentralized-algorithms-outperform-centralized-algorithms-a-case-study-for-decentralized-parallel-stochastic-gradient-descent", "abstract": "", "cite_num": -1}, "2": {"title": "recycling privileged learning and distribution matching for fairness.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6670-recycling-privileged-learning-and-distribution-matching-for-fairness", "abstract": "", "cite_num": -1}, "571": {"title": "net-trim: convex pruning of deep neural networks with performance guarantee.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6910-net-trim-convex-pruning-of-deep-neural-networks-with-performance-guarantee", "abstract": "", "cite_num": -1}, "39": {"title": "is the bellman residual a bad proxy?", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6913-is-the-bellman-residual-a-bad-proxy", "abstract": "", "cite_num": -1}, "455": {"title": "a minimax optimal algorithm for crowdsourcing.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7022-a-minimax-optimal-algorithm-for-crowdsourcing", "abstract": "", "cite_num": -1}, "672": {"title": "off-policy evaluation for slate recommendation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6954-off-policy-evaluation-for-slate-recommendation", "abstract": "", "cite_num": -1}, "607": {"title": "a dirichlet mixture model of hawkes processes for event sequence clustering.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6734-a-dirichlet-mixture-model-of-hawkes-processes-for-event-sequence-clustering", "abstract": "", "cite_num": -1}, "294": {"title": "interpolated policy gradient: merging on-policy and off-policy gradient estimation for deep reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6974-interpolated-policy-gradient-merging-on-policy-and-off-policy-gradient-estimation-for-deep-reinforcement-learning", "abstract": "", "cite_num": -1}, "40": {"title": "on fairness and calibration.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7151-on-fairness-and-calibration", "abstract": "", "cite_num": -1}, "459": {"title": "learning to pivot with adversarial networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6699-learning-to-pivot-with-adversarial-networks", "abstract": "", "cite_num": -1}, "604": {"title": "robust optimization for non-convex objectives.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7056-robust-optimization-for-non-convex-objectives", "abstract": "", "cite_num": -1}, "84": {"title": "efficient use of limited-memory accelerators for linear learning on heterogeneous systems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7013-efficient-use-of-limited-memory-accelerators-for-linear-learning-on-heterogeneous-systems", "abstract": "", "cite_num": -1}, "594": {"title": "robust estimation of neural signals in calcium imaging.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6883-robust-estimation-of-neural-signals-in-calcium-imaging", "abstract": "", "cite_num": -1}, "599": {"title": "bregman divergence for stochastic variance reduction: saddle-point and adversarial prediction.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7184-bregman-divergence-for-stochastic-variance-reduction-saddle-point-and-adversarial-prediction", "abstract": "", "cite_num": -1}, "8": {"title": "on the consistency of quick shift.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6610-on-the-consistency-of-quick-shift", "abstract": "", "cite_num": -1}, "523": {"title": "shape and material from sound.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6727-shape-and-material-from-sound", "abstract": "", "cite_num": -1}, "449": {"title": "efficient optimization for linear dynamical systems with applications to clustering and sparse coding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6936-efficient-optimization-for-linear-dynamical-systems-with-applications-to-clustering-and-sparse-coding", "abstract": "", "cite_num": -1}, "165": {"title": "online learning for multivariate hawkes processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7079-online-learning-for-multivariate-hawkes-processes", "abstract": "", "cite_num": -1}, "255": {"title": "online dynamic programming.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6875-online-dynamic-programming", "abstract": "", "cite_num": -1}, "122": {"title": "smooth primal-dual coordinate descent algorithms for nonsmooth convex optimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7167-smooth-primal-dual-coordinate-descent-algorithms-for-nonsmooth-convex-optimization", "abstract": "", "cite_num": -1}, "297": {"title": "neural program meta-induction.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6803-neural-program-meta-induction", "abstract": "", "cite_num": -1}, "323": {"title": "approximation and convergence properties of generative adversarial learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7138-approximation-and-convergence-properties-of-generative-adversarial-learning", "abstract": "", "cite_num": -1}, "119": {"title": "learning mixture of gaussians with streaming data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7238-learning-mixture-of-gaussians-with-streaming-data", "abstract": "", "cite_num": -1}, "518": {"title": "avoiding discrimination through causal reasoning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6668-avoiding-discrimination-through-causal-reasoning", "abstract": "", "cite_num": -1}, "547": {"title": "saliency-based sequential image attention with multiset prediction.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7102-saliency-based-sequential-image-attention-with-multiset-prediction", "abstract": "Humans process visual scenes selectively and sequentially using attention. Central to models of huma\nn visual attention is the saliency map. We propose a hierarchical visual architecture that operates \non a saliency map and uses a novel attention mechanism to sequentially focus on salient regions and \ntake additional glimpses within those regions. The architecture is motivated by human visual attenti\non, and is used for multi-label image classification on a novel multiset task, demonstrating that it\n achieves high precision and recall while localizing objects with its attention. Unlike conventional\n multi-label image classification models, the model supports multiset prediction due to a reinforcem\nent-learning based training process that allows for arbitrary label permutation and multiple instanc\nes per label.", "cite_num": 8}, "250": {"title": "svcca: singular vector canonical correlation analysis for deep learning dynamics and interpretability.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7188-svcca-singular-vector-canonical-correlation-analysis-for-deep-learning-dynamics-and-interpretability", "abstract": "", "cite_num": -1}, "73": {"title": "toward goal-driven neural network models for the rodent whisker-trigeminal system.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6849-toward-goal-driven-neural-network-models-for-the-rodent-whisker-trigeminal-system", "abstract": "", "cite_num": -1}, "499": {"title": "optimal shrinkage of singular values under random data contamination.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7196-optimal-shrinkage-of-singular-values-under-random-data-contamination", "abstract": "", "cite_num": -1}, "300": {"title": "beyond worst-case: a probabilistic analysis of affine policies in dynamic optimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7061-beyond-worst-case-a-probabilistic-analysis-of-affine-policies-in-dynamic-optimization", "abstract": "", "cite_num": -1}, "635": {"title": "a new alternating direction method for linear programming.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6746-a-new-alternating-direction-method-for-linear-programming", "abstract": "", "cite_num": -1}, "609": {"title": "ranking data with continuous labels through oriented recursive partitions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7046-ranking-data-with-continuous-labels-through-oriented-recursive-partitions", "abstract": "", "cite_num": -1}, "232": {"title": "group sparse additive machine.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6624-group-sparse-additive-machine", "abstract": "", "cite_num": -1}, "304": {"title": "a unified game-theoretic approach to multiagent reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7007-a-unified-game-theoretic-approach-to-multiagent-reinforcement-learning", "abstract": "", "cite_num": -1}, "64": {"title": "inverse reward design.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7253-inverse-reward-design", "abstract": "", "cite_num": -1}, "281": {"title": "sticking the landing: simple, lower-variance gradient estimators for variational inference.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7268-sticking-the-landing-simple-lower-variance-gradient-estimators-for-variational-inference", "abstract": "", "cite_num": -1}, "559": {"title": "online convex optimization with stochastic constraints.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6741-online-convex-optimization-with-stochastic-constraints", "abstract": "", "cite_num": -1}, "650": {"title": "straggler mitigation in distributed optimization through data encoding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7127-straggler-mitigation-in-distributed-optimization-through-data-encoding", "abstract": "", "cite_num": -1}, "360": {"title": "maskrnn: instance level video object segmentation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6636-maskrnn-instance-level-video-object-segmentation", "abstract": "", "cite_num": -1}, "20": {"title": "discriminative state space models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7150-discriminative-state-space-models", "abstract": "", "cite_num": -1}, "159": {"title": "deep supervised discrete hashing.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6842-deep-supervised-discrete-hashing", "abstract": "", "cite_num": -1}, "3": {"title": "improving regret bounds for combinatorial semi-bandits with probabilistically triggered arms and its applications.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6716-improving-regret-bounds-for-combinatorial-semi-bandits-with-probabilistically-triggered-arms-and-its-applications", "abstract": "", "cite_num": -1}, "375": {"title": "online reinforcement learning in stochastic games.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7084-online-reinforcement-learning-in-stochastic-games", "abstract": "", "cite_num": -1}, "67": {"title": "predicting scene parsing and motion dynamics in the future.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7267-predicting-scene-parsing-and-motion-dynamics-in-the-future", "abstract": "", "cite_num": -1}, "322": {"title": "optimal sample complexity of m-wise data for top-k ranking.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6766-optimal-sample-complexity-of-m-wise-data-for-top-k-ranking", "abstract": "", "cite_num": -1}, "377": {"title": "imagination-augmented agents for deep reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7152-imagination-augmented-agents-for-deep-reinforcement-learning", "abstract": "", "cite_num": -1}, "603": {"title": "learning to prune deep neural networks via layer-wise optimal brain surgeon.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7071-learning-to-prune-deep-neural-networks-via-layer-wise-optimal-brain-surgeon", "abstract": "", "cite_num": -1}, "251": {"title": "tomography of the london underground: a scalable model for origin-destination data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6899-tomography-of-the-london-underground-a-scalable-model-for-origin-destination-data", "abstract": "", "cite_num": -1}, "549": {"title": "a universal analysis of large-scale regularized least squares solutions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6930-a-universal-analysis-of-large-scale-regularized-least-squares-solutions", "abstract": "", "cite_num": -1}, "306": {"title": "online multiclass boosting.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6693-online-multiclass-boosting", "abstract": "", "cite_num": -1}, "330": {"title": "from which world is your graph.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6745-from-which-world-is-your-graph", "abstract": "", "cite_num": -1}, "87": {"title": "identification of gaussian process state space models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7115-identification-of-gaussian-process-state-space-models", "abstract": "", "cite_num": -1}, "295": {"title": "neural variational inference and learning in undirected graphical models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7250-neural-variational-inference-and-learning-in-undirected-graphical-models", "abstract": "", "cite_num": -1}, "422": {"title": "random projection filter bank for time series data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7234-random-projection-filter-bank-for-time-series-data", "abstract": "", "cite_num": -1}, "227": {"title": "a probabilistic framework for nonlinearities in stochastic neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7035-a-probabilistic-framework-for-nonlinearities-in-stochastic-neural-networks", "abstract": "", "cite_num": -1}, "589": {"title": "learning efficient object detection models with knowledge distillation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6676-learning-efficient-object-detection-models-with-knowledge-distillation", "abstract": "", "cite_num": -1}, "50": {"title": "neural discrete representation learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7210-neural-discrete-representation-learning", "abstract": "", "cite_num": -1}, "237": {"title": "filtering variational objectives.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7235-filtering-variational-objectives", "abstract": "", "cite_num": -1}, "567": {"title": "convolutional phase retrieval.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7189-convolutional-phase-retrieval", "abstract": "", "cite_num": -1}, "535": {"title": "hierarchical attentive recurrent tracking.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6898-hierarchical-attentive-recurrent-tracking", "abstract": "", "cite_num": -1}, "334": {"title": "toward multimodal image-to-image translation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6650-toward-multimodal-image-to-image-translation", "abstract": "Many image-to-image translation problems are ambiguous, as a single input image may correspond to mu\nltiple possible outputs. In this work, we aim to model a \\emph{distribution} of possible outputs in \na conditional generative modeling setting. The ambiguity of the mapping is distilled in a low-dimens\nional latent vector, which can be randomly sampled at test time. A generator learns to map the given\n input, combined with this latent code, to the output. We explicitly encourage the connection betwee\nn output and the latent code to be invertible. This helps prevent a many-to-one mapping from the lat\nent code to the output during training, also known as the problem of mode collapse, and produces mor\ne diverse results. We explore several variants of this approach by employing different training obje\nctives, network architectures, and methods of injecting the latent code. Our proposed method encoura\nges bijective consistency between the latent encoding and output modes. We present a systematic comp\narison of our method and other variants on both perceptual realism and diversity.", "cite_num": 123}, "63": {"title": "max-margin invariant features from transformed unlabelled data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6742-max-margin-invariant-features-from-transformed-unlabelled-data", "abstract": "", "cite_num": -1}, "507": {"title": "scalable variational inference for dynamical systems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7066-scalable-variational-inference-for-dynamical-systems", "abstract": "", "cite_num": -1}, "646": {"title": "consistent robust regression.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6806-consistent-robust-regression", "abstract": "", "cite_num": -1}, "141": {"title": "safe and nested subgame solving for imperfect-information games.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6671-safe-and-nested-subgame-solving-for-imperfect-information-games", "abstract": "", "cite_num": -1}, "305": {"title": "differentiable learning of submodular functions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6702-differentiable-learning-of-submodular-functions", "abstract": "", "cite_num": -1}, "238": {"title": "universal style transfer via feature transforms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6642-universal-style-transfer-via-feature-transforms", "abstract": "", "cite_num": -1}, "246": {"title": "real time image saliency for black box classifiers.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7272-real-time-image-saliency-for-black-box-classifiers", "abstract": "", "cite_num": -1}, "198": {"title": "gradient descent gan optimization is locally stable.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7142-gradient-descent-gan-optimization-is-locally-stable", "abstract": "", "cite_num": -1}, "208": {"title": "fixed-rank approximation of a positive-semidefinite matrix from streaming data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6722-fixed-rank-approximation-of-a-positive-semidefinite-matrix-from-streaming-data", "abstract": "", "cite_num": -1}, "352": {"title": "dynamic-depth context tree weighting.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6925-dynamic-depth-context-tree-weighting", "abstract": "", "cite_num": -1}, "271": {"title": "faster and non-ergodic o(1/k) stochastic alternating direction method of multipliers.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7034-faster-and-non-ergodic-o1k-stochastic-alternating-direction-method-of-multipliers", "abstract": "", "cite_num": -1}, "541": {"title": "bayesian gan.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6953-bayesian-gan", "abstract": "", "cite_num": -1}, "195": {"title": "differentiable learning of logical rules for knowledge base reasoning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6826-differentiable-learning-of-logical-rules-for-knowledge-base-reasoning", "abstract": "", "cite_num": -1}, "468": {"title": "predicting user activity level in point processes with mass transport equation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6762-predicting-user-activity-level-in-point-processes-with-mass-transport-equation", "abstract": "", "cite_num": -1}, "516": {"title": "efficient modeling of latent information in supervised learning using gaussian processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7098-efficient-modeling-of-latent-information-in-supervised-learning-using-gaussian-processes", "abstract": "", "cite_num": -1}, "444": {"title": "safe adaptive importance sampling.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7025-safe-adaptive-importance-sampling", "abstract": "", "cite_num": -1}, "513": {"title": "do deep neural networks suffer from crowding?", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7146-do-deep-neural-networks-suffer-from-crowding", "abstract": "", "cite_num": -1}, "551": {"title": "hiding images in plain sight: deep steganography.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6802-hiding-images-in-plain-sight-deep-steganography", "abstract": "", "cite_num": -1}, "337": {"title": "independence clustering (without a matrix).", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6990-independence-clustering-without-a-matrix", "abstract": "", "cite_num": -1}, "645": {"title": "spectral mixture kernels for multi-output gaussian processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7245-spectral-mixture-kernels-for-multi-output-gaussian-processes", "abstract": "", "cite_num": -1}, "28": {"title": "dynamic revenue sharing.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6861-dynamic-revenue-sharing", "abstract": "", "cite_num": -1}, "562": {"title": "learning to see physics via visual de-animation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6620-learning-to-see-physics-via-visual-de-animation", "abstract": "", "cite_num": -1}, "345": {"title": "on the fine-grained complexity of empirical risk minimization: kernel methods and neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7018-on-the-fine-grained-complexity-of-empirical-risk-minimization-kernel-methods-and-neural-networks", "abstract": "", "cite_num": -1}, "401": {"title": "dual path networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7033-dual-path-networks", "abstract": "", "cite_num": -1}, "190": {"title": "consistent multitask learning with nonlinear output relations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6794-consistent-multitask-learning-with-nonlinear-output-relations", "abstract": "", "cite_num": -1}, "561": {"title": "countering feedback delays in multi-agent learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7197-countering-feedback-delays-in-multi-agent-learning", "abstract": "", "cite_num": -1}, "654": {"title": "active bias: training more accurate neural networks by emphasizing high variance samples.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6701-active-bias-training-more-accurate-neural-networks-by-emphasizing-high-variance-samples", "abstract": "", "cite_num": -1}, "303": {"title": "runtime neural pruning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6813-runtime-neural-pruning", "abstract": "", "cite_num": -1}, "425": {"title": "on quadratic convergence of dc proximal newton algorithm in nonconvex sparse learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6867-on-quadratic-convergence-of-dc-proximal-newton-algorithm-in-nonconvex-sparse-learning", "abstract": "", "cite_num": -1}, "506": {"title": "non-convex finite-sum optimization via scsg methods.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6829-non-convex-finite-sum-optimization-via-scsg-methods", "abstract": "", "cite_num": -1}, "259": {"title": "lower bounds on the robustness to adversarial perturbations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6682-lower-bounds-on-the-robustness-to-adversarial-perturbations", "abstract": "", "cite_num": -1}, "573": {"title": "multiplicative weights update with constant step-size in congestion games: convergence, limit cycles and chaos.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7169-multiplicative-weights-update-with-constant-step-size-in-congestion-games-convergence-limit-cycles-and-chaos", "abstract": "", "cite_num": -1}, "368": {"title": "dynamic importance sampling for anytime bounds of the partition function.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6912-dynamic-importance-sampling-for-anytime-bounds-of-the-partition-function", "abstract": "", "cite_num": -1}, "34": {"title": "learning hierarchical information flow with recurrent neural modules.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7249-learning-hierarchical-information-flow-with-recurrent-neural-modules", "abstract": "", "cite_num": -1}, "302": {"title": "semi-supervised learning with gans: manifold invariance with improved inference.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7137-semi-supervised-learning-with-gans-manifold-invariance-with-improved-inference", "abstract": "", "cite_num": -1}, "217": {"title": "alternating minimization for dictionary learning with random initialization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6795-alternating-minimization-for-dictionary-learning-with-random-initialization", "abstract": "", "cite_num": -1}, "5": {"title": "the marginal value of adaptive gradient methods in machine learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning", "abstract": "", "cite_num": -1}, "171": {"title": "riemannian approach to batch normalization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7107-riemannian-approach-to-batch-normalization", "abstract": "", "cite_num": -1}, "505": {"title": "visual reference resolution using attention memory for visual dialog.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6962-visual-reference-resolution-using-attention-memory-for-visual-dialog", "abstract": "Visual dialog is a task of answering a series of inter-dependent questions given an input image, and\n often requires to resolve visual references among the questions. This problem is different from vis\nual question answering (VQA), which relies on spatial attention (a.k.a. visual grounding) estimated \nfrom an image and question pair. We propose a novel attention mechanism that exploits visual attenti\nons in the past to resolve the current reference in the visual dialog scenario. The proposed model i\ns equipped with an associative attention memory storing a sequence of previous (attention, key) pair\ns. From this memory, the model retrieves the previous attention, taking into account recency, which \nis most relevant for the current question, in order to resolve potentially ambiguous references. The\n model then merges the retrieved attention with a tentative one to obtain the final attention for th\ne current question; specifically, we use dynamic parameter prediction to combine the two attentions \nconditioned on the question. Through extensive experiments on a new synthetic visual dialog dataset,\n we show that our model significantly outperforms the state-of-the-art (by ~16 % points) in situatio\nns, where visual reference resolution plays an important role. Moreover, the proposed model achieves\n superior performance (~ 2 % points improvement) in the Visual Dialog dataset, despite having signif\nicantly fewer parameters than the baselines.", "cite_num": 20}, "332": {"title": "semi-supervised learning for optical flow with generative adversarial networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6639-semi-supervised-learning-for-optical-flow-with-generative-adversarial-networks", "abstract": "", "cite_num": -1}, "140": {"title": "dual-agent gans for photorealistic and identity preserving profile face synthesis.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6612-dual-agent-gans-for-photorealistic-and-identity-preserving-profile-face-synthesis", "abstract": "", "cite_num": -1}, "333": {"title": "a sample complexity measure with applications to learning optimal auctions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7119-a-sample-complexity-measure-with-applications-to-learning-optimal-auctions", "abstract": "", "cite_num": -1}, "308": {"title": "training recurrent networks to generate hypotheses about how the brain solves hard navigation problems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7039-training-recurrent-networks-to-generate-hypotheses-about-how-the-brain-solves-hard-navigation-problems", "abstract": "", "cite_num": -1}, "182": {"title": "natural value approximators: learning when to trust past estimates.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6807-natural-value-approximators-learning-when-to-trust-past-estimates", "abstract": "", "cite_num": -1}, "510": {"title": "a linear-time kernel goodness-of-fit test.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6630-a-linear-time-kernel-goodness-of-fit-test", "abstract": "", "cite_num": -1}, "484": {"title": "partial hard thresholding: towards a principled analysis of support recovery.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6905-partial-hard-thresholding-towards-a-principled-analysis-of-support-recovery", "abstract": "", "cite_num": -1}, "383": {"title": "admm without a fixed penalty parameter: faster convergence with new adaptive penalization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6726-admm-without-a-fixed-penalty-parameter-faster-convergence-with-new-adaptive-penalization", "abstract": "", "cite_num": -1}, "467": {"title": "a decomposition of forecast error in prediction markets.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7024-a-decomposition-of-forecast-error-in-prediction-markets", "abstract": "", "cite_num": -1}, "206": {"title": "self-supervised learning of motion capture.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7108-self-supervised-learning-of-motion-capture", "abstract": "", "cite_num": -1}, "261": {"title": "min-max propagation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7140-min-max-propagation", "abstract": "", "cite_num": -1}, "411": {"title": "renyi differential privacy mechanisms for posterior sampling.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7113-renyi-differential-privacy-mechanisms-for-posterior-sampling", "abstract": "", "cite_num": -1}, "521": {"title": "decomposition-invariant conditional gradient for general polytopes with line search.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6862-decomposition-invariant-conditional-gradient-for-general-polytopes-with-line-search", "abstract": "", "cite_num": -1}, "517": {"title": "context selection for embedding models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7067-context-selection-for-embedding-models", "abstract": "", "cite_num": -1}, "394": {"title": "deep lattice networks and partial monotonic functions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6891-deep-lattice-networks-and-partial-monotonic-functions", "abstract": "", "cite_num": -1}, "149": {"title": "fast-slow recurrent neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7173-fast-slow-recurrent-neural-networks", "abstract": "", "cite_num": -1}, "174": {"title": "sobolev training for neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7015-sobolev-training-for-neural-networks", "abstract": "", "cite_num": -1}, "661": {"title": "near-linear time approximation algorithms for optimal transport via sinkhorn iteration.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6792-near-linear-time-approximation-algorithms-for-optimal-transport-via-sinkhorn-iteration", "abstract": "", "cite_num": -1}, "366": {"title": "pixels to graphs by associative embedding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6812-pixels-to-graphs-by-associative-embedding", "abstract": "", "cite_num": -1}, "164": {"title": "learning causal structures using regression invariance.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6894-learning-causal-structures-using-regression-invariance", "abstract": "", "cite_num": -1}, "89": {"title": "resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7064-resurrecting-the-sigmoid-in-deep-learning-through-dynamical-isometry-theory-and-practice", "abstract": "", "cite_num": -1}, "131": {"title": "ensemble sampling.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6918-ensemble-sampling", "abstract": "", "cite_num": -1}, "77": {"title": "gaussian process based nonlinear latent structure discovery in multivariate spike train data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6941-gaussian-process-based-nonlinear-latent-structure-discovery-in-multivariate-spike-train-data", "abstract": "", "cite_num": -1}, "142": {"title": "extremeweather: a large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6932-extremeweather-a-large-scale-climate-dataset-for-semi-supervised-detection-localization-and-understanding-of-extreme-weather-events", "abstract": "", "cite_num": -1}, "153": {"title": "soft-to-hard vector quantization for end-to-end learning compressible representations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6714-soft-to-hard-vector-quantization-for-end-to-end-learning-compressible-representations", "abstract": "", "cite_num": -1}, "555": {"title": "matrix norm estimation from a few entries.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7221-matrix-norm-estimation-from-a-few-entries", "abstract": "", "cite_num": -1}, "557": {"title": "inhomogeneous hypergraph clustering with applications.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6825-inhomogeneous-hypergraph-clustering-with-applications", "abstract": "", "cite_num": -1}, "503": {"title": "approximate supermodularity bounds for experimental design.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7124-approximate-supermodularity-bounds-for-experimental-design", "abstract": "", "cite_num": -1}, "287": {"title": "practical bayesian optimization for model fitting with bayesian adaptive direct search.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6780-practical-bayesian-optimization-for-model-fitting-with-bayesian-adaptive-direct-search", "abstract": "", "cite_num": -1}, "640": {"title": "efficient and flexible inference for stochastic systems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7274-efficient-and-flexible-inference-for-stochastic-systems", "abstract": "", "cite_num": -1}, "342": {"title": "flexible statistical inference for mechanistic models of neural dynamics.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6728-flexible-statistical-inference-for-mechanistic-models-of-neural-dynamics", "abstract": "", "cite_num": -1}, "630": {"title": "process-constrained batch bayesian optimisation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6933-process-constrained-batch-bayesian-optimisation", "abstract": "", "cite_num": -1}, "72": {"title": "hierarchical methods of moments.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6786-hierarchical-methods-of-moments", "abstract": "", "cite_num": -1}, "545": {"title": "elementary symmetric polynomials for optimal experimental design.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6809-elementary-symmetric-polynomials-for-optimal-experimental-design", "abstract": "", "cite_num": -1}, "163": {"title": "learning a multi-view stereo machine.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6640-learning-a-multi-view-stereo-machine", "abstract": "", "cite_num": -1}, "477": {"title": "thinking fast and slow with deep learning and tree search.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7120-thinking-fast-and-slow-with-deep-learning-and-tree-search", "abstract": "", "cite_num": -1}, "546": {"title": "dynamic safe interruptibility for decentralized multi-agent reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6618-dynamic-safe-interruptibility-for-decentralized-multi-agent-reinforcement-learning", "abstract": "", "cite_num": -1}, "434": {"title": "gans trained by a two time-scale update rule converge to a local nash equilibrium.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7240-gans-trained-by-a-two-time-scale-update-rule-converge-to-a-local-nash-equilibrium", "abstract": "", "cite_num": -1}, "101": {"title": "dualing gans.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7144-dualing-gans", "abstract": "", "cite_num": -1}, "229": {"title": "on the power of truncated svd for general high-rank matrix estimation problems.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6648-on-the-power-of-truncated-svd-for-general-high-rank-matrix-estimation-problems", "abstract": "", "cite_num": -1}, "285": {"title": "rotting bandits.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6900-rotting-bandits", "abstract": "", "cite_num": -1}, "236": {"title": "learning unknown markov decision processes: a thompson sampling approach.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6732-learning-unknown-markov-decision-processes-a-thompson-sampling-approach", "abstract": "", "cite_num": -1}, "416": {"title": "cost efficient gradient boosting.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6753-cost-efficient-gradient-boosting", "abstract": "", "cite_num": -1}, "188": {"title": "non-parametric structured output networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7009-non-parametric-structured-output-networks", "abstract": "", "cite_num": -1}, "478": {"title": "selective classification for deep neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7073-selective-classification-for-deep-neural-networks", "abstract": "", "cite_num": -1}, "98": {"title": "clone mcmc: parallel high-dimensional gaussian gibbs sampling.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7087-clone-mcmc-parallel-high-dimensional-gaussian-gibbs-sampling", "abstract": "", "cite_num": -1}, "550": {"title": "maximizing subset accuracy with recurrent neural networks in multi-label classification.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7125-maximizing-subset-accuracy-with-recurrent-neural-networks-in-multi-label-classification", "abstract": "", "cite_num": -1}, "90": {"title": "testing and learning on distributions with symmetric noise invariance.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6733-testing-and-learning-on-distributions-with-symmetric-noise-invariance", "abstract": "", "cite_num": -1}, "637": {"title": "q-lda: uncovering latent patterns in text-based sequential decision processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7083-q-lda-uncovering-latent-patterns-in-text-based-sequential-decision-processes", "abstract": "", "cite_num": -1}, "671": {"title": "streaming weak submodularity: interpreting neural networks on the fly.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6993-streaming-weak-submodularity-interpreting-neural-networks-on-the-fly", "abstract": "", "cite_num": -1}, "137": {"title": "convergent block coordinate descent for training tikhonov regularized deep neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6769-convergent-block-coordinate-descent-for-training-tikhonov-regularized-deep-neural-networks", "abstract": "", "cite_num": -1}, "621": {"title": "adaptive batch size for safe policy gradients.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6950-adaptive-batch-size-for-safe-policy-gradients", "abstract": "", "cite_num": -1}, "74": {"title": "fader networks: manipulating images by sliding attributes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7178-fader-networksmanipulating-images-by-sliding-attributes", "abstract": "", "cite_num": -1}, "24": {"title": "bayesian dyadic trees and histograms for regression.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6804-bayesian-dyadic-trees-and-histograms-for-regression", "abstract": "", "cite_num": -1}, "598": {"title": "reinforcement learning under model mismatch.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6897-reinforcement-learning-under-model-mismatch", "abstract": "", "cite_num": -1}, "210": {"title": "learning affinity via spatial propagation networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6750-learning-affinity-via-spatial-propagation-networks", "abstract": "", "cite_num": -1}, "587": {"title": "the neural hawkes process: a neurally self-modulating multivariate point process.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7252-the-neural-hawkes-process-a-neurally-self-modulating-multivariate-point-process", "abstract": "", "cite_num": -1}, "365": {"title": "dynamic routing between capsules.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6975-dynamic-routing-between-capsules", "abstract": "", "cite_num": -1}, "644": {"title": "hybrid reward architecture for reinforcement learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7123-hybrid-reward-architecture-for-reinforcement-learning", "abstract": "", "cite_num": -1}, "485": {"title": "welfare guarantees from data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6967-welfare-guarantees-from-data", "abstract": "", "cite_num": -1}, "331": {"title": "stabilizing training of generative adversarial networks through regularization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6797-stabilizing-training-of-generative-adversarial-networks-through-regularization", "abstract": "", "cite_num": -1}, "81": {"title": "mixture-rank matrix approximation for collaborative filtering.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6651-mixture-rank-matrix-approximation-for-collaborative-filtering", "abstract": "", "cite_num": -1}, "430": {"title": "deep recurrent neural network-based identification of precursor micrornas.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6882-deep-recurrent-neural-network-based-identification-of-precursor-micrornas", "abstract": "", "cite_num": -1}, "652": {"title": "a disentangled recognition and nonlinear dynamics model for unsupervised learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6951-a-disentangled-recognition-and-nonlinear-dynamics-model-for-unsupervised-learning", "abstract": "", "cite_num": -1}, "462": {"title": "convergence rates of a partition based bayesian multivariate density estimation method.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7059-convergence-rates-of-a-partition-based-bayesian-multivariate-density-estimation-method", "abstract": "", "cite_num": -1}, "544": {"title": "a pac-bayesian analysis of randomized learning with application to stochastic gradient descent.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6886-a-pac-bayesian-analysis-of-randomized-learning-with-application-to-stochastic-gradient-descent", "abstract": "", "cite_num": -1}, "639": {"title": "learning active learning from data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7010-learning-active-learning-from-data", "abstract": "", "cite_num": -1}, "344": {"title": "machine learning with adversaries: byzantine tolerant gradient descent.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6617-machine-learning-with-adversaries-byzantine-tolerant-gradient-descent", "abstract": "", "cite_num": -1}, "338": {"title": "accelerated consensus via min-sum splitting.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6736-accelerated-consensus-via-min-sum-splitting", "abstract": "", "cite_num": -1}, "126": {"title": "stochastic optimization with variance reduction for infinite datasets with finite sum structure.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6760-stochastic-optimization-with-variance-reduction-for-infinite-datasets-with-finite-sum-structure", "abstract": "", "cite_num": -1}, "125": {"title": "multiscale quantization for fast similarity search.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7157-multiscale-quantization-for-fast-similarity-search", "abstract": "", "cite_num": -1}, "253": {"title": "an error detection and correction framework for connectomics.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7258-an-error-detection-and-correction-framework-for-connectomics", "abstract": "", "cite_num": -1}, "80": {"title": "hunt for the unique, stable, sparse and fast feature learning on graphs.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6614-hunt-for-the-unique-stable-sparse-and-fast-feature-learning-on-graphs", "abstract": "", "cite_num": -1}, "565": {"title": "a meta-learning perspective on cold-start recommendations for items.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7266-a-meta-learning-perspective-on-cold-start-recommendations-for-items", "abstract": "", "cite_num": -1}, "272": {"title": "beyond parity: fairness objectives for collaborative filtering.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6885-beyond-parity-fairness-objectives-for-collaborative-filtering", "abstract": "", "cite_num": -1}, "353": {"title": "learning low-dimensional metrics.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7002-learning-low-dimensional-metrics", "abstract": "", "cite_num": -1}, "448": {"title": "population matching discrepancy and applications in deep learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7206-population-matching-discrepancy-and-applications-in-deep-learning", "abstract": "", "cite_num": -1}, "501": {"title": "bandits dueling on partially ordered sets.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6808-bandits-dueling-on-partially-ordered-sets", "abstract": "", "cite_num": -1}, "395": {"title": "introspective classification with convolutional nets.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6684-introspective-classification-with-convolutional-nets", "abstract": "", "cite_num": -1}, "66": {"title": "balancing information exposure in social networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7052-balancing-information-exposure-in-social-networks", "abstract": "", "cite_num": -1}, "318": {"title": "minimizing a submodular function from samples.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6683-minimizing-a-submodular-function-from-samples", "abstract": "", "cite_num": -1}, "466": {"title": "linear convergence of a frank-wolfe type algorithm over trace-norm balls.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7199-linear-convergence-of-a-frank-wolfe-type-algorithm-over-trace-norm-balls", "abstract": "", "cite_num": -1}, "623": {"title": "scalable levy process priors for spectral kernel learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6983-scalable-levy-process-priors-for-spectral-kernel-learning", "abstract": "", "cite_num": -1}, "433": {"title": "scalable planning with tensorflow for hybrid nonlinear domains.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7207-scalable-planning-with-tensorflow-for-hybrid-nonlinear-domains", "abstract": "", "cite_num": -1}, "128": {"title": "marrnet: 3d shape reconstruction via 2.5d sketches.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6657-marrnet-3d-shape-reconstruction-via-25d-sketches", "abstract": "", "cite_num": -1}, "602": {"title": "learning the morphology of brain signals using alpha-stable convolutional sparse coding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6710-learning-the-morphology-of-brain-signals-using-alpha-stable-convolutional-sparse-coding", "abstract": "", "cite_num": -1}, "273": {"title": "alternating estimation for structured high-dimensional multi-response models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6876-alternating-estimation-for-structured-high-dimensional-multi-response-models", "abstract": "", "cite_num": -1}, "486": {"title": "prototypical networks for few-shot learning.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning", "abstract": "", "cite_num": -1}, "157": {"title": "diverse and accurate image description using a variational auto-encoder with an additive gaussian encoding space.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7158-diverse-and-accurate-image-description-using-a-variational-auto-encoder-with-an-additive-gaussian-encoding-space", "abstract": "", "cite_num": -1}, "100": {"title": "causal effect inference with deep latent-variable models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7223-causal-effect-inference-with-deep-latent-variable-models", "abstract": "", "cite_num": -1}, "214": {"title": "unsupervised image-to-image translation networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6672-unsupervised-image-to-image-translation-networks", "abstract": "", "cite_num": -1}, "362": {"title": "on-the-fly operation batching in dynamic computation graphs.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6986-on-the-fly-operation-batching-in-dynamic-computation-graphs", "abstract": "", "cite_num": -1}, "552": {"title": "unsupervised transformation learning via convex relaxations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7263-unsupervised-transformation-learning-via-convex-relaxations", "abstract": "", "cite_num": -1}, "177": {"title": "learning linear dynamical systems via spectral filtering.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7247-learning-linear-dynamical-systems-via-spectral-filtering", "abstract": "", "cite_num": -1}, "95": {"title": "an inner-loop free solution to inverse problems using deep neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6831-an-inner-loop-free-solution-to-inverse-problems-using-deep-neural-networks", "abstract": "", "cite_num": -1}, "431": {"title": "semisupervised clustering, and-queries and locally encodable source coding.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7227-semisupervised-clustering-and-queries-and-locally-encodable-source-coding", "abstract": "", "cite_num": -1}, "289": {"title": "optimized pre-processing for discrimination prevention.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6988-optimized-pre-processing-for-discrimination-prevention", "abstract": "", "cite_num": -1}, "414": {"title": "learning a structured optimal bipartite graph for co-clustering.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7001-learning-a-structured-optimal-bipartite-graph-for-co-clustering", "abstract": "", "cite_num": -1}, "292": {"title": "unsupervised learning of object frames by dense equivariant image labelling.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6686-unsupervised-learning-of-object-frames-by-dense-equivariant-image-labelling", "abstract": "", "cite_num": -1}, "528": {"title": "first-order adaptive sample size methods to reduce complexity of empirical risk minimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6801-first-order-adaptive-sample-size-methods-to-reduce-complexity-of-empirical-risk-minimization", "abstract": "", "cite_num": -1}, "620": {"title": "scalable generalized linear bandits: online computation and hashing.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6615-scalable-generalized-linear-bandits-online-computation-and-hashing", "abstract": "", "cite_num": -1}, "207": {"title": "maximum margin interval trees.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7080-maximum-margin-interval-trees", "abstract": "", "cite_num": -1}, "402": {"title": "online prediction with selfish experts.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6729-online-prediction-with-selfish-experts", "abstract": "", "cite_num": -1}, "221": {"title": "adversarial symmetric variational autoencoder.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7020-adversarial-symmetric-variational-autoencoder", "abstract": "", "cite_num": -1}, "471": {"title": "learning deep structured multi-scale features using attention-gated crfs for contour prediction.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6985-learning-deep-structured-multi-scale-features-using-attention-gated-crfs-for-contour-prediction", "abstract": "Recent works have shown that exploiting multi-scale representations deeply learned via convolutional\n neural networks (CNN) is of tremendous importance for accurate contour detection. This paper presen\nts a novel approach for predicting contours which advances the state of the art in two fundamental a\nspects, i.e. multi-scale feature generation and fusion. Different from previous works directly consi\nder- ing multi-scale feature maps obtained from the inner layers of a primary CNN architecture, we i\nntroduce a hierarchical deep model which produces more rich and complementary representations. Furth\nermore, to refine and robustly fuse the representations learned at different scales, the novel Atten\ntion-Gated Conditional Random Fields (AG-CRFs) are proposed. The experiments ran on two publicly ava\nilable datasets (BSDS500 and NYUDv2) demonstrate the effectiveness of the latent AG-CRF model and of\n the overall hierarchical framework.", "cite_num": -1}, "612": {"title": "learning with bandit feedback in potential games.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7216-learning-with-bandit-feedback-in-potential-games", "abstract": "", "cite_num": -1}, "70": {"title": "dykstra's algorithm, admm, and coordinate descent: connections, insights, and extensions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6655-dykstras-algorithm-admm-and-coordinate-descent-connections-insights-and-extensions", "abstract": "", "cite_num": -1}, "86": {"title": "incorporating side information by adaptive convolution.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6976-incorporating-side-information-by-adaptive-convolution", "abstract": "", "cite_num": -1}, "465": {"title": "active exploration for learning symbolic representations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7086-active-exploration-for-learning-symbolic-representations", "abstract": "", "cite_num": -1}, "504": {"title": "targeting eeg/lfp synchrony with neural nets.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7048-targeting-eeglfp-synchrony-with-neural-nets", "abstract": "", "cite_num": -1}, "376": {"title": "learning spatiotemporal piecewise-geodesic trajectories from longitudinal manifold-valued data.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6715-learning-spatiotemporal-piecewise-geodesic-trajectories-from-longitudinal-manifold-valued-data", "abstract": "", "cite_num": -1}, "463": {"title": "implicit regularization in matrix factorization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization", "abstract": "", "cite_num": -1}, "7": {"title": "influence maximization with \u03b5-almost submodular threshold functions.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6970-influence-maximization-with-varepsilon-almost-submodular-threshold-functions", "abstract": "", "cite_num": -1}, "595": {"title": "online influence maximization under independent cascade model with semi-bandit feedback.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6895-online-influence-maximization-under-independent-cascade-model-with-semi-bandit-feedback", "abstract": "", "cite_num": -1}, "186": {"title": "robust imitation of diverse behaviors.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7116-robust-imitation-of-diverse-behaviors", "abstract": "", "cite_num": -1}, "525": {"title": "plan, attend, generate: planning for sequence-to-sequence models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7131-plan-attend-generate-planning-for-sequence-to-sequence-models", "abstract": "", "cite_num": -1}, "601": {"title": "batch renormalization: towards reducing minibatch dependence in batch-normalized models.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6790-batch-renormalization-towards-reducing-minibatch-dependence-in-batch-normalized-models", "abstract": "", "cite_num": -1}, "534": {"title": "data-efficient reinforcement learning in continuous state-action gaussian-pomdps.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6799-data-efficient-reinforcement-learning-in-continuous-state-action-gaussian-pomdps", "abstract": "", "cite_num": -1}, "286": {"title": "working hard to know your neighbor's margins: local descriptor learning loss.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7068-working-hard-to-know-your-neighbors-margins-local-descriptor-learning-loss", "abstract": "", "cite_num": -1}, "107": {"title": "information-theoretic analysis of generalization capability of learning algorithms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6846-information-theoretic-analysis-of-generalization-capability-of-learning-algorithms", "abstract": "", "cite_num": -1}, "367": {"title": "trimmed density ratio estimation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7038-trimmed-density-ratio-estimation", "abstract": "", "cite_num": -1}, "55": {"title": "how regularization affects the critical points in linear networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6844-how-regularization-affects-the-critical-points-in-linear-networks", "abstract": "", "cite_num": -1}, "580": {"title": "regularizing deep neural networks by noise: its interpretation and optimization.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7096-regularizing-deep-neural-networks-by-noise-its-interpretation-and-optimization", "abstract": "", "cite_num": -1}, "307": {"title": "learning from uncertain curves: the 2-wasserstein metric for gaussian processes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7149-learning-from-uncertain-curves-the-2-wasserstein-metric-for-gaussian-processes", "abstract": "", "cite_num": -1}, "202": {"title": "perturbative black box variational inference.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7093-perturbative-black-box-variational-inference", "abstract": "", "cite_num": -1}, "154": {"title": "spherical convolutions and their application in molecular modelling.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6935-spherical-convolutions-and-their-application-in-molecular-modelling", "abstract": "", "cite_num": -1}, "664": {"title": "gradient descent can take exponential time to escape saddle points.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6707-gradient-descent-can-take-exponential-time-to-escape-saddle-points", "abstract": "", "cite_num": -1}, "47": {"title": "clustering billions of reads for dna data storage.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6928-clustering-billions-of-reads-for-dna-data-storage", "abstract": "", "cite_num": -1}, "497": {"title": "multitask spectral learning of weighted automata.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6852-multitask-spectral-learning-of-weighted-automata", "abstract": "", "cite_num": -1}, "439": {"title": "estimating high-dimensional non-gaussian multiple index models via stein's lemma.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7190-estimating-high-dimensional-non-gaussian-multiple-index-models-via-steins-lemma", "abstract": "", "cite_num": -1}, "540": {"title": "question asking as program generation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6705-question-asking-as-program-generation", "abstract": "", "cite_num": -1}, "132": {"title": "quantifying how much sensory information in a neural code is relevant for behavior.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6959-quantifying-how-much-sensory-information-in-a-neural-code-is-relevant-for-behavior", "abstract": "", "cite_num": -1}, "129": {"title": "online to offline conversions, universality and adaptive minibatch sizes.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6759-online-to-offline-conversions-universality-and-adaptive-minibatch-sizes", "abstract": "", "cite_num": -1}, "41": {"title": "k-support and ordered weighted sparsity for overlapping groups: hardness and algorithms.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6632-k-support-and-ordered-weighted-sparsity-for-overlapping-groups-hardness-and-algorithms", "abstract": "", "cite_num": -1}, "560": {"title": "improving the expected improvement algorithm.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7122-improving-the-expected-improvement-algorithm", "abstract": "", "cite_num": -1}, "280": {"title": "langevin dynamics with continuous tempering for training deep neural networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6664-langevin-dynamics-with-continuous-tempering-for-training-deep-neural-networks", "abstract": "", "cite_num": -1}, "436": {"title": "triangle generative adversarial networks.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7109-triangle-generative-adversarial-networks", "abstract": "", "cite_num": -1}, "429": {"title": "scalable trust-region method for deep reinforcement learning using kronecker-factored approximation.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7112-scalable-trust-region-method-for-deep-reinforcement-learning-using-kronecker-factored-approximation", "abstract": "", "cite_num": -1}, "19": {"title": "extracting low-dimensional dynamics from multiple large-scale neural population recordings by learning to predict correlations.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/7153-extracting-low-dimensional-dynamics-from-multiple-large-scale-neural-population-recordings-by-learning-to-predict-correlations", "abstract": "", "cite_num": -1}, "675": {"title": "mmd gan: towards deeper understanding of moment matching network.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6815-mmd-gan-towards-deeper-understanding-of-moment-matching-network", "abstract": "", "cite_num": -1}, "611": {"title": "counterfactual fairness.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6995-counterfactual-fairness", "abstract": "", "cite_num": -1}, "299": {"title": "tensor biclustering.", "conf": "nips", "time": "2017", "url": "http://papers.nips.cc/paper/6730-tensor-biclustering", "abstract": "", "cite_num": -1}}