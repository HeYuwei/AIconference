{"52": {"title": "learning wasserstein embeddings.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJyEH91A-", "abstract": "", "cite_num": -1}, "68": {"title": "memory augmented control networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyfHgI6aW", "abstract": "", "cite_num": -1}, "285": {"title": "few-shot learning with graph neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJj6qGbRW", "abstract": "", "cite_num": -1}, "266": {"title": "enhancing the reliability of out-of-distribution image detection in neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1VGkIxRZ", "abstract": "", "cite_num": -1}, "124": {"title": "cascade adversarial machine learning regularized with a unified embedding.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyRVBzap-", "abstract": "", "cite_num": -1}, "307": {"title": "eigenoption discovery through the deep successor representation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Bk8ZcAxR-", "abstract": "", "cite_num": -1}, "38": {"title": "depthwise separable convolutions for neural machine translation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1jBcueAb", "abstract": "", "cite_num": -1}, "291": {"title": "semantic interpolation in implicit models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H15odZ-C-", "abstract": "", "cite_num": -1}, "306": {"title": "matrix capsules with em routing.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJWLfGWRb", "abstract": "", "cite_num": -1}, "284": {"title": "can recurrent neural networks warp time?", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJcKhk-Ab", "abstract": "", "cite_num": -1}, "305": {"title": "emergent complexity via multi-agent competition.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Sy0GnUxCb", "abstract": "", "cite_num": -1}, "8": {"title": "beyond shared hierarchies: deep multitask learning through soft layer ordering.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkXmYfbAZ", "abstract": "", "cite_num": -1}, "197": {"title": "fusionnet: fusing via fully-aware attention with application to machine comprehension.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJIgi_eCZ", "abstract": "This paper introduces a new neural structure called FusionNet, which extends existing attention appr\noaches from three perspectives. First, it puts forward a novel concept of \"history of word\" to chara\ncterize attention information from the lowest word-level embedding up to the highest semantic-level \nrepresentation. Second, it introduces an improved attention scoring function that better utilizes th\ne \"history of word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to cap\nture the complete information in one text (such as a question) and exploit it in its counterpart (su\nch as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Data\nset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQ\nuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of \nFusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datase\nts: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet\n boosts the best F1 metric from 56.0% to 60.7%.", "cite_num": 30}, "274": {"title": "efficient sparse-winograd convolutional neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJzgZ3JCW", "abstract": "", "cite_num": -1}, "29": {"title": "leave no trace: learning to reset for safe and autonomous reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1vuO-bCW", "abstract": "", "cite_num": -1}, "252": {"title": "an image representation based convolutional network for dna classification.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJvvRoe0W", "abstract": "", "cite_num": -1}, "316": {"title": "adversarial dropout regularization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJIoJWZCZ", "abstract": "", "cite_num": -1}, "269": {"title": "divide-and-conquer reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJwelMbR-", "abstract": "", "cite_num": -1}, "325": {"title": "learning deep mean field games for modeling large population behavior.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HktK4BeCZ", "abstract": "", "cite_num": -1}, "256": {"title": "fastgcn: fast learning with graph convolutional networks via importance sampling.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rytstxWAW", "abstract": "", "cite_num": -1}, "110": {"title": "parametrized hierarchical procedures for neural programming.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJl63fZRb", "abstract": "", "cite_num": -1}, "218": {"title": "backpropagation through the void: optimizing control variates for black-box gradient estimation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyzKd1bCW", "abstract": "", "cite_num": -1}, "239": {"title": "the kanerva machine: a generative distributed memory.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1HlA-ZAZ", "abstract": "", "cite_num": -1}, "35": {"title": "towards neural phrase-based machine translation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HktJec1RZ", "abstract": "", "cite_num": -1}, "59": {"title": "multi-level residual networks from dynamical systems view.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyJS-OgR-", "abstract": "", "cite_num": -1}, "221": {"title": "stochastic gradient descent performs variational inference, converges to limit cycles for deep networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyWrIgW0W", "abstract": "", "cite_num": -1}, "23": {"title": "on the state of the art of evaluation in neural language models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByJHuTgA-", "abstract": "", "cite_num": -1}, "116": {"title": "emergence of linguistic communication from referential games with symbolic and pixel input.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJGv1Z-AW", "abstract": "", "cite_num": -1}, "242": {"title": "fix your classifier: the marginal value of training the last weight layer.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1Dh8Tg0-", "abstract": "", "cite_num": -1}, "123": {"title": "on the insufficiency of existing momentum schemes for stochastic optimization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJTutzbA-", "abstract": "", "cite_num": -1}, "136": {"title": "interactive grounded language acquisition and generalization in a 2d world.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1UOm4gA-", "abstract": "", "cite_num": -1}, "327": {"title": "flipout: efficient pseudo-independent weight perturbations on mini-batches.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJNpifWAb", "abstract": "", "cite_num": -1}, "205": {"title": "gradient estimators for implicit models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJi9WOeRb", "abstract": "", "cite_num": -1}, "240": {"title": "natural language inference over interaction space.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1dHXnH6-", "abstract": "", "cite_num": -1}, "138": {"title": "learning to cluster in order to transfer across domains and tasks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByRWCqvT-", "abstract": "", "cite_num": -1}, "276": {"title": "continuous adaptation via meta-learning in nonstationary and competitive environments.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Sk2u1g-0-", "abstract": "", "cite_num": -1}, "112": {"title": "deep learning for physical processes: incorporating prior scientific knowledge.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=By4HsfWAZ", "abstract": "", "cite_num": -1}, "296": {"title": "neural language modeling by jointly learning syntax and lexicon.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkgOLb-0W", "abstract": "", "cite_num": -1}, "314": {"title": "cgans with projection discriminator.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByS1VpgRZ", "abstract": "", "cite_num": -1}, "147": {"title": "boundary seeking gans.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkTS8lZAb", "abstract": "", "cite_num": -1}, "45": {"title": "training wide residual networks for deployment using a single bit for each weight.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rytNfI1AZ", "abstract": "", "cite_num": -1}, "60": {"title": "meta-learning for semi-supervised few-shot classification.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJcSzz-CZ", "abstract": "", "cite_num": -1}, "258": {"title": "a dirt-t approach to unsupervised domain adaptation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1q-TM-AW", "abstract": "", "cite_num": -1}, "233": {"title": "deep gaussian embedding of graphs: unsupervised inductive learning via ranking.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1ZdKJ-0W", "abstract": "", "cite_num": -1}, "169": {"title": "auto-conditioned recurrent networks for extended complex human motion synthesis.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r11Q2SlRW", "abstract": "", "cite_num": -1}, "67": {"title": "semi-parametric topological memory for navigation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SygwwGbRW", "abstract": "", "cite_num": -1}, "100": {"title": "reinforcement learning on web interfaces using workflow-guided exploration.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ryTp3f-0-", "abstract": "", "cite_num": -1}, "313": {"title": "skip connections eliminate singularities.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkwBEMWCZ", "abstract": "", "cite_num": -1}, "193": {"title": "towards reverse-engineering black-box neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BydjJte0-", "abstract": "", "cite_num": -1}, "236": {"title": "a new method of region embedding for text classification.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkSDMA36Z", "abstract": "", "cite_num": -1}, "166": {"title": "generating natural adversarial examples.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1BLjgZCb", "abstract": "", "cite_num": -1}, "113": {"title": "compressing word embeddings via deep compositional code learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJRZzFlRb", "abstract": "", "cite_num": -1}, "297": {"title": "parallelizing linear recurrent neural nets over sequence length.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyUNwulC-", "abstract": "", "cite_num": -1}, "220": {"title": "mixed precision training.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1gs9JgRZ", "abstract": "", "cite_num": -1}, "4": {"title": "variational inference of disentangled latent concepts from unlabeled observations.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1kG7GZAW", "abstract": "", "cite_num": -1}, "263": {"title": "quantitatively evaluating gans with divergences proposed for training.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJQHjzZ0-", "abstract": "", "cite_num": -1}, "244": {"title": "towards better understanding of gradient-based attribution methods for deep neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Sy21R9JAW", "abstract": "", "cite_num": -1}, "190": {"title": "training confidence-calibrated classifiers for detecting out-of-distribution samples.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ryiAv2xAZ", "abstract": "", "cite_num": -1}, "315": {"title": "neumann optimizer: a practical optimization algorithm for deep neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkLyJl-0-", "abstract": "", "cite_num": -1}, "199": {"title": "generalizing hamiltonian monte carlo with neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1n8LexRZ", "abstract": "", "cite_num": -1}, "36": {"title": "a neural representation of sketch drawings.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hy6GHpkCW", "abstract": "", "cite_num": -1}, "99": {"title": "sparse persistent rnns: squeezing large recurrent networks on-chip.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkxF5RgC-", "abstract": "", "cite_num": -1}, "14": {"title": "viterbi-based pruning for sparse matrix with fixed and high index compression ratio.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1D8MPxA-", "abstract": "", "cite_num": -1}, "288": {"title": "defense-gan: protecting classifiers against adversarial attacks using generative models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkJ3ibb0-", "abstract": "In recent years, deep neural network approaches have been widely adopted for machine learning tasks,\n including classification. However, they were shown to be vulnerable to adversarial perturbations: c\narefully crafted small perturbations can cause misclassification of legitimate images. We propose De\nfense-GAN, a new framework leveraging the expressive capability of generative models to defend deep \nneural networks against such attacks. Defense-GAN is trained to model the distribution of unperturbe\nd images. At inference time, it finds a close output to a given image which does not contain the adv\nersarial changes. This output is then fed to the classifier. Our proposed method can be used with an\ny classification model and does not modify the classifier structure or training procedure. It can al\nso be used as a defense against any attack as it does not assume knowledge of the process for genera\nting the adversarial examples. We empirically show that Defense-GAN is consistently effective agains\nt different attack methods and improves on existing defense strategies. Our code has been made publi\ncly available at this https URL", "cite_num": 113}, "201": {"title": "simulated+unsupervised learning with adaptive data generation and bidirectional mappings.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SkHDoG-Cb", "abstract": "", "cite_num": -1}, "102": {"title": "temporal difference models: model-free deep rl for model-based control.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Skw0n-W0Z", "abstract": "", "cite_num": -1}, "106": {"title": "distributed fine-tuning of language models on private data.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkgNdt26Z", "abstract": "", "cite_num": -1}, "130": {"title": "learning latent representations in neural networks for clustering through pseudo supervision and graph-based activity regularization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkMvEOlAb", "abstract": "", "cite_num": -1}, "192": {"title": "dcn+: mixed objective and deep residual coattention for question answering.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1meywxRW", "abstract": "Traditional models for question answering optimize using cross entropy loss, which encourages exact \nanswers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate.\n We propose a mixed objective that combines cross entropy loss with self-critical policy learning. T\nhe objective uses rewards derived from word overlap to solve the misalignment between evaluation met\nric and optimization objective. In addition to the mixed objective, we improve dynamic coattention n\networks (DCN) with a deep residual coattention encoder that is inspired by recent work in deep self-\nattention and residual networks. Our proposals improve model performance across question types and i\nnput lengths, especially for long questions that requires the ability to capture long-term dependenc\nies. On the Stanford Question Answering Dataset, our model achieves state-of-the-art results with 75\n.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.\n0% F1.", "cite_num": -1}, "335": {"title": "multi-view data generation without view supervision.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ryRh0bb0Z", "abstract": "", "cite_num": -1}, "103": {"title": "evaluating the robustness of neural networks: an extreme value theory approach.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkUHlMZ0b", "abstract": "", "cite_num": -1}, "155": {"title": "all-but-the-top: simple and effective postprocessing for word representations.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkuGJ3kCb", "abstract": "", "cite_num": -1}, "54": {"title": "generating wikipedia by summarizing long sequences.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hyg0vbWC-", "abstract": "", "cite_num": -1}, "57": {"title": "hierarchical representations for efficient architecture search.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJQRKzbA-", "abstract": "", "cite_num": -1}, "73": {"title": "characterizing adversarial subspaces using local intrinsic dimensionality.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1gJ1L2aW", "abstract": "", "cite_num": -1}, "56": {"title": "training and inference with integers in deep neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJGXzmspb", "abstract": "", "cite_num": -1}, "278": {"title": "mastering the dungeon: grounded language learning by mechanical turker descent.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJ-C6JbRW", "abstract": "", "cite_num": -1}, "254": {"title": "don't decay the learning rate, increase the batch size.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1Yy1BxCZ", "abstract": "", "cite_num": -1}, "248": {"title": "maskgan: better text generation via filling in the _______.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByOExmWAb", "abstract": "", "cite_num": -1}, "107": {"title": "initialization matters: orthogonal predictive state recurrent neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJJ23bW0b", "abstract": "", "cite_num": -1}, "109": {"title": "progressive growing of gans for improved quality, stability, and variation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hk99zCeAb", "abstract": "", "cite_num": -1}, "71": {"title": "smooth loss functions for deep top-k classification.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hk5elxbRW", "abstract": "", "cite_num": -1}, "281": {"title": "trust-pcl: an off-policy trust region method for continuous control.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyrCWeWCb", "abstract": "", "cite_num": -1}, "282": {"title": "learning how to explain neural networks: patternnet and patternattribution.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hkn7CBaTW", "abstract": "", "cite_num": -1}, "48": {"title": "learning an embedding space for transferable robot skills.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rk07ZXZRb", "abstract": "", "cite_num": -1}, "257": {"title": "minimax curriculum learning: machine teaching with desirable difficulties and scheduled diversity.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BywyFQlAW", "abstract": "", "cite_num": -1}, "181": {"title": "learning a generative model for validity in complex discrete structures.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkrC3GbRW", "abstract": "", "cite_num": -1}, "224": {"title": "wavelet pooling for convolutional neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkhlb8lCZ", "abstract": "", "cite_num": -1}, "160": {"title": "decoupling the layers in residual networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyMvJrdaW", "abstract": "", "cite_num": -1}, "127": {"title": "graph attention networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJXMpikCZ", "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph\n-structured data, leveraging masked self-attentional layers to address the shortcomings of prior met\nhods based on graph convolutions or their approximations. By stacking layers in which nodes are able\n to attend over their neighborhoods' features, we enable (implicitly) specifying different weights t\no different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as \ninversion) or depending on knowing the graph structure upfront. In this way, we address several key \nchallenges of spectral-based graph neural networks simultaneously, and make our model readily applic\nable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of\n-the-art results across four established transductive and inductive graph benchmarks: the Cora, Cite\nseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein\n test graphs remain unseen during training).", "cite_num": 216}, "225": {"title": "syntax-directed variational autoencoder for structured data.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyqShMZRb", "abstract": "", "cite_num": -1}, "215": {"title": "deep voice 3: scaling text-to-speech with convolutional sequence learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJtEm4p6Z", "abstract": "", "cite_num": -1}, "299": {"title": "memory architectures in recurrent neural network language models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SkFqf0lAZ", "abstract": "", "cite_num": -1}, "277": {"title": "emergent translation in multi-agent communication.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1vEXaxA-", "abstract": "", "cite_num": -1}, "219": {"title": "auto-encoding sequential monte carlo.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJ8c3f-0b", "abstract": "", "cite_num": -1}, "194": {"title": "latent constraints: learning to generate conditionally from unconditional generative models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Sy8XvGb0-", "abstract": "", "cite_num": -1}, "152": {"title": "deep rewiring: training very sparse deep networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJ_wN01C-", "abstract": "", "cite_num": -1}, "121": {"title": "deep learning and quantum entanglement: fundamental connections with implications to network design.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SywXXwJAb", "abstract": "", "cite_num": -1}, "183": {"title": "improving gans using optimal transport.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkQkBnJAb", "abstract": "", "cite_num": -1}, "230": {"title": "synthetic and natural noise both break neural machine translation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJ8vJebC-", "abstract": "", "cite_num": -1}, "283": {"title": "generative networks as inverse problems with scattering transforms.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1NYjfbR-", "abstract": "", "cite_num": -1}, "83": {"title": "monotonic chunkwise attention.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hko85plCW", "abstract": "Sequence-to-sequence models with soft attention have been successfully applied to a wide variety of \nproblems, but their decoding process incurs a quadratic time and space cost and is inapplicable to r\neal-time sequence transduction. To address these issues, we propose Monotonic Chunkwise Attention (M\noChA), which adaptively splits the input sequence into small chunks over which soft attention is com\nputed. We show that models utilizing MoChA can be trained efficiently with standard backpropagation \nwhile allowing online and linear-time decoding at test time. When applied to online speech recogniti\non, we obtain state-of-the-art results and match the performance of a model using an offline soft at\ntention mechanism. In document summarization experiments where we do not expect monotonic alignments\n, we show significantly improved performance compared to a baseline monotonic attention-based model.\n", "cite_num": 7}, "319": {"title": "maximum a posteriori policy optimisation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1ANxQW0b", "abstract": "", "cite_num": -1}, "2": {"title": "deep learning as a mixed convex-combinatorial optimization problem.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1Lc-Gb0Z", "abstract": "", "cite_num": -1}, "317": {"title": "meta learning shared hierarchies.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyX0IeWAW", "abstract": "", "cite_num": -1}, "262": {"title": "n2n learning: network to network compression via policy gradient reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1hcZZ-AW", "abstract": "", "cite_num": -1}, "203": {"title": "model-ensemble trust-region policy optimization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJJinbWRZ", "abstract": "", "cite_num": -1}, "150": {"title": "on the convergence of adam and beyond.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ryQu7f-RZ", "abstract": "", "cite_num": -1}, "294": {"title": "learning parametric closed-loop policies for markov potential games.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJm7VfZA-", "abstract": "", "cite_num": -1}, "158": {"title": "active learning for convolutional neural networks: a core-set approach.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1aIuk-RW", "abstract": "", "cite_num": -1}, "47": {"title": "on unifying deep generative models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rylSzl-R-", "abstract": "", "cite_num": -1}, "79": {"title": "distributed distributional deterministic policy gradients.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyZipzbCb", "abstract": "", "cite_num": -1}, "84": {"title": "deep autoencoding gaussian mixture model for unsupervised anomaly detection.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJJLHbb0-", "abstract": "Unsupervised anomaly detection on multi- or high-dimensional data is of great importance in both fun\ndamental machine learning research and industrial applications, for which density estimation lies at\n the core. Although previous approaches based on dimensionality reduction followed by density estima\ntion have made fruitful progress, they mainly suffer from decoupled model learning with inconsistent\n optimization goals and incapability of preserving essential information in the low-dimensional spac\ne. In this paper, we present a Deep Autoencoding Gaussian Mixture Model (DAGMM) for unsupervised ano\nmaly detection. Our model utilizes a deep autoencoder to generate a low-dimensional representation a\nnd reconstruction error for each input data point, which is further fed into a Gaussian Mixture Mode\nl (GMM). Instead of using decoupled two-stage training and the standard Expectation-Maximization (EM\n) algorithm, DAGMM jointly optimizes the parameters of the deep autoencoder and the mixture model si\nmultaneously in an end-to-end fashion, leveraging a separate estimation network to facilitate the pa\nrameter learning of the mixture model. The joint optimization, which well balances autoencoding reco\nnstruction, density estimation of latent representation, and regularization, helps the autoencoder e\nscape from less attractive local optima and further reduce reconstruction errors, avoiding the need \nof pre-training. Experimental results on several public benchmark datasets show that, DAGMM signific\nantly outperforms state-of-the-art anomaly detection techniques, and achieves up to 14% improvement \nbased on the standard F1 score.", "cite_num": 42}, "168": {"title": "a deep reinforced model for abstractive summarization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkAClQgA-", "abstract": "", "cite_num": -1}, "323": {"title": "a hierarchical model for device placement.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hkc-TeZ0W", "abstract": "", "cite_num": -1}, "145": {"title": "simulating action dynamics with neural process networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJYFzMZC-", "abstract": "", "cite_num": -1}, "245": {"title": "semantically decomposing the latent spaces of generative adversarial networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1nQvfgA-", "abstract": "", "cite_num": -1}, "304": {"title": "on the expressive power of overlapping architectures of deep learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkNGsseC-", "abstract": "", "cite_num": -1}, "165": {"title": "predicting floor-level for 911 calls with neural networks and smartphone sensor data.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ryBnUWb0b", "abstract": "", "cite_num": -1}, "255": {"title": "stochastic variational video prediction.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rk49Mg-CW", "abstract": "", "cite_num": -1}, "78": {"title": "learning approximate inference networks for structured prediction.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1WgVz-AZ", "abstract": "", "cite_num": -1}, "206": {"title": "coulomb gans: provably optimal nash equilibria via potential fields.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SkVqXOxCb", "abstract": "", "cite_num": -1}, "88": {"title": "on the regularization of wasserstein gans.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1hYRMbCW", "abstract": "", "cite_num": -1}, "210": {"title": "qanet: combining local convolution with global self-attention for reading comprehension.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B14TlG-RW", "abstract": "Current end-to-end machine reading and question answering (Q\\&A) models are primarily based on recur\nrent neural networks (RNNs) with attention. Despite their success, these models are often slow for b\noth training and inference due to the sequential nature of RNNs. We propose a new Q\\&A model that do\nes not require recurrent networks: It consists exclusively of attention and convolutions, yet achiev\nes equivalent or better performance than existing models. On the SQuAD dataset, our model is 3x to 1\n3x faster in training and 4x to 9x faster in inference. The speed-up gain allows us to train the mod\nel with much more data. We hence combine our model with data generated by backtranslation from a neu\nral machine translation model. This data augmentation technique not only enhances the training examp\nles but also diversifies the phrasing of the sentences, which results in immediate accuracy improvem\nents. Our single model achieves 84.6 F1 score on the test set, which is significantly better than th\ne best published F1 score of 81.8.", "cite_num": -1}, "250": {"title": "alternating multi-bit quantization for recurrent neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S19dR9x0b", "abstract": "", "cite_num": -1}, "267": {"title": "modular continual learning in a unified visual environment.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkPLzgZAZ", "abstract": "", "cite_num": -1}, "93": {"title": "breaking the softmax bottleneck: a high-rank rnn language model.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkwZSG-CZ", "abstract": "", "cite_num": -1}, "308": {"title": "on the discrimination-generalization tradeoff in gans.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hk9Xc_lR-", "abstract": "", "cite_num": -1}, "300": {"title": "regularizing and optimizing lstm language models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyyGPP0TZ", "abstract": "", "cite_num": -1}, "9": {"title": "debiasing evidence approximations: on importance-weighted autoencoders and jackknife variational inference.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyZoi-WRb", "abstract": "", "cite_num": -1}, "85": {"title": "a pac-bayesian approach to spectrally-normalized margin bounds for neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Skz_WfbCZ", "abstract": "", "cite_num": -1}, "232": {"title": "learning one-hidden-layer neural networks with landscape design.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkwHObbRZ", "abstract": "", "cite_num": -1}, "31": {"title": "unsupervised learning of goal spaces for intrinsically motivated goal exploration.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1DWPP1A-", "abstract": "", "cite_num": -1}, "64": {"title": "deep sensing: active sensing using multi-directional recurrent neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1SnX5xCb", "abstract": "", "cite_num": -1}, "191": {"title": "kernel implicit variational inference.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1l4eQW0Z", "abstract": "", "cite_num": -1}, "241": {"title": "spectralnet: spectral clustering using deep neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJ_aoCyRZ", "abstract": "", "cite_num": -1}, "122": {"title": "neural map: structured memory for deep reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Bk9zbyZCZ", "abstract": "", "cite_num": -1}, "20": {"title": "deep active learning for named entity recognition.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ry018WZAZ", "abstract": "", "cite_num": -1}, "159": {"title": "improving gan training via binarized representation entropy (bre) regularization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkLhaGZRW", "abstract": "", "cite_num": -1}, "146": {"title": "on the importance of single directions for generalization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1iuQjxCZ", "abstract": "", "cite_num": -1}, "94": {"title": "whai: weibull hybrid autoencoding inference for deep topic modeling.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1cZsf-RW", "abstract": "", "cite_num": -1}, "58": {"title": "towards synthesizing complex programs from input-output examples.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Skp1ESxRZ", "abstract": "", "cite_num": -1}, "322": {"title": "towards deep learning models resistant to adversarial attacks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJzIBfZAb", "abstract": "Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inpu\nts that are almost indistinguishable from natural data and yet classified incorrectly by the network\n. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an i\nnherent weakness of deep learning models. To address this problem, we study the adversarial robustne\nss of neural networks through the lens of robust optimization. This approach provides us with a broa\nd and unifying view on much of the prior work on this topic. Its principled nature also enables us t\no identify methods for both training and attacking neural networks that are reliable and, in a certa\nin sense, universal. In particular, they specify a concrete security guarantee that would protect ag\nainst any adversary. These methods let us train networks with significantly improved resistance to a\n wide range of adversarial attacks. They also suggest the notion of security against a first-order a\ndversary as a natural and broad security guarantee. We believe that robustness against such well-def\nined classes of adversaries is an important stepping stone towards fully resistant deep learning mod\nels.", "cite_num": 479}, "91": {"title": "training gans with optimism.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJJySbbAZ", "abstract": "", "cite_num": -1}, "175": {"title": "mixup: beyond empirical risk minimization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1Ddp1-Rb", "abstract": "", "cite_num": -1}, "326": {"title": "temporally efficient deep learning with spikes.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkZy-bW0-", "abstract": "", "cite_num": -1}, "251": {"title": "kronecker-factored curvature approximations for recurrent neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyMTkQZAb", "abstract": "", "cite_num": -1}, "148": {"title": "leveraging grammar and reinforcement learning for neural program synthesis.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1Xw62kRZ", "abstract": "", "cite_num": -1}, "104": {"title": "neural speed reading via skim-rnn.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Sy-dQG-Rb", "abstract": "", "cite_num": -1}, "286": {"title": "self-ensembling for visual domain adaptation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkpoTaxA-", "abstract": "", "cite_num": -1}, "330": {"title": "critical points of linear neural networks: analytical forms and landscape properties.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SysEexbRb", "abstract": "", "cite_num": -1}, "87": {"title": "synthesizing realistic neural population activity patterns using generative adversarial networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1VVsebAZ", "abstract": "", "cite_num": -1}, "179": {"title": "learning to teach.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJewuJWCZ", "abstract": "", "cite_num": -1}, "114": {"title": "adaptive dropout with rademacher complexity regularization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1uxsye0Z", "abstract": "", "cite_num": -1}, "39": {"title": "stabilizing adversarial nets with prediction methods.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Skj8Kag0Z", "abstract": "", "cite_num": -1}, "50": {"title": "learn to pay attention.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyzbhfWRW", "abstract": "We propose an end-to-end-trainable attention module for convolutional neural network (CNN) architect\nures built for image classification. The module takes as input the 2D feature vector maps which form\n the intermediate representations of the input image at different stages in the CNN pipeline, and ou\ntputs a 2D matrix of scores for each map. Standard CNN architectures are modified through the incorp\noration of this module, and trained under the constraint that a convex combination of the intermedia\nte 2D feature vectors, as parameterised by the score matrices, must \\textit{alone} be used for class\nification. Incentivised to amplify the relevant and suppress the irrelevant or misleading, the score\ns thus assume the role of attention values. Our experimental observations provide clear evidence to \nthis effect: the learned attention maps neatly highlight the regions of interest while suppressing b\nackground clutter. Consequently, the proposed function is able to bootstrap standard CNN architectur\nes for the task of image classification, demonstrating superior generalisation over 6 unseen benchma\nrk datasets. When binarised, our attention maps outperform other CNN-based attention maps, tradition\nal saliency maps, and top object proposals for weakly supervised segmentation as demonstrated on the\n Object Discovery dataset. We also demonstrate improved robustness against the fast gradient sign me\nthod of adversarial attack.", "cite_num": 22}, "7": {"title": "dynamic neural program embeddings for program repair.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJuWrGW0Z", "abstract": "", "cite_num": -1}, "237": {"title": "latent space oddity: on the curvature of deep generative models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJzRZ-WCZ", "abstract": "", "cite_num": -1}, "27": {"title": "the power of deeper networks for expressing natural functions.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyProzZAW", "abstract": "", "cite_num": -1}, "261": {"title": "communication algorithms via deep learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ryazCMbR-", "abstract": "", "cite_num": -1}, "108": {"title": "certified defenses against adversarial examples.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Bys4ob-Rb", "abstract": "", "cite_num": -1}, "63": {"title": "unbiased online recurrent optimization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJQDjk-0b", "abstract": "", "cite_num": -1}, "176": {"title": "learning robust rewards with adverserial inverse reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkHywl-A-", "abstract": "", "cite_num": -1}, "143": {"title": "treeqn and atreec: differentiable tree-structured models for deep reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1dh6Ax0Z", "abstract": "", "cite_num": -1}, "238": {"title": "learning awareness models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1HhRfWRZ", "abstract": "", "cite_num": -1}, "246": {"title": "emergent communication through negotiation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hk6WhagRW", "abstract": "", "cite_num": -1}, "32": {"title": "spectral normalization for generative adversarial networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1QRgziT-", "abstract": "", "cite_num": -1}, "198": {"title": "fidelity-weighted learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1X0mzZCW", "abstract": "", "cite_num": -1}, "208": {"title": "compositional obverter communication learning from raw visual input.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rknt2Be0-", "abstract": "", "cite_num": -1}, "200": {"title": "gaussian process behaviour in wide deep neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1-nGgWC-", "abstract": "", "cite_num": -1}, "234": {"title": "generalizing across domains via cross-gradient training.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1Dx7fbCW", "abstract": "", "cite_num": -1}, "184": {"title": "decision-based adversarial attacks: reliable attacks against black-box machine learning models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyZI0GWCZ", "abstract": "Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their input\ns. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world \nmachine learning applications because most methods used to generate such perturbations rely either o\nn detailed model information (gradient-based attacks) or on confidence scores such as class probabil\nities (score-based attacks), neither of which are available in most real-world scenarios. In many su\nch cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitut\ne models, need access to the training data and can be defended against. Here we emphasise the import\nance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) a\npplicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are ea\nsier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- \nor score-based attacks. Previous attacks in this category were limited to simple models or simple da\ntasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adve\nrsarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack\n is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute mod\nels and is competitive with the best gradient-based attacks in standard computer vision tasks like I\nmageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in p\narticular and the class of decision-based attacks in general open new avenues to study the robustnes\ns of machine learning models and raise new questions regarding the safety of deployed machine learni\nng systems. An implementation of the attack is available as part of Foolbox at this https URL .", "cite_num": 67}, "195": {"title": "mgan: training generative adversarial nets with multiple generators.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkmu5b0a-", "abstract": "", "cite_num": -1}, "21": {"title": "ambientgan: generative models from lossy measurements.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hy7fDog0b", "abstract": "", "cite_num": -1}, "76": {"title": "global optimality conditions for deep neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJk7Gf-CZ", "abstract": "", "cite_num": -1}, "28": {"title": "combining symbolic expressions and black-box function evaluations in neural programs.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hksj2WWAW", "abstract": "", "cite_num": -1}, "333": {"title": "truncated horizon policy search: combining reinforcement learning & imitation learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ryUlhzWCZ", "abstract": "", "cite_num": -1}, "321": {"title": "adaptive quantization of neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyOK1Sg0W", "abstract": "", "cite_num": -1}, "51": {"title": "hierarchical and interpretable skill acquisition in multi-task reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJJQVZW0b", "abstract": "", "cite_num": -1}, "264": {"title": "interpretable counting for visual question answering.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1J2ZyZ0Z", "abstract": "", "cite_num": -1}, "42": {"title": "overcoming catastrophic interference using conceptor-aided backpropagation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1al7jg0b", "abstract": "", "cite_num": -1}, "231": {"title": "variational network quantization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ry-TW-WAb", "abstract": "", "cite_num": -1}, "105": {"title": "smash: one-shot model architecture search through hypernetworks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rydeCEhs-", "abstract": "", "cite_num": -1}, "311": {"title": "meta-learning and universality: deep representations and gradient descent can approximate any learning algorithm.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyjC5yWCW", "abstract": "", "cite_num": -1}, "259": {"title": "pixelnn: example-based image synthesis.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Syhr6pxCW", "abstract": "", "cite_num": -1}, "134": {"title": "bi-directional block self-attention for fast and memory-efficient sequence modeling.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1cWzoxA-", "abstract": "Recurrent neural networks (RNN), convolutional neural networks (CNN) and self-attention networks (SA\nN) are commonly used to produce context-aware representations. RNN can capture long-range dependency\n but is hard to parallelize and not time-efficient. CNN focuses on local dependency but does not per\nform well on some tasks. SAN can model both such dependencies via highly parallelizable computation,\n but memory requirement grows rapidly in line with sequence length. In this paper, we propose a mode\nl, called \"bi-directional block self-attention network (Bi-BloSAN)\", for RNN/CNN-free sequence encod\ning. It requires as little memory as RNN but with all the merits of SAN. Bi-BloSAN splits the entire\n sequence into blocks, and applies an intra-block SAN to each block for modeling local context, then\n applies an inter-block SAN to the outputs for all blocks to capture long-range dependency. Thus, ea\nch SAN only needs to process a short sequence, and only a small amount of memory is required. Additi\nonally, we use feature-level attention to handle the variation of contexts around the same word, and\n use forward/backward masks to encode temporal order information. On nine benchmark datasets for dif\nferent NLP tasks, Bi-BloSAN achieves or improves upon state-of-the-art accuracy, and shows better ef\nficiency-memory trade-off than existing RNN/CNN/SAN.", "cite_num": -1}, "34": {"title": "learning to share: simultaneous parameter tying and sparsification in deep learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rypT3fb0b", "abstract": "", "cite_num": -1}, "13": {"title": "can neural networks understand logical entailment?", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SkZxCk-0Z", "abstract": "", "cite_num": -1}, "217": {"title": "learning general purpose distributed sentence representations via large scale multi-task learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B18WgG-CZ", "abstract": "", "cite_num": -1}, "12": {"title": "reinforcement learning algorithm selection.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyoDInJ0-", "abstract": "", "cite_num": -1}, "5": {"title": "residual connections encourage iterative inference.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJa9iHgAZ", "abstract": "", "cite_num": -1}, "171": {"title": "learning differentially private recurrent language models.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJ0hF1Z0b", "abstract": "", "cite_num": -1}, "332": {"title": "hyperparameter optimization: a spectral approach.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1zriGeCZ", "abstract": "", "cite_num": -1}, "140": {"title": "stochastic activation pruning for robust adversarial defense.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1uR4GZRZ", "abstract": "", "cite_num": -1}, "25": {"title": "towards image understanding from deep compression without decoding.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkXWCMbRW", "abstract": "", "cite_num": -1}, "185": {"title": "sobolev gan.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJA7xfb0b", "abstract": "", "cite_num": -1}, "182": {"title": "understanding deep neural networks with rectified linear units.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1J_rgWRW", "abstract": "", "cite_num": -1}, "144": {"title": "consequentialist conditional cooperation in social dilemmas with imperfect information.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkabRiQpb", "abstract": "", "cite_num": -1}, "172": {"title": "not-so-random features.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hk8XMWgRb", "abstract": "", "cite_num": -1}, "228": {"title": "neural sketch learning for conditional program generation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkfXMz-Ab", "abstract": "", "cite_num": -1}, "10": {"title": "apprentice: using knowledge distillation techniques to improve low-precision network accuracy.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1ae1lZRb", "abstract": "", "cite_num": -1}, "111": {"title": "unsupervised representation learning by predicting image rotations.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1v4N2l0-", "abstract": "", "cite_num": -1}, "227": {"title": "boosting the actor with dual critic.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkUp6GZRW", "abstract": "", "cite_num": -1}, "125": {"title": "voiceloop: voice fitting and synthesis via a phonological loop.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SkFAWax0-", "abstract": "", "cite_num": -1}, "302": {"title": "demystifying mmd gans.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1lUOzWCW", "abstract": "", "cite_num": -1}, "265": {"title": "large scale optimal transport and mapping estimation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1zlp1bRW", "abstract": "", "cite_num": -1}, "6": {"title": "learning discrete weights using the local reparameterization trick.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BySRH6CpW", "abstract": "", "cite_num": -1}, "17": {"title": "espresso: efficient forward propagation for binary deep neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Sk6fD5yCb", "abstract": "", "cite_num": -1}, "61": {"title": "proximal backpropagation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByeqORgAW", "abstract": "", "cite_num": -1}, "22": {"title": "progressive reinforcement learning with distillation for multi-skilled motion control.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B13njo1R-", "abstract": "", "cite_num": -1}, "149": {"title": "minimal-entropy correlation alignment for unsupervised deep domain adaptation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJWechg0Z", "abstract": "", "cite_num": -1}, "174": {"title": "do gans learn the distribution? some theory and empirics.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJehNfW0-", "abstract": "", "cite_num": -1}, "295": {"title": "relational neural expectation maximization: unsupervised discovery of objects and their interactions.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ryH20GbRW", "abstract": "", "cite_num": -1}, "82": {"title": "lifelong learning with dynamically expandable networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Sk7KsfW0-", "abstract": "", "cite_num": -1}, "92": {"title": "multi-mention learning for reading comprehension with neural cascades.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyRnez-RW", "abstract": "", "cite_num": -1}, "222": {"title": "scalable private learning with pate.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkZB1XbRZ", "abstract": "", "cite_num": -1}, "77": {"title": "neural-guided deductive search for real-time program synthesis from examples.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rywDjg-RW", "abstract": "", "cite_num": -1}, "142": {"title": "the role of minimal complexity functions in unsupervised learning of semantic mappings.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1VjBebR-", "abstract": "", "cite_num": -1}, "164": {"title": "wasserstein auto-encoders.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkL7n1-0b", "abstract": "", "cite_num": -1}, "153": {"title": "automatically inferring data quality for spatiotemporal forecasting.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByJIWUnpW", "abstract": "", "cite_num": -1}, "167": {"title": "certifying some distributional robustness with principled adversarial training.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hk6kPgZA-", "abstract": "", "cite_num": -1}, "204": {"title": "measuring the intrinsic dimension of objective landscapes.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ryup8-WCW", "abstract": "", "cite_num": -1}, "270": {"title": "imitation learning from visual data with multiple intentions.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hk3ddfWRW", "abstract": "", "cite_num": -1}, "44": {"title": "deep bayesian bandits showdown: an empirical comparison of bayesian deep networks for thompson sampling.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyYe6k-CW", "abstract": "", "cite_num": -1}, "173": {"title": "understanding short-horizon bias in stochastic meta-optimization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1MczcgR-", "abstract": "", "cite_num": -1}, "15": {"title": "deep neural networks as gaussian processes.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1EA-M-0Z", "abstract": "", "cite_num": -1}, "72": {"title": "attacking binarized neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkTEFfZRb", "abstract": "", "cite_num": -1}, "163": {"title": "thermometer encoding: one hot way to resist adversarial examples.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S18Su--CW", "abstract": "", "cite_num": -1}, "249": {"title": "model compression via distillation and quantization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1XolQbRW", "abstract": "", "cite_num": -1}, "18": {"title": "the reactor: a fast and sample-efficient actor-critic agent for reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkHVZWZAZ", "abstract": "", "cite_num": -1}, "279": {"title": "i-revnet: deep invertible networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJsjkMb0Z", "abstract": "", "cite_num": -1}, "101": {"title": "rethinking the smaller-norm-less-informative assumption in channel pruning of convolution layers.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJ94fqApW", "abstract": "", "cite_num": -1}, "229": {"title": "empirical risk landscape analysis for understanding deep neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1QgVti6Z", "abstract": "", "cite_num": -1}, "119": {"title": "loss-aware weight quantization of deep networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkrSv0lA-", "abstract": "", "cite_num": -1}, "118": {"title": "compositional attention networks for machine reasoning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1Euwz-Rb", "abstract": "We present the MAC network, a novel fully differentiable neural network architecture, designed to fa\ncilitate explicit and expressive reasoning. MAC moves away from monolithic black-box neural architec\ntures towards a design that encourages both transparency and versatility. The model approaches probl\nems by decomposing them into a series of attention-based reasoning steps, each performed by a novel \nrecurrent Memory, Attention, and Composition (MAC) cell that maintains a separation between control \nand memory. By stringing the cells together and imposing structural constraints that regulate their \ninteraction, MAC effectively learns to perform iterative reasoning processes that are directly infer\nred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and int\nerpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-ar\nt 98.9% accuracy, halving the error rate of the previous best model. More importantly, we show that \nthe model is computationally-efficient and data-efficient, in particular requiring 5x less data than\n existing models to achieve strong results.", "cite_num": 38}, "178": {"title": "multi-task learning for document ranking and query suggestion.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJ1nzBeA-", "abstract": "", "cite_num": -1}, "188": {"title": "skip rnn: learning to skip state updates in recurrent neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkwVAXyCW", "abstract": "", "cite_num": -1}, "98": {"title": "variational image compression with a scale hyperprior.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkcQFMZRb", "abstract": "", "cite_num": -1}, "30": {"title": "expressive power of recurrent neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1WRibb0Z", "abstract": "", "cite_num": -1}, "90": {"title": "active neural localization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ry6-G_66b", "abstract": "", "cite_num": -1}, "293": {"title": "sgd learns over-parameterized networks that provably generalize on linearly separable data.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJ33wwxRb", "abstract": "", "cite_num": -1}, "137": {"title": "parameter space noise for exploration.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByBAl2eAZ", "abstract": "", "cite_num": -1}, "320": {"title": "sensitivity and generalization in neural networks: an empirical study.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJC2SzZCW", "abstract": "", "cite_num": -1}, "74": {"title": "routing networks: adaptive selection of non-linear functions for multi-task learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ry8dvM-R-", "abstract": "", "cite_num": -1}, "24": {"title": "variance reduction for policy gradient with action-dependent factorized baselines.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1tSsb-AW", "abstract": "", "cite_num": -1}, "328": {"title": "many paths to equilibrium: gans do not need to decrease a divergence at every step.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByQpn1ZA-", "abstract": "", "cite_num": -1}, "151": {"title": "guide actor-critic for continuous control.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJk59JZ0b", "abstract": "", "cite_num": -1}, "331": {"title": "ensemble adversarial training: attacks and defenses.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkZvSe-RZ", "abstract": "Adversarial examples are perturbed inputs designed to fool machine learning models. Adversarial trai\nning injects such examples into training data to increase robustness. To scale this technique to lar\nge datasets, perturbations are crafted using fast single-step methods that maximize a linear approxi\nmation of the model's loss. We show that this form of adversarial training converges to a degenerate\n global minimum, wherein small curvature artifacts near the data points obfuscate a linear approxima\ntion of the loss. The model thus learns to generate weak perturbations, rather than defend against s\ntrong ones. As a result, we find that adversarial training remains vulnerable to black-box attacks, \nwhere we transfer perturbations computed on undefended models, as well as to a powerful novel single\n-step attack that escapes the non-smooth vicinity of the input data via a small random step. We furt\nher introduce Ensemble Adversarial Training, a technique that augments training data with perturbati\nons transferred from other models. On ImageNet, Ensemble Adversarial Training yields models with str\nong robustness to black-box attacks. In particular, our most robust model won the first round of the\n NIPS 2017 competition on Defenses against Adversarial Attacks.", "cite_num": 319}, "81": {"title": "dora the explorer: directed outreaching reinforcement action-selection.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ry1arUgCW", "abstract": "", "cite_num": -1}, "334": {"title": "implicit causal models for genome-wide association studies.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyELrEeAb", "abstract": "", "cite_num": -1}, "53": {"title": "a simple neural attentive meta-learner.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1DmUzWAW", "abstract": "", "cite_num": -1}, "89": {"title": "non-autoregressive neural machine translation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1l8BtlCb", "abstract": "", "cite_num": -1}, "216": {"title": "evidence aggregation for answer re-ranking in open-domain question answering.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJl3yM-Ab", "abstract": "", "cite_num": -1}, "16": {"title": "learning sparse latent representations with the deep copula information bottleneck.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hk0wHx-RW", "abstract": "", "cite_num": -1}, "115": {"title": "unsupervised cipher cracking using discrete gans.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkeqO7x0-", "abstract": "", "cite_num": -1}, "126": {"title": "generative models of visually grounded imagination.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkCsm6lRb", "abstract": "", "cite_num": -1}, "139": {"title": "improving the universality and learnability of neural programmer-interpreters with combinator abstraction.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJlMAAeC-", "abstract": "", "cite_num": -1}, "187": {"title": "mixed precision training of convolutional neural networks using integer operations.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H135uzZ0-", "abstract": "", "cite_num": -1}, "253": {"title": "countering adversarial images using input transformations.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SyJ7ClWCb", "abstract": "", "cite_num": -1}, "301": {"title": "fearnet: brain-inspired model for incremental learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJ1Xmf-Rb", "abstract": "", "cite_num": -1}, "80": {"title": "td or not td: analyzing the role of temporal differencing in deep reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyiAuyb0b", "abstract": "", "cite_num": -1}, "235": {"title": "spherical cnns.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hkbd5xZRb", "abstract": "", "cite_num": -1}, "272": {"title": "critical percolation as a framework to analyze the training of deep networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJGWO9k0Z", "abstract": "", "cite_num": -1}, "318": {"title": "a bayesian perspective on generalization and stochastic gradient descent.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJij4yg0Z", "abstract": "", "cite_num": -1}, "43": {"title": "wrpn: wide reduced-precision networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1ZvaaeAZ", "abstract": "", "cite_num": -1}, "309": {"title": "memory-based parameter adaptation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkfOvGbCW", "abstract": "", "cite_num": -1}, "268": {"title": "the high-dimensional geometry of binary neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1IDRdeCW", "abstract": "", "cite_num": -1}, "66": {"title": "improving the improved training of wasserstein gans: a consistency term and its dual effect.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJx9GQb0-", "abstract": "", "cite_num": -1}, "69": {"title": "robustness of classifiers to universal perturbations: a geometric perspective.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByrZyglCb", "abstract": "", "cite_num": -1}, "298": {"title": "noisy networks for exploration.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rywHCPkAW", "abstract": "", "cite_num": -1}, "46": {"title": "learning to count objects in natural images for visual question answering.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B12Js_yRb", "abstract": "", "cite_num": -1}, "75": {"title": "hierarchical density order embeddings.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJCXZQbAZ", "abstract": "", "cite_num": -1}, "189": {"title": "memorization precedes generation: learning unsupervised gans with memory networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkO3uTkAZ", "abstract": "", "cite_num": -1}, "273": {"title": "residual loss prediction: reinforcement learning with no incremental feedback.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJNMYceCW", "abstract": "", "cite_num": -1}, "223": {"title": "hierarchical subtask discovery with non-negative matrix factorization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ry80wMW0W", "abstract": "", "cite_num": -1}, "157": {"title": "a scalable laplace approximation for neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Skdvd2xAZ", "abstract": "", "cite_num": -1}, "0": {"title": "a framework for the quantitative evaluation of disentangled representations.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=By-7dz-AZ", "abstract": "", "cite_num": -1}, "135": {"title": "unsupervised neural machine translation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Sy2ogebAW", "abstract": "", "cite_num": -1}, "209": {"title": "word translation without parallel data.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H196sainb", "abstract": "", "cite_num": -1}, "260": {"title": "zero-shot visual imitation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkisuzWRW", "abstract": "", "cite_num": -1}, "95": {"title": "the implicit bias of gradient descent on separable data.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1q7n9gAb", "abstract": "", "cite_num": -1}, "287": {"title": "unsupervised machine translation using monolingual corpora only.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkYTTf-AZ", "abstract": "", "cite_num": -1}, "289": {"title": "universal agent for disentangling environments and tasks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1mvVm-C-", "abstract": "", "cite_num": -1}, "62": {"title": "action-dependent control variates for policy optimization via stein identity.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1mCp-ZRZ", "abstract": "", "cite_num": -1}, "128": {"title": "hexaconv.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1vuQG-CW", "abstract": "", "cite_num": -1}, "329": {"title": "emergent communication in a multi-modal, multi-step referential game.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJGZq6g0-", "abstract": "Inspired by previous work on emergent communication in referential games, we propose a novel multi-m\nodal, multi-step referential game, where the sender and receiver have access to distinct modalities \nof an object, and their information exchange is bidirectional and of arbitrary duration. The multi-m\nodal multi-step setting allows agents to develop an internal communication significantly closer to n\natural language, in that they share a single set of messages, and that the length of the conversatio\nn may vary according to the difficulty of the task. We examine these properties empirically using a \ndataset consisting of images and textual descriptions of mammals, where the agents are tasked with i\ndentifying the correct object. Our experiments indicate that a robust and efficient communication pr\notocol emerges, where gradual information exchange informs better predictions and higher communicati\non bandwidth improves generalization.", "cite_num": 12}, "303": {"title": "an efficient framework for learning sentence representations.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJvJXZb0W", "abstract": "", "cite_num": -1}, "120": {"title": "deep learning with logged bandit feedback.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJaP_-xAb", "abstract": "", "cite_num": -1}, "280": {"title": "learning to represent programs with graphs.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJOFETxR-", "abstract": "", "cite_num": -1}, "213": {"title": "fraternal dropout.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJyVzQ-C-", "abstract": "", "cite_num": -1}, "214": {"title": "identifying analogies across domains.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkN_r2lR-", "abstract": "", "cite_num": -1}, "207": {"title": "beyond word importance: contextual decomposition to extract interactions from lstms.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkRwGg-0Z", "abstract": "", "cite_num": -1}, "162": {"title": "spatially transformed adversarial examples.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyydRMZC-", "abstract": "", "cite_num": -1}, "33": {"title": "large scale distributed neural network training through online distillation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkr1UDeC-", "abstract": "", "cite_num": -1}, "324": {"title": "emergence of grid-like representations by training recurrent neural networks to perform spatial localization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B17JTOe0-", "abstract": "", "cite_num": -1}, "292": {"title": "mitigating adversarial effects through randomization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Sk9yuql0Z", "abstract": "", "cite_num": -1}, "247": {"title": "learning a neural response metric for retinal prosthesis.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HJhIM0xAW", "abstract": "", "cite_num": -1}, "180": {"title": "decision boundary analysis of adversarial examples.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkpiPMbA-", "abstract": "", "cite_num": -1}, "70": {"title": "when is a convolutional filter easy to learn?", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SkA-IE06W", "abstract": "", "cite_num": -1}, "312": {"title": "twin networks: matching the future for sequence generation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BydLzGb0Z", "abstract": "", "cite_num": -1}, "196": {"title": "variational message passing with structured inference networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyH9lbZAW", "abstract": "", "cite_num": -1}, "243": {"title": "pixeldefend: leveraging generative models to understand and defend against adversarial examples.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rJUYGxbCW", "abstract": "", "cite_num": -1}, "86": {"title": "few-shot autoregressive density estimation: towards learning to learn distributions.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=r1wEFyWCW", "abstract": "", "cite_num": -1}, "11": {"title": "learning from between-class examples for deep sound recognition.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1Gi6LeRZ", "abstract": "", "cite_num": -1}, "211": {"title": "detecting statistical interactions from neural network weights.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByOfBggRZ", "abstract": "", "cite_num": -1}, "156": {"title": "distributed prioritized experience replay.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1Dy---0Z", "abstract": "", "cite_num": -1}, "271": {"title": "policy optimization by genetic distillation.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByOnmlWC-", "abstract": "", "cite_num": -1}, "117": {"title": "learning from noisy singly-labeled data.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1sUHgb0Z", "abstract": "", "cite_num": -1}, "186": {"title": "learning latent permutations with gumbel-sinkhorn networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Byt3oJ-0W", "abstract": "", "cite_num": -1}, "212": {"title": "understanding image motion with group representations.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJLlmG-AZ", "abstract": "", "cite_num": -1}, "275": {"title": "multi-scale dense networks for resource efficient image classification.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Hk2aImxAb", "abstract": "", "cite_num": -1}, "26": {"title": "activation maximization generative adversarial nets.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HyyP33gAZ", "abstract": "", "cite_num": -1}, "37": {"title": "diffusion convolutional recurrent neural network: data-driven traffic forecasting.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SJiHXGWAZ", "abstract": "", "cite_num": -1}, "55": {"title": "deep gradient compression: reducing the communication bandwidth for distributed training.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SkhQHMW0W", "abstract": "", "cite_num": -1}, "310": {"title": "learning sparse neural networks through l_0 regularization.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1Y8hhg0b", "abstract": "", "cite_num": -1}, "40": {"title": "variational continual learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkQqq0gRb", "abstract": "", "cite_num": -1}, "131": {"title": "ask the right questions: active question reformulation with reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1CChZ-CZ", "abstract": "", "cite_num": -1}, "202": {"title": "divide and conquer networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1jscMbAW", "abstract": "", "cite_num": -1}, "154": {"title": "ganite: estimation of individualized treatment effects using generative adversarial nets.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ByKWUeWA-", "abstract": "", "cite_num": -1}, "290": {"title": "intrinsic motivation and automatic curricula via asymmetric self-play.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=SkT5Yg-RZ", "abstract": "", "cite_num": -1}, "1": {"title": "online learning rate adaptation with hypergradient descent.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BkrsAzWAb", "abstract": "", "cite_num": -1}, "3": {"title": "learning intrinsic sparse structures within long short-term memory.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rk6cfpRjZ", "abstract": "", "cite_num": -1}, "132": {"title": "go for a walk and arrive at the answer: reasoning over paths in knowledge bases using reinforcement learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=Syg-YfWCW", "abstract": "", "cite_num": -1}, "129": {"title": "polar transformer networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HktRlUlAZ", "abstract": "", "cite_num": -1}, "41": {"title": "on the information bottleneck theory of deep learning.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=ry_WPG-A-", "abstract": "", "cite_num": -1}, "96": {"title": "searnn: training rnns with global-local losses.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=HkUR_y-RZ", "abstract": "", "cite_num": -1}, "177": {"title": "training generative adversarial networks via primal-dual subgradient methods: a lagrangian perspective on gan.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJNRFNlRW", "abstract": "", "cite_num": -1}, "133": {"title": "deep complex networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1T2hmZAb", "abstract": "", "cite_num": -1}, "170": {"title": "boosting dilated convolutional networks with mixed tensor decompositions.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1JHhv6TW", "abstract": "", "cite_num": -1}, "19": {"title": "nervenet: learning structured policy with graph neural networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=S1sqHMZCb", "abstract": "", "cite_num": -1}, "161": {"title": "causalgan: learning causal implicit generative models with adversarial training.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJE-4xW0W", "abstract": "", "cite_num": -1}, "141": {"title": "recasting gradient-based meta-learning as hierarchical bayes.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=BJ_UL-k0b", "abstract": "", "cite_num": -1}, "49": {"title": "an online learning approach to generative adversarial networks.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=H1Yp-j1Cb", "abstract": "", "cite_num": -1}, "97": {"title": "scan: learning hierarchical compositional visual concepts.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=rkN2Il-RZ", "abstract": "", "cite_num": -1}, "226": {"title": "learning to multi-task by active sampling.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1nZ1weCZ", "abstract": "", "cite_num": -1}, "65": {"title": "a compressed sensing view of unsupervised text embeddings, bag-of-n-grams, and lstms.", "conf": "iclr", "time": "2018", "url": "https://openreview.net/forum?id=B1e5ef-C-", "abstract": "", "cite_num": -1}}