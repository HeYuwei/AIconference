{"0": {"title": "making neural programming architectures generalize via recursion.", "url": "https://openreview.net/forum?id=BkbY4psgg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "1": {"title": "end-to-end optimized image compression.", "url": "https://openreview.net/forum?id=rJxdQ3jeg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "2": {"title": "optimization as a model for few-shot learning.", "url": "https://openreview.net/forum?id=rJY0-Kcll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "3": {"title": "learning end-to-end goal-oriented dialog.", "url": "https://openreview.net/forum?id=S1Bb3D5gg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "4": {"title": "towards principled methods for training generative adversarial networks.", "url": "https://openreview.net/forum?id=Hk4_qw5xe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "5": {"title": "reinforcement learning with unsupervised auxiliary tasks.", "url": "https://openreview.net/forum?id=SJ6yPD5xg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "6": {"title": "multi-agent cooperation and the emergence of (natural) language.", "url": "https://openreview.net/forum?id=Hk8N3Sclg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "7": {"title": "understanding deep learning requires rethinking generalization.", "url": "https://openreview.net/forum?id=Sy8gdB9xx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "8": {"title": "neural architecture search with reinforcement learning.", "url": "https://openreview.net/forum?id=r1Ue8Hcxg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "9": {"title": "q-prop: sample-efficient policy gradient with an off-policy critic.", "url": "https://openreview.net/forum?id=SJ3rcZcxl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "10": {"title": "learning to act by predicting the future.", "url": "https://openreview.net/forum?id=rJLS7qKel", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "11": {"title": "on large-batch training for deep learning: generalization gap and sharp minima.", "url": "https://openreview.net/forum?id=H1oyRlYgg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "12": {"title": "semi-supervised knowledge transfer for deep learning from private training data.", "url": "https://openreview.net/forum?id=HkwoSDPgg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "13": {"title": "amortised map inference for image super-resolution.", "url": "https://openreview.net/forum?id=S1RP6GLle", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "14": {"title": "learning graphical state transitions.", "url": "https://openreview.net/forum?id=HJ0NvFzxl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "15": {"title": "maximum entropy flow networks.", "url": "https://openreview.net/forum?id=H1acq85gx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "16": {"title": "topology and geometry of half-rectified network optimization.", "url": "https://openreview.net/forum?id=Bk0FWVcgx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "17": {"title": "paying more attention to attention: improving the performance of convolutional neural networks via attention transfer.", "url": "https://openreview.net/forum?id=Sks9_ajex", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demons\ntrated that attention can also play an important role in the context of applying artificial neural n\networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that\n, by properly defining attention for convolutional neural networks, we can actually use this type of\n information in order to significantly improve the performance of a student CNN network by forcing i\nt to mimic the attention maps of a powerful teacher network. To that end, we propose several novel m\nethods of transferring attention, showing consistent improvement across a variety of datasets and co\nnvolutional neural network architectures.", "cite_num": -1, "conf": "iclr", "time": "2017"}, "18": {"title": "learning visual servoing with deep features and fitted q-iteration.", "url": "https://openreview.net/forum?id=r1YNw6sxg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "19": {"title": "stochastic neural networks for hierarchical reinforcement learning.", "url": "https://openreview.net/forum?id=B1oK8aoxe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "20": {"title": "nonparametric neural networks.", "url": "https://openreview.net/forum?id=BJK3Xasel", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "21": {"title": "distributed second-order optimization using kronecker-factored approximations.", "url": "https://openreview.net/forum?id=SkkTMpjex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "22": {"title": "pruning filters for efficient convnets.", "url": "https://openreview.net/forum?id=rJqFGTslg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "23": {"title": "learning to generate samples from noise through infusion training.", "url": "https://openreview.net/forum?id=BJAFbaolg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "24": {"title": "filter shaping for convolutional neural networks.", "url": "https://openreview.net/forum?id=S1TER2oll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "25": {"title": "normalizing the normalizers: comparing and extending network normalization schemes.", "url": "https://openreview.net/forum?id=rk5upnsxe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "26": {"title": "multilayer recurrent network models of primate retinal ganglion cell responses.", "url": "https://openreview.net/forum?id=HkEI22jeg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "27": {"title": "improving generative adversarial networks with denoising feature matching.", "url": "https://openreview.net/forum?id=S1X7nhsxl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "28": {"title": "efficient vector representation for documents through corruption.", "url": "https://openreview.net/forum?id=B1Igu2ogg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "29": {"title": "learning invariant feature spaces to transfer skills with reinforcement learning.", "url": "https://openreview.net/forum?id=Hyq4yhile", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "30": {"title": "transfer of view-manifold learning to similarity perception of novel objects.", "url": "https://openreview.net/forum?id=B1gtu5ilg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "31": {"title": "what does it take to generate natural textures?", "url": "https://openreview.net/forum?id=BJhZeLsxx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "32": {"title": "emergence of foveal image sampling from learning to attend in visual scenes.", "url": "https://openreview.net/forum?id=SJJKxrsgl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "33": {"title": "an information-theoretic framework for fast and robust unsupervised learning via neural population infomax.", "url": "https://openreview.net/forum?id=SkYbF1slg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "34": {"title": "pixelcnn++: improving the pixelcnn with discretized logistic mixture likelihood and other modifications.", "url": "https://openreview.net/forum?id=BJrFC6ceg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "35": {"title": "mode regularized generative adversarial networks.", "url": "https://openreview.net/forum?id=HJKkY35le", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "36": {"title": "highway and residual networks learn unrolled iterative estimation.", "url": "https://openreview.net/forum?id=Skn9Shcxe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "37": {"title": "improving neural language models with a continuous cache.", "url": "https://openreview.net/forum?id=B184E5qee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "38": {"title": "unsupervised cross-domain image generation.", "url": "https://openreview.net/forum?id=Sk2Im59ex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "39": {"title": "third person imitation learning.", "url": "https://openreview.net/forum?id=B16dGcqlx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "40": {"title": "variational recurrent adversarial deep domain adaptation.", "url": "https://openreview.net/forum?id=rk9eAFcxg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "41": {"title": "program synthesis for character level language modeling.", "url": "https://openreview.net/forum?id=ry_sjFqgx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "42": {"title": "episodic exploration for deep deterministic policies for starcraft micromanagement.", "url": "https://openreview.net/forum?id=r1LXit5ee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "43": {"title": "soft weight-sharing for neural network compression.", "url": "https://openreview.net/forum?id=HJGwcKclx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "44": {"title": "neural program lattices.", "url": "https://openreview.net/forum?id=HJjiFK5gx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "45": {"title": "tracking the world state with recurrent entity networks.", "url": "https://openreview.net/forum?id=rJTKKKqeg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "46": {"title": "steerable cnns.", "url": "https://openreview.net/forum?id=rJQKYt5ll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "47": {"title": "learning to query, reason, and answer questions on ambiguous texts.", "url": "https://openreview.net/forum?id=rJ0-tY5xe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "48": {"title": "deep predictive coding networks for video prediction and unsupervised learning.", "url": "https://openreview.net/forum?id=B1ewdt9xe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "49": {"title": "diet networks: thin parameters for fat genomics.", "url": "https://openreview.net/forum?id=Sk-oDY9ge", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "50": {"title": "deep biaffine attention for neural dependency parsing.", "url": "https://openreview.net/forum?id=Hk95PK9le", "abstract": "This paper builds off recent work from Kiperwasser & Goldberg (2016) using neural attention in a sim\nple graph-based dependency parser. We use a larger but more thoroughly regularized parser than other\n recent BiLSTM-based approaches, with#N#biaffine classifiers to predict arcs and labels. Our parser \ngets state of the art or near state of the art performance on standard treebanks for six different l\nanguages, achieving 95.7% UAS and 94.1% LAS on the most popular English PTB dataset. This makes it t\nhe highest-performing graph-based parser on this benchmark\u2014outperforming Kiperwasser & Goldberg (201\n6) by 1.8% and 2.2%\u2014and comparable to the highest performing transition-based parser (Kuncoro et al.\n, 2016), which achieves 95.8% UAS and 94.6% LAS. We also show which hyperparameter choices had a sig\nnificant effect on parsing accuracy, allowing us to achieve large gains over other graph-based appro\naches.", "cite_num": 40, "conf": "iclr", "time": "2017"}, "51": {"title": "pixelvae: a latent variable model for natural images.", "url": "https://openreview.net/forum?id=BJKYvt5lg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "52": {"title": "snapshot ensembles: train 1, get m for free.", "url": "https://openreview.net/forum?id=BJYwwY9ll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "53": {"title": "training agent for first-person shooter game with actor-critic curriculum learning.", "url": "https://openreview.net/forum?id=Hk3mPK5gg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "54": {"title": "neuro-symbolic program synthesis.", "url": "https://openreview.net/forum?id=rJ0JwFcex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "55": {"title": "decomposing motion and content for natural video sequence prediction.", "url": "https://openreview.net/forum?id=rkEFLFqee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "56": {"title": "towards a neural statistician.", "url": "https://openreview.net/forum?id=HJDBUF5le", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "57": {"title": "generative models and model criticism via optimized maximum mean discrepancy.", "url": "https://openreview.net/forum?id=HJWHIKqgl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "58": {"title": "generalizing skills with semi-supervised reinforcement learning.", "url": "https://openreview.net/forum?id=ryHlUtqge", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "59": {"title": "learning curve prediction with bayesian neural networks.", "url": "https://openreview.net/forum?id=S11KBYclx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "60": {"title": "learning to optimize.", "url": "https://openreview.net/forum?id=ry4Vrt5gl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "61": {"title": "a compare-aggregate model for matching text sequences.", "url": "https://openreview.net/forum?id=HJTzHtqee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "62": {"title": "data noising as smoothing in neural network language models.", "url": "https://openreview.net/forum?id=H1VyHY9gg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "63": {"title": "training compressed fully-connected networks with a density-diversity penalty.", "url": "https://openreview.net/forum?id=Hku9NK5lx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "64": {"title": "autoencoding variational inference for topic models.", "url": "https://openreview.net/forum?id=BybtVK9lg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "65": {"title": "optimal binary autoencoding with pairwise correlations.", "url": "https://openreview.net/forum?id=ryelgY5eg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "66": {"title": "on the quantitative analysis of decoder-based generative models.", "url": "https://openreview.net/forum?id=B1M8JF9xx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "67": {"title": "trained ternary quantization.", "url": "https://openreview.net/forum?id=S1_pAu9xl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "68": {"title": "dsd: dense-sparse-dense training for deep neural networks.", "url": "https://openreview.net/forum?id=HyoST_9xl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "69": {"title": "a compositional object-based approach to learning physical dynamics.", "url": "https://openreview.net/forum?id=Bkab5dqxe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "70": {"title": "learning to remember rare events.", "url": "https://openreview.net/forum?id=SJTQLdqlg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "71": {"title": "transfer learning for sequence tagging with hierarchical recurrent networks.", "url": "https://openreview.net/forum?id=ByxpMd9lx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "72": {"title": "words or characters? fine-grained gating for reading comprehension.", "url": "https://openreview.net/forum?id=B1hdzd5lg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "73": {"title": "a simple but tough-to-beat baseline for sentence embeddings.", "url": "https://openreview.net/forum?id=SyK00v5xx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "74": {"title": "capacity and trainability in recurrent neural networks.", "url": "https://openreview.net/forum?id=BydARw9ex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "75": {"title": "learning to perform physics experiments via deep reinforcement learning.", "url": "https://openreview.net/forum?id=r1nTpv9eg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "76": {"title": "improving policy gradient by exploring under-appreciated rewards.", "url": "https://openreview.net/forum?id=ryT4pvqll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "77": {"title": "deep learning with dynamic computation graphs.", "url": "https://openreview.net/forum?id=ryrGawqex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "78": {"title": "calibrating energy-based generative adversarial networks.", "url": "https://openreview.net/forum?id=SyxeqhP9ll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "79": {"title": "pruning convolutional neural networks for resource efficient inference.", "url": "https://openreview.net/forum?id=SJGCiw5gl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "80": {"title": "query-reduction networks for question answering.", "url": "https://openreview.net/forum?id=B1MRcPclx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "81": {"title": "designing neural network architectures using reinforcement learning.", "url": "https://openreview.net/forum?id=S1c2cvqee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "82": {"title": "machine comprehension using match-lstm and answer pointer.", "url": "https://openreview.net/forum?id=B1-q5Pqxl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "83": {"title": "deepdsl: a compilation-based domain-specific language for deep learning.", "url": "https://openreview.net/forum?id=Bks8cPcxe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "84": {"title": "bidirectional attention flow for machine comprehension.", "url": "https://openreview.net/forum?id=HJ0UKP9ge", "abstract": "Machine comprehension (MC), answering a query about a given context paragraph, requires modeling com\nplex interactions between the context and the query. Recently, attention mechanisms have been succes\nsfully extended to MC. Typically these methods use attention to focus on a small portion of the cont\next and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni\n-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network\n, a multi-stage hierarchical process that represents the context at different levels of granularity \nand uses bi-directional attention flow mechanism to obtain a query-aware context representation with\nout early summarization. Our experimental evaluations show that our model achieves the state-of-the-\nart results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test.", "cite_num": 343, "conf": "iclr", "time": "2017"}, "85": {"title": "incorporating long-range consistency in cnn-based texture generation.", "url": "https://openreview.net/forum?id=HyGTuv9eg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "86": {"title": "dynamic coattention networks for question answering.", "url": "https://openreview.net/forum?id=rJeKjwvclx", "abstract": "Several deep learning models have been proposed for question answering. However, due to their single\n-pass nature, they have no way to recover from local maxima corresponding to incorrect answers. To a\nddress this problem, we introduce the Dynamic Coattention Network (DCN) for question answering. The \nDCN first fuses co-dependent representations of the question and the document in order to focus on r\nelevant parts of both. Then a dynamic pointing decoder iterates over potential answer spans. This it\nerative procedure enables the model to recover from initial local maxima corresponding to incorrect \nanswers. On the Stanford question answering dataset, a single DCN model improves the previous state \nof the art from 71.0% F1 to 75.9%, while a DCN ensemble obtains 80.4% F1.", "cite_num": 241, "conf": "iclr", "time": "2017"}, "87": {"title": "samplernn: an unconditional end-to-end neural audio generation model.", "url": "https://openreview.net/forum?id=SkxKPDv5xl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "88": {"title": "metacontrol for adaptive imagination-based optimization.", "url": "https://openreview.net/forum?id=Bk8BvDqex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "89": {"title": "exploring sparsity in recurrent neural networks.", "url": "https://openreview.net/forum?id=BylSPv9gx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "90": {"title": "lossy image compression with compressive autoencoders.", "url": "https://openreview.net/forum?id=rJiNwv9gg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "91": {"title": "structured attention networks.", "url": "https://openreview.net/forum?id=HkE0Nvqlg", "abstract": "Attention networks have proven to be an effective approach for embedding categorical inference withi\nn a deep neural network. However, for many tasks we may want to model richer structural dependencies\n without abandoning end-to-end training. In this work, we experiment with incorporating richer struc\ntural distributions, encoded using graphical models, within deep networks. We show that these struct\nured attention networks are simple extensions of the basic attention procedure, and that they allow \nfor extending attention beyond the standard soft-selection approach, such as attending to partial se\ngmentations or to subtrees. We experiment with two different classes of structured attention network\ns: a linear-chain conditional random field and a graph-based parsing model, and describe how these m\nodels can be practically implemented as neural network layers. Experiments show that this approach i\ns effective for incorporating structural biases, and structured attention networks outperform baseli\nne attention models on a variety of synthetic and real tasks: tree transduction, neural machine tran\nslation, question answering, and natural language inference. We further find that models trained in \nthis way learn interesting unsupervised hidden representations that generalize simple attention.", "cite_num": 88, "conf": "iclr", "time": "2017"}, "92": {"title": "zoneout: regularizing rnns by randomly preserving hidden activations.", "url": "https://openreview.net/forum?id=rJqBEPcxe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "93": {"title": "deep probabilistic programming.", "url": "https://openreview.net/forum?id=Hy6b4Pqee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "94": {"title": "lr-gan: layered recursive generative adversarial networks for image generation.", "url": "https://openreview.net/forum?id=HJ1kmv9xx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "95": {"title": "variational lossy autoencoder.", "url": "https://openreview.net/forum?id=BysvGP5ee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "96": {"title": "a recurrent neural network without chaos.", "url": "https://openreview.net/forum?id=S1dIzvclg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "97": {"title": "outrageously large neural networks: the sparsely-gated mixture-of-experts layer.", "url": "https://openreview.net/forum?id=B1ckMDqlg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "98": {"title": "tree-structured decoding with doubly-recurrent neural networks.", "url": "https://openreview.net/forum?id=HkYhZDqxg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "99": {"title": "introspection: accelerating neural network training by learning weight evolution.", "url": "https://openreview.net/forum?id=Hkg8bDqee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "100": {"title": "hyperband: bandit-based configuration evaluation for hyperparameter optimization.", "url": "https://openreview.net/forum?id=ry18Ww5ee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "101": {"title": "lie-access neural turing machines.", "url": "https://openreview.net/forum?id=Byiy-Pqlx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "102": {"title": "quasi-recurrent neural networks.", "url": "https://openreview.net/forum?id=H1zJ-v5xl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "103": {"title": "recurrent environment simulators.", "url": "https://openreview.net/forum?id=B1s6xvqlx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "104": {"title": "epopt: learning robust neural network policies using model ensembles.", "url": "https://openreview.net/forum?id=SyWvgP5el", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "105": {"title": "attend, adapt and transfer: attentive deep architecture for adaptive transfer from multiple sources in the same domain.", "url": "https://openreview.net/forum?id=Sy6iJDqlx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "106": {"title": "multi-view recurrent neural acoustic word embeddings.", "url": "https://openreview.net/forum?id=rJxDkvqee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "107": {"title": "learning features of music from scratch.", "url": "https://openreview.net/forum?id=rkFBJv9gg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "108": {"title": "a baseline for detecting misclassified and out-of-distribution examples in neural networks.", "url": "https://openreview.net/forum?id=Hkg4TI9xl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "109": {"title": "learning to superoptimize programs.", "url": "https://openreview.net/forum?id=r1rz6U5lg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "110": {"title": "trusting svm for piecewise linear cnns.", "url": "https://openreview.net/forum?id=By5e2L9gl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "111": {"title": "sigma delta quantized networks.", "url": "https://openreview.net/forum?id=HkNRsU5ge", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "112": {"title": "a structured self-attentive sentence embedding.", "url": "https://openreview.net/forum?id=BJC_jUqxe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "113": {"title": "regularizing cnns with locally constrained decorrelations.", "url": "https://openreview.net/forum?id=ByOvsIqeg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "114": {"title": "the concrete distribution: a continuous relaxation of discrete random variables.", "url": "https://openreview.net/forum?id=S1jE5L5gl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "115": {"title": "unrolled generative adversarial networks.", "url": "https://openreview.net/forum?id=BydrOIcle", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "116": {"title": "topicrnn: a recurrent neural network with long-range semantic dependency.", "url": "https://openreview.net/forum?id=rJbbOLcex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "117": {"title": "frustratingly short attention spans in neural language modeling.", "url": "https://openreview.net/forum?id=ByIAPUcee", "abstract": "Neural language models predict the next token using a latent representation of the immediate token h\nistory. Recently, various methods for augmenting neural language models with an attention mechanism \nover a differentiable memory have been proposed. For predicting the next token, these models query i\nnformation from a memory of the recent history which can facilitate learning mid- and long-range dep\nendencies. However, conventional attention mechanisms used in memory-augmented neural language model\ns produce a single output vector per time step. This vector is used both for predicting the next tok\nen as well as for the key and value of a differentiable memory of a token history. In this paper, we\n propose a neural language model with a key-value attention mechanism that outputs separate represen\ntations for the key and value of a differentiable memory, as well as for encoding the next-word dist\nribution. This model outperforms existing memory-augmented neural language models on two corpora. Ye\nt, we found that our method mainly utilizes a memory of the five most recent output representations.\n This led to the unexpected main finding that a much simpler model based only on the concatenation o\nf recent output representations from previous time steps is on par with more sophisticated memory-au\ngmented neural language models.", "cite_num": 29, "conf": "iclr", "time": "2017"}, "118": {"title": "recurrent hidden semi-markov model.", "url": "https://openreview.net/forum?id=HJGODLqgx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "119": {"title": "deep variational bayes filters: unsupervised learning of state space models from raw data.", "url": "https://openreview.net/forum?id=HyTqHL5xg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "120": {"title": "generative multi-adversarial networks.", "url": "https://openreview.net/forum?id=Byk-VI9eg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "121": {"title": "mollifying networks.", "url": "https://openreview.net/forum?id=r1G4z8cge", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "122": {"title": "beta-vae: learning basic visual concepts with a constrained variational framework.", "url": "https://openreview.net/forum?id=Sy2fzU9gl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "123": {"title": "offline bilingual word vectors, orthogonal transformations and the inverted softmax.", "url": "https://openreview.net/forum?id=r1Aab85gg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "124": {"title": "visualizing deep neural network decisions: prediction difference analysis.", "url": "https://openreview.net/forum?id=BJ5UeU9xx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "125": {"title": "categorical reparameterization with gumbel-softmax.", "url": "https://openreview.net/forum?id=rkE3y85ee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "126": {"title": "online bayesian transfer learning for sequential data modeling.", "url": "https://openreview.net/forum?id=ByqiJIqxg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "127": {"title": "latent sequence decompositions.", "url": "https://openreview.net/forum?id=SyQq185lg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "128": {"title": "paleo: a performance model for deep neural networks.", "url": "https://openreview.net/forum?id=SyVVJ85lg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "129": {"title": "combining policy gradient and q-learning.", "url": "https://openreview.net/forum?id=B1kJ6H9ex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "130": {"title": "density estimation using real nvp.", "url": "https://openreview.net/forum?id=HkpbnH9lx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "131": {"title": "recurrent batch normalization.", "url": "https://openreview.net/forum?id=r1VdcHcxx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "132": {"title": "sgdr: stochastic gradient descent with warm restarts.", "url": "https://openreview.net/forum?id=Skq89Scxx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "133": {"title": "learning a natural language interface with neural programmer.", "url": "https://openreview.net/forum?id=ry2YOrcge", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "134": {"title": "reinforcement learning through asynchronous advantage actor-critic on a gpu.", "url": "https://openreview.net/forum?id=r1VGvBcxl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "135": {"title": "learning to navigate in complex environments.", "url": "https://openreview.net/forum?id=SJMGPrcle", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "136": {"title": "deepcoder: learning to write programs.", "url": "https://openreview.net/forum?id=ByldLrqlx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "137": {"title": "learning and policy search in stochastic dynamical systems with bayesian neural networks.", "url": "https://openreview.net/forum?id=H1fl8S9ee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "138": {"title": "variable computation in recurrent neural networks.", "url": "https://openreview.net/forum?id=S1LVSrcge", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "139": {"title": "deep variational information bottleneck.", "url": "https://openreview.net/forum?id=HyxQzBceg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "140": {"title": "the neural noisy channel.", "url": "https://openreview.net/forum?id=SJ25-B5eg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "141": {"title": "automatic rule extraction from long short term memory networks.", "url": "https://openreview.net/forum?id=SJvYgH9xe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "142": {"title": "dialogue learning with human-in-the-loop.", "url": "https://openreview.net/forum?id=HJgXCV9xx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "143": {"title": "adversarially learned inference.", "url": "https://openreview.net/forum?id=B1ElR4cgg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "144": {"title": "learning through dialogue interactions by asking questions.", "url": "https://openreview.net/forum?id=rkE8pVcle", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "145": {"title": "deep information propagation.", "url": "https://openreview.net/forum?id=H1W1UN9gg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "146": {"title": "fractalnet: ultra-deep neural networks without residuals.", "url": "https://openreview.net/forum?id=S1VaB4cex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "147": {"title": "revisiting classifier two-sample tests.", "url": "https://openreview.net/forum?id=SJkXfE5xx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "148": {"title": "learning to repeat: fine grained action repetition for deep reinforcement learning.", "url": "https://openreview.net/forum?id=B1GOWV5eg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "149": {"title": "loss-aware binarization of deep networks.", "url": "https://openreview.net/forum?id=S1oWlN9ll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "150": {"title": "learning to play in a day: faster deep reinforcement learning by optimality tightening.", "url": "https://openreview.net/forum?id=rJ8Je4clg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "151": {"title": "energy-based generative adversarial networks.", "url": "https://openreview.net/forum?id=ryh9pmcee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "152": {"title": "central moment discrepancy (cmd) for domain-invariant representation learning.", "url": "https://openreview.net/forum?id=SkB-_mcel", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "153": {"title": "incremental network quantization: towards lossless cnns with low-precision weights.", "url": "https://openreview.net/forum?id=HyQJ-mclg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "154": {"title": "entropy-sgd: biasing gradient descent into wide valleys.", "url": "https://openreview.net/forum?id=B1YfAfcgl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "155": {"title": "deep multi-task representation learning: a tensor factorisation approach.", "url": "https://openreview.net/forum?id=SkhU2fcll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "156": {"title": "sample efficient actor-critic with experience replay.", "url": "https://openreview.net/forum?id=HyM25Mqel", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "157": {"title": "temporal ensembling for semi-supervised learning.", "url": "https://openreview.net/forum?id=BJ6oOfqge", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "158": {"title": "on detecting adversarial perturbations.", "url": "https://openreview.net/forum?id=SJzCSf9xg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "159": {"title": "training deep neural-networks using a noise adaptation layer.", "url": "https://openreview.net/forum?id=H12GRgcxg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "160": {"title": "learning to compose words into sentences with reinforcement learning.", "url": "https://openreview.net/forum?id=Skvgqgqxe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "161": {"title": "delving into transferable adversarial examples and black-box attacks.", "url": "https://openreview.net/forum?id=Sys6GJqxl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "162": {"title": "identity matters in deep learning.", "url": "https://openreview.net/forum?id=ryxB0Rtxx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "163": {"title": "adversarial feature learning.", "url": "https://openreview.net/forum?id=BJtNZAFgg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "164": {"title": "towards the limit of network quantization.", "url": "https://openreview.net/forum?id=rJ8uNptgl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "165": {"title": "faster cnns with direct sparse convolutions and guided pruning.", "url": "https://openreview.net/forum?id=rJPcZ3txx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "166": {"title": "stick-breaking variational autoencoders.", "url": "https://openreview.net/forum?id=S1jmAotxg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "167": {"title": "batch policy gradient methods for improving neural conversation models.", "url": "https://openreview.net/forum?id=rJfMusFll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "168": {"title": "support regularized sparse coding and its fast encoder.", "url": "https://openreview.net/forum?id=HkljfjFee", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "169": {"title": "tying word vectors and word classifiers: a loss framework for language modeling.", "url": "https://openreview.net/forum?id=r1aPbsFle", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "170": {"title": "towards deep interpretability (mus-rover ii): learning hierarchical representations of tonal music.", "url": "https://openreview.net/forum?id=ryhqQFKgl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "171": {"title": "discrete variational autoencoders.", "url": "https://openreview.net/forum?id=ryMxXPFex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "172": {"title": "do deep convolutional nets really need to be deep and convolutional?", "url": "https://openreview.net/forum?id=r10FA8Kxg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "173": {"title": "geometry of polysemy.", "url": "https://openreview.net/forum?id=HJpfMIFll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "174": {"title": "learning invariant representations of planar curves.", "url": "https://openreview.net/forum?id=BymIbLKgl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "175": {"title": "reasoning with memory augmented neural networks for language comprehension.", "url": "https://openreview.net/forum?id=Hk8TGSKlg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "176": {"title": "learning recurrent representations for hierarchical behavior modeling.", "url": "https://openreview.net/forum?id=BkLhzHtlg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "177": {"title": "adversarial machine learning at scale.", "url": "https://openreview.net/forum?id=BJm4T4Kgx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "178": {"title": "predicting medications from diagnostic codes with recurrent neural networks.", "url": "https://openreview.net/forum?id=rJEgeXFex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "179": {"title": "recurrent mixture density network for spatiotemporal visual attention.", "url": "https://openreview.net/forum?id=SJRpRfKxx", "abstract": "In many computer vision tasks, the relevant information to solve the problem at hand is mixed to irr\nelevant, distracting information. This has motivated researchers to design attentional models that c\nan dynamically focus on parts of images or videos that are salient, e.g., by down-weighting irreleva\nnt pixels. In this work, we propose a spatiotemporal attentional model that learns where to look in \na video directly from human fixation data. We model visual attention with a mixture of Gaussians at \neach frame. This distribution is used to express the probability of saliency for each pixel. Time co\nnsistency in videos is modeled hierarchically by: 1) deep 3D convolutional features to represent spa\ntial and short-term time relations and 2) a long short-term memory network on top that aggregates th\ne clip-level representation of sequential clips and therefore expands the temporal domain from few f\nrames to seconds. The parameters of the proposed model are optimized via maximum likelihood estimati\non using human fixations as training data, without knowledge of the action in each video. Our experi\nments on Hollywood2 show state-of-the-art performance on saliency prediction for video. We also show\n that our attentional model trained on Hollywood2 generalizes well to UCF101 and it can be leveraged\n to improve action classification accuracy on both datasets.", "cite_num": 25, "conf": "iclr", "time": "2017"}, "180": {"title": "inductive bias of deep convolutional networks through pooling geometry.", "url": "https://openreview.net/forum?id=BkVsEMYel", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "181": {"title": "efficient representation of low-dimensional manifolds using deep networks.", "url": "https://openreview.net/forum?id=BJ3filKll", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "182": {"title": "semi-supervised classification with graph convolutional networks.", "url": "https://openreview.net/forum?id=SJU4ayYgl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "183": {"title": "sparsely-connected neural networks: towards efficient vlsi implementation of deep neural networks.", "url": "https://openreview.net/forum?id=r1fYuytex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "184": {"title": "adversarial training methods for semi-supervised text classification.", "url": "https://openreview.net/forum?id=r1X3g2_xl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "185": {"title": "fine-grained analysis of sentence embeddings using auxiliary prediction tasks.", "url": "https://openreview.net/forum?id=BJh6Ztuxl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "186": {"title": "pointer sentinel mixture models.", "url": "https://openreview.net/forum?id=Byj72udxe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "187": {"title": "an actor-critic algorithm for sequence prediction.", "url": "https://openreview.net/forum?id=SJDaqqveg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "188": {"title": "understanding trainable sparse coding with matrix factorization.", "url": "https://openreview.net/forum?id=SJGPL9Dex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "189": {"title": "tighter bounds lead to improved classifiers.", "url": "https://openreview.net/forum?id=HyAbMKwxe", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "190": {"title": "holstep: a machine learning dataset for higher-order logic theorem proving.", "url": "https://openreview.net/forum?id=ryuxYmvel", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "191": {"title": "why deep neural networks for function approximation?", "url": "https://openreview.net/forum?id=SkpSlKIel", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "192": {"title": "hierarchical multiscale recurrent neural networks.", "url": "https://openreview.net/forum?id=S1di0sfgl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "193": {"title": "neural photo editing with introspective adversarial networks.", "url": "https://openreview.net/forum?id=HkNKFiGex", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "194": {"title": "dropout with expectation-linear regularization.", "url": "https://openreview.net/forum?id=rkGabzZgl", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "195": {"title": "hypernetworks.", "url": "https://openreview.net/forum?id=rkpACe1lx", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "196": {"title": "a learned representation for artistic style.", "url": "https://openreview.net/forum?id=BJO-BuT1g", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}, "197": {"title": "hadamard product for low-rank bilinear pooling.", "url": "https://openreview.net/forum?id=r1rhWnZkg", "abstract": "", "cite_num": -1, "conf": "iclr", "time": "2017"}}