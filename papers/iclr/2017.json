{"52": {"title": "energy-based generative adversarial networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ryh9pmcee", "abstract": "", "cite_num": -1}, "68": {"title": "sigma delta quantized networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HkNRsU5ge", "abstract": "", "cite_num": -1}, "124": {"title": "tighter bounds lead to improved classifiers.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HyAbMKwxe", "abstract": "", "cite_num": -1}, "38": {"title": "hierarchical multiscale recurrent neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1di0sfgl", "abstract": "", "cite_num": -1}, "8": {"title": "highway and residual networks learn unrolled iterative estimation.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Skn9Shcxe", "abstract": "", "cite_num": -1}, "197": {"title": "learning and policy search in stochastic dynamical systems with bayesian neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=H1fl8S9ee", "abstract": "", "cite_num": -1}, "29": {"title": "incremental network quantization: towards lossless cnns with low-precision weights.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HyQJ-mclg", "abstract": "", "cite_num": -1}, "110": {"title": "episodic exploration for deep deterministic policies for starcraft micromanagement.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1LXit5ee", "abstract": "", "cite_num": -1}, "35": {"title": "dropout with expectation-linear regularization.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rkGabzZgl", "abstract": "", "cite_num": -1}, "59": {"title": "understanding trainable sparse coding with matrix factorization.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJGPL9Dex", "abstract": "", "cite_num": -1}, "23": {"title": "sgdr: stochastic gradient descent with warm restarts.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Skq89Scxx", "abstract": "", "cite_num": -1}, "116": {"title": "temporal ensembling for semi-supervised learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJ6oOfqge", "abstract": "", "cite_num": -1}, "123": {"title": "lr-gan: layered recursive generative adversarial networks for image generation.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJ1kmv9xx", "abstract": "", "cite_num": -1}, "136": {"title": "revisiting classifier two-sample tests.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJkXfE5xx", "abstract": "", "cite_num": -1}, "138": {"title": "automatic rule extraction from long short term memory networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJvYgH9xe", "abstract": "", "cite_num": -1}, "112": {"title": "loss-aware binarization of deep networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1oWlN9ll", "abstract": "", "cite_num": -1}, "147": {"title": "mode regularized generative adversarial networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJKkY35le", "abstract": "", "cite_num": -1}, "45": {"title": "recurrent environment simulators.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1s6xvqlx", "abstract": "", "cite_num": -1}, "60": {"title": "paleo: a performance model for deep neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SyVVJ85lg", "abstract": "", "cite_num": -1}, "169": {"title": "quasi-recurrent neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=H1zJ-v5xl", "abstract": "", "cite_num": -1}, "67": {"title": "learning to navigate in complex environments.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJMGPrcle", "abstract": "", "cite_num": -1}, "100": {"title": "a recurrent neural network without chaos.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1dIzvclg", "abstract": "", "cite_num": -1}, "193": {"title": "zoneout: regularizing rnns by randomly preserving hidden activations.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJqBEPcxe", "abstract": "", "cite_num": -1}, "166": {"title": "discrete variational autoencoders.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ryMxXPFex", "abstract": "", "cite_num": -1}, "113": {"title": "towards the limit of network quantization.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJ8uNptgl", "abstract": "", "cite_num": -1}, "4": {"title": "fine-grained analysis of sentence embeddings using auxiliary prediction tasks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJh6Ztuxl", "abstract": "", "cite_num": -1}, "190": {"title": "distributed second-order optimization using kronecker-factored approximations.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SkkTMpjex", "abstract": "", "cite_num": -1}, "36": {"title": "learning invariant feature spaces to transfer skills with reinforcement learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Hyq4yhile", "abstract": "", "cite_num": -1}, "99": {"title": "learning to repeat: fine grained action repetition for deep reinforcement learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1GOWV5eg", "abstract": "", "cite_num": -1}, "14": {"title": "learning to compose words into sentences with reinforcement learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Skvgqgqxe", "abstract": "", "cite_num": -1}, "102": {"title": "making neural programming architectures generalize via recursion.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BkbY4psgg", "abstract": "", "cite_num": -1}, "106": {"title": "hyperband: bandit-based configuration evaluation for hyperparameter optimization.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ry18Ww5ee", "abstract": "", "cite_num": -1}, "130": {"title": "learning curve prediction with bayesian neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S11KBYclx", "abstract": "", "cite_num": -1}, "192": {"title": "geometry of polysemy.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJpfMIFll", "abstract": "", "cite_num": -1}, "103": {"title": "dialogue learning with human-in-the-loop.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJgXCV9xx", "abstract": "", "cite_num": -1}, "155": {"title": "normalizing the normalizers: comparing and extending network normalization schemes.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rk5upnsxe", "abstract": "", "cite_num": -1}, "54": {"title": "multi-view recurrent neural acoustic word embeddings.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJxDkvqee", "abstract": "", "cite_num": -1}, "57": {"title": "filter shaping for convolutional neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1TER2oll", "abstract": "", "cite_num": -1}, "73": {"title": "semi-supervised knowledge transfer for deep learning from private training data.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HkwoSDPgg", "abstract": "", "cite_num": -1}, "56": {"title": "a simple but tough-to-beat baseline for sentence embeddings.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SyK00v5xx", "abstract": "", "cite_num": -1}, "107": {"title": "learning to play in a day: faster deep reinforcement learning by optimality tightening.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJ8Je4clg", "abstract": "", "cite_num": -1}, "109": {"title": "tracking the world state with recurrent entity networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJTKKKqeg", "abstract": "", "cite_num": -1}, "71": {"title": "on detecting adversarial perturbations.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJzCSf9xg", "abstract": "", "cite_num": -1}, "48": {"title": "deep predictive coding networks for video prediction and unsupervised learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1ewdt9xe", "abstract": "", "cite_num": -1}, "181": {"title": "neural program lattices.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJjiFK5gx", "abstract": "", "cite_num": -1}, "160": {"title": "training compressed fully-connected networks with a density-diversity penalty.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Hku9NK5lx", "abstract": "", "cite_num": -1}, "127": {"title": "offline bilingual word vectors, orthogonal transformations and the inverted softmax.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1Aab85gg", "abstract": "", "cite_num": -1}, "194": {"title": "pruning filters for efficient convnets.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJqFGTslg", "abstract": "", "cite_num": -1}, "152": {"title": "improving policy gradient by exploring under-appreciated rewards.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ryT4pvqll", "abstract": "", "cite_num": -1}, "121": {"title": "data noising as smoothing in neural network language models.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=H1VyHY9gg", "abstract": "", "cite_num": -1}, "183": {"title": "inductive bias of deep convolutional networks through pooling geometry.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BkVsEMYel", "abstract": "", "cite_num": -1}, "83": {"title": "recurrent hidden semi-markov model.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJGODLqgx", "abstract": "", "cite_num": -1}, "2": {"title": "hadamard product for low-rank bilinear pooling.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1rhWnZkg", "abstract": "", "cite_num": -1}, "150": {"title": "learning graphical state transitions.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJ0NvFzxl", "abstract": "", "cite_num": -1}, "158": {"title": "learning to remember rare events.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJTQLdqlg", "abstract": "", "cite_num": -1}, "47": {"title": "learning to query, reason, and answer questions on ambiguous texts.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJ0-tY5xe", "abstract": "", "cite_num": -1}, "79": {"title": "steerable cnns.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJQKYt5ll", "abstract": "", "cite_num": -1}, "84": {"title": "multi-agent cooperation and the emergence of (natural) language.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Hk8N3Sclg", "abstract": "", "cite_num": -1}, "168": {"title": "do deep convolutional nets really need to be deep and convolutional?", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r10FA8Kxg", "abstract": "", "cite_num": -1}, "145": {"title": "towards principled methods for training generative adversarial networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Hk4_qw5xe", "abstract": "", "cite_num": -1}, "165": {"title": "a compare-aggregate model for matching text sequences.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJTzHtqee", "abstract": "", "cite_num": -1}, "78": {"title": "incorporating long-range consistency in cnn-based texture generation.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HyGTuv9eg", "abstract": "", "cite_num": -1}, "88": {"title": "learning end-to-end goal-oriented dialog.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1Bb3D5gg", "abstract": "", "cite_num": -1}, "93": {"title": "holstep: a machine learning dataset for higher-order logic theorem proving.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ryuxYmvel", "abstract": "", "cite_num": -1}, "9": {"title": "support regularized sparse coding and its fast encoder.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HkljfjFee", "abstract": "", "cite_num": -1}, "85": {"title": "metacontrol for adaptive imagination-based optimization.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Bk8BvDqex", "abstract": "", "cite_num": -1}, "31": {"title": "a baseline for detecting misclassified and out-of-distribution examples in neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Hkg4TI9xl", "abstract": "", "cite_num": -1}, "64": {"title": "exploring sparsity in recurrent neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BylSPv9gx", "abstract": "", "cite_num": -1}, "191": {"title": "deep learning with dynamic computation graphs.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ryrGawqex", "abstract": "", "cite_num": -1}, "122": {"title": "paying more attention to attention: improving the performance of convolutional neural networks via attention transfer.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Sks9_ajex", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demons\ntrated that attention can also play an important role in the context of applying artificial neural n\networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that\n, by properly defining attention for convolutional neural networks, we can actually use this type of\n information in order to significantly improve the performance of a student CNN network by forcing i\nt to mimic the attention maps of a powerful teacher network. To that end, we propose several novel m\nethods of transferring attention, showing consistent improvement across a variety of datasets and co\nnvolutional neural network architectures.", "cite_num": -1}, "20": {"title": "q-prop: sample-efficient policy gradient with an off-policy critic.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJ3rcZcxl", "abstract": "", "cite_num": -1}, "159": {"title": "recurrent batch normalization.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1VdcHcxx", "abstract": "", "cite_num": -1}, "146": {"title": "deep variational information bottleneck.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HyxQzBceg", "abstract": "", "cite_num": -1}, "94": {"title": "trained ternary quantization.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1_pAu9xl", "abstract": "", "cite_num": -1}, "58": {"title": "bidirectional attention flow for machine comprehension.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJ0UKP9ge", "abstract": "Machine comprehension (MC), answering a query about a given context paragraph, requires modeling com\nplex interactions between the context and the query. Recently, attention mechanisms have been succes\nsfully extended to MC. Typically these methods use attention to focus on a small portion of the cont\next and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni\n-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network\n, a multi-stage hierarchical process that represents the context at different levels of granularity \nand uses bi-directional attention flow mechanism to obtain a query-aware context representation with\nout early summarization. Our experimental evaluations show that our model achieves the state-of-the-\nart results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test.", "cite_num": 343}, "91": {"title": "pixelvae: a latent variable model for natural images.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJKYvt5lg", "abstract": "", "cite_num": -1}, "175": {"title": "introspection: accelerating neural network training by learning weight evolution.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Hkg8bDqee", "abstract": "", "cite_num": -1}, "148": {"title": "adversarial training methods for semi-supervised text classification.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1X3g2_xl", "abstract": "", "cite_num": -1}, "104": {"title": "neural architecture search with reinforcement learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1Ue8Hcxg", "abstract": "", "cite_num": -1}, "87": {"title": "the neural noisy channel.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJ25-B5eg", "abstract": "", "cite_num": -1}, "179": {"title": "end-to-end optimized image compression.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJxdQ3jeg", "abstract": "", "cite_num": -1}, "114": {"title": "soft weight-sharing for neural network compression.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJGwcKclx", "abstract": "", "cite_num": -1}, "39": {"title": "stochastic neural networks for hierarchical reinforcement learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1oK8aoxe", "abstract": "", "cite_num": -1}, "50": {"title": "trusting svm for piecewise linear cnns.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=By5e2L9gl", "abstract": "", "cite_num": -1}, "7": {"title": "batch policy gradient methods for improving neural conversation models.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJfMusFll", "abstract": "", "cite_num": -1}, "27": {"title": "beta-vae: learning basic visual concepts with a constrained variational framework.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Sy2fzU9gl", "abstract": "", "cite_num": -1}, "108": {"title": "an actor-critic algorithm for sequence prediction.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJDaqqveg", "abstract": "", "cite_num": -1}, "63": {"title": "fractalnet: ultra-deep neural networks without residuals.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1VaB4cex", "abstract": "", "cite_num": -1}, "176": {"title": "learning visual servoing with deep features and fitted q-iteration.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1YNw6sxg", "abstract": "", "cite_num": -1}, "143": {"title": "efficient representation of low-dimensional manifolds using deep networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJ3filKll", "abstract": "", "cite_num": -1}, "32": {"title": "deepcoder: learning to write programs.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ByldLrqlx", "abstract": "", "cite_num": -1}, "184": {"title": "unsupervised cross-domain image generation.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Sk2Im59ex", "abstract": "", "cite_num": -1}, "195": {"title": "sample efficient actor-critic with experience replay.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HyM25Mqel", "abstract": "", "cite_num": -1}, "21": {"title": "outrageously large neural networks: the sparsely-gated mixture-of-experts layer.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1ckMDqlg", "abstract": "", "cite_num": -1}, "76": {"title": "a structured self-attentive sentence embedding.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJC_jUqxe", "abstract": "", "cite_num": -1}, "28": {"title": "latent sequence decompositions.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SyQq185lg", "abstract": "", "cite_num": -1}, "51": {"title": "reinforcement learning through asynchronous advantage actor-critic on a gpu.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1VGvBcxl", "abstract": "", "cite_num": -1}, "42": {"title": "the concrete distribution: a continuous relaxation of discrete random variables.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1jE5L5gl", "abstract": "", "cite_num": -1}, "105": {"title": "topology and geometry of half-rectified network optimization.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Bk0FWVcgx", "abstract": "", "cite_num": -1}, "134": {"title": "entropy-sgd: biasing gradient descent into wide valleys.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1YfAfcgl", "abstract": "", "cite_num": -1}, "34": {"title": "why deep neural networks for function approximation?", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SkpSlKIel", "abstract": "", "cite_num": -1}, "13": {"title": "tying word vectors and word classifiers: a loss framework for language modeling.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1aPbsFle", "abstract": "", "cite_num": -1}, "12": {"title": "recurrent mixture density network for spatiotemporal visual attention.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJRpRfKxx", "abstract": "In many computer vision tasks, the relevant information to solve the problem at hand is mixed to irr\nelevant, distracting information. This has motivated researchers to design attentional models that c\nan dynamically focus on parts of images or videos that are salient, e.g., by down-weighting irreleva\nnt pixels. In this work, we propose a spatiotemporal attentional model that learns where to look in \na video directly from human fixation data. We model visual attention with a mixture of Gaussians at \neach frame. This distribution is used to express the probability of saliency for each pixel. Time co\nnsistency in videos is modeled hierarchically by: 1) deep 3D convolutional features to represent spa\ntial and short-term time relations and 2) a long short-term memory network on top that aggregates th\ne clip-level representation of sequential clips and therefore expands the temporal domain from few f\nrames to seconds. The parameters of the proposed model are optimized via maximum likelihood estimati\non using human fixations as training data, without knowledge of the action in each video. Our experi\nments on Hollywood2 show state-of-the-art performance on saliency prediction for video. We also show\n that our attentional model trained on Hollywood2 generalizes well to UCF101 and it can be leveraged\n to improve action classification accuracy on both datasets.", "cite_num": 25}, "5": {"title": "topicrnn: a recurrent neural network with long-range semantic dependency.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJbbOLcex", "abstract": "", "cite_num": -1}, "171": {"title": "a compositional object-based approach to learning physical dynamics.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Bkab5dqxe", "abstract": "", "cite_num": -1}, "140": {"title": "words or characters? fine-grained gating for reading comprehension.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1hdzd5lg", "abstract": "", "cite_num": -1}, "25": {"title": "deep biaffine attention for neural dependency parsing.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Hk95PK9le", "abstract": "This paper builds off recent work from Kiperwasser & Goldberg (2016) using neural attention in a sim\nple graph-based dependency parser. We use a larger but more thoroughly regularized parser than other\n recent BiLSTM-based approaches, with#N#biaffine classifiers to predict arcs and labels. Our parser \ngets state of the art or near state of the art performance on standard treebanks for six different l\nanguages, achieving 95.7% UAS and 94.1% LAS on the most popular English PTB dataset. This makes it t\nhe highest-performing graph-based parser on this benchmark\u2014outperforming Kiperwasser & Goldberg (201\n6) by 1.8% and 2.2%\u2014and comparable to the highest performing transition-based parser (Kuncoro et al.\n, 2016), which achieves 95.8% UAS and 94.6% LAS. We also show which hyperparameter choices had a sig\nnificant effect on parsing accuracy, allowing us to achieve large gains over other graph-based appro\naches.", "cite_num": 40}, "185": {"title": "learning features of music from scratch.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rkFBJv9gg", "abstract": "", "cite_num": -1}, "182": {"title": "unrolled generative adversarial networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BydrOIcle", "abstract": "", "cite_num": -1}, "144": {"title": "learning to optimize.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ry4Vrt5gl", "abstract": "", "cite_num": -1}, "172": {"title": "delving into transferable adversarial examples and black-box attacks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Sys6GJqxl", "abstract": "An intriguing property of deep neural networks is the existence of adversarial examples, which can t\nransfer among different architectures. These transferable adversarial examples may severely hinder d\neep neural network-based applications. Previous works mostly study the transferability using small s\ncale datasets. In this work, we are the first to conduct an extensive study of the transferability o\nver large models and a large scale dataset, and we are also the first to study the transferability o\nf targeted adversarial examples with their target labels. We study both non-targeted and targeted ad\nversarial examples, and show that while transferable non-targeted adversarial examples are easy to f\nind, targeted adversarial examples generated using existing approaches almost never transfer with th\neir target labels. Therefore, we propose novel ensemble-based approaches to generating transferable \nadversarial examples. Using such approaches, we observe a large proportion of targeted adversarial e\nxamples that are able to transfer with their target labels for the first time. We also present some \ngeometric studies to help understanding the transferable adversarial examples. Finally, we show that\n the adversarial examples generated using ensemble-based approaches can successfully attack Clarifai\n.com, which is a black-box image classification system.", "cite_num": 78}, "10": {"title": "improving generative adversarial networks with denoising feature matching.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1X7nhsxl", "abstract": "", "cite_num": -1}, "111": {"title": "learning through dialogue interactions by asking questions.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rkE8pVcle", "abstract": "", "cite_num": -1}, "125": {"title": "regularizing cnns with locally constrained decorrelations.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ByOvsIqeg", "abstract": "", "cite_num": -1}, "6": {"title": "emergence of foveal image sampling from learning to attend in visual scenes.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJJKxrsgl", "abstract": "", "cite_num": -1}, "17": {"title": "optimal binary autoencoding with pairwise correlations.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ryelgY5eg", "abstract": "", "cite_num": -1}, "61": {"title": "query-reduction networks for question answering.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1MRcPclx", "abstract": "", "cite_num": -1}, "22": {"title": "adversarially learned inference.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1ElR4cgg", "abstract": "", "cite_num": -1}, "149": {"title": "categorical reparameterization with gumbel-softmax.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rkE3y85ee", "abstract": "", "cite_num": -1}, "174": {"title": "what does it take to generate natural textures?", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJhZeLsxx", "abstract": "", "cite_num": -1}, "82": {"title": "towards a neural statistician.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJDBUF5le", "abstract": "", "cite_num": -1}, "92": {"title": "diet networks: thin parameters for fat genomics.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Sk-oDY9ge", "abstract": "", "cite_num": -1}, "77": {"title": "density estimation using real nvp.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HkpbnH9lx", "abstract": "", "cite_num": -1}, "142": {"title": "adversarial machine learning at scale.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJm4T4Kgx", "abstract": "", "cite_num": -1}, "164": {"title": "optimization as a model for few-shot learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJY0-Kcll", "abstract": "", "cite_num": -1}, "153": {"title": "pruning convolutional neural networks for resource efficient inference.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJGCiw5gl", "abstract": "", "cite_num": -1}, "167": {"title": "deep multi-task representation learning: a tensor factorisation approach.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SkhU2fcll", "abstract": "", "cite_num": -1}, "44": {"title": "pointer sentinel mixture models.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Byj72udxe", "abstract": "", "cite_num": -1}, "173": {"title": "an information-theoretic framework for fast and robust unsupervised learning via neural population infomax.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SkYbF1slg", "abstract": "", "cite_num": -1}, "15": {"title": "efficient vector representation for documents through corruption.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1Igu2ogg", "abstract": "", "cite_num": -1}, "72": {"title": "variable computation in recurrent neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1LVSrcge", "abstract": "", "cite_num": -1}, "163": {"title": "neuro-symbolic program synthesis.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJ0JwFcex", "abstract": "", "cite_num": -1}, "18": {"title": "on large-batch training for deep learning: generalization gap and sharp minima.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=H1oyRlYgg", "abstract": "", "cite_num": -1}, "101": {"title": "learning to perform physics experiments via deep reinforcement learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1nTpv9eg", "abstract": "", "cite_num": -1}, "119": {"title": "dsd: dense-sparse-dense training for deep neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HyoST_9xl", "abstract": "", "cite_num": -1}, "118": {"title": "generative models and model criticism via optimized maximum mean discrepancy.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HJWHIKqgl", "abstract": "", "cite_num": -1}, "178": {"title": "variational recurrent adversarial deep domain adaptation.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rk9eAFcxg", "abstract": "", "cite_num": -1}, "188": {"title": "hypernetworks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rkpACe1lx", "abstract": "", "cite_num": -1}, "98": {"title": "program synthesis for character level language modeling.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ry_sjFqgx", "abstract": "", "cite_num": -1}, "30": {"title": "epopt: learning robust neural network policies using model ensembles.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SyWvgP5el", "abstract": "", "cite_num": -1}, "90": {"title": "tree-structured decoding with doubly-recurrent neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HkYhZDqxg", "abstract": "", "cite_num": -1}, "137": {"title": "learning recurrent representations for hierarchical behavior modeling.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BkLhzHtlg", "abstract": "", "cite_num": -1}, "74": {"title": "semi-supervised classification with graph convolutional networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJU4ayYgl", "abstract": "", "cite_num": -1}, "24": {"title": "learning to superoptimize programs.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1rz6U5lg", "abstract": "", "cite_num": -1}, "151": {"title": "identity matters in deep learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ryxB0Rtxx", "abstract": "", "cite_num": -1}, "81": {"title": "machine comprehension using match-lstm and answer pointer.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1-q5Pqxl", "abstract": "", "cite_num": -1}, "53": {"title": "calibrating energy-based generative adversarial networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SyxeqhP9ll", "abstract": "", "cite_num": -1}, "89": {"title": "a learned representation for artistic style.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJO-BuT1g", "abstract": "", "cite_num": -1}, "16": {"title": "central moment discrepancy (cmd) for domain-invariant representation learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SkB-_mcel", "abstract": "", "cite_num": -1}, "115": {"title": "deepdsl: a compilation-based domain-specific language for deep learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Bks8cPcxe", "abstract": "", "cite_num": -1}, "126": {"title": "snapshot ensembles: train 1, get m for free.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJYwwY9ll", "abstract": "", "cite_num": -1}, "139": {"title": "generative multi-adversarial networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Byk-VI9eg", "abstract": "", "cite_num": -1}, "187": {"title": "deep probabilistic programming.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Hy6b4Pqee", "abstract": "", "cite_num": -1}, "80": {"title": "reasoning with memory augmented neural networks for language comprehension.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Hk8TGSKlg", "abstract": "", "cite_num": -1}, "43": {"title": "variational lossy autoencoder.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BysvGP5ee", "abstract": "", "cite_num": -1}, "66": {"title": "deep information propagation.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=H1W1UN9gg", "abstract": "", "cite_num": -1}, "69": {"title": "frustratingly short attention spans in neural language modeling.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ByIAPUcee", "abstract": "Neural language models predict the next token using a latent representation of the immediate token h\nistory. Recently, various methods for augmenting neural language models with an attention mechanism \nover a differentiable memory have been proposed. For predicting the next token, these models query i\nnformation from a memory of the recent history which can facilitate learning mid- and long-range dep\nendencies. However, conventional attention mechanisms used in memory-augmented neural language model\ns produce a single output vector per time step. This vector is used both for predicting the next tok\nen as well as for the key and value of a differentiable memory of a token history. In this paper, we\n propose a neural language model with a key-value attention mechanism that outputs separate represen\ntations for the key and value of a differentiable memory, as well as for encoding the next-word dist\nribution. This model outperforms existing memory-augmented neural language models on two corpora. Ye\nt, we found that our method mainly utilizes a memory of the five most recent output representations.\n This led to the unexpected main finding that a much simpler model based only on the concatenation o\nf recent output representations from previous time steps is on par with more sophisticated memory-au\ngmented neural language models.", "cite_num": 29}, "46": {"title": "learning a natural language interface with neural programmer.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ry2YOrcge", "abstract": "", "cite_num": -1}, "75": {"title": "designing neural network architectures using reinforcement learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1c2cvqee", "abstract": "", "cite_num": -1}, "189": {"title": "improving neural language models with a continuous cache.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B184E5qee", "abstract": "", "cite_num": -1}, "157": {"title": "predicting medications from diagnostic codes with recurrent neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJEgeXFex", "abstract": "", "cite_num": -1}, "0": {"title": "stick-breaking variational autoencoders.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1jmAotxg", "abstract": "", "cite_num": -1}, "135": {"title": "deep variational bayes filters: unsupervised learning of state space models from raw data.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HyTqHL5xg", "abstract": "", "cite_num": -1}, "95": {"title": "nonparametric neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJK3Xasel", "abstract": "", "cite_num": -1}, "62": {"title": "maximum entropy flow networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=H1acq85gx", "abstract": "", "cite_num": -1}, "128": {"title": "towards deep interpretability (mus-rover ii): learning hierarchical representations of tonal music.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ryhqQFKgl", "abstract": "", "cite_num": -1}, "120": {"title": "attend, adapt and transfer: attentive deep architecture for adaptive transfer from multiple sources in the same domain.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Sy6iJDqlx", "abstract": "", "cite_num": -1}, "162": {"title": "dynamic coattention networks for question answering.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJeKjwvclx", "abstract": "Several deep learning models have been proposed for question answering. However, due to their single\n-pass nature, they have no way to recover from local maxima corresponding to incorrect answers. To a\nddress this problem, we introduce the Dynamic Coattention Network (DCN) for question answering. The \nDCN first fuses co-dependent representations of the question and the document in order to focus on r\nelevant parts of both. Then a dynamic pointing decoder iterates over potential answer spans. This it\nerative procedure enables the model to recover from initial local maxima corresponding to incorrect \nanswers. On the Stanford question answering dataset, a single DCN model improves the previous state \nof the art from 71.0% F1 to 75.9%, while a DCN ensemble obtains 80.4% F1.", "cite_num": 241}, "33": {"title": "on the quantitative analysis of decoder-based generative models.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1M8JF9xx", "abstract": "", "cite_num": -1}, "180": {"title": "autoencoding variational inference for topic models.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BybtVK9lg", "abstract": "", "cite_num": -1}, "70": {"title": "understanding deep learning requires rethinking generalization.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Sy8gdB9xx", "abstract": "", "cite_num": -1}, "196": {"title": "learning invariant representations of planar curves.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BymIbLKgl", "abstract": "", "cite_num": -1}, "86": {"title": "transfer of view-manifold learning to similarity perception of novel objects.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1gtu5ilg", "abstract": "", "cite_num": -1}, "11": {"title": "combining policy gradient and q-learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B1kJ6H9ex", "abstract": "", "cite_num": -1}, "156": {"title": "sparsely-connected neural networks: towards efficient vlsi implementation of deep neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1fYuytex", "abstract": "", "cite_num": -1}, "117": {"title": "online bayesian transfer learning for sequential data modeling.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ByqiJIqxg", "abstract": "", "cite_num": -1}, "186": {"title": "faster cnns with direct sparse convolutions and guided pruning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJPcZ3txx", "abstract": "", "cite_num": -1}, "26": {"title": "pixelcnn++: improving the pixelcnn with discretized logistic mixture likelihood and other modifications.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJrFC6ceg", "abstract": "", "cite_num": -1}, "37": {"title": "neural photo editing with introspective adversarial networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HkNKFiGex", "abstract": "", "cite_num": -1}, "55": {"title": "adversarial feature learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJtNZAFgg", "abstract": "", "cite_num": -1}, "40": {"title": "samplernn: an unconditional end-to-end neural audio generation model.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SkxKPDv5xl", "abstract": "", "cite_num": -1}, "131": {"title": "learning to generate samples from noise through infusion training.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJAFbaolg", "abstract": "", "cite_num": -1}, "154": {"title": "transfer learning for sequence tagging with hierarchical recurrent networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ByxpMd9lx", "abstract": "", "cite_num": -1}, "1": {"title": "mollifying networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=r1G4z8cge", "abstract": "", "cite_num": -1}, "3": {"title": "lie-access neural turing machines.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Byiy-Pqlx", "abstract": "", "cite_num": -1}, "132": {"title": "structured attention networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HkE0Nvqlg", "abstract": "Attention networks have proven to be an effective approach for embedding categorical inference withi\nn a deep neural network. However, for many tasks we may want to model richer structural dependencies\n without abandoning end-to-end training. In this work, we experiment with incorporating richer struc\ntural distributions, encoded using graphical models, within deep networks. We show that these struct\nured attention networks are simple extensions of the basic attention procedure, and that they allow \nfor extending attention beyond the standard soft-selection approach, such as attending to partial se\ngmentations or to subtrees. We experiment with two different classes of structured attention network\ns: a linear-chain conditional random field and a graph-based parsing model, and describe how these m\nodels can be practically implemented as neural network layers. Experiments show that this approach i\ns effective for incorporating structural biases, and structured attention networks outperform baseli\nne attention models on a variety of synthetic and real tasks: tree transduction, neural machine tran\nslation, question answering, and natural language inference. We further find that models trained in \nthis way learn interesting unsupervised hidden representations that generalize simple attention.", "cite_num": 88}, "129": {"title": "learning to act by predicting the future.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJLS7qKel", "abstract": "", "cite_num": -1}, "41": {"title": "visualizing deep neural network decisions: prediction difference analysis.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BJ5UeU9xx", "abstract": "", "cite_num": -1}, "96": {"title": "amortised map inference for image super-resolution.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=S1RP6GLle", "abstract": "", "cite_num": -1}, "177": {"title": "reinforcement learning with unsupervised auxiliary tasks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=SJ6yPD5xg", "abstract": "", "cite_num": -1}, "133": {"title": "generalizing skills with semi-supervised reinforcement learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=ryHlUtqge", "abstract": "", "cite_num": -1}, "170": {"title": "training agent for first-person shooter game with actor-critic curriculum learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=Hk3mPK5gg", "abstract": "", "cite_num": -1}, "19": {"title": "training deep neural-networks using a noise adaptation layer.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=H12GRgcxg", "abstract": "", "cite_num": -1}, "161": {"title": "capacity and trainability in recurrent neural networks.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=BydARw9ex", "abstract": "", "cite_num": -1}, "141": {"title": "third person imitation learning.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=B16dGcqlx", "abstract": "", "cite_num": -1}, "49": {"title": "lossy image compression with compressive autoencoders.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rJiNwv9gg", "abstract": "", "cite_num": -1}, "97": {"title": "multilayer recurrent network models of primate retinal ganglion cell responses.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=HkEI22jeg", "abstract": "", "cite_num": -1}, "65": {"title": "decomposing motion and content for natural video sequence prediction.", "conf": "iclr", "time": "2017", "url": "https://openreview.net/forum?id=rkEFLFqee", "abstract": "", "cite_num": -1}}